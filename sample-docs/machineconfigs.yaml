apiVersion: v1
items:
- apiVersion: machineconfiguration.openshift.io/v1
  kind: MachineConfig
  metadata:
    annotations:
      machineconfiguration.openshift.io/generated-by-controller-version: fcf8f254943cbcba1400ba55f3978cc292b6460b
    creationTimestamp: "2025-11-04T16:09:16Z"
    generation: 1
    labels:
      machineconfiguration.openshift.io/role: master
    name: 00-master
    ownerReferences:
    - apiVersion: machineconfiguration.openshift.io/v1
      blockOwnerDeletion: true
      controller: true
      kind: ControllerConfig
      name: machine-config-controller
      uid: 18dbcd72-fa02-401e-8486-bd239a092409
    resourceVersion: "10956"
    uid: f4d96332-7c43-4e73-a78a-3067dc608296
  spec:
    baseOSExtensionsContainerImage: ""
    config:
      ignition:
        version: 3.4.0
      storage:
        files:
        - contents:
            source: data:,%23%20This%20file%20signals%20NetworkManager-clean-initrd-state%20service%20to%20run%20on%0A%23%20boot.%20This%20service%20is%20used%20to%20clean%20up%20the%20network%20activation%20state%0A%23%20generated%20by%20dracut%20so%20that%20other%20network%20configuration%20deployed%20by%20the%0A%23%20user%20can%20be%20activated.%20This%20only%20happens%20if%20dracut%20activated%20a%20default%0A%23%20network%20configuration%20and%20there%20is%20an%20alternate%20configuration%20available%20in%0A%23%20the%20root%20filesystem.%20Otherwise%2C%20it%20is%20assumed%20that%20the%20network%0A%23%20configuration%20activated%20by%20dracut%20is%20the%20one%20that%20is%20intended%20to%20be%20used%0A%23%20throughout%20the%20life%20of%20the%20system.%0A%23%20Opt-out%20for%20baremetal%20IPI%20deplyments%2C%20opt-in%20otherwise.%0A
          mode: 493
          overwrite: true
          path: /var/lib/mco/nm-clean-initrd-state
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-ex%20-o%20pipefail%0A%0ANM_DEVICES_DIR%3D%2Frun%2FNetworkManager%2Fdevices%0ANM_RUN_CONN_DIR%3D%2Frun%2FNetworkManager%2Fsystem-connections%0ANM_ETC_CONN_DIR%3D%2Fetc%2FNetworkManager%2Fsystem-connections%0A%0Alogger%20-t%20nm-clean-initrd-state%20%22Cleaning%20network%20activation%20state%20generated%20by%20dracut...%22%0Alogger%20-t%20nm-clean-initrd-state%20%22To%20disable%2C%20remove%20%2Fvar%2Flib%2Fmco%2Fnm-clean-initrd-state%22%0A%0Aif%20%5B%20!%20-e%20%22%24NM_DEVICES_DIR%22%20%5D%20%7C%7C%20%5B%20!%20-e%20%22%24NM_RUN_CONN_DIR%22%20%5D%20%7C%7C%20%5B%20!%20-e%20%22%24NM_ETC_CONN_DIR%22%20%5D%3B%20then%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22There%20is%20no%20network%20activation%20state%20to%20clean%22%0A%20%20exit%0Afi%0A%0A%23%20Some%20deployments%20require%20an%20active%20network%20early%20in%20the%20boot%20process.%20To%0A%23%20achieve%20this%2C%20dracut%20runs%20specific%20NetworkManager%20modules.%20This%20results%20in%0A%23%20NetworkManager%20keyfiles%20being%20generated%20(either%20default%20or%20from%20ip%20kernel%0A%23%20arguments)%20and%20activated.%20This%20activation%20generates%20state%20that%20makes%20those%0A%23%20profiles%20to%20be%20re-activated%20by%20the%20NetworkManager%20service%20later%20in%20the%0A%23%20boot%20process.%20And%20this%20has%20the%20effect%20that%20other%20profiles%20deployed%20by%20the%0A%23%20user%20for%20the%20same%20set%20of%20devices%20are%20ignored.%0A%0A%23%20Most%20of%20the%20time%20this%20is%20the%20desired%20behavior.%20The%20exception%20to%20this%20rule%0A%23%20is%20when%20the%20user%20wants%20to%20run%20the%20boot%20process%20with%20a%20different%20network%0A%23%20setup%20than%20the%20real%20root%20which%20is%20usually%20related%20to%20the%20fact%20that%0A%23%20generating%20images%20with%20customized%20kernel%20arguments%20is%20a%20complication%20in%0A%23%20the%20deployment%20pipeline.%0A%0A%23%20This%20need%20has%20been%20exacerbated%20by%20past%20NetworkManager%20bugs%20that%20activated%0A%23%20the%20network%20on%20boot%20when%20it%20was%20not%20really%20needed.%20Most%20notably%20when%20ip%0A%23%20kernel%20argument%20is%20present%2C%20something%20that%20the%20baremetal%20installer%20adds%20by%0A%23%20default.%0A%0A%23%20The%20intention%20here%20is%20to%20remove%20the%20state%20that%20was%20generated%20with%20the%0A%23%20activation%20of%20those%20profiles%20during%20dracut%20execution.%20Then%20when%0A%23%20NetworkManager%20service%20runs%2C%20the%20profiles%20generated%20by%20dracut%2C%20along%20with%0A%23%20other%20profiles%20configured%20by%20the%20user%2C%20are%20evaluated%20towards%20finding%20the%0A%23%20most%20appropriate%20profile%20to%20connect%20a%20device%20with.%20As%20a%20precaution%2C%20clean%0A%23%20state%20only%20for%20devices%20that%3A%0A%23%20-%20have%20been%20activated%20with%20a%20default%20profile%20(assume%20that%20a%20non-default%0A%23%20%20%20configuration%20expresses%20intention%20by%20user%20to%20run%20with%20it%20permanently)%0A%23%20-%20have%20a%20specific%20configured%20profile%20set%20to%20auto-connect%20(if%20there%20is%20no%0A%23%20%20%20alternate%20configured%20profile%20for%20a%20device%20it%20makes%20no%20sense%20to%0A%23%20%20%20de-activate%20anything)%0A%23%0A%23%20Although%20this%20can%20theoretically%20happen%20on%20any%20deployment%20type%2C%20need%20has%0A%23%20mostly%20come%20from%20IPI%20bare%20metal%20deployments.%20For%20the%20time%20being%2C%20this%0A%23%20should%20be%20opt-in%20in%20any%20other%20deploment%20type.%0A%23%0A%23%20There%20is%20an%20RFE%20filed%20against%20NM%20that%20once%20implemented%20would%20make%20this%0A%23%20script%20unnecessary%3A%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D2089707%0A%0Afor%20device%20in%20%22%24%7BNM_DEVICES_DIR%7D%22%2F*%3B%20do%0A%20%20if%20%5B%20!%20-e%20%22%24device%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20the%20device%20file%20name%20is%20the%20ifindex%0A%20%20ifindex%3D%24(basename%20%22%24device%22)%0A%20%20%0A%20%20%23%20get%20the%20interface%20name%20by%20ifindex%0A%20%20ifname%3D%24(ip%20-j%20link%20show%20%7C%20jq%20-r%20%22.%5B%5D%20%7C%20select(.ifindex%20%3D%3D%20%24%7Bifindex%7D)%20%7C%20.ifname%20%2F%2F%20empty%22)%0A%0A%20%20%23%20no%20interface%20name%20found%2C%20ignore%0A%20%20if%20%5B%20-z%20%22%24ifname%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20get%20the%20uuid%20of%20the%20profile%20the%20device%20has%20been%20activated%20with%0A%20%20active_profile_uuid%3D%24(sed%20-nr%20'%2F%5E%5C%5Bdevice%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Econnection-uuid%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24device%22)%0A%0A%20%20%23%20the%20device%20was%20not%20activated%20with%20any%20profile%2C%20ignore%0A%20%20if%20%5B%20-z%20%22%24active_profile_uuid%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20find%20the%20generated%20profile%20by%20uuid%0A%20%20for%20profile%20in%20%22%24%7BNM_RUN_CONN_DIR%7D%22%2F*%3B%20do%0A%20%20%20%20generated_profile_uuid%3D%24(sed%20-nr%20'%2F%5E%5C%5Bconnection%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Euuid%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20%20%20if%20%5B%20%22%24active_profile_uuid%22%20%3D%20%22%24generated_profile_uuid%22%20%5D%3B%20then%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20done%0A%0A%20%20%23%20generated%20profile%20not%20found%2C%20ignore%0A%20%20if%20%5B%20%22%24active_profile_uuid%22%20!%3D%20%22%24generated_profile_uuid%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20check%20that%20it%20is%20not%20specific%20for%20the%20device%2C%20otherwise%20ignore%0A%20%20profile_ifname%3D%24(sed%20-nr%20'%2F%5E%5C%5Bconnection%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Einterface-name%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20if%20%5B%20-n%20%22%24profile_ifname%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20profile%20not%20generated%20by%20nm-initrd-generator%2C%20ignore%0A%20%20%23%20only%20check%20it%20if%20the%20key%20is%20set%20(from%20NM%201.32.4)%0A%20%20origin%3D%24(sed%20-nr%20'%2F%5E%5C%5Buser%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Eorg.freedesktop.NetworkManager.origin%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20if%20%5B%20-n%20%22%24origin%22%20%5D%20%26%26%20%5B%20%22%24origin%22%20!%3D%20%22nm-initrd-generator%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20find%20the%20configured%20profile%20by%20name%20with%20auto-connect%20set%0A%20%20for%20profile%20in%20%22%24%7BNM_ETC_CONN_DIR%7D%22%2F*%3B%20do%0A%20%20%20%20profile_ifname%3D%24(sed%20-nr%20'%2F%5E%5C%5Bconnection%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Einterface-name%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20%20%20autoconnect%3D%24(sed%20-nr%20'%2F%5E%5C%5Bconnection%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Eautoconnect%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20%20%20if%20%5B%20%22%24profile_ifname%22%20%3D%20%22%24ifname%22%20%5D%20%26%26%20%5B%20%22%24autoconnect%22%20!%3D%20%22false%22%20%5D%3B%20then%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20done%0A%0A%20%20%23%20configured%20profile%20not%20found%2C%20ignore%0A%20%20if%20%5B%20%22%24profile_ifname%22%20!%3D%20%22%24ifname%22%20%5D%20%7C%7C%20%5B%20%22%24autoconnect%22%20%3D%20%22false%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20configured_profile_uuid%3D%24(sed%20-nr%20'%2F%5E%5C%5Bconnection%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Euuid%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22%24ifname%20activated%20with%20default%20generated%20profile%20%24generated_profile_uuid%22%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22%24ifname%20has%20different%20configured%20specific%20profile%20%24configured_profile_uuid%22%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22%24ifname%3A%20removing%20state...%22%0A%20%20%0A%20%20%23%20NM%20can%20still%20generate%20internal%20profiles%20from%20the%20IP%20address%0A%20%20%23%20configuration%20of%20devices%2C%20so%20flush%20addresses%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22Flushing%20IP%20addresses%20from%20%24ifname%22%0A%20%20ip%20addr%20flush%20%22%24ifname%22%0A%20%20ip%20-6%20addr%20flush%20%22%24ifname%22%0A%0A%20%20%23%20remove%20device%20state%20file%20to%20prevent%20NM%20to%20unilaterally%20connect%20with%20the%0A%20%20%23%20latest%20activated%20profile%20without%20evaluating%20other%20profiles%20%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22Removing%20%24device%22%0A%20%20rm%20-f%20--%20%22%24device%22%0A%0Adone%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/nm-clean-initrd-state.sh
        - contents:
            source: data:,%5Bconnection%5D%0Aipv6.dhcp-duid%3Dll%0Aipv6.dhcp-iaid%3Dmac%0A
          mode: 420
          overwrite: true
          path: /etc/NetworkManager/conf.d/01-ipv6.conf
        - contents:
            source: data:,%5Bmain%5D%0Aplugins%3Dkeyfile%2Cifcfg-rh%0A%5Bkeyfile%5D%0Apath%3D%2Fetc%2FNetworkManager%2Fsystem-connections%0A
          mode: 420
          overwrite: true
          path: /etc/NetworkManager/conf.d/20-keyfiles.conf
        - contents:
            source: data:,%5Bmain%5D%0Arc-manager%3Dunmanaged%0A
          mode: 420
          overwrite: true
          path: /etc/NetworkManager/conf.d/99-kni.conf
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-eo%20pipefail%0AIFACE%3D%241%0ASTATUS%3D%242%0A%0Afunction%20resolv_prepender%20%7B%0A%20%20mkdir%20-p%20%2Frun%2Fresolv-prepender%0A%20%20echo%20%22IP4_DOMAINS%3D%24IP4_DOMAINS%22%20%3E%20%2Frun%2Fresolv-prepender%2Fenv.new%0A%20%20echo%20%22IP6_DOMAINS%3D%24IP6_DOMAINS%22%20%3E%3E%20%2Frun%2Fresolv-prepender%2Fenv.new%0A%0A%20%20if%20!%20diff%20-q%20%2Frun%2Fresolv-prepender%2Fenv%20%2Frun%2Fresolv-prepender%2Fenv.new%3B%20then%0A%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Environment%20variable(s)%20changed.%20Systemd%20path%20unit%20will%20pick%20the%20change.%22%0A%20%20%20%20mv%20-f%20%2Frun%2Fresolv-prepender%2Fenv.new%20%2Frun%2Fresolv-prepender%2Fenv%0A%20%20fi%0A%7D%0A%0Aexport%20IP4_DOMAINS%20IP6_DOMAINS%0Aexport%20-f%20resolv_prepender%0A%0A%23%20For%20RHEL8%20with%20NetworkManager%20%3E%3D%201.36%20and%20RHEL9%20with%20NetworkManager%20%3E%3D1.42%20we%20can%20use%20simplified%20logic%0A%23%20of%20observing%20only%20a%20single%20%22dns-change%22%20event.%20Older%20version%20of%20NetworkManager%20require%20however%20that%20we%0A%23%20react%20on%20a%20set%20of%20multiple%20events.%20Once%20dns-change%20event%20is%20detected%20we%20create%20a%20flag%20file%20to%20ignore%0A%23%20subsequent%20up%26co.%20events%20as%20undesired.%0A%23%0A%23%20Given%20an%20overall%20Network%20Manager%20dispatcher%20timeout%20of%2090%20seconds%2C%20we%20are%20enforcing%20a%20slightly%20shorter%0A%23%20timeout%20for%20the%20observed%20events.%20It%20is%20not%20really%20required%20because%20all%20we%20do%20in%20this%20function%20is%20to%20write%20a%20file.%0A%23%20We%20could%20get%20rid%20of%20this%20timeout%20completely%2C%20but%20it%20also%20does%20not%20cost%20much%20to%20keep%20it.%0Acase%20%22%24STATUS%22%20in%0A%20%20dns-change)%0A%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%20triggered%20by%20%24%7BIFACE%7D%20%24%7BSTATUS%7D.%22%0A%20%20%20%20if%20%5B%20!%20-f%20%22%2Frun%2Fnetworkmanager-dns-event-detected%22%20%5D%3B%20then%0A%20%20%20%20%20%20touch%20%2Frun%2Fnetworkmanager-dns-event-detected%0A%20%20%20%20fi%0A%20%20%20%20if%20!%20timeout%2060s%20bash%20-c%20resolv_prepender%3B%20then%0A%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Timeout%20occurred%22%0A%20%20%20%20%20%20exit%201%0A%20%20%20%20fi%0A%20%20%3B%3B%0A%0A%20%20up%7Cdhcp4-change%7Cdhcp6-change%7Creapply)%0A%20%20%20%20if%20%5B%20!%20-f%20%22%2Frun%2Fnetworkmanager-dns-event-detected%22%20%5D%3B%20then%0A%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%20triggered%20by%20%24%7BIFACE%7D%20%24%7BSTATUS%7D.%22%0A%20%20%20%20%20%20if%20!%20timeout%2030s%20bash%20-c%20resolv_prepender%3B%20then%0A%20%20%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Timeout%20occurred%22%0A%20%20%20%20%20%20%20%20exit%201%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20If%20%24DHCP6_FQDN_FQDN%20is%20not%20empty%20and%20is%20not%20localhost.localdomain%20and%20static%20hostname%20was%20not%20already%20set%0A%20%20%20%20if%20%5B%5B%20-n%20%22%24DHCP6_FQDN_FQDN%22%20%26%26%20%22%24DHCP6_FQDN_FQDN%22%20!%3D%20%22localhost.localdomain%22%20%26%26%20%22%24DHCP6_FQDN_FQDN%22%20%3D~%20%22.%22%20%5D%5D%20%3B%20then%0A%20%20%20%20%20%20%20STATIC_HOSTNAME%3D%22%24(test%20!%20-e%20%2Fetc%2Fhostname%20%26%26%20echo%20-n%20%7C%7C%20cat%20%2Fetc%2Fhostname%20%7C%20xargs)%22%0A%0A%20%20%20%20%20%20%20if%20%5B%5B%20-z%20%22%24STATIC_HOSTNAME%22%20%7C%7C%20%22%24STATIC_HOSTNAME%22%20%3D%3D%20%22localhost.localdomain%22%20%5D%5D%20%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%23%20run%20with%20systemd-run%20to%20avoid%20selinux%20problems%0A%20%20%20%20%20%20%20%20%20%20systemd-run%20--property%3DType%3Doneshot%20--unit%20resolve-prepender-hostnamectl%20-Pq%20%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20hostnamectl%20set-hostname%20--static%20--transient%20%24DHCP6_FQDN_FQDN%0A%20%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20if%20%5B%5B%20%22%24STATUS%22%20%3D%3D%20%22up%22%20%5D%5D%20%26%26%20%5B%5B%20%24IFACE%20%3D%3D%20%22br-ex%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20%2Fbin%2Fmkdir%20-p%20%2Frun%2Fnodeip-configuration%0A%20%20%20%20%20%20%20%20touch%20%2Frun%2Fnodeip-configuration%2Fbr-ex-up%0A%20%20%20%20fi%0A%20%20%3B%3B%0A%20%20*)%0A%20%20%3B%3B%0Aesac%0A
          mode: 493
          overwrite: true
          path: /etc/NetworkManager/dispatcher.d/30-resolv-prepender
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-ex%20-o%20pipefail%0A%0Aif%20%5B%5B%20%22OVNKubernetes%22%20%3D%3D%20%22OVNKubernetes%22%20%26%26%20%22%24CONNECTION_ID%22%20%3D%3D%20%22Wired%20Connection%22%20%5D%5D%0Athen%0A%20%20%20%20%3E%262%20echo%20%22Refusing%20to%20modify%20default%20connection.%22%0A%20%20%20%20exit%200%0Afi%0A%0Aif%20%5B%20-z%20%24%7BDHCP4_IP_ADDRESS%3A-%7D%20%5D%0Athen%0A%20%20%20%20%3E%262%20echo%20%22Not%20a%20DHCP4%20address.%20Ignoring.%22%0A%20%20%20%20exit%200%0Afi%0A%0Aif%20%5B%20%24%7BDHCP4_DHCP_LEASE_TIME%3A-0%7D%20-lt%204294967295%20%5D%0Athen%0A%20%20%20%20%3E%262%20echo%20%22Not%20an%20infinite%20DHCP4%20lease.%20Ignoring.%22%0A%20%20%20%20exit%200%0Afi%0A%0AIPS%3D(%24IP4_ADDRESS_0)%0ACIDR%3D%24%7BIPS%5B0%5D%7D%0AGATEWAY%3D%24%7BIPS%5B1%5D%7D%0A%0ATYPE%3D%24(nmcli%20--get-values%20connection.type%20connection%20show%20%22%24CONNECTION_ID%22)%0A%0A%23%20Modifying%20the%20default%20connection%20id%20directly%20doesn't%20do%20what%20we%20want.%0A%23%20If%20we%20see%20that%2C%20then%20we%20need%20to%20create%20a%20new%20connection.%0Aif%20%5B%20%22%24CONNECTION_ID%22%20%3D%3D%20%22Wired%20Connection%22%20%5D%0Athen%0A%20%20%20%20if%20!%20nmcli%20con%20show%20inf-lease-to-static%0A%20%20%20%20then%0A%20%20%20%20%20%20%20%20nmcli%20con%20add%20type%20%22%24TYPE%22%20con-name%20inf-lease-to-static%0A%20%20%20%20fi%0A%20%20%20%20STATIC_INT_NAME%3Dinf-lease-to-static%0Aelse%0A%20%20%20%20STATIC_INT_NAME%3D%22%24CONNECTION_ID%22%0Afi%0Anmcli%20con%20mod%20%22%24STATIC_INT_NAME%22%20%5C%0A%20%20conn.interface%20%22%241%22%20%5C%0A%20%20connection.autoconnect%20yes%20%5C%0A%20%20ipv4.addresses%20%22%24CIDR%22%20%5C%0A%20%20ipv4.method%20manual%20%5C%0A%20%20ipv4.gateway%20%22%24GATEWAY%22%20%5C%0A%20%20ipv4.dns%20%22%24IP4_NAMESERVERS%22%0A%0Aif%20%5B%20-n%20%22%24IP4_DOMAINS%22%20%5D%3B%20then%0A%20%20%20%20nmcli%20con%20mod%20%22%24STATIC_INT_NAME%22%20ipv4.dns-search%20%22%24IP4_DOMAINS%22%0Afi%0Aplus%3D''%0Afor%20i%20in%20%24(seq%200%20%24((%24IP4_NUM_ROUTES-1))%20)%0Ado%0A%20%20%20%20varname%3D%22IP4_ROUTE_%24i%22%0A%20%20%20%20nmcli%20con%20mod%20%22%24STATIC_INT_NAME%22%20%24%7Bplus%7Dipv4.routes%20%22%24%7B!varname%7D%22%0A%20%20%20%20plus%3D'%2B'%0Adone%0A%0Anmcli%20con%20up%20%22%24STATIC_INT_NAME%22%0A%0Aif%20%5B%20-n%20%22%24%7BDHCP4_HOST_NAME%3A-%7D%22%20%5D%0Athen%0A%20%20%20%20systemd-run%20--property%3DType%3Doneshot%20--unit%20static-dhcp-hostnamectl%20-Pq%20%5C%0A%20%20%20%20%20%20hostnamectl%20set-hostname%20--static%20--transient%20%22%24DHCP4_HOST_NAME%22%0Afi%0A
          mode: 493
          overwrite: true
          path: /etc/NetworkManager/dispatcher.d/30-static-dhcp
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-ex%20-o%20pipefail%0A%0Aif%20%5B%20-z%20%22%24DHCP6_IP6_ADDRESS%22%20%5D%0Athen%0A%20%20%20%20%3E%262%20echo%20%22Not%20a%20DHCP6%20address.%20Ignoring.%22%0A%20%20%20%20exit%200%0Afi%0A%0ALEASE_TIME%3D%24(ip%20-j%20-6%20a%20show%20%22%24DEVICE_IFACE%22%20%7C%20jq%20-r%20%22.%5B%5D.addr_info%5B%5D%20%7C%20select(.scope%3D%3D%5C%22global%5C%22)%20%7C%20select(.deprecated!%3Dtrue)%20%7C%20select(.local%3D%3D%5C%22%24DHCP6_IP6_ADDRESS%5C%22)%20%7C%20.preferred_life_time%22)%0APREFIX_LEN%3D%24(ip%20-j%20-6%20a%20show%20%22%24DEVICE_IFACE%22%20%7C%20jq%20-r%20%22.%5B%5D.addr_info%5B%5D%20%7C%20select(.scope%3D%3D%5C%22global%5C%22)%20%7C%20select(.deprecated!%3Dtrue)%20%7C%20select(.local%3D%3D%5C%22%24DHCP6_IP6_ADDRESS%5C%22)%20%7C%20.prefixlen%22)%0A%0Aif%20%5B%20%24%7BLEASE_TIME%3A-0%7D%20-lt%204294967295%20%5D%0Athen%0A%20%20%20%20%3E%262%20echo%20%22Not%20an%20infinite%20DHCP6%20lease.%20Ignoring.%22%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20We%20don't%20want%20this%20to%20run%20before%20OVNKubernetes%20creates%20its%20bridge.%20If%20we%0A%23%20see%20the%20default%20CONNECTION_ID%20we%20know%20to%20wait.%0Aif%20%5B%20%22%24CONNECTION_ID%22%20%3D%3D%20%22Wired%20Connection%22%20%5D%0Athen%0A%20%20%20%20%3E%262%20echo%20%22Refusing%20to%20modify%20default%20connection.%22%0A%20%20%20%20exit%200%0Afi%0A%0ACIDR%3D%22%24DHCP6_IP6_ADDRESS%2F%24PREFIX_LEN%22%0Anmcli%20con%20mod%20%22%24CONNECTION_ID%22%20ipv6.addresses%20%22%24CIDR%22%0Anmcli%20con%20mod%20%22%24CONNECTION_ID%22%20connection.autoconnect%20%22yes%22%0Anmcli%20con%20mod%20%22%24CONNECTION_ID%22%20ipv6.method%20%22manual%22%0Anmcli%20con%20mod%20%22%24CONNECTION_ID%22%20ipv6.gateway%20%22%24IP6_GATEWAY%22%0Anmcli%20con%20mod%20%22%24CONNECTION_ID%22%20ipv6.dns%20%22%24IP6_NAMESERVERS%22%0ASEARCH_DOMAIN%3D%22%24%7BDHCP6_FQDN_FQDN%23*.%7D%22%0Aif%20%5B%20-n%20%22%24SEARCH_DOMAIN%22%20%5D%3B%20then%0A%20%20%20%20nmcli%20con%20mod%20%22%24CONNECTION_ID%22%20ipv6.dns-search%20%22%24SEARCH_DOMAIN%22%0Afi%0Aplus%3D''%0Afor%20i%20in%20%24(seq%200%20%24((%24IP6_NUM_ROUTES-1))%20)%0Ado%0A%20%20%20%20varname%3D%22IP6_ROUTE_%24i%22%0A%20%20%20%20nmcli%20con%20mod%20%22%24CONNECTION_ID%22%20%24%7Bplus%7Dipv6.routes%20%22%24%7B!varname%7D%22%0A%20%20%20%20plus%3D'%2B'%0Adone%0A%0A%23%20Copy%20it%20from%20the%20OverlayFS%20mount%20to%20the%20persistent%20lowerdir%0Acp%20%22%24CONNECTION_FILENAME%22%20%2Fetc%2FNetworkManager%2Fsystem-connections%0A
          mode: 493
          overwrite: true
          path: /etc/NetworkManager/dispatcher.d/30-static-dhcpv6
        - contents:
            source: data:,
          mode: 384
          overwrite: true
          path: /etc/pki/ca-trust/source/anchors/openshift-config-user-ca-bundle.crt
        - contents:
            source: data:,KUBERNETES_SERVICE_HOST%3D'api-int.comp-poc-rh01.rhpoc.int'%0AKUBERNETES_SERVICE_PORT%3D'6443'%0A
          mode: 420
          overwrite: true
          path: /etc/kubernetes/apiserver-url.env
        - contents:
            source: data:,%23%20This%20file%20is%20managed%20by%20machine-config-operator.%0A%23%20Suppress%20audit%20rules%20which%20always%20trigger%20for%20container%0A%23%20workloads%2C%20as%20they%20spam%20the%20audit%20log.%20%20Workloads%20are%20expected%0A%23%20to%20be%20dynamic%2C%20and%20the%20networking%20stack%20uses%20iptables.%0A-a%20exclude%2Calways%20-F%20msgtype%3DNETFILTER_CFG%0A%23%20The%20default%20bridged%20networking%20enables%20promiscuous%20on%20the%20veth%0A%23%20device.%20%20Ideally%2C%20we'd%20teach%20audit%20to%20ignore%20only%20veth%20devices%2C%0A%23%20since%20one%20might%20legitimately%20care%20about%20promiscuous%20on%20real%20physical%0A%23%20devices.%20%20But%20we%20can't%20currently%20differentiate.%0A-a%20exclude%2Calways%20-F%20msgtype%3DANOM_PROMISCUOUS%0A
          mode: 420
          overwrite: true
          path: /etc/audit/rules.d/mco-audit-quiet-containers.rules
        - contents:
            source: data:,mode%3A%20unicast%0A
          mode: 420
          overwrite: true
          path: /etc/keepalived/monitor.conf
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%0A%23%20ESP%20offload%2C%20either%20in%20actual%20hardware%20or%20as%20part%20as%20GRO%20(generic%0A%23%20recieve%20offload)%20does%20not%20work%20for%20interfaces%20attached%20to%20an%20OVS%20bridge%0A%23%20so%20turn%20it%20off%20for%20the%20time%20being.%0A%23%20https%3A%2F%2Fissues.redhat.com%2Fbrowse%2FRHEL-58811%0A%0A%23%20Depends%20on%20ipsec%20service%20drop-in%20to%20start%20it%20after%20configure-ovs%20to%20make%0A%23%20sure%20offloads%20are%20disabled%20before%20ipsec%20starts.%0A%0Aif%20%5B%5B%20%22%242%22%20!%3D%20%22up%22%20%5D%5D%3B%20then%0A%20%20exit%0Afi%0A%0Adevice%3D%24DEVICE_IFACE%0Akind_slave%3D%24(ip%20-j%20-d%20link%20show%20%22%24device%22%20%7C%20jq%20-r%20'.%5B0%5D%20%7C%20.linkinfo.info_slave_kind%20%2F%2F%20empty')%0A%0Aif%20%5B%20%22%24kind_slave%22%20%3D%20%22openvswitch%22%20%5D%3B%20then%0A%20%20for%20feature%20in%20tx-esp-segmentation%20esp-hw-offload%20esp-tx-csum-hw-offload%3B%20do%0A%20%20%20%20if%20ethtool%20-k%20%22%24device%22%20%7C%20grep%20-qE%20%22%5E%24%7Bfeature%7D%3A%20off%22%3B%20then%0A%20%20%20%20%20%20%23%20already%20disabled%2C%20nothing%20to%20do%0A%20%20%20%20%20%20continue%0A%20%20%20%20fi%0A%20%20%20%20%0A%20%20%20%20logger%20-t%2099-esp-offload%20-s%20%22Setting%20%24feature%20off%20for%20%24device%3A%20unsupported%20when%20attached%20to%20Open%20vSwitch%20bridge%22%0A%20%20%20%20ethtool%20-K%20%22%24device%22%20%22%24feature%22%20off%0A%20%20done%0Afi%0A
          mode: 484
          overwrite: true
          path: /etc/NetworkManager/dispatcher.d/99-esp-offload
        - contents:
            source: data:,r%20%2Fetc%2Fkubernetes%2Fcni%2Fnet.d%2F80-openshift-network.conf%0Ar%20%2Fetc%2Fkubernetes%2Fcni%2Fnet.d%2F10-ovn-kubernetes.conf%0Ad%20%2Frun%2Fmultus%2Fcni%2Fnet.d%2F%200755%20root%20root%20-%20-%0AD%20%2Fvar%2Flib%2Fcni%2Fnetworks%2Fopenshift-sdn%2F%200755%20root%20root%20-%20-%0A
          mode: 420
          overwrite: true
          path: /etc/tmpfiles.d/cleanup-cni.conf
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-ex%0A%0A%23%20Used%20for%20on-prem%20deployments%20to%20enable%20ip%20forwarding%20as%20part%20of%20nodeip-configuration%20service.%0A%23%20IP%20forwarding%20is%20required%20on%20the%20node%20IP%20(k8s%20API)%20interface%20in%20order%20for%20keepalived%20to%20function.%0A%0Aecho%20%22Configuring%20IP%20Forwarding...%22%0Aovnk_config_dir%3D'%2Fetc%2Fovnk'%0Aip_hint_file%3D%22%2Frun%2Fnodeip-configuration%2Fprimary-ip%22%0A%0Aget_ip_from_ip_hint_file()%20%7B%0A%20%20local%20ip_hint_file%3D%22%241%22%0A%20%20if%20%5B%5B%20!%20-f%20%22%24%7Bip_hint_file%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22error%3A%20unable%20to%20enable%20IP%20forwarding.%20IP%20hint%20file%3A%20%24%7Bip_hint_file%7D%20does%20not%20exist!%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%20%20ip_hint%3D%24(cat%20%22%24%7Bip_hint_file%7D%22)%0A%20%20echo%20%22%24%7Bip_hint%7D%22%0A%7D%0A%0Aget_nodeip_hint_interface()%20%7B%0A%20%20local%20ip_hint%3D%22%22%0A%20%20local%20ip_hint_file%3D%22%241%22%0A%20%20local%20iface%3D%22%22%0A%0A%20%20ip_hint%3D%24(get_ip_from_ip_hint_file%20%22%24%7Bip_hint_file%7D%22)%0A%20%20if%20%5B%5B%20-z%20%22%24%7Bip_hint%7D%22%20%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22error%3A%20unable%20to%20enable%20IP%20forwarding.%20IP%20hint%20file%3A%20%24%7Bip_hint_file%7D%20is%20empty!%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%0A%20%20iface%3D%24(ip%20-j%20addr%20%7C%20jq%20-r%20%22first(.%5B%5D%20%7C%20select(any(.addr_info%5B%5D%3B%20.local%3D%3D%5C%22%24%7Bip_hint%7D%5C%22)))%20%7C%20.ifname%22)%0A%20%20if%20%5B%5B%20-z%20%22%24%7Biface%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22error%3A%20unable%20to%20enable%20IP%20forwarding.%20Cannot%20detect%20valid%20interface%20within%20file%3A%20%24%7Bip_hint_file%7D%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%20%20echo%20%22%24%7Biface%7D%22%0A%7D%0A%0Aiface%3D%24(get_nodeip_hint_interface%20%22%24%7Bip_hint_file%7D%22)%0A%0Aecho%20%22Node%20IP%20interface%20determined%20as%3A%20%24%7Biface%7D.%20Enabling%20IP%20forwarding...%22%0Afile_paths%3D(%22%2Fproc%2Fsys%2Fnet%2Fipv4%2Fconf%2F%24%7Biface%7D%2Fforwarding%22%20%22%2Fproc%2Fsys%2Fnet%2Fipv6%2Fconf%2F%24%7Biface%7D%2Fforwarding%22)%0Afor%20file_path%20in%20%22%24%7Bfile_paths%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20if%20%5B%20-f%20%22%24%7Bfile_path%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%221%22%20%3E%20%22%24%7Bfile_path%7D%22%0A%20%20%20%20fi%0Adone%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/configure-ip-forwarding.sh
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-x%0A%0Aif%20%5B%20-e%20%2Fetc%2Fnmstate%2Fopenshift%2Fapplied%20%5D%3B%20then%0A%20%20echo%20%22Skipping%20configure-ovs%20due%20to%20manual%20network%20configuration%22%0A%20%20exit%200%0Afi%0A%0A%23%20This%20file%20is%20not%20needed%20anymore%20in%204.7%2B%2C%20but%20when%20rolling%20back%20to%204.6%0A%23%20the%20ovs%20pod%20needs%20it%20to%20know%20ovs%20is%20running%20on%20the%20host.%0Atouch%20%2Fvar%2Frun%2Fovs-config-executed%0A%0A%23%20These%20are%20well%20knwon%20NM%20default%20paths%0ANM_CONN_ETC_PATH%3D%22%2Fetc%2FNetworkManager%2Fsystem-connections%22%0ANM_CONN_RUN_PATH%3D%22%2Frun%2FNetworkManager%2Fsystem-connections%22%0A%0A%23%20This%20is%20the%20path%20where%20NM%20is%20known%20to%20be%20configured%20to%20store%20user%20keyfiles%20%0ANM_CONN_CONF_PATH%3D%22%24NM_CONN_ETC_PATH%22%0A%0A%23%20This%20is%20where%20we%20want%20our%20keyfiles%20to%20finally%20reside.%20configure-ovs%0A%23%20operates%20with%20temporary%20keyfiles%20in%20NM_CONN_RUN_PATH%20and%20then%20as%20a%20last%0A%23%20step%20moves%20those%20keyfiles%20to%20NM_CONN_SET_PATH%20if%20it%20is%20a%20different%20path%0A%23%20(not%20by%20default).%20This%20mitigates%20hard%20interruptions%20(SIGKILL%2C%20hard%20reboot)%0A%23%20of%20configure-ovs%20leaving%20the%20machine%20with%20a%20half-baked%20set%20of%20keyfiles%0A%23%20that%20might%20prevent%20machine%20networking%20from%20working%20correctly.%0ANM_CONN_SET_PATH%3D%22%24%7BNM_CONN_SET_PATH%3A-%24NM_CONN_RUN_PATH%7D%22%0A%0AMANAGED_NM_CONN_SUFFIX%3D%22-slave-ovs-clone%22%0A%23%20Workaround%20to%20ensure%20OVS%20is%20installed%20due%20to%20bug%20in%20systemd%20Requires%3A%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1888017%0Acopy_nm_conn_files()%20%7B%0A%20%20local%20dst_path%3D%22%241%22%0A%20%20for%20src%20in%20%22%24%7BMANAGED_NM_CONN_FILES%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20src_path%3D%24(dirname%20%22%24src%22)%0A%20%20%20%20file%3D%24(basename%20%22%24src%22)%0A%20%20%20%20if%20%5B%20-f%20%22%24src_path%2F%24file%22%20%5D%3B%20then%0A%20%20%20%20%20%20if%20%5B%20!%20-f%20%22%24dst_path%2F%24file%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22Copying%20configuration%20%24file%22%0A%20%20%20%20%20%20%20%20cp%20%22%24src_path%2F%24file%22%20%22%24dst_path%2F%24file%22%0A%20%20%20%20%20%20elif%20!%20cmp%20--silent%20%22%24src_path%2F%24file%22%20%22%24dst_path%2F%24file%22%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22Copying%20updated%20configuration%20%24file%22%0A%20%20%20%20%20%20%20%20cp%20-f%20%22%24src_path%2F%24file%22%20%22%24dst_path%2F%24file%22%0A%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20echo%20%22Skipping%20%24file%20since%20it's%20equal%20at%20destination%22%0A%20%20%20%20%20%20fi%0A%20%20%20%20else%0A%20%20%20%20%20%20echo%20%22Skipping%20%24file%20since%20it%20does%20not%20exist%20at%20source%22%0A%20%20%20%20fi%0A%20%20done%0A%7D%0A%0Aupdate_nm_conn_files_base()%20%7B%0A%20%20base_path%3D%24%7B1%7D%0A%20%20bridge_name%3D%24%7B2%7D%0A%20%20port_name%3D%24%7B3%7D%0A%20%20ovs_port%3D%22ovs-port-%24%7Bbridge_name%7D%22%0A%20%20ovs_interface%3D%22ovs-if-%24%7Bbridge_name%7D%22%0A%20%20default_port_name%3D%22ovs-port-%24%7Bport_name%7D%22%20%23%20ovs-port-phys0%0A%20%20bridge_interface_name%3D%22ovs-if-%24%7Bport_name%7D%22%20%23%20ovs-if-phys0%0A%20%20%23%20In%20RHEL7%20files%20in%20%2F%7Betc%2Crun%7D%2FNetworkManager%2Fsystem-connections%20end%20without%20the%20suffix%20'.nmconnection'%2C%20whereas%20in%20RHCOS%20they%20end%20with%20the%20suffix.%0A%20%20MANAGED_NM_CONN_FILES%3D(%24(echo%20%22%24%7Bbase_path%7D%22%2F%7B%22%24bridge_name%22%2C%22%24ovs_interface%22%2C%22%24ovs_port%22%2C%22%24bridge_interface_name%22%2C%22%24default_port_name%22%7D%7B%2C.nmconnection%7D))%0A%20%20shopt%20-s%20nullglob%0A%20%20MANAGED_NM_CONN_FILES%2B%3D(%24%7Bbase_path%7D%2F*%24%7BMANAGED_NM_CONN_SUFFIX%7D.nmconnection%20%24%7Bbase_path%7D%2F*%24%7BMANAGED_NM_CONN_SUFFIX%7D)%0A%20%20shopt%20-u%20nullglob%0A%7D%0A%0Aupdate_nm_conn_run_files()%20%7B%0A%20%20update_nm_conn_files_base%20%22%24%7BNM_CONN_RUN_PATH%7D%22%20%22%24%7B1%7D%22%20%22%24%7B2%7D%22%0A%7D%0A%0Aupdate_nm_conn_set_files()%20%7B%0A%20%20update_nm_conn_files_base%20%22%24%7BNM_CONN_SET_PATH%7D%22%20%22%24%7B1%7D%22%20%22%24%7B2%7D%22%0A%7D%0A%0Aupdate_nm_conn_etc_files()%20%7B%0A%20%20update_nm_conn_files_base%20%22%24%7BNM_CONN_ETC_PATH%7D%22%20%22%24%7B1%7D%22%20%22%24%7B2%7D%22%0A%7D%0A%0A%23%20Move%20and%20reload%20keyfiles%20at%20their%20final%20destination%0Aset_nm_conn_files()%20%7B%0A%20%20if%20%5B%20%22%24NM_CONN_RUN_PATH%22%20!%3D%20%22%24NM_CONN_SET_PATH%22%20%5D%3B%20then%0A%20%20%20%20update_nm_conn_run_files%20br-ex%20phys0%0A%20%20%20%20copy_nm_conn_files%20%22%24NM_CONN_SET_PATH%22%0A%20%20%20%20rm_nm_conn_files%0A%20%20%20%20update_nm_conn_run_files%20br-ex1%20phys1%0A%20%20%20%20copy_nm_conn_files%20%22%24NM_CONN_SET_PATH%22%0A%20%20%20%20rm_nm_conn_files%0A%0A%20%20%20%20%23%20reload%20keyfiles%0A%20%20%20%20nmcli%20connection%20reload%0A%20%20fi%0A%7D%0A%0A%23%20Used%20to%20remove%20files%20managed%20by%20configure-ovs%20and%20temporary%20leftover%20files%20from%20network%20manager%0Arm_nm_conn_files()%20%7B%0A%20%20for%20file%20in%20%22%24%7BMANAGED_NM_CONN_FILES%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20if%20%5B%20-f%20%22%24file%22%20%5D%3B%20then%0A%20%20%20%20%20%20rm%20-f%20%22%24file%22%0A%20%20%20%20%20%20echo%20%22Removed%20nmconnection%20file%20%24file%22%0A%20%20%20%20%20%20nm_config_changed%3D1%0A%20%20%20%20fi%0A%20%20done%0A%20%20for%20file%20in%20%22%24%7BMANAGED_NM_CONN_FILES%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20for%20temp%20in%20%24(compgen%20-G%20%22%24%7Bfile%7D.*%22)%3B%20do%0A%20%20%20%20%20%20rm%20-f%20%22%24temp%22%0A%20%20%20%20%20%20echo%20%22Removed%20nmconnection%20temporary%20file%20%24temp%22%0A%20%20%20%20%20%20nm_config_changed%3D1%0A%20%20%20%20done%0A%20%20done%0A%7D%0A%0A%23%20Used%20to%20clone%20a%20slave%20connection%20by%20uuid%2C%20returns%20new%20name%0Aclone_slave_connection()%20%7B%0A%20%20local%20uuid%3D%22%241%22%0A%20%20local%20old_name%0A%20%20old_name%3D%22%24(nmcli%20-g%20connection.id%20connection%20show%20uuid%20%22%24uuid%22)%22%0A%20%20local%20new_name%3D%22%24%7Bold_name%7D%24%7BMANAGED_NM_CONN_SUFFIX%7D%22%0A%20%20if%20nmcli%20connection%20show%20id%20%22%24%7Bnew_name%7D%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20echo%20%22WARNING%3A%20existing%20ovs%20slave%20%24%7Bnew_name%7D%20connection%20profile%20file%20found%2C%20overwriting...%22%20%3E%262%0A%20%20%20%20nmcli%20connection%20delete%20id%20%22%24%7Bnew_name%7D%22%20%26%3E%20%2Fdev%2Fnull%0A%20%20fi%0A%20%20clone_nm_conn%20%24uuid%20%22%24%7Bnew_name%7D%22%0A%20%20echo%20%22%24%7Bnew_name%7D%22%0A%7D%0A%0A%23%20Used%20to%20replace%20an%20old%20master%20connection%20uuid%20with%20a%20new%20one%20on%20all%20connections%0Areplace_connection_master()%20%7B%0A%20%20local%20old%3D%22%241%22%0A%20%20local%20new%3D%22%242%22%0A%20%20for%20conn_uuid%20in%20%24(nmcli%20-g%20UUID%20connection%20show)%20%3B%20do%0A%20%20%20%20if%20%5B%20%22%24(nmcli%20-g%20connection.master%20connection%20show%20uuid%20%22%24conn_uuid%22)%22%20!%3D%20%22%24old%22%20%5D%3B%20then%0A%20%20%20%20%20%20continue%0A%20%20%20%20fi%0A%0A%20%20%20%20local%20active_state%3D%24(nmcli%20-g%20GENERAL.STATE%20connection%20show%20%22%24conn_uuid%22)%0A%20%20%20%20local%20autoconnect%3D%24(nmcli%20-g%20connection.autoconnect%20connection%20show%20%22%24conn_uuid%22)%0A%20%20%20%20if%20%5B%20%22%24active_state%22%20!%3D%20%22activated%22%20%5D%20%26%26%20%5B%20%22%24autoconnect%22%20!%3D%20%22yes%22%20%5D%3B%20then%0A%20%20%20%20%20%20%23%20Assume%20that%20slave%20profiles%20intended%20to%20be%20used%20are%20those%20that%20are%3A%0A%20%20%20%20%20%20%23%20-%20active%0A%20%20%20%20%20%20%23%20-%20or%20inactive%20(which%20might%20be%20due%20to%20link%20being%20down)%20but%20to%20be%20autoconnected.%0A%20%20%20%20%20%20%23%20Otherwise%2C%20ignore%20them.%0A%20%20%20%20%20%20continue%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20make%20changes%20for%20slave%20profiles%20in%20a%20new%20clone%0A%20%20%20%20local%20new_name%0A%20%20%20%20new_name%3D%24(clone_slave_connection%20%24conn_uuid)%0A%0A%20%20%20%20mod_nm_conn%20%22%24new_name%22%20connection.master%20%22%24new%22%20connection.autoconnect-priority%20100%20connection.autoconnect%20no%20%0A%20%20%20%20echo%20%22Replaced%20master%20%24old%20with%20%24new%20for%20slave%20profile%20%24new_name%22%0A%20%20done%0A%7D%0A%0A%23%20when%20creating%20the%20bridge%2C%20we%20use%20a%20value%20lower%20than%20NM's%20ethernet%20device%20default%20route%20metric%0A%23%20(we%20pick%2048%20and%2049%20to%20be%20lower%20than%20anything%20that%20NM%20chooses%20by%20default)%0ABRIDGE_METRIC%3D%2248%22%0ABRIDGE1_METRIC%3D%2249%22%0A%23%20Given%20an%20interface%2C%20generates%20NM%20configuration%20to%20add%20to%20an%20OVS%20bridge%0Aconvert_to_bridge()%20%7B%0A%20%20local%20iface%3D%24%7B1%7D%0A%20%20local%20bridge_name%3D%24%7B2%7D%0A%20%20local%20port_name%3D%24%7B3%7D%0A%20%20local%20bridge_metric%3D%24%7B4%7D%0A%20%20local%20ovs_port%3D%22ovs-port-%24%7Bbridge_name%7D%22%0A%20%20local%20ovs_interface%3D%22ovs-if-%24%7Bbridge_name%7D%22%0A%20%20local%20default_port_name%3D%22ovs-port-%24%7Bport_name%7D%22%20%23%20ovs-port-phys0%0A%20%20local%20bridge_interface_name%3D%22ovs-if-%24%7Bport_name%7D%22%20%23%20ovs-if-phys0%0A%0A%20%20if%20%5B%20%22%24iface%22%20%3D%20%22%24bridge_name%22%20%5D%3B%20then%0A%20%20%20%20%23%20handle%20vlans%20and%20bonds%20etc%20if%20they%20have%20already%20been%0A%20%20%20%20%23%20configured%20via%20nm%20key%20files%20and%20br-ex%20is%20already%20up%0A%20%20%20%20ifaces%3D%24(ovs-vsctl%20list-ifaces%20%24%7Biface%7D)%0A%20%20%20%20for%20intf%20in%20%24ifaces%3B%20do%20configure_driver_options%20%24intf%3B%20done%0A%20%20%20%20echo%20%22Networking%20already%20configured%20and%20up%20for%20%24%7Bbridge-name%7D!%22%0A%20%20%20%20return%0A%20%20fi%0A%0A%20%20%23%20flag%20to%20reload%20NM%20to%20account%20for%20all%20the%20configuration%20changes%0A%20%20%23%20going%20forward%0A%20%20nm_config_changed%3D1%0A%0A%20%20if%20%5B%20-z%20%22%24iface%22%20%5D%3B%20then%0A%20%20%20%20echo%20%22ERROR%3A%20Unable%20to%20find%20default%20gateway%20interface%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%20%20%23%20find%20the%20MAC%20from%20OVS%20config%20or%20the%20default%20interface%20to%20use%20for%20OVS%20internal%20port%0A%20%20%23%20this%20prevents%20us%20from%20getting%20a%20different%20DHCP%20lease%20and%20dropping%20connection%0A%20%20if%20!%20iface_mac%3D%24(%3C%22%2Fsys%2Fclass%2Fnet%2F%24%7Biface%7D%2Faddress%22)%3B%20then%0A%20%20%20%20echo%20%22Unable%20to%20determine%20default%20interface%20MAC%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%0A%20%20echo%20%22MAC%20address%20found%20for%20iface%3A%20%24%7Biface%7D%3A%20%24%7Biface_mac%7D%22%0A%0A%20%20%23%20find%20MTU%20from%20original%20iface%0A%20%20iface_mtu%3D%24(ip%20link%20show%20%22%24iface%22%20%7C%20awk%20'%7Bprint%20%245%3B%20exit%7D')%0A%20%20if%20%5B%5B%20-z%20%22%24iface_mtu%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22Unable%20to%20determine%20default%20interface%20MTU%2C%20defaulting%20to%201500%22%0A%20%20%20%20iface_mtu%3D1500%0A%20%20else%0A%20%20%20%20echo%20%22MTU%20found%20for%20iface%3A%20%24%7Biface%7D%3A%20%24%7Biface_mtu%7D%22%0A%20%20fi%0A%0A%20%20%23%20store%20old%20conn%20for%20later%0A%20%20old_conn%3D%24(nmcli%20--fields%20UUID%2CDEVICE%20conn%20show%20--active%20%7C%20awk%20%22%2F%5Cs%24%7Biface%7D%5Cs*%5C%24%2F%20%7Bprint%20%5C%241%7D%22)%0A%0A%20%20if%20%5B%5B%20-z%20%22%24old_conn%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22ERROR%3A%20cannot%20find%20connection%20for%20interface%3A%20%24%7Biface%7D%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%0A%20%20%23%20create%20bridge%0A%20%20if%20!%20nmcli%20connection%20show%20%22%24bridge_name%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-br%20%22%24bridge_name%22%0A%20%20%20%20add_nm_conn%20%22%24bridge_name%22%20type%20ovs-bridge%20conn.interface%20%22%24bridge_name%22%20802-3-ethernet.mtu%20%24%7Biface_mtu%7D%20%5C%0A%20%20%20%20connection.autoconnect-slaves%201%0A%20%20fi%0A%0A%20%20%23%20find%20default%20port%20to%20add%20to%20bridge%0A%20%20if%20!%20nmcli%20connection%20show%20%22%24default_port_name%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-port%20%22%24bridge_name%22%20%24%7Biface%7D%0A%20%20%20%20add_nm_conn%20%22%24default_port_name%22%20type%20ovs-port%20conn.interface%20%24%7Biface%7D%20slave-type%20ovs-bridge%20master%20%22%24bridge_name%22%20%5C%0A%20%20%20%20connection.autoconnect-slaves%201%0A%20%20fi%0A%0A%20%20if%20!%20nmcli%20connection%20show%20%22%24ovs_port%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-port%20%22%24bridge_name%22%20%22%24bridge_name%22%0A%20%20%20%20add_nm_conn%20%22%24ovs_port%22%20type%20ovs-port%20conn.interface%20%22%24bridge_name%22%20slave-type%20ovs-bridge%20master%20%22%24bridge_name%22%0A%20%20fi%0A%0A%20%20extra_phys_args%3D()%0A%20%20%23%20check%20if%20this%20interface%20is%20a%20vlan%2C%20bond%2C%20team%2C%20or%20ethernet%20type%0A%20%20if%20%5B%20%22%24(nmcli%20--get-values%20connection.type%20conn%20show%20%24%7Bold_conn%7D)%22%20%3D%3D%20%22vlan%22%20%5D%3B%20then%0A%20%20%20%20iface_type%3Dvlan%0A%20%20%20%20vlan_id%3D%24(nmcli%20--get-values%20vlan.id%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20if%20%5B%20-z%20%22%24vlan_id%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22ERROR%3A%20unable%20to%20determine%20vlan_id%20for%20vlan%20connection%3A%20%24%7Bold_conn%7D%22%0A%20%20%20%20%20%20exit%201%0A%20%20%20%20fi%0A%20%20%20%20vlan_parent%3D%24(nmcli%20--get-values%20vlan.parent%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20if%20%5B%20-z%20%22%24vlan_parent%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22ERROR%3A%20unable%20to%20determine%20vlan_parent%20for%20vlan%20connection%3A%20%24%7Bold_conn%7D%22%0A%20%20%20%20%20%20exit%201%0A%20%20%20%20fi%0A%0A%20%20%20%20if%20nmcli%20connection%20show%20uuid%20%22%24vlan_parent%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20%20%20%23%20if%20the%20VLAN%20connection%20is%20configured%20with%20a%20connection%20UUID%20as%20parent%2C%20we%20need%20to%20find%20the%20underlying%20device%0A%20%20%20%20%20%20%23%20and%20create%20the%20bridge%20against%20it%2C%20as%20the%20parent%20connection%20can%20be%20replaced%20by%20another%20bridge.%0A%20%20%20%20%20%20vlan_parent%3D%24(nmcli%20--get-values%20GENERAL.DEVICES%20conn%20show%20uuid%20%24%7Bvlan_parent%7D)%0A%20%20%20%20fi%0A%0A%20%20%20%20extra_phys_args%3D(%20dev%20%22%24%7Bvlan_parent%7D%22%20id%20%22%24%7Bvlan_id%7D%22%20)%0A%20%20elif%20%5B%20%22%24(nmcli%20--get-values%20connection.type%20conn%20show%20%24%7Bold_conn%7D)%22%20%3D%3D%20%22bond%22%20%5D%3B%20then%0A%20%20%20%20iface_type%3Dbond%0A%20%20%20%20%23%20check%20bond%20options%0A%20%20%20%20bond_opts%3D%24(nmcli%20--get-values%20bond.options%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20if%20%5B%20-n%20%22%24bond_opts%22%20%5D%3B%20then%0A%20%20%20%20%20%20extra_phys_args%2B%3D(%20bond.options%20%22%24%7Bbond_opts%7D%22%20)%0A%20%20%20%20%20%20MODE_REGEX%3D%22(%5E%7C%2C)mode%3Dactive-backup(%2C%7C%24)%22%0A%20%20%20%20%20%20MAC_REGEX%3D%22(%5E%7C%2C)fail_over_mac%3D(1%7Cactive%7C2%7Cfollow)(%2C%7C%24)%22%0A%20%20%20%20%20%20if%20%5B%5B%20%24bond_opts%20%3D~%20%24MODE_REGEX%20%5D%5D%20%26%26%20%5B%5B%20%24bond_opts%20%3D~%20%24MAC_REGEX%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20clone_mac%3D0%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%20%20elif%20%5B%20%22%24(nmcli%20--get-values%20connection.type%20conn%20show%20%24%7Bold_conn%7D)%22%20%3D%3D%20%22team%22%20%5D%3B%20then%0A%20%20%20%20iface_type%3Dteam%0A%20%20%20%20%23%20check%20team%20config%20options%0A%20%20%20%20team_config_opts%3D%24(nmcli%20--get-values%20team.config%20-e%20no%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20if%20%5B%20-n%20%22%24team_config_opts%22%20%5D%3B%20then%0A%20%20%20%20%20%20%23%20team.config%20is%20json%2C%20remove%20spaces%20to%20avoid%20problems%20later%20on%0A%20%20%20%20%20%20extra_phys_args%2B%3D(%20team.config%20%22%24%7Bteam_config_opts%2F%2F%5B%5B%3Aspace%3A%5D%5D%2F%7D%22%20)%0A%20%20%20%20%20%20team_mode%3D%24(echo%20%22%24%7Bteam_config_opts%7D%22%20%7C%20jq%20-r%20%22.runner.name%20%2F%2F%20empty%22)%0A%20%20%20%20%20%20team_mac_policy%3D%24(echo%20%22%24%7Bteam_config_opts%7D%22%20%7C%20jq%20-r%20%22.runner.hwaddr_policy%20%2F%2F%20empty%22)%0A%20%20%20%20%20%20MAC_REGEX%3D%22(by_active%7Conly_active)%22%0A%20%20%20%20%20%20if%20%5B%20%22%24team_mode%22%20%3D%20%22activebackup%22%20%5D%20%26%26%20%5B%5B%20%22%24team_mac_policy%22%20%3D~%20%24MAC_REGEX%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20clone_mac%3D0%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%20%20elif%20%5B%20%22%24(nmcli%20--get-values%20connection.type%20conn%20show%20%24%7Bold_conn%7D)%22%20%3D%3D%20%22tun%22%20%5D%3B%20then%0A%20%20%20%20iface_type%3Dtun%0A%20%20%20%20tun_mode%3D%24(nmcli%20--get-values%20tun.mode%20-e%20no%20connection%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20extra_phys_args%2B%3D(%20tun.mode%20%22%24%7Btun_mode%7D%22%20)%0A%20%20elif%20%5B%20%22%24(nmcli%20--get-values%20connection.type%20conn%20show%20%24%7Bold_conn%7D)%22%20%3D%3D%20%22bridge%22%20%5D%3B%20then%0A%20%20%20%20iface_type%3Dbridge%0A%20%20else%0A%20%20%20%20iface_type%3D802-3-ethernet%0A%20%20fi%0A%0A%20%20if%20%5B%20!%20%22%24%7Bclone_mac%3A-%7D%22%20%3D%20%220%22%20%5D%3B%20then%0A%20%20%20%20%23%20In%20active-backup%20link%20aggregation%2C%20with%20fail_over_mac%20mode%20enabled%2C%0A%20%20%20%20%23%20cloning%20the%20mac%20address%20is%20not%20supported.%20It%20is%20possible%20then%20that%0A%20%20%20%20%23%20br-ex%20has%20a%20different%20mac%20address%20than%20the%20bond%20which%20might%20be%0A%20%20%20%20%23%20troublesome%20on%20some%20platforms%20where%20the%20nic%20won't%20accept%20packets%20with%0A%20%20%20%20%23%20a%20different%20destination%20mac.%20But%20nobody%20has%20complained%20so%20far%20so%20go%20on%0A%20%20%20%20%23%20with%20what%20we%20got.%20%0A%20%20%20%20%0A%20%20%20%20%23%20Do%20set%20it%20though%20for%20other%20link%20aggregation%20configurations%20where%20the%0A%20%20%20%20%23%20mac%20address%20would%20otherwise%20depend%20on%20enslave%20order%20for%20which%20we%20have%0A%20%20%20%20%23%20no%20control%20going%20forward.%0A%20%20%20%20extra_phys_args%2B%3D(%20802-3-ethernet.cloned-mac-address%20%22%24%7Biface_mac%7D%22%20)%0A%20%20fi%0A%0A%20%20%23%20use%20%24%7Bextra_phys_args%5B%40%5D%2B%22%24%7Bextra_phys_args%5B%40%5D%7D%22%7D%20instead%20of%20%24%7Bextra_phys_args%5B%40%5D%7D%20to%20be%20compatible%20with%20bash%204.2%20in%20RHEL7.9%0A%20%20if%20!%20nmcli%20connection%20show%20%22%24bridge_interface_name%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20destroy%20interface%20%24%7Biface%7D%0A%20%20%20%20ovs_default_port_conn%3D%24(nmcli%20-g%20connection.uuid%20conn%20show%20%22%24default_port_name%22)%0A%20%20%20%20add_nm_conn%20%22%24bridge_interface_name%22%20type%20%24%7Biface_type%7D%20conn.interface%20%24%7Biface%7D%20master%20%22%24ovs_default_port_conn%22%20%5C%0A%20%20%20%20%20%20slave-type%20ovs-port%20connection.autoconnect-priority%20100%20connection.autoconnect-slaves%201%20802-3-ethernet.mtu%20%24%7Biface_mtu%7D%20%5C%0A%20%20%20%20%20%20%24%7Bextra_phys_args%5B%40%5D%2B%22%24%7Bextra_phys_args%5B%40%5D%7D%22%7D%0A%20%20fi%0A%0A%20%20%23%20Get%20the%20new%20connection%20uuids%0A%20%20new_conn%3D%24(nmcli%20-g%20connection.uuid%20conn%20show%20%22%24bridge_interface_name%22)%0A%20%20ovs_port_conn%3D%24(nmcli%20-g%20connection.uuid%20conn%20show%20%22%24ovs_port%22)%0A%0A%20%20%23%20Update%20connections%20with%20master%20property%20set%20to%20use%20the%20new%20connection%0A%20%20replace_connection_master%20%24old_conn%20%24new_conn%0A%20%20replace_connection_master%20%24iface%20%24new_conn%0A%0A%20%20ipv4_method%3D%24(nmcli%20-g%20ipv4.method%20conn%20show%20%22%24old_conn%22)%0A%20%20ipv6_method%3D%24(nmcli%20-g%20ipv6.method%20conn%20show%20%22%24old_conn%22)%0A%0A%20%20ipv4_addresses%3D%24(nmcli%20-g%20ipv4.addresses%20conn%20show%20%22%24old_conn%22)%0A%20%20ipv6_addresses%3D%24(nmcli%20-g%20ipv6.addresses%20conn%20show%20%22%24old_conn%22)%0A%0A%20%20%23%20Warn%20about%20an%20invalid%20MTU%20that%20will%20most%20likely%20fail%20in%20one%20way%20or%0A%20%20%23%20another%0A%20%20if%20%5B%20%24%7Biface_mtu%7D%20-lt%201280%20%5D%20%26%26%20%5B%20%22%24%7Bipv6_method%7D%22%20!%3D%20%22disabled%22%20%5D%3B%20then%0A%20%20%20%20echo%20%22WARNING%3A%20MTU%20%24%7Biface_mtu%7D%20is%20lower%20than%20the%20minimum%20required%20of%201280%20for%20IPv6%22%0A%20%20fi%0A%0A%20%20if%20!%20nmcli%20connection%20show%20%22%24ovs_interface%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20destroy%20interface%20%22%24bridge_name%22%0A%20%20%20%20%23%20Clone%20the%20connection%20in%20case%20the%20method%20is%20manual%20or%20in%20case%20the%20an%20address%20is%20set%20(DHCP%20%2B%20static%20IP)%0A%20%20%20%20if%20%5B%20%22%24%7Bipv4_method%7D%22%20%3D%20%22manual%22%20%5D%20%7C%7C%20%5B%20%22%24%7Bipv4_addresses%7D%22%20!%3D%20%22%22%20%5D%20%7C%7C%20%5B%20%22%24%7Bipv6_method%7D%22%20%3D%20%22manual%22%20%5D%20%7C%7C%20%5B%20%22%24%7Bipv6_addresses%7D%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22Static%20IP%20addressing%20detected%20on%20default%20gateway%20connection%3A%20%24%7Bold_conn%7D%22%0A%20%20%20%20%20%20%23%20clone%20the%20old%20connection%20to%20get%20the%20address%20settings%0A%20%20%20%20%20%20%23%20prefer%20cloning%20vs%20copying%20the%20connection%20file%20to%20avoid%20problems%20with%20selinux%0A%20%20%20%20%20%20clone_nm_conn%20%22%24%7Bold_conn%7D%22%20%22%24%7Bovs_interface%7D%22%0A%20%20%20%20%20%20shopt%20-s%20nullglob%0A%20%20%20%20%20%20new_conn_files%3D(%24%7BNM_CONN_RUN_PATH%7D%2F%22%24%7Bovs_interface%7D%22*)%0A%20%20%20%20%20%20shopt%20-u%20nullglob%0A%20%20%20%20%20%20if%20%5B%20%24%7B%23new_conn_files%5B%40%5D%7D%20-ne%201%20%5D%20%7C%7C%20%5B%20!%20-f%20%22%24%7Bnew_conn_files%5B0%5D%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22ERROR%3A%20could%20not%20find%20%24%7Bovs_interface%7D%20conn%20file%20after%20cloning%20from%20%24%7Bold_conn%7D%22%0A%20%20%20%20%20%20%20%20exit%201%0A%20%20%20%20%20%20fi%0A%20%20%20%20%20%20new_conn_file%3D%22%24%7Bnew_conn_files%5B0%5D%7D%22%0A%0A%20%20%20%20%20%20%23%20modify%20the%20connection%20type%20directly%20because%20it%20can't%20be%20modified%0A%20%20%20%20%20%20%23%20through%20nmcli%0A%20%20%20%20%20%20sed%20-i%20'%2F%5E%5C%5Bconnection%5C%5D%24%2F%2C%2F%5E%5C%5B%2F%20s%2F%5Etype%3D.*%24%2Ftype%3Dovs-interface%2F'%20%24%7Bnew_conn_file%7D%0A%0A%20%20%20%20%20%20%23%20modify%20some%20more%20settings%20through%20nmcli%0A%20%20%20%20%20%20mod_nm_conn%20%22%24%7Bovs_interface%7D%22%20conn.interface%20%22%24bridge_name%22%20%5C%0A%20%20%20%20%20%20%20%20connection.multi-connect%20%22%22%20connection.autoconnect%20no%20%5C%0A%20%20%20%20%20%20%20%20connection.master%20%22%24ovs_port_conn%22%20connection.slave-type%20ovs-port%20%5C%0A%20%20%20%20%20%20%20%20ovs-interface.type%20internal%20%5C%0A%20%20%20%20%20%20%20%20802-3-ethernet.mtu%20%24%7Biface_mtu%7D%20802-3-ethernet.cloned-mac-address%20%24%7Biface_mac%7D%20%5C%0A%20%20%20%20%20%20%20%20ipv4.route-metric%20%22%24%7Bbridge_metric%7D%22%20ipv6.route-metric%20%22%24%7Bbridge_metric%7D%22%0A%0A%20%20%20%20%20%20echo%20%22Loaded%20new%20%24ovs_interface%20connection%20file%3A%20%24%7Bnew_conn_file%7D%22%0A%20%20%20%20else%0A%20%20%20%20%20%20extra_if_brex_args%3D%22%22%0A%20%20%20%20%20%20%23%20check%20if%20interface%20had%20ipv4%2Fipv6%20addresses%20assigned%0A%20%20%20%20%20%20num_ipv4_addrs%3D%24(ip%20-j%20a%20show%20dev%20%24%7Biface%7D%20%7C%20jq%20%22.%5B0%5D.addr_info%20%7C%20map(.%20%7C%20select(.family%20%3D%3D%20%5C%22inet%5C%22))%20%7C%20length%22)%0A%20%20%20%20%20%20if%20%5B%20%22%24num_ipv4_addrs%22%20-gt%200%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20extra_if_brex_args%2B%3D%22ipv4.may-fail%20no%20%22%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20%23%20IPV6%20should%20have%20at%20least%20a%20link%20local%20address.%20Check%20for%20more%20than%201%20to%20see%20if%20there%20is%20an%0A%20%20%20%20%20%20%23%20assigned%20address.%0A%20%20%20%20%20%20num_ip6_addrs%3D%24(ip%20-j%20a%20show%20dev%20%24%7Biface%7D%20%7C%20jq%20%22.%5B0%5D.addr_info%20%7C%20map(.%20%7C%20select(.family%20%3D%3D%20%5C%22inet6%5C%22%20and%20.scope%20!%3D%20%5C%22link%5C%22))%20%7C%20length%22)%0A%20%20%20%20%20%20if%20%5B%20%22%24num_ip6_addrs%22%20-gt%200%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20extra_if_brex_args%2B%3D%22ipv6.may-fail%20no%20%22%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20%23%20check%20for%20dhcp%20client%20ids%0A%20%20%20%20%20%20dhcp_client_id%3D%24(nmcli%20--get-values%20ipv4.dhcp-client-id%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20%20%20if%20%5B%20-n%20%22%24dhcp_client_id%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20extra_if_brex_args%2B%3D%22ipv4.dhcp-client-id%20%24%7Bdhcp_client_id%7D%20%22%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20dhcp6_client_id%3D%24(nmcli%20--get-values%20ipv6.dhcp-duid%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20%20%20if%20%5B%20-n%20%22%24dhcp6_client_id%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20extra_if_brex_args%2B%3D%22ipv6.dhcp-duid%20%24%7Bdhcp6_client_id%7D%20%22%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20ipv6_addr_gen_mode%3D%24(nmcli%20--get-values%20ipv6.addr-gen-mode%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20%20%20if%20%5B%20-n%20%22%24ipv6_addr_gen_mode%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20extra_if_brex_args%2B%3D%22ipv6.addr-gen-mode%20%24%7Bipv6_addr_gen_mode%7D%20%22%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20add_nm_conn%20%22%24ovs_interface%22%20type%20ovs-interface%20slave-type%20ovs-port%20conn.interface%20%22%24bridge_name%22%20master%20%22%24ovs_port_conn%22%20%5C%0A%20%20%20%20%20%20%20%20802-3-ethernet.mtu%20%24%7Biface_mtu%7D%20802-3-ethernet.cloned-mac-address%20%24%7Biface_mac%7D%20%5C%0A%20%20%20%20%20%20%20%20ipv4.method%20%22%24%7Bipv4_method%7D%22%20ipv4.route-metric%20%22%24%7Bbridge_metric%7D%22%20%5C%0A%20%20%20%20%20%20%20%20ipv6.method%20%22%24%7Bipv6_method%7D%22%20ipv6.route-metric%20%22%24%7Bbridge_metric%7D%22%20%5C%0A%20%20%20%20%20%20%20%20%24%7Bextra_if_brex_args%7D%0A%20%20%20%20fi%0A%20%20fi%0A%0A%20%20configure_driver_options%20%22%24%7Biface%7D%22%0A%7D%0A%0A%23%20Used%20to%20remove%20a%20bridge%0Aremove_ovn_bridges()%20%7B%0A%20%20bridge_name%3D%24%7B1%7D%0A%20%20port_name%3D%24%7B2%7D%0A%0A%20%20%23%20Remove%20the%20keyfiles%20from%20known%20configuration%20paths%0A%20%20update_nm_conn_run_files%20%24%7Bbridge_name%7D%20%24%7Bport_name%7D%0A%20%20rm_nm_conn_files%0A%20%20update_nm_conn_set_files%20%24%7Bbridge_name%7D%20%24%7Bport_name%7D%0A%20%20rm_nm_conn_files%0A%20%20%23%20Shouldn't%20be%20necessary%2C%20workaround%20for%20https%3A%2F%2Fissues.redhat.com%2Fbrowse%2FOCPBUGS-41489%0A%20%20update_nm_conn_etc_files%20%24%7Bbridge_name%7D%20%24%7Bport_name%7D%0A%20%20rm_nm_conn_files%0A%0A%20%20%23%20NetworkManager%20will%20not%20remove%20%24%7Bbridge_name%7D%20if%20it%20has%20the%20patch%20port%20created%20by%20ovn-kubernetes%0A%20%20%23%20so%20remove%20explicitly%0A%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-br%20%24%7Bbridge_name%7D%0A%7D%0A%0A%23%20Removes%20any%20previous%20ovs%20configuration%0Aremove_all_ovn_bridges()%20%7B%0A%20%20echo%20%22Reverting%20any%20previous%20OVS%20configuration%22%0A%20%20%0A%20%20remove_ovn_bridges%20br-ex%20phys0%0A%20%20remove_ovn_bridges%20br-ex1%20phys1%0A%20%20%0A%20%20echo%20%22OVS%20configuration%20successfully%20reverted%22%0A%7D%0A%0A%23%20Reloads%20NM%20NetworkManager%20profiles%20if%20any%20configuration%20change%20was%20done.%0A%23%20Accepts%20a%20list%20of%20devices%20that%20should%20be%20re-connect%20after%20reload.%0Areload_profiles_nm()%20%7B%0A%20%20if%20%5B%20%24%7Bnm_config_changed%3A-0%7D%20-eq%200%20%5D%3B%20then%0A%20%20%20%20%23%20no%20config%20was%20changed%2C%20no%20need%20to%20reload%0A%20%20%20%20return%0A%20%20fi%0A%0A%20%20%23%20reload%20profiles%0A%20%20nmcli%20connection%20reload%0A%0A%20%20%23%20precautionary%20sleep%20of%2010s%20(default%20timeout%20of%20NM%20to%20bring%20down%20devices)%0A%20%20sleep%2010%0A%0A%20%20%23%20After%20reload%2C%20devices%20that%20were%20already%20connected%20should%20connect%20again%0A%20%20%23%20if%20any%20profile%20is%20available.%20If%20no%20profile%20is%20available%2C%20a%20device%20can%0A%20%20%23%20remain%20disconnected%20and%20we%20have%20to%20explicitly%20connect%20it%20so%20that%20a%0A%20%20%23%20profile%20is%20generated.%20This%20can%20happen%20for%20physical%20devices%20but%20should%0A%20%20%23%20not%20happen%20for%20software%20devices%20as%20those%20always%20require%20a%20profile.%0A%20%20for%20dev%20in%20%24%40%3B%20do%0A%20%20%20%20%23%20Only%20attempt%20to%20connect%20a%20disconnected%20device%0A%20%20%20%20local%20connected_state%3D%24(nmcli%20-g%20GENERAL.STATE%20device%20show%20%22%24dev%22%20%7C%7C%20echo%20%22%22)%0A%20%20%20%20if%20%5B%5B%20%22%24connected_state%22%20%3D~%20%22disconnected%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%23%20keep%20track%20if%20a%20profile%20by%20the%20same%20name%20as%20the%20device%20existed%20%0A%20%20%20%20%20%20%23%20before%20we%20attempt%20activation%0A%20%20%20%20%20%20local%20named_profile_existed%3D%24(%5B%20-f%20%22%24%7BNM_CONN_CONF_PATH%7D%2F%24%7Bdev%7D%22%20%5D%20%7C%7C%20%5B%20-f%20%22%24%7BNM_CONN_CONF_PATH%7D%2F%24%7Bdev%7D.nmconnection%22%20%5D%20%26%26%20echo%20%22yes%22)%0A%20%20%20%20%20%20%0A%20%20%20%20%20%20for%20i%20in%20%7B1..10%7D%3B%20do%0A%20%20%20%20%20%20%20%20%20%20echo%20%22Attempt%20%24i%20to%20connect%20device%20%24dev%22%0A%20%20%20%20%20%20%20%20%20%20nmcli%20device%20connect%20%22%24dev%22%20%26%26%20break%0A%20%20%20%20%20%20%20%20%20%20sleep%205%0A%20%20%20%20%20%20done%0A%0A%20%20%20%20%20%20%23%20if%20a%20profile%20did%20not%20exist%20before%20but%20does%20now%2C%20it%20was%20generated%0A%20%20%20%20%20%20%23%20but%20we%20want%20it%20to%20be%20ephemeral%2C%20so%20move%20it%20back%20to%20%2Frun%0A%20%20%20%20%20%20if%20%5B%20!%20%22%24named_profile_existed%22%20%3D%20%22yes%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20MANAGED_NM_CONN_FILES%3D(%22%24%7BNM_CONN_CONF_PATH%7D%2F%24%7Bdev%7D%22%20%22%24%7BNM_CONN_CONF_PATH%7D%2F%24%7Bdev%7D.nmconnection%22)%0A%20%20%20%20%20%20%20%20copy_nm_conn_files%20%22%24%7BNM_CONN_RUN_PATH%7D%22%0A%20%20%20%20%20%20%20%20rm_nm_conn_files%0A%20%20%20%20%20%20%20%20%23%20reload%20profiles%20so%20that%20NM%20notices%20that%20some%20might%20have%20been%20moved%0A%20%20%20%20%20%20%20%20nmcli%20connection%20reload%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20echo%20%22Waiting%20for%20interface%20%24dev%20to%20activate...%22%0A%20%20%20%20if%20!%20timeout%2060%20bash%20-c%20%22while%20!%20nmcli%20-g%20DEVICE%2CSTATE%20c%20%7C%20grep%20%22'%22'%22%24dev%22%3Aactivated'%22'%22%3B%20do%20sleep%205%3B%20done%22%3B%20then%0A%20%20%20%20%20%20echo%20%22WARNING%3A%20%24dev%20did%20not%20activate%22%0A%20%20%20%20fi%0A%20%20done%0A%0A%20%20nm_config_changed%3D0%0A%7D%0A%0A%23%20Removes%20all%20configuration%20and%20reloads%20NM%20if%20necessary%0Arollback_nm()%20%7B%0A%20%20phys0%3D%24(get_bridge_physical_interface%20ovs-if-phys0)%0A%20%20phys1%3D%24(get_bridge_physical_interface%20ovs-if-phys1)%0A%20%20%0A%20%20%23%20Revert%20changes%20made%20by%20%2Fusr%2Flocal%2Fbin%2Fconfigure-ovs.sh%20during%20SDN%20migration.%0A%20%20remove_all_ovn_bridges%0A%20%20%0A%20%20%23%20reload%20profiles%20so%20that%20NM%20notices%20that%20some%20were%20removed%0A%20%20reload_profiles_nm%20%22%24phys0%22%20%22%24phys1%22%0A%7D%0A%0A%23%20Add%20a%20temporary%20deactivated%20connection%20profile%20%0A%23%20First%20argument%20is%20the%20connection%20name%20folowed%20by%20arguments%20passed%20to%0A%23%20%60nmcli%20connection%20add%60%0Aadd_nm_conn()%20%7B%0A%20%20%23%20Use%20%60save%20no%60%20to%20add%20a%20temporary%20profile%0A%20%20nmcli%20c%20add%20save%20no%20con-name%20%22%24%40%22%20connection.autoconnect%20no%0A%7D%0A%0A%23%20Modify%20a%20temporary%20connection%20profile%20%0A%23%20First%20argument%20is%20the%20connection%20name%20followed%20by%20arguments%20passed%20to%0A%23%20%60nmcli%20connection%20modify%60%0Amod_nm_conn()%20%7B%0A%20%20%23%20the%20easiest%20thing%20to%20do%20here%20would%20be%20to%20use%20%60nmcli%20c%20mod%20--temporary%60%0A%20%20%23%20but%20there%20is%20a%20bug%20in%20selinux%20profiles%20that%20denies%20NM%20from%20performing%0A%20%20%23%20the%20operation%0A%20%20local%20dst_path%3D%24%7BNM_CONN_RUN_PATH%7D%2F%241.nmconnection%0A%20%20local%20src_path%0A%20%20src_path%3D%24(mktemp)%0A%20%20shift%0A%20%20cat%20%22%24dst_path%22%20%3E%20%22%24src_path%22%0A%20%20rm%20-f%20%22%24dst_path%22%0A%20%20nmcli%20--offline%20c%20mod%20%22%24%40%22%20%3C%20%22%24src_path%22%20%3E%20%22%24dst_path%22%0A%20%20rm%20-f%20%22%24src_path%22%0A%20%20chmod%20600%20%22%24dst_path%22%0A%20%20nmcli%20c%20load%20%22%24dst_path%22%0A%7D%0A%0A%23%20Clone%20to%20a%20temporary%20connection%20profile%20%0A%23%20First%20argument%20is%20the%20connection%20to%20clone%2C%20second%20argument%20is%20the%20clone%20name%0Aclone_nm_conn()%20%7B%0A%20%20%23%20clone%20as%20temporary%20so%20that%20it%20is%20generated%20in%20NM_CONN_RUN_PATH%0A%20%20nmcli%20connection%20clone%20--temporary%20%22%241%22%20%22%242%22%20%26%3E%20%2Fdev%2Fnull%0A%7D%0A%0A%23%20Activates%20an%20ordered%20set%20of%20NM%20connection%20profiles%0Aactivate_nm_connections()%20%7B%0A%20%20local%20connections%3D(%22%24%40%22)%0A%0A%20%20%23%20We%20want%20autoconnect%20set%20for%20our%20cloned%20slave%20profiles%20so%20that%20they%20are%0A%20%20%23%20used%20over%20the%20original%20profiles%20if%20implicitly%20re-activated%20with%20other%0A%20%20%23%20dependant%20profiles.%20Otherwise%20if%20a%20slave%20activates%20with%20an%20old%20profile%2C%0A%20%20%23%20the%20old%20master%20profile%20might%20activate%20as%20well%2C%20interfering%20and%20causing%0A%20%20%23%20further%20activations%20to%20fail.%0A%20%20%23%20Slave%20interfaces%20should%20already%20be%20active%20so%20setting%20autoconnect%20here%0A%20%20%23%20won't%20implicitly%20activate%20them%20but%20there%20is%20an%20edge%20case%20where%20a%20slave%0A%20%20%23%20might%20be%20inactive%20(link%20down%20for%20example)%20and%20in%20that%20case%20setting%0A%20%20%23%20autoconnect%20will%20cause%20an%20implicit%20activation.%20This%20is%20not%20necessarily%20a%0A%20%20%23%20problem%20and%20hopefully%20we%20can%20make%20sure%20everything%20is%20activated%20as%20we%0A%20%20%23%20want%20next.%0A%20%20for%20conn%20in%20%22%24%7Bconnections%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20local%20slave_type%3D%24(nmcli%20-g%20connection.slave-type%20connection%20show%20%22%24conn%22)%0A%20%20%20%20if%20%5B%20%22%24slave_type%22%20%3D%20%22team%22%20%5D%20%7C%7C%20%5B%20%22%24slave_type%22%20%3D%20%22bond%22%20%5D%3B%20then%0A%20%20%20%20%20%20mod_nm_conn%20%22%24conn%22%20connection.autoconnect%20yes%0A%20%20%20%20fi%0A%20%20done%0A%0A%20%20%23%20Activate%20all%20connections%20and%20fail%20if%20activation%20fails%0A%20%20%23%20For%20slave%20connections%20-%20for%20as%20long%20as%20at%20least%20one%20slave%20that%20belongs%20to%20a%20bond%2Fteam%0A%20%20%23%20comes%20up%2C%20we%20should%20not%20fail%0A%20%20declare%20-A%20master_interfaces%0A%20%20for%20conn%20in%20%22%24%7Bconnections%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20%23%20Get%20the%20slave%20type%0A%20%20%20%20local%20slave_type%3D%24(nmcli%20-g%20connection.slave-type%20connection%20show%20%22%24conn%22)%0A%20%20%20%20local%20is_slave%3Dfalse%0A%20%20%20%20if%20%5B%20%22%24slave_type%22%20%3D%20%22team%22%20%5D%20%7C%7C%20%5B%20%22%24slave_type%22%20%3D%20%22bond%22%20%5D%3B%20then%0A%20%20%20%20%20%20is_slave%3Dtrue%0A%20%20%20%20fi%20%0A%0A%20%20%20%20%23%20For%20slave%20interfaces%2C%20initialize%20the%20master%20interface%20to%20false%20if%20the%20key%20is%20not%20yet%20in%20the%20array%0A%20%20%20%20local%20master_interface%0A%20%20%20%20if%20%24is_slave%3B%20then%0A%20%20%20%20%20%20master_interface%3D%24(nmcli%20-g%20connection.master%20connection%20show%20%22%24conn%22)%0A%20%20%20%20%20%20if%20!%20%5B%5B%20-v%20%22master_interfaces%5B%24master_interface%5D%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20master_interfaces%5B%22%24master_interface%22%5D%3Dfalse%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20slaves%20should%20implicitly%20activate%2C%20give%20them%20a%20chance%20to%20do%20so%0A%20%20%20%20if%20%24is_slave%3B%20then%0A%20%20%20%20%20%20if%20!%20timeout%205%20bash%20-c%20%22while%20!%20nmcli%20-g%20GENERAL.STATE%20conn%20show%20%22%24conn%22%20%7C%20grep%20activated%3B%20do%20sleep%201%3B%20done%22%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22WARNING%3A%20slave%20%24conn%20did%20not%20implicitly%20activate%20in%205s%2C%20activating%20explicitly.%22%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Do%20not%20activate%20interfaces%20that%20are%20already%20active%0A%20%20%20%20%23%20But%20set%20the%20entry%20in%20master_interfaces%20to%20true%20if%20this%20is%20a%20slave%0A%20%20%20%20%23%20Also%20set%20autoconnect%20to%20yes%0A%20%20%20%20local%20active_state%3D%24(nmcli%20-g%20GENERAL.STATE%20conn%20show%20%22%24conn%22)%0A%20%20%20%20if%20%5B%20%22%24active_state%22%20%3D%3D%20%22activated%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22Connection%20%24conn%20already%20activated%22%0A%20%20%20%20%20%20if%20%24is_slave%3B%20then%0A%20%20%20%20%20%20%20%20master_interfaces%5B%24master_interface%5D%3Dtrue%0A%20%20%20%20%20%20fi%0A%20%20%20%20%20%20mod_nm_conn%20%22%24conn%22%20connection.autoconnect%20yes%0A%20%20%20%20%20%20continue%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Activate%20all%20interfaces%20that%20are%20not%20yet%20active%0A%20%20%20%20for%20i%20in%20%7B1..10%7D%3B%20do%0A%20%20%20%20%20%20echo%20%22Attempt%20%24i%20to%20bring%20up%20connection%20%24conn%22%0A%20%20%20%20%20%20nmcli%20conn%20up%20%22%24conn%22%20%26%26%20s%3D0%20%26%26%20break%20%7C%7C%20s%3D%24%3F%0A%20%20%20%20%20%20sleep%205%0A%20%20%20%20done%0A%20%20%20%20if%20%5B%20%24s%20-eq%200%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22Brought%20up%20connection%20%24conn%20successfully%22%0A%20%20%20%20%20%20if%20%24is_slave%3B%20then%0A%20%20%20%20%20%20%20%20master_interfaces%5B%22%24master_interface%22%5D%3Dtrue%0A%20%20%20%20%20%20fi%0A%20%20%20%20elif%20!%20%24is_slave%3B%20then%0A%20%20%20%20%20%20echo%20%22ERROR%3A%20Cannot%20bring%20up%20connection%20%24conn%20after%20%24i%20attempts%22%0A%20%20%20%20%20%20return%20%24s%0A%20%20%20%20fi%0A%20%20%20%20mod_nm_conn%20%22%24conn%22%20connection.autoconnect%20yes%0A%20%20done%0A%20%20%23%20Check%20that%20all%20master%20interfaces%20report%20at%20least%20a%20single%20active%20slave%0A%20%20%23%20Note%3A%20associative%20arrays%20require%20an%20exclamation%20mark%20when%20looping%0A%20%20for%20i%20in%20%22%24%7B!master_interfaces%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20if%20!%20%24%7Bmaster_interfaces%5B%22%24i%22%5D%7D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22ERROR%3A%20Cannot%20bring%20up%20any%20slave%20interface%20for%20master%20interface%3A%20%24i%22%0A%20%20%20%20%20%20%20%20return%201%0A%20%20%20%20fi%0A%20%20done%0A%7D%0A%0A%23%20Accepts%20parameters%20%24iface_default_hint_file%2C%20%24iface%0A%23%20Writes%20content%20of%20%24iface%20into%20%24iface_default_hint_file%0Awrite_iface_default_hint()%20%7B%0A%20%20local%20iface_default_hint_file%3D%22%241%22%0A%20%20local%20iface%3D%22%242%22%0A%0A%20%20echo%20%22%24%7Biface%7D%22%20%3E%7C%20%22%24%7Biface_default_hint_file%7D%22%0A%7D%0A%0A%23%20Accepts%20parameters%20%24iface_default_hint_file%0A%23%20Returns%20the%20stored%20interface%20default%20hint%20if%20the%20hint%20is%20non-empty%2C%0A%23%20not%20br-ex%2C%20not%20br-ex1%20and%20if%20the%20interface%20can%20be%20found%20in%20%2Fsys%2Fclass%2Fnet%0Aget_iface_default_hint()%20%7B%0A%20%20local%20iface_default_hint_file%3D%241%0A%20%20if%20%5B%20-f%20%22%24%7Biface_default_hint_file%7D%22%20%5D%3B%20then%0A%20%20%20%20local%20iface_default_hint%3D%24(cat%20%22%24%7Biface_default_hint_file%7D%22)%0A%20%20%20%20if%20%5B%20%22%24%7Biface_default_hint%7D%22%20!%3D%20%22%22%20%5D%20%26%26%0A%20%20%20%20%20%20%20%20%5B%20%22%24%7Biface_default_hint%7D%22%20!%3D%20%22br-ex%22%20%5D%20%26%26%0A%20%20%20%20%20%20%20%20%5B%20%22%24%7Biface_default_hint%7D%22%20!%3D%20%22br-ex1%22%20%5D%20%26%26%0A%20%20%20%20%20%20%20%20%5B%20-d%20%22%2Fsys%2Fclass%2Fnet%2F%24%7Biface_default_hint%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22%24%7Biface_default_hint%7D%22%0A%20%20%20%20%20%20%20%20return%0A%20%20%20%20fi%0A%20%20fi%0A%20%20echo%20%22%22%0A%7D%0A%0Aget_ip_from_ip_hint_file()%20%7B%0A%20%20local%20ip_hint_file%3D%22%241%22%0A%20%20if%20%5B%5B%20!%20-f%20%22%24%7Bip_hint_file%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20return%0A%20%20fi%0A%20%20ip_hint%3D%24(cat%20%22%24%7Bip_hint_file%7D%22)%0A%20%20echo%20%22%24%7Bip_hint%7D%22%0A%7D%0A%0A%23%20This%20function%20waits%20for%20ip%20address%20of%20br-ex%20to%20be%20bindable%20only%20in%20case%20of%20ipv6%0A%23%20This%20is%20workaround%20for%20OCPBUGS-673%20as%20it%20will%20not%20allow%20starting%20crio%0A%23%20before%20address%20is%20bindable%0Atry_to_bind_ipv6_address()%20%7B%0A%20%20%23%20Retry%20for%201%20minute%0A%20%20retries%3D60%0A%20%20until%20%5B%5B%20%24%7Bretries%7D%20-eq%200%20%5D%5D%3B%20do%0A%20%20%20%20ip%3D%24(ip%20-6%20-j%20addr%20%7C%20jq%20-r%20%22first(.%5B%5D%20%7C%20select(.ifname%3D%3D%5C%22br-ex%5C%22)%20%7C%20.addr_info%5B%5D%20%7C%20select(.scope%3D%3D%5C%22global%5C%22)%20%7C%20.local)%22)%0A%20%20%20%20if%20%5B%5B%20%22%24%7Bip%7D%22%20%3D%3D%20%22%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22No%20ipv6%20ip%20to%20bind%20was%20found%22%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20%20%20random_port%3D%24(shuf%20-i%2050000-60000%20-n%201)%0A%20%20%20%20echo%20%22Trying%20to%20bind%20%24%7Bip%7D%20on%20port%20%24%7Brandom_port%7D%22%0A%20%20%20%20exit_code%3D%24(timeout%202s%20nc%20-l%20%22%24%7Bip%7D%22%20%24%7Brandom_port%7D%3B%20echo%20%24%3F)%0A%20%20%20%20if%20%5B%5B%20exit_code%20-eq%20124%20%5D%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22Address%20bound%20successfully%22%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20%20%20sleep%201%0A%20%20%20%20((%20retries--%20))%0A%20%20done%0A%20%20if%20%5B%5B%20%24%7Bretries%7D%20-eq%200%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22Failed%20to%20bind%20ip%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%7D%0A%0A%23%20Get%20interface%20that%20matches%20ip%20from%20node%20ip%20hint%20file%0A%23%20in%20case%20file%20not%20exists%20return%20nothing%20and%0A%23%20fallback%20to%20default%20interface%20search%20flow%0Aget_nodeip_hint_interface()%20%7B%0A%20%20local%20ip_hint%3D%22%22%0A%20%20local%20ip_hint_file%3D%22%241%22%0A%20%20local%20extra_bridge%3D%22%242%22%0A%20%20local%20iface%3D%22%22%0A%0A%20%20ip_hint%3D%24(get_ip_from_ip_hint_file%20%22%24%7Bip_hint_file%7D%22)%0A%20%20if%20%5B%5B%20-z%20%22%24%7Bip_hint%7D%22%20%20%5D%5D%3B%20then%0A%20%20%20%20return%0A%20%20fi%0A%0A%20%20iface%3D%24(ip%20-j%20addr%20%7C%20jq%20-r%20%22first(.%5B%5D%20%7C%20select(any(.addr_info%5B%5D%3B%20.local%3D%3D%5C%22%24%7Bip_hint%7D%5C%22)%20and%20.ifname!%3D%5C%22br-ex1%5C%22%20and%20.ifname!%3D%5C%22%24%7Bextra_bridge%7D%5C%22))%20%7C%20.ifname%22)%0A%20%20if%20%5B%5B%20-n%20%22%24%7Biface%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22%24%7Biface%7D%22%0A%20%20fi%0A%7D%0A%0A%23%20Accepts%20parameters%20%24bridge_interface%20(e.g.%20ovs-port-phys0)%0A%23%20Returns%20the%20physical%20interface%20name%20if%20%24bridge_interface%20exists%2C%20%22%22%20otherwise%0Aget_bridge_physical_interface()%20%7B%0A%20%20local%20bridge_interface%3D%22%241%22%0A%20%20local%20physical_interface%3D%22%22%0A%20%20physical_interface%3D%24(nmcli%20-g%20connection.interface-name%20conn%20show%20%22%24%7Bbridge_interface%7D%22%202%3E%2Fdev%2Fnull%20%7C%7C%20echo%20%22%22)%0A%20%20echo%20%22%24%7Bphysical_interface%7D%22%0A%7D%0A%0A%23%20Accepts%20parameters%20%24iface_default_hint_file%2C%20%24extra_bridge_file%2C%20%24ip_hint_file%2C%20%24default_bridge_file%0A%23%20Determines%20the%20interface%20to%20be%20used%20for%20br-ex.%20Order%20of%20priority%20is%3A%0A%23%201.%20Use%20the%20user%20specified%20interface%20if%20provided%20in%20the%20default%20bridge%20file%0A%23%202.%20Use%20the%20node%20IP%20hint%20interface%0A%23%203.%20Use%20the%20previously%20selected%20interface%0A%23%204.%20Use%20the%20interface%20detected%20as%20default%20gateway%0A%23%0A%23%20Read%20%24default_bridge_file%20and%20return%20the%20contained%20interface.%20Otherwise%2C%0A%23%20read%20%24ip_hint_file%20and%20return%20the%20interface%20that%20matches%20this%20ip.%20Otherwise%2C%0A%23%20if%20the%20default%20interface%20is%20br-ex%2C%20use%20that%20and%20return.%0A%23%20If%20the%20default%20interface%20is%20not%20br-ex%3A%0A%23%20Check%20if%20there%20is%20a%20valid%20hint%20inside%20%24iface_default_hint_file.%20If%20so%2C%20use%20that%20hint.%0A%23%20If%20there%20is%20no%20valid%20hint%2C%20use%20the%20default%20interface%20that%20we%20found%20during%20the%20step%0A%23%20earlier.%0A%23%20Never%20use%20the%20interface%20that%20is%20provided%20inside%20%24extra_bridge_file%20for%20br-ex1.%0A%23%20Never%20use%20br-ex1.%0A%23%20Write%20the%20default%20interface%20to%20%24iface_default_hint_file%0Aget_default_bridge_interface()%20%7B%0A%20%20local%20iface%3D%22%22%0A%20%20local%20counter%3D0%0A%20%20local%20iface_default_hint_file%3D%22%241%22%0A%20%20local%20extra_bridge_file%3D%22%242%22%0A%20%20local%20ip_hint_file%3D%22%243%22%0A%20%20local%20default_bridge_file%3D%22%244%22%0A%20%20local%20extra_bridge%3D%22%22%0A%0A%20%20if%20%5B%20-f%20%22%24%7Bextra_bridge_file%7D%22%20%5D%3B%20then%0A%20%20%20%20extra_bridge%3D%24(cat%20%24%7Bextra_bridge_file%7D)%0A%20%20fi%0A%0A%20%20%23%20try%20to%20use%20user%20specified%20file%20first%0A%20%20if%20%5B%20-f%20%22%24default_bridge_file%22%20%5D%3B%20then%0A%20%20%20%20iface%3D%24(cat%20%22%24%7Bdefault_bridge_file%7D%22)%0A%20%20%20%20if%20%5B%20-z%20%22%24iface%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22ERROR%3A%20User%20specified%20bridge%20file%20detected%20without%20any%20data%22%0A%20%20%20%20%20%20exit%201%0A%20%20%20%20fi%0A%20%20%20%20echo%20%22%24%7Biface%7D%22%0A%20%20%20%20return%0A%20%20fi%0A%0A%20%20%23%20if%20node%20ip%20was%20set%2C%20we%20should%20search%20for%20interface%20that%20matches%20it%0A%20%20iface%3D%24(get_nodeip_hint_interface%20%22%24%7Bip_hint_file%7D%22%20%22%24%7Bextra_bridge%7D%22)%0A%20%20if%20%5B%5B%20-n%20%22%24%7Biface%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22%24%7Biface%7D%22%0A%20%20%20%20return%0A%20%20fi%0A%0A%20%20%23%20find%20default%20interface%0A%20%20%23%20the%20default%20interface%20might%20be%20br-ex%2C%20so%20check%20this%20before%20looking%20at%20the%20hint%0A%20%20while%20%5B%20%24%7Bcounter%7D%20-lt%2012%20%5D%3B%20do%0A%20%20%20%20%23%20check%20ipv4%0A%20%20%20%20%23%20never%20use%20the%20interface%20that's%20specified%20in%20extra_bridge_file%0A%20%20%20%20%23%20never%20use%20br-ex1%0A%20%20%20%20if%20%5B%20%22%24%7Bextra_bridge%7D%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20iface%3D%24(ip%20route%20show%20default%20%7C%20grep%20-v%20%22br-ex1%22%20%7C%20grep%20-v%20%22%24%7Bextra_bridge%7D%22%20%7C%20awk%20'%7B%20if%20(%244%20%3D%3D%20%22dev%22)%20%7B%20print%20%245%3B%20exit%20%7D%20%7D')%0A%20%20%20%20else%0A%20%20%20%20%20%20iface%3D%24(ip%20route%20show%20default%20%7C%20grep%20-v%20%22br-ex1%22%20%7C%20awk%20'%7B%20if%20(%244%20%3D%3D%20%22dev%22)%20%7B%20print%20%245%3B%20exit%20%7D%20%7D')%0A%20%20%20%20fi%0A%20%20%20%20if%20%5B%5B%20-n%20%22%24%7Biface%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20%20%20%23%20check%20ipv6%0A%20%20%20%20%23%20never%20use%20the%20interface%20that's%20specified%20in%20extra_bridge_file%0A%20%20%20%20%23%20never%20use%20br-ex1%0A%20%20%20%20if%20%5B%20%22%24%7Bextra_bridge%7D%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20iface%3D%24(ip%20-6%20route%20show%20default%20%7C%20grep%20-v%20%22br-ex1%22%20%7C%20grep%20-v%20%22%24%7Bextra_bridge%7D%22%20%7C%20awk%20'%7B%20if%20(%244%20%3D%3D%20%22dev%22)%20%7B%20print%20%245%3B%20exit%20%7D%20%7D')%0A%20%20%20%20else%0A%20%20%20%20%20%20iface%3D%24(ip%20-6%20route%20show%20default%20%7C%20grep%20-v%20%22br-ex1%22%20%7C%20awk%20'%7B%20if%20(%244%20%3D%3D%20%22dev%22)%20%7B%20print%20%245%3B%20exit%20%7D%20%7D')%0A%20%20%20%20fi%0A%20%20%20%20if%20%5B%5B%20-n%20%22%24%7Biface%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20%20%20counter%3D%24((counter%2B1))%0A%20%20%20%20sleep%205%0A%20%20done%0A%0A%20%20%23%20if%20the%20default%20interface%20does%20not%20point%20out%20of%20br-ex%20or%20br-ex1%0A%20%20if%20%5B%20%22%24%7Biface%7D%22%20!%3D%20%22br-ex%22%20%5D%20%26%26%20%5B%20%22%24%7Biface%7D%22%20!%3D%20%22br-ex1%22%20%5D%3B%20then%0A%20%20%20%20%23%20determine%20if%20an%20interface%20default%20hint%20exists%20from%20a%20previous%20run%0A%20%20%20%20%23%20and%20if%20the%20interface%20has%20a%20valid%20default%20route%0A%20%20%20%20iface_default_hint%3D%24(get_iface_default_hint%20%22%24%7Biface_default_hint_file%7D%22)%0A%20%20%20%20if%20%5B%20%22%24%7Biface_default_hint%7D%22%20!%3D%20%22%22%20%5D%20%26%26%0A%20%20%20%20%20%20%20%20%5B%20%22%24%7Biface_default_hint%7D%22%20!%3D%20%22%24%7Biface%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%23%20start%20wherever%20count%20left%20off%20in%20the%20previous%20loop%0A%20%20%20%20%20%20%23%20allow%20this%20for%20one%20more%20iteration%20than%20the%20previous%20loop%0A%20%20%20%20%20%20while%20%5B%20%24%7Bcounter%7D%20-le%2012%20%5D%3B%20do%0A%20%20%20%20%20%20%20%20%23%20check%20ipv4%0A%20%20%20%20%20%20%20%20if%20%5B%20%22%24(ip%20route%20show%20default%20dev%20%22%24%7Biface_default_hint%7D%22)%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20iface%3D%22%24%7Biface_default_hint%7D%22%0A%20%20%20%20%20%20%20%20%20%20break%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20%23%20check%20ipv6%0A%20%20%20%20%20%20%20%20if%20%5B%20%22%24(ip%20-6%20route%20show%20default%20dev%20%22%24%7Biface_default_hint%7D%22)%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20iface%3D%22%24%7Biface_default_hint%7D%22%0A%20%20%20%20%20%20%20%20%20%20break%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20counter%3D%24((counter%2B1))%0A%20%20%20%20%20%20%20%20sleep%205%0A%20%20%20%20%20%20done%0A%20%20%20%20fi%0A%20%20%20%20%23%20store%20what%20was%20determined%20was%20the%20(new)%20default%20interface%20inside%0A%20%20%20%20%23%20the%20default%20hint%20file%20for%20future%20reference%0A%20%20%20%20if%20%5B%20%22%24%7Biface%7D%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20write_iface_default_hint%20%22%24%7Biface_default_hint_file%7D%22%20%22%24%7Biface%7D%22%0A%20%20%20%20fi%0A%20%20fi%0A%20%20echo%20%22%24%7Biface%7D%22%0A%7D%0A%0A%23%20Used%20to%20print%20network%20state%0Aprint_state()%20%7B%0A%20%20echo%20%22Current%20device%2C%20connection%2C%20interface%20and%20routing%20state%3A%22%0A%20%20nmcli%20-g%20all%20device%20%7C%20grep%20-v%20unmanaged%0A%20%20nmcli%20-g%20all%20connection%0A%20%20ip%20-d%20address%20show%0A%20%20ip%20route%20show%0A%20%20ip%20-6%20route%20show%0A%7D%0A%0A%23%20Setup%20an%20exit%20trap%20to%20rollback%20on%20error%0Ahandle_exit()%20%7B%0A%20%20e%3D%24%3F%0A%20%20tdir%3D%24(mktemp%20-u%20-d%20-t%20%22configure-ovs-%24(date%20%2B%25Y-%25m-%25d-%25H-%25M-%25S)-XXXXXXXXXX%22)%0A%20%20%0A%20%20if%20%5B%20%24e%20-eq%200%20%5D%3B%20then%0A%20%20%20%20print_state%0A%20%20%20%20%23%20remove%20previous%20troubleshooting%20information%0A%20%20%20%20rm%20-rf%20%22%24(dirname%20%22%24tdir%22)%2Fconfigure-ovs-*%22%0A%20%20%20%20exit%200%0A%20%20fi%0A%0A%20%20echo%20%22ERROR%3A%20configure-ovs%20exited%20with%20error%3A%20%24e%22%0A%20%20print_state%0A%0A%20%20%23%20remove%20previous%20troubleshooting%20information%20except%20the%20oldest%20one%0A%20%20mapfile%20-t%20tdirs%20%3C%20%3C(compgen%20-G%20%22%24(dirname%20%22%24tdir%22)%2Fconfigure-ovs-*%22)%0A%20%20unset%20-v%20%22tdirs%5B0%5D%22%0A%20%20for%20dir%20in%20%22%24%7Btdirs%5B%40%5D%7D%22%3B%20do%20rm%20-rf%20%22%24dir%22%3B%20done%0A%0A%20%20%23%20copy%20configuration%20to%20tmp%20for%20troubleshooting%0A%20%20mkdir%20-p%20%22%24tdir%22%0A%20%20update_nm_conn_run_files%20br-ex%20phys0%0A%20%20copy_nm_conn_files%20%22%24tdir%22%0A%20%20update_nm_conn_run_files%20br-ex1%20phys1%0A%20%20copy_nm_conn_files%20%22%24tdir%22%0A%20%20echo%20%22Copied%20OVS%20configuration%20to%20%24tdir%20for%20troubleshooting%22%0A%0A%20%20%23%20attempt%20to%20restore%20the%20previous%20network%20state%0A%20%20echo%20%22Attempting%20to%20restore%20previous%20configuration...%22%0A%20%20rollback_nm%0A%20%20print_state%0A%0A%20%20exit%20%24e%0A%7D%0A%0A%23%20Setup%20a%20signal%20trap%20to%20rollback%0Ahandle_termination()%20%7B%0A%20%20echo%20%22WARNING%3A%20configure-ovs%20has%20been%20requested%20to%20terminate%2C%20quitting...%22%0A%20%20%0A%20%20%23%20by%20exiting%20with%20an%20error%20we%20will%20cleanup%20after%20ourselves%20in%20a%0A%20%20%23%20subsequent%20call%20to%20handle_exit%0A%20%20exit%201%0A%7D%0A%0A%23%20main%20function%0Aconfigure_ovs()%20%7B%0A%20%20set%20-eu%0A%0A%20%20%23%20setup%20traps%20to%20handle%20signals%20and%20other%20abnormal%20exits%0A%20%20trap%20'handle_termination'%20TERM%20INT%0A%20%20trap%20'handle_exit'%20EXIT%0A%0A%20%20%23%20this%20flag%20tracks%20if%20any%20config%20change%20was%20made%0A%20%20nm_config_changed%3D0%0A%0A%20%20%23%20Check%20that%20we%20are%20provided%20a%20valid%20NM%20connection%20path%0A%20%20if%20%5B%20%22%24NM_CONN_SET_PATH%22%20!%3D%20%22%24NM_CONN_CONF_PATH%22%20%5D%20%26%26%20%5B%20%22%24NM_CONN_SET_PATH%22%20!%3D%20%22%24NM_CONN_RUN_PATH%22%20%5D%3B%20then%0A%20%20%20%20echo%20%22Error%3A%20Incorrect%20NM%20connection%20path%3A%20%24NM_CONN_SET_PATH%20is%20not%20%24NM_CONN_CONF_PATH%20nor%20%24NM_CONN_RUN_PATH%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%0A%20%20%23%20Clean%20up%20old%20config%20on%20behalf%20of%20mtu-migration%0A%20%20if%20!%20systemctl%20-q%20is-enabled%20mtu-migration%3B%20then%0A%20%20%20%20echo%20%22Cleaning%20up%20left%20over%20mtu%20migration%20configuration%22%0A%20%20%20%20rm%20-rf%20%2Fetc%2Fcno%2Fmtu-migration%0A%20%20fi%0A%0A%20%20if%20!%20rpm%20-qa%20%7C%20grep%20-q%20openvswitch%3B%20then%0A%20%20%20%20echo%20%22WARNING%3A%20Openvswitch%20package%20is%20not%20installed!%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%0A%20%20%23%20print%20initial%20state%0A%20%20print_state%0A%0A%20%20if%20%5B%20%22%241%22%20%3D%3D%20%22OVNKubernetes%22%20%5D%3B%20then%0A%20%20%20%20%23%20Configures%20NICs%20onto%20OVS%20bridge%20%22br-ex%22%0A%20%20%20%20%23%20Configuration%20is%20either%20auto-detected%20or%20provided%20through%20a%20config%20file%20written%20already%20in%20Network%20Manager%0A%20%20%20%20%23%20key%20files%20under%20%2Fetc%2FNetworkManager%2Fsystem-connections%2F%0A%20%20%20%20%23%20Managing%20key%20files%20is%20outside%20of%20the%20scope%20of%20this%20script%0A%0A%20%20%20%20%23%20if%20the%20interface%20is%20of%20type%20vmxnet3%20add%20multicast%20capability%20for%20that%20driver%0A%20%20%20%20%23%20History%3A%20BZ%3A1854355%0A%20%20%20%20function%20configure_driver_options%20%7B%0A%20%20%20%20%20%20intf%3D%241%0A%20%20%20%20%20%20if%20%5B%20!%20-f%20%22%2Fsys%2Fclass%2Fnet%2F%24%7Bintf%7D%2Fdevice%2Fuevent%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22Device%20file%20doesn't%20exist%2C%20skipping%20setting%20multicast%20mode%22%0A%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20driver%3D%24(cat%20%22%2Fsys%2Fclass%2Fnet%2F%24%7Bintf%7D%2Fdevice%2Fuevent%22%20%7C%20grep%20DRIVER%20%7C%20awk%20-F%20%22%3D%22%20'%7Bprint%20%242%7D')%0A%20%20%20%20%20%20%20%20echo%20%22Driver%20name%20is%22%20%24driver%0A%20%20%20%20%20%20%20%20if%20%5B%20%22%24driver%22%20%3D%20%22vmxnet3%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20ip%20link%20set%20dev%20%22%24%7Bintf%7D%22%20allmulticast%20on%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20fi%0A%20%20%20%20%7D%0A%0A%20%20%20%20ovnk_config_dir%3D'%2Fetc%2Fovnk'%0A%20%20%20%20ovnk_var_dir%3D'%2Fvar%2Flib%2Fovnk'%0A%20%20%20%20extra_bridge_file%3D%22%24%7Bovnk_config_dir%7D%2Fextra_bridge%22%0A%20%20%20%20iface_default_hint_file%3D%22%24%7Bovnk_var_dir%7D%2Fiface_default_hint%22%0A%20%20%20%20ip_hint_file%3D%22%2Frun%2Fnodeip-configuration%2Fprimary-ip%22%0A%20%20%20%20%23%20explicitly%20specify%20which%20interface%20should%20be%20used%20with%20the%20default%20bridge%0A%20%20%20%20default_bridge_file%3D%22%24%7Bovnk_config_dir%7D%2Fdefault_bridge%22%0A%0A%20%20%20%20%23%20make%20sure%20to%20create%20ovnk_config_dir%20if%20it%20does%20not%20exist%2C%20yet%0A%20%20%20%20mkdir%20-p%20%22%24%7Bovnk_config_dir%7D%22%0A%20%20%20%20%23%20make%20sure%20to%20create%20ovnk_var_dir%20if%20it%20does%20not%20exist%2C%20yet%0A%20%20%20%20mkdir%20-p%20%22%24%7Bovnk_var_dir%7D%22%0A%0A%20%20%20%20%23%20For%20upgrade%20scenarios%2C%20make%20sure%20that%20we%20stabilize%20what%20we%20already%20configured%0A%20%20%20%20%23%20before.%20If%20we%20do%20not%20have%20a%20valid%20interface%20hint%2C%20find%20the%20physical%20interface%0A%20%20%20%20%23%20that's%20attached%20to%20ovs-if-phys0.%0A%20%20%20%20%23%20If%20we%20find%20such%20an%20interface%2C%20write%20it%20to%20the%20hint%20file.%0A%20%20%20%20iface_default_hint%3D%24(get_iface_default_hint%20%22%24%7Biface_default_hint_file%7D%22)%0A%20%20%20%20if%20%5B%20%22%24%7Biface_default_hint%7D%22%20%3D%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20current_interface%3D%24(get_bridge_physical_interface%20ovs-if-phys0)%0A%20%20%20%20%20%20if%20%5B%20%22%24%7Bcurrent_interface%7D%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20write_iface_default_hint%20%22%24%7Biface_default_hint_file%7D%22%20%22%24%7Bcurrent_interface%7D%22%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20delete%20iface_default_hint_file%20if%20it%20has%20the%20same%20content%20as%20extra_bridge_file%0A%20%20%20%20%23%20in%20that%20case%2C%20we%20must%20also%20force%20a%20reconfiguration%20of%20our%20network%20interfaces%0A%20%20%20%20%23%20to%20make%20sure%20that%20we%20reconcile%20this%20conflict%0A%20%20%20%20if%20%5B%20-f%20%22%24%7Biface_default_hint_file%7D%22%20%5D%20%26%26%0A%20%20%20%20%20%20%5B%20-f%20%22%24%7Bextra_bridge_file%7D%22%20%5D%20%26%26%0A%20%20%20%20%20%20%5B%20%22%24(cat%20%22%24%7Biface_default_hint_file%7D%22)%22%20%3D%3D%20%22%24(cat%20%22%24%7Bextra_bridge_file%7D%22)%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22%24%7Biface_default_hint_file%7D%20and%20%24%7Bextra_bridge_file%7D%20share%20the%20same%20content%22%0A%20%20%20%20%20%20echo%20%22Deleting%20file%20%24%7Biface_default_hint_file%7D%20to%20choose%20a%20different%20interface%22%0A%20%20%20%20%20%20rm%20-f%20%22%24%7Biface_default_hint_file%7D%22%0A%20%20%20%20%20%20rm%20-f%20%2Frun%2Fconfigure-ovs-boot-done%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20on%20every%20boot%20we%20rollback%20and%20generate%20the%20configuration%20again%2C%20to%20take%0A%20%20%20%20%23%20in%20any%20changes%20that%20have%20possibly%20been%20applied%20in%20the%20standard%0A%20%20%20%20%23%20configuration%20sources%0A%20%20%20%20if%20%5B%20!%20-f%20%2Frun%2Fconfigure-ovs-boot-done%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22Running%20on%20boot%2C%20restoring%20previous%20configuration%20before%20proceeding...%22%0A%20%20%20%20%20%20rollback_nm%0A%20%20%20%20%20%20print_state%0A%20%20%20%20fi%0A%20%20%20%20touch%20%2Frun%2Fconfigure-ovs-boot-done%0A%0A%20%20%20%20iface%3D%24(get_default_bridge_interface%20%22%24%7Biface_default_hint_file%7D%22%20%22%24%7Bextra_bridge_file%7D%22%20%22%24%7Bip_hint_file%7D%22%20%22%24%7Bdefault_bridge_file%7D%22)%0A%0A%20%20%20%20if%20%5B%20%22%24iface%22%20!%3D%20%22br-ex%22%20%5D%3B%20then%0A%20%20%20%20%20%20%23%20Specified%20interface%20is%20not%20br-ex.%0A%20%20%20%20%20%20%23%20Some%20deployments%20use%20a%20temporary%20solution%20where%20br-ex%20is%20moved%20out%20from%20the%20default%20gateway%20interface%0A%20%20%20%20%20%20%23%20and%20bound%20to%20a%20different%20nic%20(https%3A%2F%2Fgithub.com%2Ftrozet%2Fopenshift-ovn-migration).%0A%20%20%20%20%20%20%23%20This%20is%20now%20supported%20through%20an%20extra%20bridge%20if%20requested.%20If%20that%20is%20the%20case%2C%20we%20rollback.%0A%20%20%20%20%20%20%23%20We%20also%20rollback%20if%20it%20looks%20like%20we%20need%20to%20configure%20things%2C%20just%20in%20case%20there%20are%20any%20leftovers%0A%20%20%20%20%20%20%23%20from%20previous%20attempts.%0A%20%20%20%20%20%20if%20%5B%20-f%20%22%24extra_bridge_file%22%20%5D%20%7C%7C%20%5B%20-z%20%22%24(nmcli%20connection%20show%20--active%20br-ex%202%3E%20%2Fdev%2Fnull)%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22Bridge%20br-ex%20is%20not%20active%2C%20restoring%20previous%20configuration%20before%20proceeding...%22%0A%20%20%20%20%20%20%20%20rollback_nm%0A%20%20%20%20%20%20%20%20print_state%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20convert_to_bridge%20%22%24iface%22%20%22br-ex%22%20%22phys0%22%20%22%24%7BBRIDGE_METRIC%7D%22%0A%0A%20%20%20%20%23%20Check%20if%20we%20need%20to%20configure%20the%20second%20bridge%0A%20%20%20%20if%20%5B%20-f%20%22%24extra_bridge_file%22%20%5D%20%26%26%20(!%20nmcli%20connection%20show%20br-ex1%20%26%3E%20%2Fdev%2Fnull%20%7C%7C%20!%20nmcli%20connection%20show%20ovs-if-phys1%20%26%3E%20%2Fdev%2Fnull)%3B%20then%0A%20%20%20%20%20%20interface%3D%24(head%20-n%201%20%24extra_bridge_file)%0A%20%20%20%20%20%20convert_to_bridge%20%22%24interface%22%20%22br-ex1%22%20%22phys1%22%20%22%24%7BBRIDGE1_METRIC%7D%22%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Check%20if%20we%20need%20to%20remove%20the%20second%20bridge%0A%20%20%20%20if%20%5B%20!%20-f%20%22%24extra_bridge_file%22%20%5D%20%26%26%20(nmcli%20connection%20show%20br-ex1%20%26%3E%20%2Fdev%2Fnull%20%7C%7C%20nmcli%20connection%20show%20ovs-if-phys1%20%26%3E%20%2Fdev%2Fnull)%3B%20then%0A%20%20%20%20%20%20remove_ovn_bridges%20br-ex1%20phys1%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Remove%20bridges%20created%20by%20openshift-sdn%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-br%20br0%0A%0A%20%20%20%20%23%20Make%20sure%20everything%20is%20activated.%20Do%20it%20in%20a%20specific%20order%3A%0A%20%20%20%20%23%20-%20activate%20br-ex%20first%2C%20due%20to%20autoconnect-slaves%20this%20will%20also%0A%20%20%20%20%23%20%20%20activate%20ovs-port-br-ex%2C%20ovs-port-phys0%20and%20ovs-if-phys0.%20It%20is%0A%20%20%20%20%23%20%20%20important%20that%20ovs-if-phys0%20activates%20with%20br-ex%20to%20avoid%20the%0A%20%20%20%20%23%20%20%20ovs-if-phys0%20profile%20being%20overridden%20with%20a%20profile%20generated%20from%0A%20%20%20%20%23%20%20%20kargs.%20The%20activation%20of%20ovs-if-phys0%2C%20if%20a%20bond%2C%20might%20cause%20the%0A%20%20%20%20%23%20%20%20slaves%20to%20re-activate%2C%20but%20it%20should%20be%20with%20our%20profiles%20since%20they%0A%20%20%20%20%23%20%20%20have%20higher%20priority%0A%20%20%20%20%23%20-%20make%20sure%20that%20ovs-if-phys0%20and%20its%20slaves%2C%20if%20any%2C%20are%20activated.%0A%20%20%20%20%23%20-%20finally%20activate%20ovs-if-br-ex%20which%20holds%20the%20IP%20configuration.%0A%20%20%20%20connections%3D(br-ex%20ovs-if-phys0)%0A%20%20%20%20if%20%5B%20-f%20%22%24extra_bridge_file%22%20%5D%3B%20then%0A%20%20%20%20%20%20connections%2B%3D(br-ex1%20ovs-if-phys1)%0A%20%20%20%20fi%0A%20%20%20%20while%20IFS%3D%20read%20-r%20connection%3B%20do%0A%20%20%20%20%20%20if%20%5B%5B%20%24connection%20%3D%3D%20*%22%24MANAGED_NM_CONN_SUFFIX%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20connections%2B%3D(%22%24connection%22)%0A%20%20%20%20%20%20fi%0A%20%20%20%20done%20%3C%20%3C(nmcli%20-g%20NAME%20c)%0A%20%20%20%20connections%2B%3D(ovs-if-br-ex)%0A%20%20%20%20if%20%5B%20-f%20%22%24extra_bridge_file%22%20%5D%3B%20then%0A%20%20%20%20%20%20connections%2B%3D(ovs-if-br-ex1)%0A%20%20%20%20fi%0A%20%20%20%20activate_nm_connections%20%22%24%7Bconnections%5B%40%5D%7D%22%0A%20%20%20%20try_to_bind_ipv6_address%0A%20%20%20%20set_nm_conn_files%0A%20%20elif%20%5B%20%22%241%22%20%3D%3D%20%22OpenShiftSDN%22%20%5D%3B%20then%0A%20%20%20%20%23%20Revert%20changes%20made%20by%20%2Fusr%2Flocal%2Fbin%2Fconfigure-ovs.sh%20during%20SDN%20migration.%0A%20%20%20%20rollback_nm%0A%20%20%20%20%0A%20%20%20%20%23%20Remove%20bridges%20created%20by%20ovn-kubernetes%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-br%20br-int%20--%20--if-exists%20del-br%20br-local%0A%20%20fi%0A%7D%0A%0A%23%20Retry%20configure_ovs%20until%20it%20succeeds.%0A%23%20By%20default%2C%20retry%20every%2015%20minutes%20to%20give%20enough%20time%20to%20gather%0A%23%20troubleshooting%20information%20in%20between.%20Note%20that%20configure_ovs%20has%20other%0A%23%20internal%20retry%20mechanisms.%20This%20retry%20is%20intended%20to%20give%20some%0A%23%20self-healing%20capabilities%20to%20temporary%20but%20not%20necessarily%20short-lived%0A%23%20infrastructure%20problems.%0ARETRY%3D%22%24%7BRETRY-15m%7D%22%0Awhile%20true%3B%20do%0A%0A%20%20%23%20Disable%20retries%20if%20termination%20signal%20is%20received.%20Note%20that%20systemd%0A%20%20%23%20sends%20the%20signals%20to%20all%20processes%20in%20the%20group%20by%20default%20so%20we%20expect%0A%20%20%23%20configure_ovs%20to%20get%20its%20own%20signals.%0A%20%20trap%20'echo%20%22WARNING%3A%20termination%20requested%2C%20disabling%20retries%22%3B%20RETRY%3D%22%22'%20INT%20TERM%0A%20%20%0A%20%20%23%20Run%20configure_ovs%20in%20a%20sub-shell.%20%0A%20%20(%20configure_ovs%20%22%24%40%22%20)%0A%20%20e%3D%24%3F%0A%0A%20%20%23%20Handle%20signals%20while%20we%20sleep%0A%20%20trap%20'handle_termination'%20INT%20TERM%0A%20%20%0A%20%20%23%20Exit%20if%20succesful%20and%20not%20configured%20to%20retry%0A%20%20%5B%20%22%24e%22%20-eq%200%20%5D%20%7C%7C%20%5B%20-z%20%22%24RETRY%22%20%5D%20%26%26%20exit%20%22%24e%22%0A%20%20%0A%20%20echo%20%22configure-ovs%20failed%2C%20will%20retry%20after%20%24RETRY%22%0A%20%20%23%20flag%20that%20a%20retry%20has%20happened%0A%20%20touch%20%2Ftmp%2Fconfigure-ovs-retry%0A%20%20sleep%20%22%24RETRY%22%0A%0Adone%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/configure-ovs.sh
        - contents:
            source: data:,%23%20This%20file%20is%20generated%20by%20the%20Machine%20Config%20Operator's%20containerruntimeconfig%20controller.%0A%23%0A%23%20storage.conf%20is%20the%20configuration%20file%20for%20all%20tools%0A%23%20that%20share%20the%20containers%2Fstorage%20libraries%0A%23%20See%20man%205%20containers-storage.conf%20for%20more%20information%0A%23%20The%20%22container%20storage%22%20table%20contains%20all%20of%20the%20server%20options.%0A%5Bstorage%5D%0A%0A%23%20Default%20storage%20driver%2C%20must%20be%20set%20for%20proper%20operation.%0Adriver%20%3D%20%22overlay%22%0A%0A%23%20Temporary%20storage%20location%0Arunroot%20%3D%20%22%2Frun%2Fcontainers%2Fstorage%22%0A%0A%23%20Primary%20Read%2FWrite%20location%20of%20container%20storage%0Agraphroot%20%3D%20%22%2Fvar%2Flib%2Fcontainers%2Fstorage%22%0A%0A%5Bstorage.options%5D%0A%23%20Storage%20options%20to%20be%20passed%20to%20underlying%20storage%20drivers%0A%0A%23%20AdditionalImageStores%20is%20used%20to%20pass%20paths%20to%20additional%20Read%2FOnly%20image%20stores%0A%23%20Must%20be%20comma%20separated%20list.%0Aadditionalimagestores%20%3D%20%5B%0A%5D%0A%0A%23%20Remap-UIDs%2FGIDs%20is%20the%20mapping%20from%20UIDs%2FGIDs%20as%20they%20should%20appear%20inside%20of%0A%23%20a%20container%2C%20to%20UIDs%2FGIDs%20as%20they%20should%20appear%20outside%20of%20the%20container%2C%20and%0A%23%20the%20length%20of%20the%20range%20of%20UIDs%2FGIDs.%20%20Additional%20mapped%20sets%20can%20be%20listed%0A%23%20and%20will%20be%20heeded%20by%20libraries%2C%20but%20there%20are%20limits%20to%20the%20number%20of%0A%23%20mappings%20which%20the%20kernel%20will%20allow%20when%20you%20later%20attempt%20to%20run%20a%0A%23%20container.%0A%23%0A%23%20remap-uids%20%3D%200%3A1668442479%3A65536%0A%23%20remap-gids%20%3D%200%3A1668442479%3A65536%0A%0A%23%20Remap-User%2FGroup%20is%20a%20name%20which%20can%20be%20used%20to%20look%20up%20one%20or%20more%20UID%2FGID%0A%23%20ranges%20in%20the%20%2Fetc%2Fsubuid%20or%20%2Fetc%2Fsubgid%20file.%20%20Mappings%20are%20set%20up%20starting%0A%23%20with%20an%20in-container%20ID%20of%200%20and%20the%20a%20host-level%20ID%20taken%20from%20the%20lowest%0A%23%20range%20that%20matches%20the%20specified%20name%2C%20and%20using%20the%20length%20of%20that%20range.%0A%23%20Additional%20ranges%20are%20then%20assigned%2C%20using%20the%20ranges%20which%20specify%20the%0A%23%20lowest%20host-level%20IDs%20first%2C%20to%20the%20lowest%20not-yet-mapped%20container-level%20ID%2C%0A%23%20until%20all%20of%20the%20entries%20have%20been%20used%20for%20maps.%20This%20setting%20overrides%20the%0A%23%20Remap-UIDs%2FGIDs%20setting.%0A%23%0A%23%20remap-user%20%3D%20%22storage%22%0A%23%20remap-group%20%3D%20%22storage%22%0A%0A%5Bstorage.options.pull_options%5D%0A%23%20Options%20controlling%20how%20storage%20is%20populated%20when%20pulling%20images.%0A%0A%23%20Enable%20the%20%22zstd%3Achunked%22%20feature%2C%20which%20allows%20partial%20pulls%2C%20reusing%0A%23%20content%20that%20already%20exists%20on%20the%20system.%20This%20is%20disabled%20by%20default%2C%0A%23%20and%20must%20be%20explicitly%20enabled%20to%20be%20used.%20For%20more%20on%20zstd%3Achunked%2C%20see%0A%23%20https%3A%2F%2Fgithub.com%2Fcontainers%2Fstorage%2Fblob%2Fmain%2Fdocs%2Fcontainers-storage-zstd-chunked.md%0Aenable_partial_images%20%3D%20%22false%22%0A%0A%23%20Tells%20containers%2Fstorage%20to%20use%20hard%20links%20rather%20then%20create%20new%20files%20in%0A%23%20the%20image%2C%20if%20an%20identical%20file%20already%20existed%20in%20storage.%0Ause_hard_links%20%3D%20%22false%22%0A%0A%23%20Path%20to%20an%20ostree%20repository%20that%20might%20have%0A%23%20previously%20pulled%20content%20which%20can%20be%20used%20when%20attempting%20to%20avoid%0A%23%20pulling%20content%20from%20the%20container%20registry.%0Aostree_repos%20%3D%20%22%22%0A%0A%5Bstorage.options.overlay%5D%0A%23%20Storage%20Options%20for%20overlay%0A%0A%23%20Do%20not%20create%20a%20PRIVATE%20bind%20mount%20on%20the%20home%20directory.%0Askip_mount_home%20%3D%20%22true%22%0A%0A%23%20Size%20is%20used%20to%20set%20a%20maximum%20size%20of%20the%20container%20image.%20%20Only%20supported%20by%0A%23%20certain%20container%20storage%20drivers.%0Asize%20%3D%20%22%22%0A
          mode: 420
          overwrite: true
          path: /etc/containers/storage.conf
        - contents:
            source: data:,.%20%7B%0A%20%20%20%20errors%0A%20%20%20%20bufsize%20512%0A%20%20%20%20health%20%3A18080%0A%20%20%20%20forward%20.%20%7B%7B-%20range%20%24upstream%20%3A%3D%20.DNSUpstreams%7D%7D%20%7B%7B%24upstream%7D%7D%7B%7B-%20end%7D%7D%20%7B%0A%20%20%20%20%20%20%20%20policy%20sequential%0A%20%20%20%20%7D%0A%20%20%20%20cache%2030%0A%20%20%20%20reload%0A%20%20%20%20template%20IN%20%7B%7B%20.Cluster.IngressVIPRecordType%20%7D%7D%20comp-poc-rh01.rhpoc.int%20%7B%0A%20%20%20%20%20%20%20%20match%20.*%5B.%5Dapps.comp-poc-rh01.rhpoc.int%0A%20%20%20%20%20%20%20%20answer%20%22%7B%7B%22%7B%7B%20.Name%20%7D%7D%22%7D%7D%2060%20in%20%7B%7B%22%7B%7B%20.Type%20%7D%7D%22%7D%7D%2010.100.0.51%22%0A%20%20%20%20%20%20%20%20fallthrough%0A%20%20%20%20%7D%0A%20%20%20%20template%20IN%20%7B%7B%20.Cluster.IngressVIPEmptyType%20%7D%7D%20comp-poc-rh01.rhpoc.int%20%7B%0A%20%20%20%20%20%20%20%20match%20.*%5B.%5Dapps.comp-poc-rh01.rhpoc.int%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20fallthrough%0A%20%20%20%20%7D%0A%20%20%20%20template%20IN%20%7B%7B%20.Cluster.APIVIPRecordType%20%7D%7D%20comp-poc-rh01.rhpoc.int%20%7B%0A%20%20%20%20%20%20%20%20match%20%5Eapi.comp-poc-rh01.rhpoc.int%0A%20%20%20%20%20%20%20%20answer%20%22%7B%7B%22%7B%7B%20.Name%20%7D%7D%22%7D%7D%2060%20in%20%7B%7B%22%7B%7B%20.Type%20%7D%7D%22%7D%7D%2010.100.0.50%22%0A%20%20%20%20%20%20%20%20fallthrough%0A%20%20%20%20%7D%0A%20%20%20%20template%20IN%20%7B%7B%20.Cluster.APIVIPEmptyType%20%7D%7D%20comp-poc-rh01.rhpoc.int%20%7B%0A%20%20%20%20%20%20%20%20match%20%5Eapi.comp-poc-rh01.rhpoc.int%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20fallthrough%0A%20%20%20%20%7D%0A%20%20%20%20template%20IN%20%7B%7B%20.Cluster.APIVIPRecordType%20%7D%7D%20comp-poc-rh01.rhpoc.int%20%7B%0A%20%20%20%20%20%20%20%20match%20%5Eapi-int.comp-poc-rh01.rhpoc.int%0A%20%20%20%20%20%20%20%20answer%20%22%7B%7B%22%7B%7B%20.Name%20%7D%7D%22%7D%7D%2060%20in%20%7B%7B%22%7B%7B%20.Type%20%7D%7D%22%7D%7D%2010.100.0.50%22%0A%20%20%20%20%20%20%20%20fallthrough%0A%20%20%20%20%7D%0A%20%20%20%20template%20IN%20%7B%7B%20.Cluster.APIVIPEmptyType%20%7D%7D%20comp-poc-rh01.rhpoc.int%20%7B%0A%20%20%20%20%20%20%20%20match%20%5Eapi-int.comp-poc-rh01.rhpoc.int%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20fallthrough%0A%20%20%20%20%7D%0A%20%20%20%20hosts%20%7B%0A%20%20%20%20%20%20%20%20%7B%7B-%20range%20.Cluster.NodeAddresses%20%7D%7D%0A%20%20%20%20%20%20%20%20%7B%7B%20.Address%20%7D%7D%20%7B%7B%20.Name%20%7D%7D%20%7B%7B%20.Name%20%7D%7D.%7B%7B%20%24.Cluster.Name%20%7D%7D.%7B%7B%20%24.Cluster.Domain%20%7D%7D%0A%20%20%20%20%20%20%20%20%7B%7B-%20end%20%7D%7D%0A%20%20%20%20%20%20%20%20fallthrough%0A%20%20%20%20%7D%0A%7D%0A
          mode: 420
          overwrite: true
          path: /etc/kubernetes/static-pod-resources/coredns/Corefile.tmpl
        - contents:
            source: data:,kind%3A%20Pod%0AapiVersion%3A%20v1%0Ametadata%3A%0A%20%20name%3A%20coredns%0A%20%20namespace%3A%20openshift-kni-infra%0A%20%20creationTimestamp%3A%0A%20%20deletionGracePeriodSeconds%3A%2065%0A%20%20labels%3A%0A%20%20%20%20app%3A%20kni-infra-coredns%0A%20%20annotations%3A%0A%20%20%20%20target.workload.openshift.io%2Fmanagement%3A%20'%7B%22effect%22%3A%20%22PreferredDuringScheduling%22%7D'%0A%20%20%20%20openshift.io%2Frequired-scc%3A%20privileged%0Aspec%3A%0A%20%20volumes%3A%0A%20%20-%20name%3A%20resource-dir%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fetc%2Fkubernetes%2Fstatic-pod-resources%2Fcoredns%22%0A%20%20-%20name%3A%20kubeconfig%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20-%20name%3A%20conf-dir%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fetc%2Fcoredns%22%0A%20%20-%20name%3A%20nm-resolv%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fvar%2Frun%2FNetworkManager%22%0A%20%20-%20name%3A%20nodeip-configuration%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Frun%2Fnodeip-configuration%22%0A%20%20initContainers%3A%0A%20%20-%20name%3A%20render-config-coredns%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A93e7b8c870261726d44bddc7ba0a702d3720d1838141dac837fb8c3be7c6e1a1%0A%20%20%20%20command%3A%0A%20%20%20%20-%20runtimecfg%0A%20%20%20%20-%20render%0A%20%20%20%20-%20%22%2Fvar%2Flib%2Fkubelet%2Fkubeconfig%22%0A%20%20%20%20-%20%22--api-vips%22%0A%20%20%20%20-%20%2210.100.0.50%22%0A%20%20%20%20-%20%22--ingress-vips%22%0A%20%20%20%20-%20%2210.100.0.51%22%0A%20%20%20%20-%20%22%2Fconfig%22%0A%20%20%20%20-%20%22--out-dir%22%0A%20%20%20%20-%20%22%2Fetc%2Fcoredns%22%0A%20%20%20%20-%20%22--resolvconf-path%22%0A%20%20%20%20-%20%22%2Fvar%2Frun%2FNetworkManager%2Fresolv.conf%22%0A%20%20%20%20resources%3A%20%7B%7D%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20kubeconfig%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20resource-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fconfig%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20conf-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fcoredns%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20nm-resolv%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Frun%2FNetworkManager%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20nodeip-configuration%0A%20%20%20%20%20%20mountPath%3A%20%22%2Frun%2Fnodeip-configuration%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20imagePullPolicy%3A%20IfNotPresent%0A%20%20containers%3A%0A%20%20-%20name%3A%20coredns%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A4f6294ed30ab476019aaaa77874157facc77413988f82ffc46f94d3a98d2e4f1%0A%20%20%20%20args%3A%0A%20%20%20%20-%20%22--conf%22%0A%20%20%20%20-%20%22%2Fetc%2Fcoredns%2FCorefile%22%0A%20%20%20%20resources%3A%0A%20%20%20%20%20%20requests%3A%0A%20%20%20%20%20%20%20%20cpu%3A%20100m%0A%20%20%20%20%20%20%20%20memory%3A%20200Mi%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20conf-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fcoredns%22%0A%20%20%20%20-%20name%3A%20nodeip-configuration%0A%20%20%20%20%20%20mountPath%3A%20%22%2Frun%2Fnodeip-configuration%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20livenessProbe%3A%0A%20%20%20%20%20%20httpGet%3A%0A%20%20%20%20%20%20%20%20path%3A%20%2Fhealth%0A%20%20%20%20%20%20%20%20port%3A%2018080%0A%20%20%20%20%20%20%20%20scheme%3A%20HTTP%0A%20%20%20%20%20%20initialDelaySeconds%3A%2060%0A%20%20%20%20%20%20timeoutSeconds%3A%205%0A%20%20%20%20%20%20successThreshold%3A%201%0A%20%20%20%20%20%20failureThreshold%3A%205%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20imagePullPolicy%3A%20IfNotPresent%0A%20%20-%20name%3A%20coredns-monitor%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A93e7b8c870261726d44bddc7ba0a702d3720d1838141dac837fb8c3be7c6e1a1%0A%20%20%20%20command%3A%0A%20%20%20%20-%20corednsmonitor%0A%20%20%20%20-%20%22%2Fvar%2Flib%2Fkubelet%2Fkubeconfig%22%0A%20%20%20%20-%20%22%2Fconfig%2FCorefile.tmpl%22%0A%20%20%20%20-%20%22%2Fetc%2Fcoredns%2FCorefile%22%0A%20%20%20%20-%20%22--api-vips%22%0A%20%20%20%20-%20%2210.100.0.50%22%0A%20%20%20%20-%20%22--ingress-vips%22%0A%20%20%20%20-%20%2210.100.0.51%22%0A%20%20%20%20resources%3A%0A%20%20%20%20%20%20requests%3A%0A%20%20%20%20%20%20%20%20cpu%3A%20100m%0A%20%20%20%20%20%20%20%20memory%3A%20200Mi%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20kubeconfig%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20resource-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fconfig%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20conf-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fcoredns%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20nm-resolv%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Frun%2FNetworkManager%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20nodeip-configuration%0A%20%20%20%20%20%20mountPath%3A%20%22%2Frun%2Fnodeip-configuration%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20imagePullPolicy%3A%20IfNotPresent%0A%20%20hostNetwork%3A%20true%0A%20%20tolerations%3A%0A%20%20-%20operator%3A%20Exists%0A%20%20priorityClassName%3A%20system-node-critical%0Astatus%3A%20%7B%7D%0A
          mode: 420
          overwrite: true
          path: /etc/kubernetes/manifests/coredns.yaml
        - contents:
            source: data:,Initial%20Creation%0A
          mode: 384
          overwrite: true
          path: /etc/docker/certs.d/.create
        - contents:
            source: data:,%23%20Proxy%20environment%20variables%20will%20be%20populated%20in%20this%20file.%20Properly%0A%23%20url%20encoded%20passwords%20with%20special%20characters%20will%20use%20'%25%3CHEX%3E%3CHEX%3E'.%0A%23%20Systemd%20requires%20that%20any%20%25%20used%20in%20a%20password%20be%20represented%20as%0A%23%20%25%25%20in%20a%20unit%20file%20since%20%25%20is%20a%20prefix%20for%20macros%3B%20this%20restriction%20does%20not%0A%23%20apply%20for%20environment%20files.%20Templates%20that%20need%20the%20proxy%20set%20should%20use%0A%23%20'EnvironmentFile%3D%2Fetc%2Fmco%2Fproxy.env'.%0A
          mode: 420
          overwrite: true
          path: /etc/mco/proxy.env
        - contents:
            source: data:,%5BManager%5D%0ADefaultEnvironment%3DGODEBUG%3Dx509ignoreCN%3D0%0A
          mode: 420
          overwrite: true
          path: /etc/systemd/system.conf.d/10-default-env-godebug.conf
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%23%20Workaround%3A%0A%23%20https%3A%2F%2Fissues.redhat.com%2Fbrowse%2FOCPBUGS-38779%0A%0Adriver%3D%24(nmcli%20-t%20-m%20tabular%20-f%20general.driver%20dev%20show%20%22%24%7BDEVICE_IFACE%7D%22)%0A%0Aif%20%5B%5B%20%22%242%22%20%3D%3D%20%22up%22%20%26%26%20%22%24%7Bdriver%7D%22%20%3D%3D%20%22idpf%22%20%5D%5D%3B%20then%0A%20%20ethtool%20-K%20%24%7BDEVICE_IFACE%7D%20tx-checksumming%20off%0Afi
          mode: 484
          overwrite: true
          path: /etc/NetworkManager/dispatcher.d/99-gcp-disable-idpf-tx-checksum-off
        - contents:
            source: data:,global%0A%20%20stats%20socket%20%2Fvar%2Flib%2Fhaproxy%2Frun%2Fhaproxy.sock%20%20mode%20600%20level%20admin%20expose-fd%20listeners%0Adefaults%0A%20%20maxconn%2040000%0A%20%20mode%20%20%20%20tcp%0A%20%20log%20%20%20%20%20%2Fvar%2Frun%2Fhaproxy%2Fhaproxy-log.sock%20local0%20notice%20alert%0A%20%20log-format%20%22%25ci%3A%25cp%20-%3E%20%25fi%3A%25fp%20%5B%25t%5D%20%25ft%20%25b%2F%25s%20%25Tw%2F%25Tc%2F%25Tt%20%25B%20%25ts%20%25ac%2F%25fc%2F%25bc%2F%25sc%2F%25rc%20%25sq%2F%25bq%22%0A%20%20option%20%20dontlognull%0A%20%20retries%203%0A%20%20timeout%20http-request%2030s%0A%20%20timeout%20queue%20%20%20%20%20%20%20%201m%0A%20%20timeout%20connect%20%20%20%20%20%2010s%0A%20%20timeout%20client%20%20%20%20%20%20%2086400s%0A%20%20timeout%20server%20%20%20%20%20%20%2086400s%0A%20%20timeout%20tunnel%20%20%20%20%20%20%2086400s%0A%7B%7B-%20if%20gt%20(len%20.LBConfig.Backends)%200%20%7D%7D%0Afrontend%20%20main%0A%20%20bind%20%3A%3A%3A%7B%7B%20.LBConfig.LbPort%20%7D%7D%20v4v6%0A%20%20default_backend%20masters%0Alisten%20health_check_http_url%0A%20%20bind%20%3A%3A%3A9444%20v4v6%0A%20%20mode%20http%0A%20%20monitor-uri%20%2Fhaproxy_ready%0A%20%20option%20dontlognull%0A%7B%7B-%20end%20%7D%7D%0Alisten%20stats%0A%20%20bind%20localhost%3A%7B%7B%20.LBConfig.StatPort%20%7D%7D%0A%20%20mode%20http%0A%20%20stats%20enable%0A%20%20stats%20hide-version%0A%20%20stats%20uri%20%2Fhaproxy_stats%0A%20%20stats%20refresh%2030s%0A%20%20stats%20auth%20Username%3APassword%0Abackend%20masters%0A%20%20%20timeout%20check%2010s%0A%20%20%20option%20%20httpchk%20GET%20%2Freadyz%20HTTP%2F1.0%0A%20%20%20balance%20roundrobin%0A%7B%7B-%20range%20.LBConfig.Backends%20%7D%7D%0A%20%20%20server%20%7B%7B%20.Host%20%7D%7D%20%7B%7B%20.Address%20%7D%7D%3A%7B%7B%20.Port%20%7D%7D%20weight%201%20verify%20none%20check%20check-ssl%20inter%205s%20fall%203%20rise%201%0A%7B%7B-%20end%20%7D%7D%0A
          mode: 420
          overwrite: true
          path: /etc/kubernetes/static-pod-resources/haproxy/haproxy.cfg.tmpl
        - contents:
            source: data:,kind%3A%20Pod%0AapiVersion%3A%20v1%0Ametadata%3A%0A%20%20name%3A%20haproxy%0A%20%20namespace%3A%20openshift-kni-infra%0A%20%20creationTimestamp%3A%0A%20%20deletionGracePeriodSeconds%3A%2065%0A%20%20labels%3A%0A%20%20%20%20app%3A%20kni-infra-api-lb%0A%20%20annotations%3A%0A%20%20%20%20target.workload.openshift.io%2Fmanagement%3A%20'%7B%22effect%22%3A%20%22PreferredDuringScheduling%22%7D'%0A%20%20%20%20openshift.io%2Frequired-scc%3A%20privileged%0Aspec%3A%0A%20%20volumes%3A%0A%20%20-%20name%3A%20resource-dir%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fetc%2Fkubernetes%2Fstatic-pod-resources%2Fhaproxy%22%0A%20%20-%20name%3A%20kubeconfigvarlib%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20-%20name%3A%20run-dir%0A%20%20%20%20empty-dir%3A%20%7B%7D%0A%20%20-%20name%3A%20conf-dir%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fetc%2Fhaproxy%22%0A%20%20-%20name%3A%20chroot-host%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2F%22%0A%20%20initContainers%3A%0A%20%20-%20name%3A%20verify-api-int-resolvable%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A93e7b8c870261726d44bddc7ba0a702d3720d1838141dac837fb8c3be7c6e1a1%0A%20%20%20%20command%3A%0A%20%20%20%20-%20%22%2Fbin%2Fbash%22%0A%20%20%20%20-%20%22-c%22%0A%20%20%20%20-%20%7C%0A%20%20%20%20%20%20%2Fusr%2Fbin%2Fcurl%20-o%20%2Fdev%2Fnull%20-kLfs%20https%3A%2F%2Fapi-int.comp-poc-rh01.rhpoc.int%3A6443%2Fhealthz%0A%20%20%20%20resources%3A%20%7B%7D%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20chroot-host%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fhost%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20kubeconfigvarlib%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20imagePullPolicy%3A%20IfNotPresent%0A%20%20containers%3A%0A%20%20-%20name%3A%20haproxy%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3Ae1eb49c0c126c193cd035f844746edd98c6c674fdfa6b822d078d4a491b4834d%0A%20%20%20%20env%3A%0A%20%20%20%20%20%20-%20name%3A%20OLD_HAPROXY_PS_FORCE_DEL_TIMEOUT%0A%20%20%20%20%20%20%20%20value%3A%20%22120%22%0A%20%20%20%20command%3A%0A%20%20%20%20-%20%22%2Fbin%2Fbash%22%0A%20%20%20%20-%20%22-c%22%0A%20%20%20%20-%20%7C%0A%20%20%20%20%20%20%23%2Fbin%2Fbash%0A%20%20%20%20%20%20verify_old_haproxy_ps_being_deleted()%0A%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20local%20prev_pids%0A%0A%20%20%20%20%20%20%20%20prev_pids%3D%22%241%22%0A%20%20%20%20%20%20%20%20sleep%20%24OLD_HAPROXY_PS_FORCE_DEL_TIMEOUT%0A%20%20%20%20%20%20%20%20cur_pids%3D%24(pidof%20haproxy)%0A%0A%20%20%20%20%20%20%20%20for%20val%20in%20%24prev_pids%3B%20do%0A%20%20%20%20%20%20%20%20%20%20%20%20if%20%5B%5B%20%24cur_pids%20%3D~%20(%5E%7C%5B%5B%3Aspace%3A%5D%5D)%22%24val%22(%24%7C%5B%5B%3Aspace%3A%5D%5D)%20%5D%5D%20%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20kill%20%24val%0A%20%20%20%20%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20done%0A%20%20%20%20%20%20%7D%0A%0A%20%20%20%20%20%20reload_haproxy()%0A%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20old_pids%3D%24(pidof%20haproxy)%0A%20%20%20%20%20%20%20%20if%20%5B%20-n%20%22%24old_pids%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%2Fusr%2Fsbin%2Fhaproxy%20-W%20-db%20-f%20%2Fetc%2Fhaproxy%2Fhaproxy.cfg%20%20-p%20%2Fvar%2Flib%2Fhaproxy%2Frun%2Fhaproxy.pid%20-x%20%2Fvar%2Flib%2Fhaproxy%2Frun%2Fhaproxy.sock%20-sf%20%24old_pids%20%26%0A%20%20%20%20%20%20%20%20%20%20%20%20%23There%20seems%20to%20be%20some%20cases%20where%20HAProxy%20doesn't%20drain%20properly.%0A%20%20%20%20%20%20%20%20%20%20%20%20%23To%20handle%20that%20case%2C%20SIGTERM%20signal%20being%20sent%20to%20old%20HAProxy%20processes%20which%20haven't%20terminated.%0A%20%20%20%20%20%20%20%20%20%20%20%20verify_old_haproxy_ps_being_deleted%20%22%24old_pids%22%20%20%26%0A%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20%2Fusr%2Fsbin%2Fhaproxy%20-W%20-db%20-f%20%2Fetc%2Fhaproxy%2Fhaproxy.cfg%20%20-p%20%2Fvar%2Flib%2Fhaproxy%2Frun%2Fhaproxy.pid%20%26%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%7D%0A%0A%20%20%20%20%20%20msg_handler()%0A%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20while%20read%20-r%20line%3B%20do%0A%20%20%20%20%20%20%20%20%20%20echo%20%22The%20client%20send%3A%20%24line%22%20%20%3E%262%0A%20%20%20%20%20%20%20%20%20%20%23%20currently%20only%20'reload'%20msg%20is%20supported%0A%20%20%20%20%20%20%20%20%20%20if%20%5B%20%22%24line%22%20%3D%20reload%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20reload_haproxy%0A%20%20%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20done%0A%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20set%20-ex%0A%20%20%20%20%20%20declare%20-r%20haproxy_sock%3D%22%2Fvar%2Frun%2Fhaproxy%2Fhaproxy-master.sock%22%0A%20%20%20%20%20%20declare%20-r%20haproxy_log_sock%3D%22%2Fvar%2Frun%2Fhaproxy%2Fhaproxy-log.sock%22%0A%20%20%20%20%20%20export%20-f%20msg_handler%0A%20%20%20%20%20%20export%20-f%20reload_haproxy%0A%20%20%20%20%20%20export%20-f%20verify_old_haproxy_ps_being_deleted%0A%20%20%20%20%20%20rm%20-f%20%22%24haproxy_sock%22%20%22%24haproxy_log_sock%22%0A%20%20%20%20%20%20socat%20UNIX-RECV%3A%24%7Bhaproxy_log_sock%7D%20STDOUT%20%26%0A%20%20%20%20%20%20if%20%5B%20-s%20%22%2Fetc%2Fhaproxy%2Fhaproxy.cfg%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%2Fusr%2Fsbin%2Fhaproxy%20-W%20-db%20-f%20%2Fetc%2Fhaproxy%2Fhaproxy.cfg%20%20-p%20%2Fvar%2Flib%2Fhaproxy%2Frun%2Fhaproxy.pid%20%26%0A%20%20%20%20%20%20fi%0A%20%20%20%20%20%20socat%20UNIX-LISTEN%3A%24%7Bhaproxy_sock%7D%2Cfork%20system%3A'bash%20-c%20msg_handler'%0A%20%20%20%20resources%3A%0A%20%20%20%20%20%20requests%3A%0A%20%20%20%20%20%20%20%20cpu%3A%20100m%0A%20%20%20%20%20%20%20%20memory%3A%20200Mi%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20conf-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fhaproxy%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20run-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Frun%2Fhaproxy%22%0A%20%20%20%20livenessProbe%3A%0A%20%20%20%20%20%20initialDelaySeconds%3A%2050%0A%20%20%20%20%20%20httpGet%3A%0A%20%20%20%20%20%20%20%20path%3A%20%2Fhaproxy_ready%0A%20%20%20%20%20%20%20%20port%3A%209444%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20imagePullPolicy%3A%20IfNotPresent%0A%20%20-%20name%3A%20haproxy-monitor%0A%20%20%20%20securityContext%3A%0A%20%20%20%20%20%20capabilities%3A%0A%20%20%20%20%20%20%20%20add%3A%20%5B%22NET_ADMIN%22%2C%20%22SYS_CHROOT%22%5D%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A93e7b8c870261726d44bddc7ba0a702d3720d1838141dac837fb8c3be7c6e1a1%0A%20%20%20%20command%3A%0A%20%20%20%20-%20monitor%0A%20%20%20%20-%20%22%2Fvar%2Flib%2Fkubelet%2Fkubeconfig%22%0A%20%20%20%20-%20%22%2Fconfig%2Fhaproxy.cfg.tmpl%22%0A%20%20%20%20-%20%22%2Fetc%2Fhaproxy%2Fhaproxy.cfg%22%0A%20%20%20%20-%20%22--api-vips%22%0A%20%20%20%20-%20%2210.100.0.50%22%0A%20%20%20%20resources%3A%0A%20%20%20%20%20%20requests%3A%0A%20%20%20%20%20%20%20%20cpu%3A%20100m%0A%20%20%20%20%20%20%20%20memory%3A%20200Mi%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20conf-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fhaproxy%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20run-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Frun%2Fhaproxy%22%0A%20%20%20%20-%20name%3A%20resource-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fconfig%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20chroot-host%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fhost%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20kubeconfigvarlib%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20imagePullPolicy%3A%20IfNotPresent%0A%20%20hostNetwork%3A%20true%0A%20%20tolerations%3A%0A%20%20-%20operator%3A%20Exists%0A%20%20priorityClassName%3A%20system-node-critical%0Astatus%3A%20%7B%7D%0A
          mode: 420
          overwrite: true
          path: /etc/kubernetes/manifests/haproxy.yaml
        - contents:
            source: data:,%23%20Force-load%20legacy%20iptables%20so%20it%20is%20usable%20from%20pod%20network%20namespaces%0Aip_tables%0A
          mode: 420
          overwrite: true
          path: /etc/modules-load.d/iptables.conf
        - contents:
            source: data:,global_defs%20%7B%0A%20%20%20%20enable_script_security%0A%20%20%20%20script_user%20root%0A%20%20%20%20max_auto_priority%20-1%0A%20%20%20%20vrrp_garp_master_refresh%2060%0A%7D%0A%0A%23%20These%20are%20separate%20checks%20to%20provide%20the%20following%20behavior%3A%0A%23%20If%20the%20loadbalancer%20is%20healthy%20then%20all%20is%20well%20regardless%0A%23%20of%20what%20the%20local%20API%20status%20is.%20Both%20checks%20will%20return%20success%20and%0A%23%20we'll%20have%20the%20maximum%20priority.%20This%20means%20as%20long%20as%20there%20is%20a%20node%0A%23%20with%20a%20functional%20loadbalancer%20it%20will%20get%20the%20VIP.%0A%23%20If%20all%20of%20the%20loadbalancers%20go%20down%20but%20the%20local%20API%20is%20still%20running%2C%0A%23%20the%20_both%20check%20will%20still%20succeed%20and%20allow%20any%20node%20with%20a%20functional%0A%23%20API%20to%20take%20the%20VIP.%20This%20isn't%20preferred%20because%20it%20means%20all%20API%0A%23%20traffic%20will%20go%20through%20one%20node%2C%20but%20at%20least%20it%20keeps%20the%20API%20available.%0Avrrp_script%20chk_ocp_lb%20%7B%0A%20%20%20%20script%20%22%2Fusr%2Fbin%2Ftimeout%201.9%20%2Fetc%2Fkeepalived%2Fchk_ocp_script.sh%22%0A%20%20%20%20interval%202%0A%20%20%20%20weight%2020%0A%20%20%20%20rise%203%0A%20%20%20%20fall%203%0A%7D%0A%0Avrrp_script%20chk_ocp_both%20%7B%0A%20%20%20%20script%20%22%2Fusr%2Fbin%2Ftimeout%201.9%20%2Fetc%2Fkeepalived%2Fchk_ocp_script_both.sh%22%0A%20%20%20%20interval%202%0A%20%20%20%20%23%20Use%20a%20smaller%20weight%20for%20this%20check%20so%20it%20won't%20trigger%20the%20move%20from%0A%20%20%20%20%23%20bootstrap%20to%20master%20by%20itself.%0A%20%20%20%20weight%205%0A%20%20%20%20rise%203%0A%20%20%20%20fall%203%0A%7D%0A%0Avrrp_script%20chk_mcs%20%7B%0A%20%20%20%20script%20%22%2Fusr%2Fbin%2Ftimeout%201.9%20%2Fetc%2Fkeepalived%2Fchk_mcs_script.sh%22%0A%20%20%20%20interval%202%0A%20%20%20%20weight%203%0A%20%20%20%20rise%203%0A%20%20%20%20fall%203%0A%7D%0A%0A%23%20TODO%3A%20Improve%20this%20check.%20The%20port%20is%20assumed%20to%20be%20alive.%0A%23%20Need%20to%20assess%20what%20is%20the%20ramification%20if%20the%20port%20is%20not%20there.%0Avrrp_script%20chk_ingress_ready%20%7B%0A%20%20%20%20script%20%22%2Fusr%2Fbin%2Ftimeout%200.9%20%2Fusr%2Fbin%2Fcurl%20-o%20%2Fdev%2Fnull%20-Lfs%20http%3A%2F%2Flocalhost%3A1936%2Fhealthz%2Fready%22%0A%20%20%20%20interval%201%0A%20%20%20%20weight%2010%0A%20%20%20%20rise%203%0A%20%20%20%20fall%202%0A%7D%0A%0Avrrp_script%20chk_ingress%20%7B%0A%20%20%20%20script%20%22%2Fusr%2Fbin%2Ftimeout%200.9%20%2Fusr%2Fbin%2Fcurl%20-o%20%2Fdev%2Fnull%20-Lfs%20http%3A%2F%2Flocalhost%3A1936%2Fhealthz%22%0A%20%20%20%20interval%201%0A%20%20%20%20rise%203%0A%20%20%20%20fall%202%0A%7D%0A%0Avrrp_script%20chk_default_ingress%20%7B%0A%20%20%20%20script%20%22%2Fusr%2Fbin%2Ftimeout%204.9%20%2Fetc%2Fkeepalived%2Fchk_default_ingress.sh%22%0A%20%20%20%20interval%205%0A%20%20%20%20weight%2050%0A%20%20%20%20rise%203%0A%20%20%20%20fall%202%0A%7D%0A%0A%7B%7B%20range%20%24i%2C%20%24config%20%3A%3D%20.Configs%20%7D%7D%0A%7B%7B%24nonVirtualIP%20%3A%3D%20.NonVirtualIP%7D%7D%0A%0A%7B%7B%24participateInAPIVRPP%20%3A%3D%20not%20.EnableUnicast%7D%7D%0A%7B%7B-%20if%20.EnableUnicast%7D%7D%0A%7B%7B-%20range%20.LBConfig.Backends%7D%7D%0A%7B%7B-%20if%20eq%20%24nonVirtualIP%20.Address%7D%7D%0A%7B%7B%24participateInAPIVRPP%20%3D%20true%7D%7D%0A%7B%7B-%20end%7D%7D%0A%7B%7B-%20end%7D%7D%0A%7B%7B-%20end%7D%7D%0A%0A%7B%7Bif%20%24participateInAPIVRPP%7D%7D%0Avrrp_instance%20%7B%7B%20.Cluster.Name%20%7D%7D_API_%7B%7B%24i%7D%7D%20%7B%0A%20%20%20%20state%20BACKUP%0A%20%20%20%20interface%20%7B%7B%20.VRRPInterface%20%7D%7D%0A%20%20%20%20virtual_router_id%20%7B%7B%20.Cluster.APIVirtualRouterID%20%7D%7D%0A%20%20%20%20priority%2040%0A%20%20%20%20advert_int%201%0A%20%20%20%20%7B%7Bif%20.EnableUnicast%7D%7D%0A%20%20%20%20unicast_src_ip%20%7B%7B.NonVirtualIP%7D%7D%0A%20%20%20%20unicast_peer%20%7B%0A%20%20%20%20%20%20%20%20%7B%7B-%20range%20.LBConfig.Backends%20-%7D%7D%0A%20%20%20%20%20%20%20%20%7B%7B-%20if%20ne%20%24nonVirtualIP%20.Address%7D%7D%0A%20%20%20%20%20%20%20%20%7B%7B.Address%7D%7D%0A%20%20%20%20%20%20%20%20%7B%7B-%20end%7D%7D%0A%20%20%20%20%20%20%20%20%7B%7B-%20end%7D%7D%0A%20%20%20%20%7D%0A%20%20%20%20%7B%7Bend%7D%7D%0A%20%20%20%20authentication%20%7B%0A%20%20%20%20%20%20%20%20auth_type%20PASS%0A%20%20%20%20%20%20%20%20auth_pass%20%7B%7B%20.Cluster.Name%20%7D%7D_api_vip%0A%20%20%20%20%7D%0A%20%20%20%20virtual_ipaddress%20%7B%0A%20%20%20%20%20%20%20%20%7B%7B%20.Cluster.APIVIP%20%7D%7D%2F%7B%7B%20.Cluster.VIPNetmask%20%7D%7D%20label%20vip%0A%20%20%20%20%7D%0A%20%20%20%20track_script%20%7B%0A%20%20%20%20%20%20%20%20chk_ocp_lb%0A%20%20%20%20%20%20%20%20chk_ocp_both%0A%20%20%20%20%20%20%20%20chk_mcs%0A%20%20%20%20%7D%0A%7D%0A%7B%7Bend%7D%7D%0A%0A%7B%7B%24participateInIngressVRPP%20%3A%3D%20not%20.EnableUnicast%7D%7D%0A%7B%7B-%20if%20.EnableUnicast%7D%7D%0A%7B%7B-%20range%20.IngressConfig.Peers%7D%7D%0A%7B%7B-%20if%20eq%20%24nonVirtualIP%20.%7D%7D%0A%7B%7B%24participateInIngressVRPP%20%3D%20true%7D%7D%0A%7B%7B-%20end%7D%7D%0A%7B%7B-%20end%7D%7D%0A%7B%7B-%20end%7D%7D%0A%0A%7B%7Bif%20%24participateInIngressVRPP%7D%7D%0Avrrp_instance%20%7B%7B%20.Cluster.Name%20%7D%7D_INGRESS_%7B%7B%24i%7D%7D%20%7B%0A%20%20%20%20state%20BACKUP%0A%20%20%20%20interface%20%7B%7B%20.VRRPInterface%20%7D%7D%0A%20%20%20%20virtual_router_id%20%7B%7B%20.Cluster.IngressVirtualRouterID%20%7D%7D%0A%20%20%20%20priority%2020%0A%20%20%20%20advert_int%201%0A%20%20%20%20%7B%7Bif%20.EnableUnicast%7D%7D%0A%20%20%20%20unicast_src_ip%20%7B%7B.NonVirtualIP%7D%7D%0A%20%20%20%20unicast_peer%20%7B%0A%20%20%20%20%20%20%20%20%7B%7B-%20range%20.IngressConfig.Peers%7D%7D%0A%20%20%20%20%20%20%20%20%7B%7B-%20if%20ne%20%24nonVirtualIP%20.%7D%7D%0A%20%20%20%20%20%20%20%20%7B%7B.%7D%7D%0A%20%20%20%20%20%20%20%20%7B%7B-%20end%7D%7D%0A%20%20%20%20%20%20%20%20%7B%7B-%20end%7D%7D%0A%20%20%20%20%7D%0A%20%20%20%20%7B%7Bend%7D%7D%0A%20%20%20%20authentication%20%7B%0A%20%20%20%20%20%20%20%20auth_type%20PASS%0A%20%20%20%20%20%20%20%20auth_pass%20%7B%7B%20.Cluster.Name%20%7D%7D_ingress_vip%0A%20%20%20%20%7D%0A%20%20%20%20virtual_ipaddress%20%7B%0A%20%20%20%20%20%20%20%20%7B%7B%20.Cluster.IngressVIP%20%7D%7D%2F%7B%7B%20.Cluster.VIPNetmask%20%7D%7D%20label%20vip%0A%20%20%20%20%7D%0A%20%20%20%20track_script%20%7B%0A%20%20%20%20%20%20%20%20chk_ingress%0A%20%20%20%20%20%20%20%20chk_ingress_ready%0A%20%20%20%20%20%20%20%20chk_default_ingress%0A%20%20%20%20%7D%0A%7D%0A%7B%7B%20end%20%7D%7D%0A%7B%7B%20end%20%7D%7D%0A
          mode: 420
          overwrite: true
          path: /etc/kubernetes/static-pod-resources/keepalived/keepalived.conf.tmpl
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Achroot%20%2Fhost%20%2Fbin%2Fcrictl%20ps%20--state%20running%20%7C%20grep%20-qE%20'%5Csmachine-config-server%5Cs'%0A
          mode: 493
          overwrite: true
          path: /etc/kubernetes/static-pod-resources/keepalived/scripts/chk_mcs_script.sh.tmpl
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%2Fusr%2Fbin%2Fcurl%20-o%20%2Fdev%2Fnull%20-kLfs%20http%3A%2F%2Flocalhost%3A9444%2Fhaproxy_ready%20%26%26%20%5B%20-e%20%2Fvar%2Frun%2Fkeepalived%2Fiptables-rule-exists%20%5D%20%7C%7C%20%2Fusr%2Fbin%2Fcurl%20-kLfs%20https%3A%2F%2Flocalhost%3A%7B%7B%20.LBConfig.ApiPort%20%7D%7D%2Freadyz%0A
          mode: 493
          overwrite: true
          path: /etc/kubernetes/static-pod-resources/keepalived/scripts/chk_ocp_script_both.sh.tmpl
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Achroot%20%2Fhost%20%2Fbin%2Fcrictl%20pods%20--namespace%20openshift-ingress%20--state%20Ready%20%7C%20grep%20-qE%20'router-default-%5B%5B%3Aalnum%3A%5D%5D%7B5%2C%7D-%5B%5B%3Aalnum%3A%5D%5D%7B5%2C%7D'%0A
          mode: 493
          overwrite: true
          path: /etc/kubernetes/static-pod-resources/keepalived/scripts/chk_default_ingress.sh.tmpl
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%2Fusr%2Fbin%2Fcurl%20-o%20%2Fdev%2Fnull%20-kLfs%20http%3A%2F%2Flocalhost%3A9444%2Fhaproxy_ready%20%26%26%20%5B%20-e%20%2Fvar%2Frun%2Fkeepalived%2Fiptables-rule-exists%20%5D%0A
          mode: 493
          overwrite: true
          path: /etc/kubernetes/static-pod-resources/keepalived/scripts/chk_ocp_script.sh.tmpl
        - contents:
            source: data:,kind%3A%20Pod%0AapiVersion%3A%20v1%0Ametadata%3A%0A%20%20name%3A%20keepalived%0A%20%20namespace%3A%20openshift-kni-infra%0A%20%20creationTimestamp%3A%0A%20%20deletionGracePeriodSeconds%3A%2065%0A%20%20labels%3A%0A%20%20%20%20app%3A%20kni-infra-vrrp%0A%20%20annotations%3A%0A%20%20%20%20target.workload.openshift.io%2Fmanagement%3A%20'%7B%22effect%22%3A%20%22PreferredDuringScheduling%22%7D'%0A%20%20%20%20openshift.io%2Frequired-scc%3A%20privileged%0Aspec%3A%0A%20%20volumes%3A%0A%20%20-%20name%3A%20resource-dir%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fetc%2Fkubernetes%2Fstatic-pod-resources%2Fkeepalived%22%0A%20%20-%20name%3A%20script-dir%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fetc%2Fkubernetes%2Fstatic-pod-resources%2Fkeepalived%2Fscripts%22%0A%20%20-%20name%3A%20kubeconfig%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fetc%2Fkubernetes%22%0A%20%20-%20name%3A%20kubeconfigvarlib%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20-%20name%3A%20conf-dir%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fetc%2Fkeepalived%22%0A%20%20-%20name%3A%20run-dir%0A%20%20%20%20empty-dir%3A%20%7B%7D%0A%20%20-%20name%3A%20chroot-host%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2F%22%0A%20%20-%20name%3A%20nodeip-configuration%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Frun%2Fnodeip-configuration%22%0A%20%20initContainers%3A%0A%20%20-%20name%3A%20render-config-keepalived%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A93e7b8c870261726d44bddc7ba0a702d3720d1838141dac837fb8c3be7c6e1a1%0A%20%20%20%20command%3A%0A%20%20%20%20-%20runtimecfg%0A%20%20%20%20-%20render%0A%20%20%20%20-%20%22%2Fetc%2Fkubernetes%2Fkubeconfig%22%0A%20%20%20%20-%20%22--api-vips%22%0A%20%20%20%20-%20%2210.100.0.50%22%0A%20%20%20%20-%20%22--ingress-vips%22%0A%20%20%20%20-%20%2210.100.0.51%22%0A%20%20%20%20-%20%22%2Fconfig%22%0A%20%20%20%20-%20%22--out-dir%22%0A%20%20%20%20-%20%22%2Fetc%2Fkeepalived%22%0A%20%20%20%20resources%3A%20%7B%7D%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20kubeconfig%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fkubernetes%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20script-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fconfig%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20conf-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fkeepalived%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20nodeip-configuration%0A%20%20%20%20%20%20mountPath%3A%20%22%2Frun%2Fnodeip-configuration%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20imagePullPolicy%3A%20IfNotPresent%0A%20%20containers%3A%0A%20%20-%20name%3A%20keepalived%0A%20%20%20%20securityContext%3A%0A%20%20%20%20%20%20capabilities%3A%0A%20%20%20%20%20%20%20%20add%3A%20%5B%22NET_ADMIN%22%2C%20%22NET_RAW%22%2C%20%22SYS_CHROOT%22%5D%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A3b0561a80561d95854d5f364f8cd6c3458d27cfb798bf93e09ffcfab97609216%0A%20%20%20%20env%3A%0A%20%20%20%20%20%20-%20name%3A%20NSS_SDB_USE_CACHE%0A%20%20%20%20%20%20%20%20value%3A%20%22no%22%0A%20%20%20%20command%3A%0A%20%20%20%20-%20%2Fbin%2Fbash%0A%20%20%20%20-%20-c%0A%20%20%20%20-%20%7C%0A%20%20%20%20%20%20%23%2Fbin%2Fbash%0A%20%20%20%20%20%20sigterm_handler()%0A%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20if%20pid%3D%24(pgrep%20-o%20keepalived)%3B%20then%0A%20%20%20%20%20%20%20%20%20%20kill%20-s%20SIGTERM%20%22%24pid%22%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%7D%0A%0A%20%20%20%20%20%20reload_keepalived()%0A%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20if%20pid%3D%24(pgrep%20-o%20keepalived)%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20kill%20-s%20SIGHUP%20%22%24pid%22%0A%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20%2Fusr%2Fsbin%2Fkeepalived%20-f%20%2Fetc%2Fkeepalived%2Fkeepalived.conf%20--dont-fork%20--vrrp%20--log-detail%20--log-console%20%26%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%7D%0A%0A%20%20%20%20%20%20msg_handler()%0A%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20while%20read%20-r%20line%3B%20do%0A%20%20%20%20%20%20%20%20%20%20echo%20%22The%20client%20sent%3A%20%24line%22%20%3E%262%0A%20%20%20%20%20%20%20%20%20%20%23%20currently%20only%20'reload'%20msg%20is%20supported%0A%20%20%20%20%20%20%20%20%20%20if%20%5B%20%22%24line%22%20%3D%20reload%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20reload_keepalived%0A%20%20%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20done%0A%20%20%20%20%20%20%7D%0A%0A%20%20%20%20%20%20remove_vip()%0A%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20address%3D%241%0A%20%20%20%20%20%20%20%20interface%3D%24(ip%20-o%20a%20%7C%20awk%20%22%2F%5Cs%24%7Baddress%7D%5C%2F%2F%20%7Bprint%20%5C%242%7D%22)%0A%20%20%20%20%20%20%20%20cidr%3D%24(ip%20-o%20a%20%7C%20awk%20%22%2F%5Cs%24%7Baddress%7D%5C%2F%2F%20%7Bprint%20%5C%244%7D%22)%0A%20%20%20%20%20%20%20%20if%20%5B%20-n%20%22%24interface%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20ip%20a%20del%20%24cidr%20dev%20%24interface%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%7D%0A%0A%20%20%20%20%20%20set%20-ex%0A%20%20%20%20%20%20%23%20Ensure%20that%20we%20don't%20have%20stale%20VIPs%20configured%0A%20%20%20%20%20%20%23%20See%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1931505%0A%20%20%20%20%20%20remove_vip%20%2210.100.0.50%22%0A%20%20%20%20%20%20remove_vip%20%2210.100.0.51%22%0A%20%20%20%20%20%20declare%20-r%20keepalived_sock%3D%22%2Fvar%2Frun%2Fkeepalived%2Fkeepalived.sock%22%0A%20%20%20%20%20%20export%20-f%20msg_handler%0A%20%20%20%20%20%20export%20-f%20reload_keepalived%0A%20%20%20%20%20%20export%20-f%20sigterm_handler%0A%0A%20%20%20%20%20%20%23%20in%20remote%20worker%20case%20sleep%20forever%0A%20%20%20%20%20%20if%20%5B%20-f%20%22%2Frun%2Fnodeip-configuration%2Fremote-worker%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20sleep%20infinity%0A%20%20%20%20%20%20%20%20%20exit%200%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20trap%20sigterm_handler%20SIGTERM%0A%20%20%20%20%20%20if%20%5B%20-s%20%22%2Fetc%2Fkeepalived%2Fkeepalived.conf%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%2Fusr%2Fsbin%2Fkeepalived%20-f%20%2Fetc%2Fkeepalived%2Fkeepalived.conf%20--dont-fork%20--vrrp%20--log-detail%20--log-console%20%26%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20rm%20-f%20%22%24keepalived_sock%22%0A%20%20%20%20%20%20socat%20UNIX-LISTEN%3A%24%7Bkeepalived_sock%7D%2Cfork%20system%3A'bash%20-c%20msg_handler'%0A%20%20%20%20resources%3A%0A%20%20%20%20%20%20requests%3A%0A%20%20%20%20%20%20%20%20cpu%3A%20100m%0A%20%20%20%20%20%20%20%20memory%3A%20200Mi%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20conf-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fkeepalived%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20run-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Frun%2Fkeepalived%22%0A%20%20%20%20-%20name%3A%20chroot-host%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fhost%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20kubeconfigvarlib%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20nodeip-configuration%0A%20%20%20%20%20%20mountPath%3A%20%22%2Frun%2Fnodeip-configuration%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20livenessProbe%3A%0A%20%20%20%20%20%20exec%3A%0A%20%20%20%20%20%20%20%20command%3A%0A%20%20%20%20%20%20%20%20-%20%2Fbin%2Fbash%0A%20%20%20%20%20%20%20%20-%20-c%0A%20%20%20%20%20%20%20%20-%20%7C%0A%20%20%20%20%20%20%20%20%20%20%5B%20!%20-s%20%22%2Fetc%2Fkeepalived%2Fkeepalived.conf%22%20%5D%20%7C%7C%20(echo%20%22%22%20%3E%20%2Ftmp%2Fkeepalived.data%20%26%26%20kill%20-s%20SIGUSR1%20%22%24(pgrep%20-o%20keepalived)%22%20%26%26%20for%20i%20in%20%24(seq%205)%3B%20do%20grep%20-q%20%22VRRP%20Instance%22%20%2Ftmp%2Fkeepalived.data%20%26%26%20exit%200%20%7C%7C%20sleep%201%3B%20done%20%26%26%20exit%201)%0A%20%20%20%20%20%20initialDelaySeconds%3A%2020%0A%20%20%20%20%20%20timeoutSeconds%3A%205%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20imagePullPolicy%3A%20IfNotPresent%0A%20%20-%20name%3A%20keepalived-monitor%0A%20%20%20%20securityContext%3A%0A%20%20%20%20%20%20capabilities%3A%0A%20%20%20%20%20%20%20%20add%3A%20%5B%22NET_ADMIN%22%2C%20%22SYS_CHROOT%22%5D%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A93e7b8c870261726d44bddc7ba0a702d3720d1838141dac837fb8c3be7c6e1a1%0A%20%20%20%20env%3A%0A%20%20%20%20%20%20-%20name%3A%20ENABLE_UNICAST%0A%20%20%20%20%20%20%20%20value%3A%20%22yes%22%0A%20%20%20%20%20%20-%20name%3A%20IS_BOOTSTRAP%0A%20%20%20%20%20%20%20%20value%3A%20%22no%22%0A%20%20%20%20%20%20-%20name%3A%20POD_NAMESPACE%0A%20%20%20%20%20%20%20%20valueFrom%3A%0A%20%20%20%20%20%20%20%20%20%20fieldRef%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20fieldPath%3A%20metadata.namespace%0A%20%20%20%20command%3A%0A%20%20%20%20-%20%2Fbin%2Fbash%0A%20%20%20%20-%20-c%0A%20%20%20%20-%20%7C%0A%20%20%20%20%20%20%23%2Fbin%2Fbash%0A%20%20%20%20%20%20%23%20in%20remote%20worker%20case%20sleep%20forever%0A%20%20%20%20%20%20if%20%5B%20-f%20%22%2Frun%2Fnodeip-configuration%2Fremote-worker%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20sleep%20infinity%0A%20%20%20%20%20%20%20%20%20%20exit%200%0A%20%20%20%20%20%20fi%0A%20%20%20%20%20%20api_vips%3D10.100.0.50%0A%20%20%20%20%20%20ingress_vips%3D10.100.0.51%0A%20%20%20%20%20%20dynkeepalived%20%2Fvar%2Flib%2Fkubelet%2Fkubeconfig%20%2Fconfig%2Fkeepalived.conf.tmpl%20%2Fetc%2Fkeepalived%2Fkeepalived.conf%20--api-vips%20%22%24%7Bapi_vips%7D%22%20--ingress-vips%20%22%24%7Bingress_vips%7D%22%0A%20%20%20%20resources%3A%0A%20%20%20%20%20%20requests%3A%0A%20%20%20%20%20%20%20%20cpu%3A%20100m%0A%20%20%20%20%20%20%20%20memory%3A%20200Mi%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20resource-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fconfig%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20kubeconfigvarlib%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20conf-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fkeepalived%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20run-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Frun%2Fkeepalived%22%0A%20%20%20%20-%20name%3A%20chroot-host%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fhost%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20nodeip-configuration%0A%20%20%20%20%20%20mountPath%3A%20%22%2Frun%2Fnodeip-configuration%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20imagePullPolicy%3A%20IfNotPresent%0A%20%20hostNetwork%3A%20true%0A%20%20tolerations%3A%0A%20%20-%20operator%3A%20Exists%0A%20%20priorityClassName%3A%20system-node-critical%0Astatus%3A%20%7B%7D%0A
          mode: 420
          overwrite: true
          path: /etc/kubernetes/manifests/keepalived.yaml
        - contents:
            source: data:,NODE_SIZING_ENABLED%3Dfalse%0ASYSTEM_RESERVED_MEMORY%3D1Gi%0ASYSTEM_RESERVED_CPU%3D500m%0ASYSTEM_RESERVED_ES%3D1Gi
          mode: 420
          overwrite: true
          path: /etc/node-sizing-enabled.env
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-e%0ANODE_SIZES_ENV%3D%24%7BNODE_SIZES_ENV%3A-%2Fetc%2Fnode-sizing.env%7D%0AVERSION_1%3D1%0AVERSION_2%3D2%0ANODE_AUTO_SIZING_VERSION%3D%24%7BNODE_AUTO_SIZING_VERSION%3A-%24VERSION_2%7D%0ANODE_AUTO_SIZING_VERSION_FILE%3D%24%7BNODE_AUTO_SIZING_VERSION_FILE%3A-%2Fetc%2Fnode-sizing-version.json%7D%0Afunction%20dynamic_memory_sizing%20%7B%0A%20%20%20%20total_memory%3D%24(free%20-g%7Cawk%20'%2F%5EMem%3A%2F%7Bprint%20%242%7D')%0A%20%20%20%20%23%20total_memory%3D8%20test%20the%20recommended%20values%20by%20modifying%20this%20value%0A%20%20%20%20recommended_systemreserved_memory%3D0%0A%20%20%20%20if%20((%24total_memory%20%3C%3D%204))%3B%20then%20%23%2025%25%20of%20the%20first%204GB%20of%20memory%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24total_memory%200.25%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D0%0A%20%20%20%20else%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D1%0A%20%20%20%20%20%20%20%20total_memory%3D%24((total_memory-4))%0A%20%20%20%20fi%0A%20%20%20%20if%20((%24total_memory%20%3C%3D%204))%3B%20then%20%23%2020%25%20of%20the%20next%204GB%20of%20memory%20(up%20to%208GB)%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%20%24(echo%20%24total_memory%200.20%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D0%0A%20%20%20%20else%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%200.80%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D%24((total_memory-4))%0A%20%20%20%20fi%0A%20%20%20%20if%20((%24total_memory%20%3C%3D%208))%3B%20then%20%23%2010%25%20of%20the%20next%208GB%20of%20memory%20(up%20to%2016GB)%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%20%24(echo%20%24total_memory%200.10%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D0%0A%20%20%20%20else%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%200.80%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D%24((total_memory-8))%0A%20%20%20%20fi%0A%20%20%20%20if%20((%24total_memory%20%3C%3D%20112))%3B%20then%20%23%206%25%20of%20the%20next%20112GB%20of%20memory%20(up%20to%20128GB)%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%20%24(echo%20%24total_memory%200.06%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D0%0A%20%20%20%20else%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%206.72%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D%24((total_memory-112))%0A%20%20%20%20fi%0A%20%20%20%20if%20((%24total_memory%20%3E%3D%200))%3B%20then%20%23%202%25%20of%20any%20memory%20above%20128GB%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%20%24(echo%20%24total_memory%200.02%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20fi%0A%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%20%7C%20awk%20'%7Bprintf(%22%25d%5Cn%22%2C%241%20%2B%200.5)%7D')%20%23%20Round%20off%20so%20we%20avoid%20float%20conversions%0A%20%20%20%20echo%20%22SYSTEM_RESERVED_MEMORY%3D%24%7Brecommended_systemreserved_memory%7DGi%22%3E%3E%20%24%7BNODE_SIZES_ENV%7D%0A%7D%0Afunction%20dynamic_cpu_sizing%20%7B%0A%20%20%20%20total_cpu%3D%24(getconf%20_NPROCESSORS_ONLN)%0A%20%20%20%20if%20%5B%20%22%241%22%20-eq%20%22%24VERSION_1%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D0%0A%20%20%20%20%20%20%20%20if%20((%24total_cpu%20%3C%3D%201))%3B%20then%20%23%206%25%20of%20the%20first%20core%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24total_cpu%200.06%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D0%0A%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D0.06%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D%24((total_cpu-1))%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20if%20((%24total_cpu%20%3C%3D%201))%3B%20then%20%23%201%25%20of%20the%20next%20core%20(up%20to%202%20cores)%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24recommended_systemreserved_cpu%20%24(echo%20%24total_cpu%200.01%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D0%0A%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24recommended_systemreserved_cpu%200.01%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D%24((total_cpu-1))%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20if%20((%24total_cpu%20%3C%3D%202))%3B%20then%20%23%200.5%25%20of%20the%20next%202%20cores%20(up%20to%204%20cores)%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24recommended_systemreserved_cpu%20%24(echo%20%24total_cpu%200.005%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D0%0A%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24recommended_systemreserved_cpu%200.01%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D%24((total_cpu-2))%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20if%20((%24total_cpu%20%3E%3D%200))%3B%20then%20%23%200.25%25%20of%20any%20cores%20above%204%20cores%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24recommended_systemreserved_cpu%20%24(echo%20%24total_cpu%200.0025%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20else%0A%20%20%20%20%20%20%20%20%23%20Base%20allocation%20for%201%20CPU%20in%20fractions%20of%20a%20core%20(60%20millicores%20%3D%200.06%20CPU%20core)%0A%20%20%20%20%20%20%20%20base_allocation_fraction%3D0.06%0A%20%20%20%20%20%20%20%20%23%20Increment%20per%20additional%20CPU%20in%20fractions%20of%20a%20core%20(12%20millicores%20%3D%200.012%20CPU%20core)%0A%20%20%20%20%20%20%20%20increment_per_cpu_fraction%3D0.012%0A%20%20%20%20%20%20%20%20if%20((total_cpu%20%3E%201))%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Calculate%20the%20total%20system-reserved%20CPU%20in%20fractions%2C%20starting%20with%20the%20base%20allocation%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20and%20adding%20the%20incremental%20fraction%20for%20each%20additional%20CPU%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(awk%20-v%20base%3D%22%24base_allocation_fraction%22%20-v%20increment%3D%22%24increment_per_cpu_fraction%22%20-v%20cpus%3D%22%24total_cpu%22%20'BEGIN%20%7Bprintf%20%22%25.2f%5Cn%22%2C%20base%20%2B%20increment%20*%20(cpus%20-%201)%7D')%0A%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20For%20a%20single%20CPU%2C%20use%20the%20base%20allocation%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24base_allocation_fraction%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Enforce%20minimum%20threshold%20of%200.5%20CPU%0A%20%20%20%20recommended_systemreserved_cpu%3D%24(awk%20-v%20val%3D%22%24recommended_systemreserved_cpu%22%20'BEGIN%20%7Bif%20(val%20%3C%200.5)%20print%200.5%3B%20else%20print%20val%7D')%0A%0A%20%20%20%20echo%20%22SYSTEM_RESERVED_CPU%3D%24%7Brecommended_systemreserved_cpu%7D%22%3E%3E%20%24%7BNODE_SIZES_ENV%7D%0A%7D%0Afunction%20dynamic_ephemeral_sizing%20%7B%0A%20%20%20%20echo%20%22Not%20implemented%20yet%22%0A%7D%0Afunction%20dynamic_pid_sizing%20%7B%0A%20%20%20%20echo%20%22Not%20implemented%20yet%22%0A%7D%0Afunction%20set_memory%20%7B%0A%20%20%20%20SYSTEM_RESERVED_MEMORY%3D%241%0A%20%20%20%20if%20%5B%20-z%20%22%24%7BSYSTEM_RESERVED_MEMORY%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20SYSTEM_RESERVED_MEMORY%3D%221Gi%22%0A%20%20%20%20fi%0A%20%20%20%20echo%20%22SYSTEM_RESERVED_MEMORY%3D%24%7BSYSTEM_RESERVED_MEMORY%7D%22%20%3E%3E%20%24%7BNODE_SIZES_ENV%7D%0A%7D%0Afunction%20set_cpu%20%7B%0A%20%20%20%20SYSTEM_RESERVED_CPU%3D%241%0A%20%20%20%20if%20%5B%20-z%20%22%24%7BSYSTEM_RESERVED_CPU%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20SYSTEM_RESERVED_CPU%3D%22500m%22%0A%20%20%20%20fi%0A%20%20%20%20echo%20%22SYSTEM_RESERVED_CPU%3D%24%7BSYSTEM_RESERVED_CPU%7D%22%20%3E%3E%20%24%7BNODE_SIZES_ENV%7D%0A%7D%0Afunction%20set_es%20%7B%0A%20%20%20%20SYSTEM_RESERVED_ES%3D%241%0A%20%20%20%20if%20%5B%20-z%20%22%24%7BSYSTEM_RESERVED_ES%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20SYSTEM_RESERVED_ES%3D%221Gi%22%0A%20%20%20%20fi%0A%20%20%20%20echo%20%22SYSTEM_RESERVED_ES%3D%24%7BSYSTEM_RESERVED_ES%7D%22%20%3E%3E%20%24%7BNODE_SIZES_ENV%7D%0A%7D%0Afunction%20dynamic_node_sizing%20%7B%0A%20%20%20%20rm%20-f%20%24%7BNODE_SIZES_ENV%7D%0A%20%20%20%20dynamic_memory_sizing%0A%20%20%20%20dynamic_cpu_sizing%20%241%0A%20%20%20%20set_es%20%242%0A%20%20%20%20%23dynamic_ephemeral_sizing%0A%20%20%20%20%23dynamic_pid_sizing%0A%7D%0Afunction%20static_node_sizing%20%7B%0A%20%20%20%20rm%20-f%20%24%7BNODE_SIZES_ENV%7D%0A%20%20%20%20set_memory%20%241%0A%20%20%20%20set_cpu%20%242%0A%20%20%20%20set_es%20%243%0A%7D%0Afunction%20create_version_file%20%7B%0A%20%20%20%20echo%20%22%7B%5C%22version%5C%22%3A%20%241%7D%22%20%3E%20%242%0A%7D%0Aif%20!%20%5B%20-f%20%24NODE_AUTO_SIZING_VERSION_FILE%20%5D%3B%20then%0A%20%20%20%20create_version_file%20%24NODE_AUTO_SIZING_VERSION%20%24NODE_AUTO_SIZING_VERSION_FILE%0Afi%0Anew_version%3D%24(jq%20.version%20%24NODE_AUTO_SIZING_VERSION_FILE)%0Aif%20%5B%20%241%20%3D%3D%20%22true%22%20%5D%3B%20then%0A%20%20%20%20dynamic_node_sizing%20%24new_version%20%244%0Aelif%20%5B%20%241%20%3D%3D%20%22false%22%20%5D%3B%20then%0A%20%20%20%20static_node_sizing%20%242%20%243%20%244%0Aelse%0A%20%20%20%20echo%20%22Unrecognized%20command%20line%20option.%20Valid%20options%20are%20%5C%22true%5C%22%20or%20%5C%22false%5C%22%22%0Afi%0A
          mode: 493
          overwrite: true
          path: /usr/local/sbin/dynamic-system-reserved-calc.sh
        - contents:
            source: data:,%23%20Turning%20on%20Accounting%20helps%20track%20down%20performance%20issues.%0A%5BManager%5D%0ADefaultCPUAccounting%3Dyes%0ADefaultMemoryAccounting%3Dyes%0ADefaultBlockIOAccounting%3Dyes%0A
          mode: 420
          overwrite: true
          path: /etc/systemd/system.conf.d/kubelet-cgroups.conf
        - contents:
            source: data:,%5BService%5D%0AEnvironment%3D%22KUBELET_LOG_LEVEL%3D2%22%0A
          mode: 420
          overwrite: true
          path: /etc/systemd/system/kubelet.service.d/20-logging.conf
        - contents:
            source: data:,%23%20ignore%20known%20SDN-managed%20devices%0A%5Bdevice%5D%0Amatch-device%3Dinterface-name%3Abr-int%3Binterface-name%3Abr-local%3Binterface-name%3Abr-nexthop%3Binterface-name%3Aovn-k8s-*%3Binterface-name%3Ak8s-*%3Binterface-name%3Atun0%3Binterface-name%3Abr0%3Binterface-name%3Apatch-br-*%3Binterface-name%3Abr-ext%3Binterface-name%3Aext-vxlan%3Binterface-name%3Aext%3Binterface-name%3Aint%3Binterface-name%3Avxlan_sys_*%3Binterface-name%3Agenev_sys_*%3Bdriver%3Aveth%0Amanaged%3D0%0A
          mode: 420
          overwrite: true
          path: /etc/NetworkManager/conf.d/sdn.conf
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-eux%0A%0A%23%20Clean%20up%20old%20config%20on%20behalf%20of%20mtu-migration%0Aif%20!%20systemctl%20-q%20is-enabled%20mtu-migration%3B%20then%0A%20%20echo%20%22Cleaning%20up%20left%20over%20mtu%20migration%20configuration%22%0A%20%20rm%20-rf%20%2Fetc%2Fcno%2Fmtu-migration%0Afi%0A%0Aif%20%5B%20-e%20%2Fetc%2Fnmstate%2Fopenshift%2Fapplied%20%5D%3B%20then%0A%20%20echo%20%22Configuration%20already%20applied%2C%20exiting%22%0A%20%20exit%200%0Afi%0A%0Asrc_path%3D%22%2Fetc%2Fnmstate%2Fopenshift%22%0Adst_path%3D%22%2Fetc%2Fnmstate%22%0Ahostname%3D%24(hostname%20-s)%0Ahost_file%3D%22%24%7Bhostname%7D.yml%22%0Acluster_file%3D%22cluster.yml%22%0Aconfig_file%3D%22%22%0Aif%20%5B%20-s%20%22%24src_path%2F%24host_file%22%20%5D%3B%20then%0A%20%20config_file%3D%24host_file%0Aelif%20%5B%20-s%20%22%24src_path%2F%24cluster_file%22%20%5D%3B%20then%0A%20%20config_file%3D%24cluster_file%0Aelse%0A%20%20echo%20%22No%20configuration%20found%20at%20%24src_path%2F%24host_file%20or%20%24src_path%2F%24cluster_file%22%0A%20%20exit%200%0Afi%0A%0Aif%20%5B%20-e%20%22%24dst_path%2F%24config_file%22%20%5D%3B%20then%0A%20%20echo%20%22ERROR%3A%20File%20%24dst_path%2F%24config_file%20exists.%20Refusing%20to%20overwrite.%22%0A%20%20exit%201%0Afi%0A%0A%23%20Handle%20the%20case%20where%20we're%20migrating%20from%20configure-ovs%0Aovs-vsctl%20--timeout%3D30%20--if-exists%20del-br%20br-ex%0A%0A%23%20Handle%20the%20case%20where%20we're%20migrating%20from%20OpenShift%20SDN%0Aovs-vsctl%20--timeout%3D30%20--if-exists%20del-br%20br0%0A%0Acp%20%22%24src_path%2F%24config_file%22%20%2Fetc%2Fnmstate%0Atouch%20%2Fetc%2Fnmstate%2Fopenshift%2Fapplied%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/nmstate-configuration.sh
        - contents:
            source: data:,%5Bservice%5D%0Akeep_state_file_after_apply%20%3D%20true%0A
          mode: 420
          overwrite: true
          path: /etc/nmstate/nmstate.conf
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%23%20Set%20interface%20ofport_request%20to%20guarantee%20stable%20ofport%20numbers.%20This%20is%20important%20for%20flow%20matches.%0A%23%20Otherwise%2C%20another%20ofport%20number%20is%20assigned%20to%20the%20interface%20on%20every%20restart%20of%20NetworkManager.%0A%23%20This%20script%20will%20build%20an%20associative%20array%20INTERFACE_NAME-%3Eofport_request%20and%20will%20save%20it%20to%20file%20CONFIGURATION_FILE.%0A%23%20When%20an%20interface%20is%20brought%20up%2C%20this%20will%20reuse%20the%20value%20from%20the%20associative%20array%20if%20such%20a%20value%20exists.%0A%23%20Otherwise%2C%20this%20will%20try%20to%20use%20the%20current%20ofport%20value.%20If%20the%20ofport%20value%20is%20already%20reserved%2C%20then%0A%23%20this%20uses%20the%20lowest%20available%20numerical%20value%2C%20instead.%0Aset%20-eux%20-o%20pipefail%0Aif%20%5B%5B%20%22OVNKubernetes%22%20!%3D%20%22OVNKubernetes%22%20%5D%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0AINTERFACE_NAME%3D%241%0AOPERATION%3D%242%0A%0A%23%20Only%20execute%20this%20on%20pre-up%0Aif%20%5B%20%22%24%7BOPERATION%7D%22%20!%3D%20%22pre-up%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20interface's%20NM%20uuid%0AINTERFACE_CONNECTION_UUID%3D%24(nmcli%20-t%20-f%20device%2Ctype%2Cuuid%20conn%20%7C%20awk%20-F%20'%3A'%20'%7Bif(%241%3D%3D%22'%24%7BINTERFACE_NAME%7D'%22%20%26%26%20%242!~%2F%5Eovs*%2F)%20print%20%24NF%7D')%0Aif%20%5B%20%22%24%7BINTERFACE_CONNECTION_UUID%7D%22%20%3D%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20interface's%20slave-type.%20If%20this%20is%20not%20an%20ovs-port%2C%20then%20exit%0AINTERFACE_OVS_SLAVE_TYPE%3D%24(nmcli%20-t%20-f%20connection.slave-type%20conn%20show%20%22%24%7BINTERFACE_CONNECTION_UUID%7D%22%20%7C%20awk%20-F%20'%3A'%20'%7Bprint%20%24NF%7D')%0Aif%20%5B%20%22%24%7BINTERFACE_OVS_SLAVE_TYPE%7D%22%20!%3D%20%22ovs-port%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20This%20is%20not%20necessarily%20a%20UUID%20(can%20be%20a%20name%20in%20case%20of%20bonds)%20but%20this%20should%20be%20unique%0APORT%3D%24(nmcli%20-t%20-f%20connection.master%20conn%20show%20%22%24%7BINTERFACE_CONNECTION_UUID%7D%22%20%7C%20awk%20-F%20'%3A'%20'%7Bprint%20%24NF%7D')%0Aif%20%5B%20%22%24%7BPORT%7D%22%20%3D%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20interface's%20NM%20uuid%0APORT_CONNECTION_UUID%3D%24(nmcli%20-t%20-f%20device%2Ctype%2Cuuid%20conn%20%7C%20awk%20-F%20'%3A'%20'%7Bif(%20(%241%3D%3D%22'%24%7BPORT%7D'%22%20%7C%7C%20%243%3D%3D%22'%24%7BPORT%7D'%22)%20%26%26%20%242~%2F%5Eovs*%2F)%20print%20%24NF%7D')%0Aif%20%5B%20%22%24%7BPORT_CONNECTION_UUID%7D%22%20%3D%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20port's%20slave-type.%20If%20this%20is%20not%20an%20ovs-bridge%2C%20then%20exit%0APORT_OVS_SLAVE_TYPE%3D%24(nmcli%20-t%20-f%20connection.slave-type%20conn%20show%20%22%24%7BPORT_CONNECTION_UUID%7D%22%20%7C%20awk%20-F%20'%3A'%20'%7Bprint%20%24NF%7D')%0Aif%20%5B%20%22%24%7BPORT_OVS_SLAVE_TYPE%7D%22%20!%3D%20%22ovs-bridge%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20port's%20master.%20If%20it%20doesn't%20have%20any%2C%20assume%20it's%20not%20our%20bridge%0ABRIDGE_ID%3D%24(nmcli%20-t%20-f%20connection.master%20conn%20show%20%22%24%7BPORT_CONNECTION_UUID%7D%22%20%7C%20awk%20-F%20'%3A'%20'%7Bprint%20%24NF%7D')%0Aif%20%5B%20%22%24%7BBRIDGE_ID%7D%22%20%3D%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20bridge%20name%0ABRIDGE_NAME%3D%24(nmcli%20-t%20-f%20connection.interface-name%20conn%20show%20%22%24%7BBRIDGE_ID%7D%22%20%7C%20awk%20-F%20'%3A'%20'%7Bprint%20%24NF%7D')%0A%23%20Limit%20this%20to%20br-ex%20and%20br-ex1%20only.%20If%20one%20wanted%20to%20enable%20this%20for%20all%20OVS%20bridges%2C%0A%23%20the%20condition%20would%20be%3A%20if%20%5B%20%22%24BRIDGE_NAME%22%20%3D%3D%20%22%22%20%5D%3B%20then%0Aif%20%5B%20%22%24%7BBRIDGE_NAME%7D%22%20!%3D%20%22br-ex%22%20%5D%20%26%26%20%5B%20%22%24%7BBRIDGE_NAME%7D%22%20!%3D%20%22br-ex1%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Make%20sure%20that%20the%20interface%20is%20plugged%20into%20OVS%0A%23%20This%20should%20always%20be%20the%20case%20given%20that%20we%20are%20in%20pre-up%2C%20but%20exit%20gracefully%20in%20the%20odd%20case%20that%20it's%20not%0Aif%20!%20ovs-vsctl%20list%20interface%20%22%24%7BINTERFACE_NAME%7D%22%20%3E%2Fdev%2Fnull%202%3E%261%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0ACONFIGURATION_FILE%3D%22%2Frun%2Fofport_requests.%24%7BBRIDGE_NAME%7D%22%0A%0A%23%20Declare%20a%20new%20associative%20array.%20If%20CONFIGURATION_FILE%20exists%2C%20source%20entries%20from%20there%0Adeclare%20-A%20INTERFACES%0Aif%20%5B%20-f%20%22%24%7BCONFIGURATION_FILE%7D%22%20%5D%3B%20then%0A%20%20%20%20echo%20%22Sourcing%20configuration%20file%20'%24%7BCONFIGURATION_FILE%7D'%20with%20contents%3A%22%0A%20%20%20%20cat%20%22%24%7BCONFIGURATION_FILE%7D%22%0A%20%20%20%20source%20%22%24%7BCONFIGURATION_FILE%7D%22%0Afi%0A%0A%23%20get_interface_ofport_request%20will%20return%0A%23%20*%20either%3A%20the%20current%20ofport%20assignment%20for%20the%20port%20if%20no%20interface%20has%20claimed%20this%20ofport%20number%2C%20yet%0A%23%20*%20or%3A%20%20%20%20%20the%20lowest%20available%20free%20ofport%20number%0Afunction%20get_interface_ofport_request()%20%7B%0A%20%20%20%20%23%20Build%20an%20array%20that%20only%20contains%20the%20currently%20reserved%20ofport_requests%0A%20%20%20%20declare%20-A%20ofport_requests%0A%20%20%20%20for%20interface_name%20in%20%22%24%7B!INTERFACES%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20%20%20%20%20ofport_requests%5B%24%7BINTERFACES%5B%24interface_name%5D%7D%5D%3D%24%7BINTERFACES%5B%24interface_name%5D%7D%0A%20%20%20%20done%0A%0A%20%20%20%20%23%20Get%20the%20current%20ofport%20number%20assignment%0A%20%20%20%20local%20current_ofport%3D%24(ovs-vsctl%20get%20Interface%20%22%24%7BINTERFACE_NAME%7D%22%20ofport)%0A%0A%20%20%20%20%23%20If%20the%20current%20ofport%20number%20is%20still%20free%2C%20use%20it%0A%20%20%20%20if%20!%20%5B%20%22%24%7Bofport_requests%5B%24current_ofport%5D%2Ba%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%24current_ofport%0A%20%20%20%20%20%20%20%20return%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20If%20the%20current%20ofport%20number%20is%20not%20free%2C%20return%20the%20lowest%20free%20entry%0A%20%20%20%20i%3D0%0A%20%20%20%20for%20i%20in%20%7B1..65000%7D%3B%20do%0A%20%20%20%20%20%20%20%20if%20!%20%5B%20%22%24%7Bofport_requests%5B%24i%5D%2Ba%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20echo%20%24i%0A%20%20%20%20%20%20%20%20%20%20%20%20return%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20done%0A%0A%20%20%20%20%23%20if%20we%20still%20cannot%20find%20an%20ID%2C%20exit%20with%20an%20error%0A%20%20%20%20echo%20%22Impossible%20to%20find%20an%20ofport%20ID%20for%20interface%20%24%7BINTERFACE_NAME%7D%22%20%3E%262%0A%20%20%20%20exit%201%0A%7D%0A%0A%23%20If%20INTERFACES%5BINTERFACE_NAME%5D%20exists%2C%20use%20that%20value%0A%23%20If%20INTERFACES%5BINTERFACE_NAME%5D%20does%20not%20exists%2C%20use%20the%20value%20from%20get_interface_ofport_request%0Aif%20!%20%5B%20%22%24%7BINTERFACES%5B%24INTERFACE_NAME%5D%2Ba%7D%22%20%5D%3B%20then%0A%20%20%20%20INTERFACES%5B%24INTERFACE_NAME%5D%3D%24(get_interface_ofport_request)%0Afi%0A%23%20Set%20ofport_request%20according%20to%20INTERFACES%5BINTERFACE_NAME%5D%0Aovs-vsctl%20set%20Interface%20%22%24%7BINTERFACE_NAME%7D%22%20ofport_request%3D%24%7BINTERFACES%5B%24INTERFACE_NAME%5D%7D%0A%0A%23%20Save%20current%20state%20of%20INTERFACES%20to%20CONFIGURATION_FILE%0Adeclare%20-p%20INTERFACES%20%3E%7C%20%22%24%7BCONFIGURATION_FILE%7D%22%0A
          mode: 493
          overwrite: true
          path: /etc/NetworkManager/dispatcher.d/pre-up.d/10-ofport-request.sh
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%0A%23%20Extract%20Podman%20version%20and%20determine%20the%20signature%20policy%0A%2Fusr%2Fbin%2Fpodman%20-v%20%7C%20%2Fbin%2Fawk%20'%7B%0A%20%20%20%20split(%243%2C%20version%2C%20%22-%22)%3B%0A%20%20%20%20clean_version%20%3D%20version%5B1%5D%3B%0A%0A%20%20%20%20split(clean_version%2C%20current%2C%20%2F%5C.%2F)%3B%0A%20%20%20%20split(%224.4.1%22%2C%20target%2C%20%2F%5C.%2F)%3B%0A%0A%20%20%20%20for%20(i%20%3D%201%3B%20i%20%3C%3D%203%3B%20i%2B%2B)%20%7B%0A%20%20%20%20%20%20%20%20if%20((current%5Bi%5D%20%2B%200)%20%3C%20(target%5Bi%5D%20%2B%200))%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20print%20%22--signature-policy%20%2Fetc%2Fmachine-config-daemon%2Fpolicy-for-old-podman.json%22%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20exit%3B%0A%20%20%20%20%20%20%20%20%7D%20else%20if%20((current%5Bi%5D%20%2B%200)%20%3E%20(target%5Bi%5D%20%2B%200))%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20exit%3B%0A%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%7D%0A%7D'%20%3E%20%2Ftmp%2Fpodman_policy_args%0A
          mode: 493
          overwrite: true
          path: /etc/machine-config-daemon/generate_podman_policy_args.sh
        - contents:
            source: data:,%7B%22auths%22%3A%7B%22cloud.openshift.com%22%3A%7B%22auth%22%3A%22b3BlbnNoaWZ0LXJlbGVhc2UtZGV2K29jbV9hY2Nlc3NfOTRmZDViZTMwOTM3NGU5NDlkM2Q5NzhmOTQzZGFlYTI6TDc0UlozWjNEUUM1U0RFMjBUUUU3UDRZR1RNSDRIRUdMUkMySzk3MjJMSE1PMlBPVUNaUDJFVVo0UDc1N1RLQw%3D%3D%22%2C%22email%22%3A%22jgoldberg%40allcovered.com%22%7D%2C%22quay.io%22%3A%7B%22auth%22%3A%22b3BlbnNoaWZ0LXJlbGVhc2UtZGV2K29jbV9hY2Nlc3NfOTRmZDViZTMwOTM3NGU5NDlkM2Q5NzhmOTQzZGFlYTI6TDc0UlozWjNEUUM1U0RFMjBUUUU3UDRZR1RNSDRIRUdMUkMySzk3MjJMSE1PMlBPVUNaUDJFVVo0UDc1N1RLQw%3D%3D%22%2C%22email%22%3A%22jgoldberg%40allcovered.com%22%7D%2C%22registry.connect.redhat.com%22%3A%7B%22auth%22%3A%22fHVoYy1wb29sLTljZTJiZWU4LTUwYWQtNDVlNC04NDExLTNkNjQ1NWNkODI1NjpleUpoYkdjaU9pSlNVelV4TWlKOS5leUp6ZFdJaU9pSTNaakppTldOallXWXhZVEEwWXpZMVlUSTFaRGN6TjJSa05UVXlNbVJqWWlKOS5NZHFkUUgzenYyMHFzQ0dfR2hGYy1WSzFRNGRsOW05TFhqcmhQNjNjUDh0dDVGX25Wc1U5NGxlcmVVSEQ4R1FXRUxDZlIzeE5HQ2dOSXFPNWUyNC02U3NGOFNTQV9RSnZIODVzLTBBWXlWMHY2QnJxV21CRHNLSWdnSzE2SFhWUzd4cTlSZ05hN200RFRMdUF2RUdtVkRSQ05VUVNFN1FMTWMxaUVhSVI4RVdrT0pPUklQd3hQM3YyUDlsTHpSRWtKYl82WVRjUWRjQUR3T0d1OWkzUHIwMWRHX1d4QU90NkFxcFZBX0JSaHRhNFRjWTFwSHk1bXBlWWVIVnE3Q3hzZWFRV3FzR01Oc0lObkFFNGdjV0MyekVXVl9NZHpIQXVad203WWsxMjg5VVhfYnhVMWhDUkVzdG5zdGdCSERheFRpSTFjalZSZkJ4X05hb0RMU01GVXBzNmlDVXhTTUxzVmc3Mi04LVJHal9nVmMxRDZPNjJkODJoakdaaW5HekJsendzMkZLYlFnNDRjb1VWcWpDdUMwdktCdVJRbDhkX0taVGZTWFVSTS0wOE91YjBNdDRIMjVjZmx6bjNERWdDcUtlSVlUYVdMS3ZranRKVy1MaGdLRjlDUHFqWmozUjhwN2xja2ZkR0lPbHRvY0hZY0xXVlM3QURjdmRNaWVLa3p5STRHb2RPamp2NU5OVF9UWDdjRHBRRVdWUnlENkxkOElXODA4SHVoSmtfa2R0MWVDSkxSTTVUdFBSRHVxZ3UwODlqcWM4WXRVWFhfcm9KcFhoSE5iMUlnekZTdFJqZktTSVJ6YTdlV2g4VWxvRmNwNXJZOV9VeDFTaFVnZ3JlQXFmQ1Y4NXF5Wjlya2RibVNZUE5PRVdzTmtUeGJoY0Q4YWpkYlJrWkFCRQ%3D%3D%22%2C%22email%22%3A%22jgoldberg%40allcovered.com%22%7D%2C%22registry.redhat.io%22%3A%7B%22auth%22%3A%22fHVoYy1wb29sLTljZTJiZWU4LTUwYWQtNDVlNC04NDExLTNkNjQ1NWNkODI1NjpleUpoYkdjaU9pSlNVelV4TWlKOS5leUp6ZFdJaU9pSTNaakppTldOallXWXhZVEEwWXpZMVlUSTFaRGN6TjJSa05UVXlNbVJqWWlKOS5NZHFkUUgzenYyMHFzQ0dfR2hGYy1WSzFRNGRsOW05TFhqcmhQNjNjUDh0dDVGX25Wc1U5NGxlcmVVSEQ4R1FXRUxDZlIzeE5HQ2dOSXFPNWUyNC02U3NGOFNTQV9RSnZIODVzLTBBWXlWMHY2QnJxV21CRHNLSWdnSzE2SFhWUzd4cTlSZ05hN200RFRMdUF2RUdtVkRSQ05VUVNFN1FMTWMxaUVhSVI4RVdrT0pPUklQd3hQM3YyUDlsTHpSRWtKYl82WVRjUWRjQUR3T0d1OWkzUHIwMWRHX1d4QU90NkFxcFZBX0JSaHRhNFRjWTFwSHk1bXBlWWVIVnE3Q3hzZWFRV3FzR01Oc0lObkFFNGdjV0MyekVXVl9NZHpIQXVad203WWsxMjg5VVhfYnhVMWhDUkVzdG5zdGdCSERheFRpSTFjalZSZkJ4X05hb0RMU01GVXBzNmlDVXhTTUxzVmc3Mi04LVJHal9nVmMxRDZPNjJkODJoakdaaW5HekJsendzMkZLYlFnNDRjb1VWcWpDdUMwdktCdVJRbDhkX0taVGZTWFVSTS0wOE91YjBNdDRIMjVjZmx6bjNERWdDcUtlSVlUYVdMS3ZranRKVy1MaGdLRjlDUHFqWmozUjhwN2xja2ZkR0lPbHRvY0hZY0xXVlM3QURjdmRNaWVLa3p5STRHb2RPamp2NU5OVF9UWDdjRHBRRVdWUnlENkxkOElXODA4SHVoSmtfa2R0MWVDSkxSTTVUdFBSRHVxZ3UwODlqcWM4WXRVWFhfcm9KcFhoSE5iMUlnekZTdFJqZktTSVJ6YTdlV2g4VWxvRmNwNXJZOV9VeDFTaFVnZ3JlQXFmQ1Y4NXF5Wjlya2RibVNZUE5PRVdzTmtUeGJoY0Q4YWpkYlJrWkFCRQ%3D%3D%22%2C%22email%22%3A%22jgoldberg%40allcovered.com%22%7D%7D%7D%0A
          mode: 384
          overwrite: true
          path: /var/lib/kubelet/config.json
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-eo%20pipefail%0A%0Afunction%20pull_baremetal_runtime_cfg_image%20%7B%0A%20%20%20%20%23%20By%20default%20podman%20retries%20to%20pull%20an%20image%203%20times%20with%201%20second%20back-off.%20It%20is%20not%20configurable.%20For%20this%0A%20%20%20%20%23%20reason%20we%20are%20implementing%20our%20own%20logic%20of%20pulling%20image%20and%20retrying%20indefinitely.%0A%20%20%20%20%23%20Ref.%3A%20https%3A%2F%2Fgithub.com%2Fcontainers%2Fcommon%2Fblob%2Fe028741ef77fdfa3ae261b9d23cdd50253d586c4%2Flibimage%2Fcopier.go%23L27-L30%0A%0A%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Checking%20if%20baremetal%20runtime%20cfg%20image%20already%20exists%22%0A%20%20%20%20if%20!%20%2Fusr%2Fbin%2Fpodman%20image%20exists%20%22quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A93e7b8c870261726d44bddc7ba0a702d3720d1838141dac837fb8c3be7c6e1a1%22%3B%20then%0A%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Starting%20download%20of%20baremetal%20runtime%20cfg%20image%22%0A%20%20%20%20%20%20while%20!%20%2Fusr%2Fbin%2Fpodman%20pull%20--authfile%20%2Fvar%2Flib%2Fkubelet%2Fconfig.json%20%22quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A93e7b8c870261726d44bddc7ba0a702d3720d1838141dac837fb8c3be7c6e1a1%22%3B%20do%20sleep%201%3B%20done%0A%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Download%20of%20baremetal%20runtime%20cfg%20image%20completed%22%0A%20%20%20%20else%0A%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Image%20exists%2C%20no%20need%20to%20download%22%0A%20%20%20%20fi%0A%7D%0A%0Afunction%20resolv_prepender%20%7B%0A%20%20%20%20%20%20%20%20%23%20In%20DHCP%20connections%2C%20the%20resolv.conf%20content%20may%20be%20late%2C%20thus%20we%20wait%20for%20nameservers%0A%20%20%20%20%20%20%20%20while%20!%20grep%20nameserver%20%2Fvar%2Frun%2FNetworkManager%2Fresolv.conf%3B%20do%0A%20%20%20%20%20%20%20%20%20%20%20%20%3E%262%20echo%20%20%22NM%20resolv-prepender%3A%20NM%20resolv.conf%20still%20empty%20of%20nameserver%22%0A%20%20%20%20%20%20%20%20%20%20%20%20sleep%200.5%0A%20%20%20%20%20%20%20%20done%0A%0A%20%20%20%20%20%20%20%20%23%20Ensure%20resolv.conf%20exists%20and%20contains%20nameservers%20before%20we%20try%20to%20pull%20image%20or%20run%20podman%0A%20%20%20%20%20%20%20%20if%20%5B%5B%20!%20-e%20%2Fetc%2Fresolv.conf%20%5D%5D%20%7C%7C%20!%20grep%20-q%20nameserver%20%2Fetc%2Fresolv.conf%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20cp%20%2Fvar%2Frun%2FNetworkManager%2Fresolv.conf%20%2Fetc%2Fresolv.conf%0A%20%20%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20%20%20%23%20Ensure%20baremetalRuntimeCfgImage%20is%20pulled%20in%20a%20reliable%20way%20before%20trying%20to%20use%20it%0A%20%20%20%20%20%20%20%20%23%20in%20the%20subsequent%20code%0A%20%20%20%20%20%20%20%20pull_baremetal_runtime_cfg_image%0A%0A%20%20%20%20%20%20%20%20NAMESERVER_IP%3D%22%24(%2Fusr%2Fbin%2Fpodman%20run%20--rm%20%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20--authfile%20%2Fvar%2Flib%2Fkubelet%2Fconfig.json%20%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20--net%3Dhost%20%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A93e7b8c870261726d44bddc7ba0a702d3720d1838141dac837fb8c3be7c6e1a1%20%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20node-ip%20%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20show%20%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%2210.100.0.50%22%20%20%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%2210.100.0.51%22%20)%22%0A%20%20%20%20%20%20%20%20DOMAINS%3D%22%24%7BIP4_DOMAINS%3A-%7D%20%24%7BIP6_DOMAINS%3A-%7D%20comp-poc-rh01.rhpoc.int%22%0A%20%20%20%20%20%20%20%20if%20%5B%5B%20-n%20%22%24NAMESERVER_IP%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20KNICONFDONEPATH%3D%22%2Frun%2Fresolv-prepender-kni-conf-done%22%0A%20%20%20%20%20%20%20%20%20%20%20%20if%20systemctl%20-q%20is-enabled%20systemd-resolved%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Configure%20for%20OKD%20domain%20and%20local%20IP%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20mkdir%20-p%20%2Fetc%2Fsystemd%2Fresolved.conf.d%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20KNICONFTMPPATH%3D%22%24(mktemp)%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20KNICONFPATH%3D%22%2Fetc%2Fsystemd%2Fresolved.conf.d%2F60-kni.conf%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20echo%20%22%5BResolve%5D%22%20%3E%20%22%24%7BKNICONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20echo%20%22DNS%3D%24NAMESERVER_IP%22%20%3E%3E%20%22%24%7BKNICONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20echo%20%22Domains%3D%24%7BDOMAINS%7D%22%20%3E%3E%20%22%24%7BKNICONFTMPPATH%7D%22%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20If%20KNI%20conf%20is%20not%20created%20or%20doesn't%20match%20what%20is%20generated%20or%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20if%20we%20haven't%20completed%20a%20full%20update%20-%20create%20or%20update%20it%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20%5B%5B%20!%20-f%20%22%24%7BKNICONFPATH%7D%22%20%5D%5D%20%7C%7C%20%5B%5B%20!%20-f%20%22%24%7BKNICONFDONEPATH%7D%22%20%5D%5D%20%7C%7C%20!%20cmp%20--silent%20%22%24%7BKNICONFPATH%7D%22%20%22%24%7BKNICONFTMPPATH%7D%22%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Creating%2Fupdating%20%2Fetc%2Fsystemd%2Fresolved.conf.d%2F60-kni.conf%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Remove%20the%20done%20file%20flag%20before%20writing%20the%20config%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20This%20would%20guard%20against%20interruptions%20and%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20prevent%20double%20restart%20of%20systemd-resolved%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20rm%20-f%20%22%24%7BKNICONFDONEPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Copy%20tmp%20file%20contents%20to%20preserve%20permissions%20and%20SELinux%20label%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20cat%20%22%24%7BKNICONFTMPPATH%7D%22%20%3E%20%22%24%7BKNICONFPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20%5B%5B%20!%20-f%20%22%24%7BKNICONFDONEPATH%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20systemctl%20-q%20is-active%20systemd-resolved%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Restarting%20systemd-resolved%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20systemctl%20restart%20systemd-resolved%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20touch%20%22%24%7BKNICONFDONEPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20rm%20-rf%20%22%24%7BKNICONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Prepending%20'nameserver%20%24NAMESERVER_IP'%20to%20%2Fetc%2Fresolv.conf%20(other%20nameservers%20from%20%2Fvar%2Frun%2FNetworkManager%2Fresolv.conf)%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20RESOLVCONFTMPPATH%3D%22%24(mktemp)%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20sed%20-e%20%22%2FGenerated%20by%2Fc%23%20Generated%20by%20KNI%20resolv%20prepender%20NM%20dispatcher%20script%22%20%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%2Fvar%2Frun%2FNetworkManager%2Fresolv.conf%20%3E%20%22%24%7BRESOLVCONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20sed%20-i%20%220%2C%2F%5Enameserver.*%2Fs%2F%2Fnameserver%20%24NAMESERVER_IP%5Cn%5C0%2F%22%20%22%24%7BRESOLVCONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20!%20grep%20-q%20search%20%22%24%7BRESOLVCONFTMPPATH%7D%22%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Make%20sure%20we%20have%20a%20search%20entry%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20echo%20%22search%20comp-poc-rh01.rhpoc.int%22%20%3E%3E%20%22%24%7BRESOLVCONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Make%20sure%20cluster%20domain%20is%20first%20in%20the%20search%20list%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20sed%20-i%20%22s%2F%5Esearch%20%5C(.*%5C)%2Fsearch%20comp-poc-rh01.rhpoc.int%20%5C1%2F%22%20%22%24%7BRESOLVCONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Remove%20duplicate%20cluster%20domain%20entries%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20sed%20-i%20%22s%2F%5C(search%20comp-poc-rh01.rhpoc.int.*%5C)%20comp-poc-rh01.rhpoc.int%5C(%20.*%5C%7C%24%5C)%2F%5C1%5C2%2F%22%20%22%24%7BRESOLVCONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Only%20leave%20the%20first%203%20nameservers%20in%20%2Fetc%2Fresolv.conf%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20sed%20-i%20'%3Aa%20%24!%7BN%3B%20ba%7D%3B%20s%2F%5C(%5E%5C%7C%5Cn%5C)nameserver%2F%5Cn%23%20nameserver%2F4g'%20%22%24%7BRESOLVCONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Only%20touch%20existing%20resolv.conf%20if%20files%20actually%20differ%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20!%20cmp%20-s%20%22%24%7BRESOLVCONFTMPPATH%7D%22%20%2Fetc%2Fresolv.conf%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20chmod%20644%20%22%24%7BRESOLVCONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20mv%20-Zf%20%22%24%7BRESOLVCONFTMPPATH%7D%22%20%2Fetc%2Fresolv.conf%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Workaround%20for%20bz%201929160.%20Reload%20NetworkManager%20to%20force%20it%20to%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20re-run%20the%20lookup%20of%20the%20hostname%20now%20that%20we%20know%20we%20have%20DNS%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20servers%20configured%20correctly%20in%20resolv.conf.%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20nmcli%20general%20reload%20dns-rc%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20touch%20%22%24%7BKNICONFDONEPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20rm%20-rf%20%22%24%7BRESOLVCONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20fi%0A%7D%0A%0Aresolv_prepender%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/resolv-prepender.sh
        - contents:
            source: data:,%23%20Needed%20by%20the%20OpenShift%20SDN.%20See%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1758552%0Anet.ipv4.conf.all.arp_announce%20%3D%202%0A
          mode: 420
          overwrite: true
          path: /etc/sysctl.d/arp.conf
        - contents:
            source: data:,%23%20See%3A%20rhbz%231384746%2C%20OCPBUGS-24012%0Anet.ipv4.neigh.default.gc_thresh1%3D8192%0Anet.ipv4.neigh.default.gc_thresh2%3D32768%0Anet.ipv4.neigh.default.gc_thresh3%3D65536%0Anet.ipv6.neigh.default.gc_thresh1%3D8192%0Anet.ipv6.neigh.default.gc_thresh2%3D32768%0Anet.ipv6.neigh.default.gc_thresh3%3D65536%0A
          mode: 420
          overwrite: true
          path: /etc/sysctl.d/gc-thresh.conf
        - contents:
            source: data:,%0Afs.inotify.max_user_watches%20%3D%2065536%0Afs.inotify.max_user_instances%20%3D%208192%0A
          mode: 420
          overwrite: true
          path: /etc/sysctl.d/inotify.conf
        - contents:
            source: data:,vm.unprivileged_userfaultfd%20%3D%201
          mode: 420
          overwrite: true
          path: /etc/sysctl.d/enable-userfaultfd.conf
        - contents:
            source: data:,%23%20Needed%20for%20OpenShift%20Logging%20(ElasticSearch).%20See%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1793714%0Avm.max_map_count%20%3D%20262144%0A
          mode: 420
          overwrite: true
          path: /etc/sysctl.d/vm-max-map.conf
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-euo%20pipefail%0A%0A%23%20First%2C%20we%20need%20to%20wait%20until%20DHCP%20finishes%20and%20the%20node%20has%20a%20non-%60localhost%60%0A%23%20hostname%20before%20%60kubelet.service%60%20starts.%0A%23%20That's%20the%20%60--wait%60%20argument%20as%20used%20by%20%60node-valid-hostname.service%60.%0A%23%0A%23%20Second%2C%20on%20GCP%20specifically%20we%20truncate%20the%20hostname%20if%20it's%20%3E63%20characters.%0A%23%20That's%20%60gcp-hostname.service%60.%0A%0A%23%20Block%20indefinitely%20until%20the%20host%20gets%20a%20non-localhost%20name.%0A%23%20Note%20node-valid-hostname.service%20uses%20systemd%20to%20abort%20if%20this%20takes%20too%20long.%0Await_localhost()%20%7B%0A%20%20%20%20echo%20%22waiting%20for%20non-localhost%20hostname%20to%20be%20assigned%22%0A%20%20%20%20while%20%5B%5B%20%22%24(%3C%20%2Fproc%2Fsys%2Fkernel%2Fhostname)%22%20%3D~%20(localhost%7Clocalhost.localdomain)%20%5D%5D%3B%0A%20%20%20%20do%0A%20%20%20%20%20%20%20%20sleep%201%0A%20%20%20%20done%0A%20%20%20%20echo%20%22node%20identified%20as%20%24(%3C%2Fproc%2Fsys%2Fkernel%2Fhostname)%22%0A%20%20%20%20echo%20%22saving%20hostname%20to%20prevent%20NetworkManager%20from%20ever%20unsetting%20it%22%0A%20%20%20%20hostnamectl%20set-hostname%20--static%20--transient%20%24(%3C%2Fproc%2Fsys%2Fkernel%2Fhostname)%0A%20%20%20%20exit%200%0A%7D%0A%0Aset_gcp_hostname()%20%7B%0A%20%20%20%20%2Fusr%2Fbin%2Fafterburn%20--provider%20gcp%20--hostname%3D%2Frun%2Fafterburn.hostname%0A%0A%20%20%20%20local%20host_name%3D%24(cat%20%2Frun%2Fafterburn.hostname)%0A%20%20%20%20local%20type_arg%3D%22transient%22%0A%0A%20%20%20%20%23%20%2Fetc%2Fhostname%20is%20used%20for%20static%20hostnames%20and%20is%20authoritative.%0A%20%20%20%20%23%20This%20will%20check%20to%20make%20sure%20that%20the%20static%20hostname%20is%20the%0A%20%20%20%20%23%20less%20than%20or%20equal%20to%2063%20characters%20in%20length.%0A%20%20%20%20if%20%5B%20-f%20%2Fetc%2Fhostname%20%5D%20%26%26%20%5B%20%22%24(cat%20%2Fetc%2Fhostname%20%7C%20wc%20-m)%22%20-gt%200%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20etc_name%3D%22%24(%3C%20%2Fetc%2Fhostname)%22%0A%20%20%20%20%20%20%20%20type_arg%3D%22static%22%0A%20%20%20%20%20%20%20%20if%20%5B%20%22%24%7Betc_name%7D%22%20!%3D%20%22%24%7Bhost_name%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20echo%20%22%2Fetc%2Fhostname%20is%20set%20to%20%24%7Betc_name%7D%20but%20does%20not%20match%20%24%7Bhost_name%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20echo%20%22using%20%2Fetc%2Fhostname%20as%20the%20authoritative%20name%22%0A%20%20%20%20%20%20%20%20%20%20%20%20host_name%3D%22%24%7Betc_name%7D%22%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Only%20mutate%20the%20hostname%20if%20the%20length%20is%20longer%20than%2063%20characters.%20The%0A%20%20%20%20%23%20hostname%20will%20be%20the%20lesser%20of%2063%20characters%20after%20the%20first%20dot%20in%20the%0A%20%20%20%20%23%20FQDN.%20%20This%20algorithm%20is%20only%20known%20to%20work%20in%20GCP%2C%20and%20hence%20is%20only%0A%20%20%20%20%23%20executed%20in%20GCP.%0A%20%20%20%20if%20%5B%20%22%24%7B%23host_name%7D%22%20-gt%2063%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20alt_name%3D%24(printf%20%22%24%7Bhost_name%7D%22%20%7C%20cut%20-f1%20-d'.'%20%7C%20cut%20-c%20-63)%0A%20%20%20%20%20%20%20%20echo%20%22%24%7Bhost_name%7D%20is%20longer%20than%2063%20characters%2C%20using%20truncated%20hostname%22%0A%20%20%20%20%20%20%20%20host_name%3D%22%24%7Balt_name%7D%22%0A%20%20%20%20fi%0A%20%20%20%20echo%20%22setting%20%24%7Btype_arg%7D%20hostname%20to%20%24%7Bhost_name%7D%22%0A%20%20%20%20%2Fbin%2Fhostnamectl%20%22--%24%7Btype_arg%7D%22%20set-hostname%20%22%24%7Bhost_name%7D%22%0A%20%20%20%20exit%200%0A%7D%0A%0Aset_openstack_hostname()%20%7B%0A%20%20%20%20%23%20Read%20metadata%20written%20by%20afterburn%20service%0A%20%20%20%20.%20%2Frun%2Fmetadata%2Fafterburn%0A%0A%20%20%20%20%23%20node-valid-hostname%20sets%20persistent%20hostname%20from%20%2Fproc%2Fsys%2Fkernel%2Fhostname%0A%20%20%20%20echo%20%22%24AFTERBURN_OPENSTACK_HOSTNAME%22%20%3E%20%2Fproc%2Fsys%2Fkernel%2Fhostname%0A%7D%0A%0Aset_powervs_hostname()%20%7B%0A%20%20%20%20%23%20Read%20metadata%20written%20by%20afterburn%20service%0A%20%20%20%20.%20%2Frun%2Fmetadata%2Fafterburn%0A%0A%20%20%20%20%23%20node-valid-hostname%20sets%20persistent%20hostname%20from%20%2Fproc%2Fsys%2Fkernel%2Fhostname%0A%20%20%20%20echo%20%22%24AFTERBURN_POWERVS_LOCAL_HOSTNAME%22%20%3E%20%2Fproc%2Fsys%2Fkernel%2Fhostname%0A%7D%0A%0Aarg%3D%24%7B1%7D%3B%20shift%3B%0Acase%20%22%24%7Barg%7D%22%20in%0A%20%20%20%20--wait)%20wait_localhost%3B%3B%0A%20%20%20%20--gcp)%20set_gcp_hostname%3B%3B%0A%20%20%20%20--openstack)%20set_openstack_hostname%3B%3B%0A%20%20%20%20--powervs)%20set_powervs_hostname%3B%3B%0A%20%20%20%20*)%20echo%20%22Unhandled%20arg%20%24arg%22%3B%20exit%201%0Aesac%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/mco-hostname
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%0Aset%20-eou%20pipefail%0A%0A%23%20context%0Aintapi%3D%24(oc%20get%20infrastructures.config.openshift.io%20cluster%20-o%20%22jsonpath%3D%7B.status.apiServerInternalURI%7D%22)%0Acontext%3D%22%24(oc%20config%20current-context)%22%0A%23%20cluster%0Acluster%3D%22%24(oc%20config%20view%20-o%20%22jsonpath%3D%7B.contexts%5B%3F(%40.name%3D%3D%5C%22%24context%5C%22)%5D.context.cluster%7D%22)%22%0Aserver%3D%22%24(oc%20config%20view%20-o%20%22jsonpath%3D%7B.clusters%5B%3F(%40.name%3D%3D%5C%22%24cluster%5C%22)%5D.cluster.server%7D%22)%22%0A%23%20token%0Aca_crt_data%3D%22%24(oc%20get%20secret%20-n%20openshift-machine-config-operator%20node-bootstrapper-token%20-o%20%22jsonpath%3D%7B.data.ca%5C.crt%7D%22%20%7C%20base64%20--decode)%22%0Anamespace%3D%22%24(oc%20get%20secret%20-n%20openshift-machine-config-operator%20node-bootstrapper-token%20%20-o%20%22jsonpath%3D%7B.data.namespace%7D%22%20%7C%20base64%20--decode)%22%0Atoken%3D%22%24(oc%20get%20secret%20-n%20openshift-machine-config-operator%20node-bootstrapper-token%20-o%20%22jsonpath%3D%7B.data.token%7D%22%20%7C%20base64%20--decode)%22%0A%0Aexport%20KUBECONFIG%3D%22%24(mktemp)%22%0Akubectl%20config%20set-credentials%20%22kubelet%22%20--token%3D%22%24token%22%20%3E%2Fdev%2Fnull%0Aca_crt%3D%22%24(mktemp)%22%3B%20echo%20%22%24ca_crt_data%22%20%3E%20%24ca_crt%0Akubectl%20config%20set-cluster%20%24cluster%20--server%3D%22%24intapi%22%20--certificate-authority%3D%22%24ca_crt%22%20--embed-certs%20%3E%2Fdev%2Fnull%0Akubectl%20config%20set-context%20kubelet%20--cluster%3D%22%24cluster%22%20--user%3D%22kubelet%22%20%3E%2Fdev%2Fnull%0Akubectl%20config%20use-context%20kubelet%20%3E%2Fdev%2Fnull%0Acat%20%22%24KUBECONFIG%22%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/recover-kubeconfig.sh
        - contents:
            source: data:,
          mode: 493
          overwrite: true
          path: /etc/kubernetes/kubelet-plugins/volume/exec/.dummy
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%23%20Workaround%3A%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1941714%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1935539%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1987108%0A%0Adriver%3D%24(nmcli%20-t%20-m%20tabular%20-f%20general.driver%20dev%20show%20%22%24%7BDEVICE_IFACE%7D%22)%0A%0Aif%20%5B%5B%20%22%242%22%20%3D%3D%20%22up%22%20%26%26%20%22%24%7Bdriver%7D%22%20%3D%3D%20%22vmxnet3%22%20%5D%5D%3B%20then%0A%20%20logger%20-s%20%2299-vsphere-disable-tx-udp-tnl%20triggered%20by%20%24%7B2%7D%20on%20device%20%24%7BDEVICE_IFACE%7D.%22%0A%20%20ethtool%20-K%20%24%7BDEVICE_IFACE%7D%20tx-udp_tnl-segmentation%20off%0A%20%20ethtool%20-K%20%24%7BDEVICE_IFACE%7D%20tx-udp_tnl-csum-segmentation%20off%0A%20%20ethtool%20-K%20%24%7BDEVICE_IFACE%7D%20tx-checksum-ip-generic%20off%0Afi%0A
          mode: 484
          overwrite: true
          path: /etc/NetworkManager/dispatcher.d/99-vsphere-disable-tx-udp-tnl
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%0Auntil%20%5B%20-e%20%2Frun%2Fnodeip-configuration%2Fbr-ex-up%20%5D%0Ado%0A%20%20sleep%201%0Adone%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/wait-for-br-ex-up.sh
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-x%0A%0Aif%20%5B%20!%20-e%20%22%2Fetc%2Fipsec.d%2Fopenshift.conf%22%20%5D%3B%20then%0A%20%20exit%200%0Afi%0A%0A%23%20Modify%20existing%20IPsec%20connection%20entries%20with%20%22auto%3Dstart%22%0A%23%20option%20and%20restart%20ipsec%20systemd%20service.%20This%20helps%20to%0A%23%20establish%20IKE%20SAs%20for%20the%20existing%20IPsec%20connections%20with%0A%23%20peer%20nodes.%20This%20option%20will%20be%20deleted%20from%20connections%0A%23%20once%20ovs-monitor-ipsec%20process%20spinned%20up%20on%20the%20node%20by%0A%23%20ovn-ipsec-host%20pod%2C%20but%20still%20it%20won't%20reestablish%20IKE%20SAs%0A%23%20again%20with%20peer%20nodes%2C%20so%20it%20shouldn't%20be%20a%20problem.%0Aif%20!%20grep%20-q%20%22auto%3Dstart%22%20%2Fetc%2Fipsec.d%2Fopenshift.conf%3B%20then%0A%20%20sed%20-i%20'%2F%5E.*conn%20ovn.*%24%2Fa%5C%20%20%20%20auto%3Dstart'%20%2Fetc%2Fipsec.d%2Fopenshift.conf%0Afi%0Achroot%20%2Fproc%2F1%2Froot%20ipsec%20restart%0A%0A%23%20Wait%20for%20upto%2060s%20to%20get%20IPsec%20SAs%20to%20establish%20with%20peer%20nodes.%0Atimeout%3D60%0Aelapsed%3D0%0Adesiredconn%3D%22%22%0Aestablishedsa%3D%22%22%0Awhile%20%5B%5B%20%24elapsed%20-lt%20%24timeout%20%5D%5D%3B%20do%0A%20%20desiredconn%3D%24(grep%20-E%20'%5E%5Cs*conn%5Cs%2B'%20%2Fetc%2Fipsec.d%2Fopenshift.conf%20%7C%20grep%20-v%20'%25default'%20%7C%20awk%20'%7Bprint%20%242%7D'%20%7C%20tr%20'%20'%20'%5Cn'%20%7C%20sort%20%7C%20tr%20'%5Cn'%20'%20')%0A%20%20establishedsa%3D%24(ipsec%20showstates%20%7C%20grep%20STATE_V2_ESTABLISHED_CHILD_SA%20%7C%20grep%20-o%20'%22%5B%5E%22%5D*%22'%20%7C%20sed%20's%2F%22%2F%2Fg'%20%7C%20tr%20'%20'%20'%5Cn'%20%7C%20sort%20%7C%20uniq%20%7C%20tr%20'%5Cn'%20'%20')%0A%20%20if%20%5B%20%22%24desiredconn%22%20%3D%3D%20%22%24establishedsa%22%20%5D%3B%20then%0A%20%20%20%20echo%20%22IPsec%20SAs%20are%20established%20for%20desired%20connections%20after%20%24%7Belapsed%7Ds%22%0A%20%20%20%20break%0A%20%20else%0A%20%20%20%20echo%20%22IPsec%20SAs%20are%20not%20established%20yet%2C%20total%20waited%20time%20%24%7Belapsed%7Ds%22%0A%20%20%20%20sleep%202s%0A%20%20fi%0A%20%20elapsed%3D%24((elapsed%20%2B%202))%0Adone%0A%0Aif%20%5B%5B%20%24elapsed%20-ge%20%24timeout%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22Timed%20out%20waiting%2C%20some%20connections%20are%20not%20established%2C%20desired%20conns%20%24desiredconn%2C%20established%20conns%20%24establishedsa%22%0Afi%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/ipsec-connect-wait.sh
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-eux%0A%0Aif%20%5B%20!%20-e%20%2Fetc%2Fnmstate%2Fopenshift%2Fapplied%20%5D%3B%20then%0A%20%20%23%20No%20need%20to%20do%20this%20if%20no%20NMState%20configuration%20was%20applied%0A%20%20exit%200%0Afi%0A%0A%23%20This%20logic%20is%20borrowed%20from%20configure-ovs.sh%0A%23%20TODO%3A%20Find%20a%20platform-agnostic%20way%20to%20do%20this.%20It%20won't%20work%20on%20platforms%20where%0A%23%20nodeip-configuration%20is%20not%20used.%0Aip%3D%24(cat%20%2Frun%2Fnodeip-configuration%2Fprimary-ip)%0Aif%20%5B%5B%20%22%24%7Bip%7D%22%20%3D%3D%20%22%22%20%5D%5D%3B%20then%0A%20%20echo%20%22No%20ip%20to%20bind%20was%20found%22%0A%20%20exit%201%0Afi%0Awhile%20%3A%0Ado%0A%20%20random_port%3D%24(shuf%20-i%2050000-60000%20-n%201)%0A%20%20echo%20%22Trying%20to%20bind%20%24%7Bip%7D%20on%20port%20%24%7Brandom_port%7D%22%0A%20%20exit_code%3D%24(timeout%202s%20nc%20-l%20%22%24%7Bip%7D%22%20%24%7Brandom_port%7D%3B%20echo%20%24%3F)%0A%20%20if%20%5B%5B%20exit_code%20-eq%20124%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22Address%20bound%20successfully%22%0A%20%20%20%20exit%200%0A%20%20fi%0A%20%20sleep%2010%0Adone%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/wait-for-primary-ip.sh
      systemd:
        units:
        - contents: |
            [Unit]
            Description=Cleans NetworkManager state generated by dracut
            # Removal of this file signals firstboot completion
            ConditionPathExists=!/etc/ignition-machine-config-encapsulated.json
            # This is opt-in for some deployment types, and opt-out for others.
            ConditionPathExists=/var/lib/mco/nm-clean-initrd-state
            Wants=network-pre.target
            Before=network-pre.target

            [Service]
            Type=oneshot
            # Remove any existing state possibly generated NM run by dracut. We want NM to
            # consider all profiles autoconnect priority when it starts instead of
            # remembering which profile was a device activated with when NM is run by
            # dracut.
            ExecStart=/usr/local/bin/nm-clean-initrd-state.sh
            StandardOutput=journal+console
            StandardError=journal+console

            [Install]
            WantedBy=network-online.target
          enabled: true
          name: NetworkManager-clean-initrd-state.service
        - dropins:
          - contents: |
              # vim:set ft=systemd :
              #
              # This drop-in will enable any service built with this
              # github.com/containers/kubemntns library to properly join the mount namespace
              # managed by kubens.service
              #

              [Unit]
              After=kubens.service

              [Service]
              EnvironmentFile=-/run/kubens/env
            name: 01-kubens.conf
          - contents: ""
            name: 10-mco-default-env.conf
          - contents: |
              [Service]
              Environment="ENABLE_PROFILE_UNIX_SOCKET=true"
            name: 10-mco-profile-unix-socket.conf
          - contents: |
              [Unit]
              After=kubelet-dependencies.target
              Requires=kubelet-dependencies.target
            name: 05-mco-ordering.conf
          - contents: |
              [Service]
              Environment="GODEBUG=x509ignoreCN=0,madvdontneed=1"
            name: 10-mco-default-madv.conf
          name: crio.service
        - dropins:
          - contents: |
              [Unit]
              ConditionPathExists=/enoent
            name: mco-disabled.conf
          name: docker.socket
        - contents: |
            [Unit]
            Description=The firstboot OS update has completed
            Documentation=https://github.com/openshift/machine-config-operator/
            Requires=basic.target

            [Install]
            WantedBy=default.target
          enabled: true
          name: firstboot-osupdate.target
        - dropins:
          - contents: |
              [Unit]
              After=ovs-configuration.service
              Before=crio.service
            name: 01-after-configure-ovs.conf
          name: ipsec.service
        - contents: |
            [Unit]
            Description=Dynamically sets the system reserved for the kubelet
            Wants=network-online.target
            After=network-online.target firstboot-osupdate.target
            Before=kubelet-dependencies.target

            [Service]
            # Need oneshot to delay kubelet
            Type=oneshot
            RemainAfterExit=yes
            EnvironmentFile=/etc/node-sizing-enabled.env
            ExecStart=/bin/bash /usr/local/sbin/dynamic-system-reserved-calc.sh ${NODE_SIZING_ENABLED} ${SYSTEM_RESERVED_MEMORY} ${SYSTEM_RESERVED_CPU} ${SYSTEM_RESERVED_ES}
            [Install]
            RequiredBy=kubelet-dependencies.target
          enabled: true
          name: kubelet-auto-node-size.service
        - contents: |
            [Unit]
            Description=Dependencies necessary to run kubelet
            Documentation=https://github.com/openshift/machine-config-operator/
            Requires=basic.target network-online.target
            Wants=NetworkManager-wait-online.service crio-wipe.service
            Wants=rpc-statd.service chrony-wait.service
          name: kubelet-dependencies.target
        - dropins:
          - contents: |
              # vim:set ft=systemd :
              #
              # This drop-in will enable any service built with this
              # github.com/containers/kubemntns library to properly join the mount namespace
              # managed by kubens.service
              #

              [Unit]
              After=kubens.service

              [Service]
              EnvironmentFile=-/run/kubens/env
            name: 01-kubens.conf
          - contents: ""
            name: 10-mco-default-env.conf
          - contents: |
              [Service]
              # Wait for resolv-prepender to configure nameservers, exit 255 otherwise
              # to mark the unit as failed and retry later
              ExecCondition=/bin/bash -c '[ -f /run/resolv-prepender-kni-conf-done ] || { echo "NM resolv-prepender failed"; exit 255; }'
            name: 10-mco-on-prem-wait-resolv.conf
          - contents: |
              [Service]
              Environment="GODEBUG=x509ignoreCN=0,madvdontneed=1"
            name: 10-mco-default-madv.conf
          name: kubelet.service
        - contents: |
            [Unit]
            Description=Manages a mount namespace for kubernetes-specific mounts

            [Service]
            Type=oneshot
            RemainAfterExit=yes
            RuntimeDirectory=kubens
            Environment=RUNTIME_DIRECTORY=%t/kubens
            Environment=BIND_POINT=%t/kubens/mnt
            Environment=ENVFILE=%t/kubens/env

            # Set up the runtime directory as an unbindable mountpoint
            ExecStartPre=bash -c "findmnt ${RUNTIME_DIRECTORY} || mount --make-unbindable --bind ${RUNTIME_DIRECTORY} ${RUNTIME_DIRECTORY}"
            # Ensure the bind point exists
            ExecStartPre=touch ${BIND_POINT}
            # Use 'unshare' to create the new mountpoint, then 'mount --make-rshared' so it cascades internally
            ExecStart=unshare --mount=${BIND_POINT} --propagation slave mount --make-rshared /
            # Finally, set an env pointer for ease-of-use
            ExecStartPost=bash -c 'echo "KUBENSMNT=${BIND_POINT}" > "${ENVFILE}"'

            # On stop, a recursive unmount cleans up the namespace and bind-mounted unbindable parent directory
            ExecStop=umount -R ${RUNTIME_DIRECTORY}

            [Install]
            WantedBy=multi-user.target
          enabled: false
          name: kubens.service
        - contents: |
            [Unit]
            Description=Machine Config Daemon Firstboot
            # Make sure it runs only on OSTree booted system
            ConditionPathExists=/run/ostree-booted
            # Removal of this file signals firstboot completion
            ConditionPathExists=/etc/ignition-machine-config-encapsulated.json
            After=machine-config-daemon-pull.service
            Before=kubelet-dependencies.target

            [Service]
            Type=oneshot
            RemainAfterExit=yes
            # Disable existing repos (if any) so that OS extensions would use embedded RPMs only
            ExecStartPre=-/usr/bin/sh -c "sed -i 's/enabled=1/enabled=0/' /etc/yum.repos.d/*.repo"
            # Run this via podman because we want to use the nmstatectl binary in our container
            ExecStart=/usr/bin/podman run --rm --privileged --net=host -v /:/rootfs  --entrypoint machine-config-daemon 'quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:94bac6c3782cf6579032c7c9dabca74146753d9a44591125acd30d606d7d340c' firstboot-complete-machineconfig --persist-nics
            ExecStart=/usr/bin/podman run --rm --privileged --pid=host --net=host -v /:/rootfs  --entrypoint machine-config-daemon 'quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:94bac6c3782cf6579032c7c9dabca74146753d9a44591125acd30d606d7d340c' firstboot-complete-machineconfig
            [Install]
            RequiredBy=firstboot-osupdate.target
          enabled: true
          name: machine-config-daemon-firstboot.service
        - contents: |
            [Unit]
            Description=Machine Config Daemon Pull
            # Make sure it runs only on OSTree booted system
            ConditionPathExists=/run/ostree-booted
            # This "stamp file" is unlinked when we complete
            # machine-config-daemon-firstboot.service
            ConditionPathExists=/etc/ignition-machine-config-encapsulated.json
            # Run after crio-wipe so the pulled MCD image is protected against a corrupted storage from a forced shutdown
            Wants=crio-wipe.service NetworkManager-wait-online.service
            After=crio-wipe.service NetworkManager-wait-online.service network.service

            [Service]
            Type=oneshot
            RemainAfterExit=yes
            ExecStartPre=/etc/machine-config-daemon/generate_podman_policy_args.sh
            ExecStart=/bin/sh -c "while ! /usr/bin/podman pull $(cat /tmp/podman_policy_args) --authfile=/var/lib/kubelet/config.json 'quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:94bac6c3782cf6579032c7c9dabca74146753d9a44591125acd30d606d7d340c'; do sleep 1; done"

            [Install]
            RequiredBy=machine-config-daemon-firstboot.service
          enabled: true
          name: machine-config-daemon-pull.service
        - contents: |
            [Unit]
            Description=Applies per-node NMState network configuration
            Requires=openvswitch.service
            Wants=NetworkManager-wait-online.service
            After=NetworkManager-wait-online.service openvswitch.service network.service nodeip-configuration.service
            Before=nmstate.service kubelet-dependencies.target ovs-configuration.service node-valid-hostname.service

            [Service]
            Type=oneshot
            # Would prefer to do Restart=on-failure instead of this bash retry loop, but
            # the version of systemd we have right now doesn't support it. It should be
            # available in systemd v244 and higher.
            ExecStart=/usr/local/bin/nmstate-configuration.sh
            StandardOutput=journal+console
            StandardError=journal+console

            [Install]
            WantedBy=network-online.target
          enabled: true
          name: nmstate-configuration.service
        - contents: |
            [Unit]
            Description=Apply nmstate on-disk state
            Documentation=man:nmstate.service(8) https://www.nmstate.io
            After=NetworkManager-wait-online.service
            Before=network-online.target
            Wants=NetworkManager-wait-online.service
            Requires=NetworkManager.service

            [Service]
            Type=oneshot
            ExecStart=/usr/bin/nmstatectl service
            RemainAfterExit=yes

            [Install]
            WantedBy=NetworkManager.service
          enabled: true
          name: nmstate.service
        - contents: |
            [Unit]
            Description=Wait for a non-localhost hostname
            Before=kubelet-dependencies.target

            [Service]
            Type=oneshot
            RemainAfterExit=yes
            User=root
            ExecStart=/usr/local/bin/mco-hostname --wait

            # Wait up to 5min for the node to get a non-localhost name
            TimeoutSec=300

            [Install]
            # TODO: Change this to RequiredBy after we fix https://github.com/openshift/machine-config-operator/pull/3865#issuecomment-1746963115
            WantedBy=kubelet-dependencies.target
          enabled: true
          name: node-valid-hostname.service
        - contents: |
            [Unit]
            Description=Writes IP address configuration so that kubelet and crio services select a valid node IP
            # This only applies to VIP managing environments where the kubelet and crio IP
            # address picking logic is flawed and may end up selecting an address from a
            # different subnet or a deprecated address
            Wants=NetworkManager-wait-online.service
            After=NetworkManager-wait-online.service firstboot-osupdate.target
            Before=kubelet-dependencies.target ovs-configuration.service

            [Service]
            # Need oneshot to delay kubelet
            Type=oneshot
            # Would prefer to do Restart=on-failure instead of this bash retry loop, but
            # the version of systemd we have right now doesn't support it. It should be
            # available in systemd v244 and higher.
            ExecStart=/bin/bash -c " \
              until \
              /usr/bin/podman run --rm \
              --authfile /var/lib/kubelet/config.json \
              --net=host \
              --security-opt label=disable \
              --volume /etc/systemd/system:/etc/systemd/system \
              --volume /run/nodeip-configuration:/run/nodeip-configuration \
              quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:93e7b8c870261726d44bddc7ba0a702d3720d1838141dac837fb8c3be7c6e1a1 \
              node-ip \
              set \
              --platform BareMetal \
              --retry-on-failure \
              ${NODEIP_HINT:-} \
              10.100.0.50  \
              10.100.0.51 ; \
              do \
              sleep 5; \
              done"
            ExecStart=/bin/systemctl daemon-reload
            ExecStartPre=/bin/mkdir -p /run/nodeip-configuration
            ExecStartPost=+/usr/local/bin/configure-ip-forwarding.sh
            StandardOutput=journal+console
            StandardError=journal+console
            EnvironmentFile=-/etc/default/nodeip-configuration

            [Install]
            RequiredBy=kubelet-dependencies.target
          enabled: true
          name: nodeip-configuration.service
        - contents: |
            [Unit]
            Description=Watches for changes in /var/run/NetworkManager/resolv.conf according to on-prem IPI needs
            [Path]
            PathModified=/var/run/NetworkManager/resolv.conf
            PathModified=/run/resolv-prepender/env
            Unit=on-prem-resolv-prepender.service
            [Install]
            WantedBy=multi-user.target
          enabled: true
          name: on-prem-resolv-prepender.path
        - contents: |
            [Unit]
            Description=Populates resolv.conf according to on-prem IPI needs
            # Per https://issues.redhat.com/browse/OCPBUGS-27162 there is a problem if this is started before crio-wipe
            After=crio-wipe.service
            StartLimitIntervalSec=0
            [Service]
            Type=oneshot
            # Would prefer to do Restart=on-failure instead of this bash retry loop, but
            # the version of systemd we have right now doesn't support it. It should be
            # available in systemd v244 and higher.
            ExecStart=/bin/bash -c " \
              until \
              /usr/local/bin/resolv-prepender.sh; \
              do \
              sleep 10; \
              done"
            EnvironmentFile=-/run/resolv-prepender/env
          enabled: false
          name: on-prem-resolv-prepender.service
        - enabled: true
          name: openvswitch.service
        - contents: |
            [Unit]
            # Kdump will generate it's initramfs based on the running state when kdump.service run
            # If OVS has already run, the kdump fails to gather a working network config,
            # which prevent network log exports, sush as SSH.
            # See https://issues.redhat.com/browse/OCPBUGS-28239
            After=kdump.service
            Description=Configures OVS with proper host networking configuration
            # This service is used to move a physical NIC into OVS and reconfigure OVS to use the host IP
            Requires=openvswitch.service
            Wants=NetworkManager-wait-online.service
            After=firstboot-osupdate.target
            After=NetworkManager-wait-online.service openvswitch.service network.service nodeip-configuration.service nmstate.service
            Before=kubelet-dependencies.target node-valid-hostname.service

            [Service]
            # Need oneshot to delay kubelet
            Type=oneshot
            ExecStart=/usr/local/bin/configure-ovs.sh OVNKubernetes
            StandardOutput=journal+console
            StandardError=journal+console

            [Install]
            RequiredBy=kubelet-dependencies.target
          enabled: true
          name: ovs-configuration.service
        - dropins:
          - contents: |
              [Service]
              Restart=always
              ExecStartPre=-/bin/sh -c '/usr/bin/chown -R :$${OVS_USER_ID##*:} /var/lib/openvswitch'
              ExecStartPre=-/bin/sh -c '/usr/bin/chown -R :$${OVS_USER_ID##*:} /etc/openvswitch'
              ExecStartPre=-/bin/sh -c '/usr/bin/chown -R :$${OVS_USER_ID##*:} /run/openvswitch'
              ExecStartPost=-/usr/bin/ovs-appctl vlog/set syslog:info
              ExecReload=-/usr/bin/ovs-appctl vlog/set syslog:info
            name: 10-ovs-vswitchd-restart.conf
          name: ovs-vswitchd.service
        - dropins:
          - contents: |
              [Service]
              Restart=always
            name: 10-ovsdb-restart.conf
          enabled: true
          name: ovsdb-server.service
        - dropins:
          - contents: ""
            name: 10-mco-default-env.conf
          - contents: |
              # See https://github.com/openshift/machine-config-operator/issues/1897
              [Service]
              Nice=10
              IOSchedulingClass=best-effort
              IOSchedulingPriority=6
            name: mco-controlplane-nice.conf
          name: rpm-ostreed.service
        - contents: |
            [Unit]
            Description=Wait for br-ex up event from NetworkManager
            Wants=ovs-configuration.service
            After=ovs-configuration.service
            Before=node-valid-hostname.service

            [Service]
            Type=oneshot
            ExecStart=/usr/local/bin/wait-for-br-ex-up.sh

            [Install]
            RequiredBy=node-valid-hostname.service
          enabled: true
          name: wait-for-br-ex-up.service
        - contents: |
            [Unit]
            Description=Ensure IKE SA established for existing IPsec connections.
            After=ipsec.service
            Before=kubelet-dependencies.target node-valid-hostname.service

            [Service]
            Type=oneshot
            ExecStart=/usr/local/bin/ipsec-connect-wait.sh
            StandardOutput=journal+console
            StandardError=journal+console

            [Install]
            WantedBy=ipsec.service
          enabled: true
          name: wait-for-ipsec-connect.service
        - contents: |
            [Unit]
            Description=Ensure primary IP is assigned and usable
            Requires=nmstate.service
            After=nmstate.service
            Before=kubelet-dependencies.target

            [Service]
            Type=oneshot
            # Would prefer to do Restart=on-failure instead of this bash retry loop, but
            # the version of systemd we have right now doesn't support it. It should be
            # available in systemd v244 and higher.
            ExecStart=/bin/bash -c " \
              until \
              /usr/local/bin/wait-for-primary-ip.sh; \
              do \
              sleep 10; \
              done"
            StandardOutput=journal+console
            StandardError=journal+console

            [Install]
            WantedBy=network-online.target
          enabled: true
          name: wait-for-primary-ip.service
        - dropins:
          - contents: |
              [Unit]
              ConditionPathExists=/enoent
            name: mco-disabled.conf
          name: zincati.service
    fips: false
    kernelArguments: null
    kernelType: ""
    osImageURL: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4e309dd906392e783a404b92dfd4fa4c32d74e2804ee37d1fb8a00c9355d5978
- apiVersion: machineconfiguration.openshift.io/v1
  kind: MachineConfig
  metadata:
    annotations:
      machineconfiguration.openshift.io/generated-by-controller-version: fcf8f254943cbcba1400ba55f3978cc292b6460b
    creationTimestamp: "2025-11-04T16:09:16Z"
    generation: 1
    labels:
      machineconfiguration.openshift.io/role: worker
    name: 00-worker
    ownerReferences:
    - apiVersion: machineconfiguration.openshift.io/v1
      blockOwnerDeletion: true
      controller: true
      kind: ControllerConfig
      name: machine-config-controller
      uid: 18dbcd72-fa02-401e-8486-bd239a092409
    resourceVersion: "10957"
    uid: 70598c34-f703-4c70-a443-8d15598030b7
  spec:
    baseOSExtensionsContainerImage: ""
    config:
      ignition:
        version: 3.4.0
      storage:
        files:
        - contents:
            source: data:,%23%20This%20file%20signals%20NetworkManager-clean-initrd-state%20service%20to%20run%20on%0A%23%20boot.%20This%20service%20is%20used%20to%20clean%20up%20the%20network%20activation%20state%0A%23%20generated%20by%20dracut%20so%20that%20other%20network%20configuration%20deployed%20by%20the%0A%23%20user%20can%20be%20activated.%20This%20only%20happens%20if%20dracut%20activated%20a%20default%0A%23%20network%20configuration%20and%20there%20is%20an%20alternate%20configuration%20available%20in%0A%23%20the%20root%20filesystem.%20Otherwise%2C%20it%20is%20assumed%20that%20the%20network%0A%23%20configuration%20activated%20by%20dracut%20is%20the%20one%20that%20is%20intended%20to%20be%20used%0A%23%20throughout%20the%20life%20of%20the%20system.%0A%23%20Opt-out%20for%20baremetal%20IPI%20deplyments%2C%20opt-in%20otherwise.%0A
          mode: 493
          overwrite: true
          path: /var/lib/mco/nm-clean-initrd-state
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-ex%20-o%20pipefail%0A%0ANM_DEVICES_DIR%3D%2Frun%2FNetworkManager%2Fdevices%0ANM_RUN_CONN_DIR%3D%2Frun%2FNetworkManager%2Fsystem-connections%0ANM_ETC_CONN_DIR%3D%2Fetc%2FNetworkManager%2Fsystem-connections%0A%0Alogger%20-t%20nm-clean-initrd-state%20%22Cleaning%20network%20activation%20state%20generated%20by%20dracut...%22%0Alogger%20-t%20nm-clean-initrd-state%20%22To%20disable%2C%20remove%20%2Fvar%2Flib%2Fmco%2Fnm-clean-initrd-state%22%0A%0Aif%20%5B%20!%20-e%20%22%24NM_DEVICES_DIR%22%20%5D%20%7C%7C%20%5B%20!%20-e%20%22%24NM_RUN_CONN_DIR%22%20%5D%20%7C%7C%20%5B%20!%20-e%20%22%24NM_ETC_CONN_DIR%22%20%5D%3B%20then%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22There%20is%20no%20network%20activation%20state%20to%20clean%22%0A%20%20exit%0Afi%0A%0A%23%20Some%20deployments%20require%20an%20active%20network%20early%20in%20the%20boot%20process.%20To%0A%23%20achieve%20this%2C%20dracut%20runs%20specific%20NetworkManager%20modules.%20This%20results%20in%0A%23%20NetworkManager%20keyfiles%20being%20generated%20(either%20default%20or%20from%20ip%20kernel%0A%23%20arguments)%20and%20activated.%20This%20activation%20generates%20state%20that%20makes%20those%0A%23%20profiles%20to%20be%20re-activated%20by%20the%20NetworkManager%20service%20later%20in%20the%0A%23%20boot%20process.%20And%20this%20has%20the%20effect%20that%20other%20profiles%20deployed%20by%20the%0A%23%20user%20for%20the%20same%20set%20of%20devices%20are%20ignored.%0A%0A%23%20Most%20of%20the%20time%20this%20is%20the%20desired%20behavior.%20The%20exception%20to%20this%20rule%0A%23%20is%20when%20the%20user%20wants%20to%20run%20the%20boot%20process%20with%20a%20different%20network%0A%23%20setup%20than%20the%20real%20root%20which%20is%20usually%20related%20to%20the%20fact%20that%0A%23%20generating%20images%20with%20customized%20kernel%20arguments%20is%20a%20complication%20in%0A%23%20the%20deployment%20pipeline.%0A%0A%23%20This%20need%20has%20been%20exacerbated%20by%20past%20NetworkManager%20bugs%20that%20activated%0A%23%20the%20network%20on%20boot%20when%20it%20was%20not%20really%20needed.%20Most%20notably%20when%20ip%0A%23%20kernel%20argument%20is%20present%2C%20something%20that%20the%20baremetal%20installer%20adds%20by%0A%23%20default.%0A%0A%23%20The%20intention%20here%20is%20to%20remove%20the%20state%20that%20was%20generated%20with%20the%0A%23%20activation%20of%20those%20profiles%20during%20dracut%20execution.%20Then%20when%0A%23%20NetworkManager%20service%20runs%2C%20the%20profiles%20generated%20by%20dracut%2C%20along%20with%0A%23%20other%20profiles%20configured%20by%20the%20user%2C%20are%20evaluated%20towards%20finding%20the%0A%23%20most%20appropriate%20profile%20to%20connect%20a%20device%20with.%20As%20a%20precaution%2C%20clean%0A%23%20state%20only%20for%20devices%20that%3A%0A%23%20-%20have%20been%20activated%20with%20a%20default%20profile%20(assume%20that%20a%20non-default%0A%23%20%20%20configuration%20expresses%20intention%20by%20user%20to%20run%20with%20it%20permanently)%0A%23%20-%20have%20a%20specific%20configured%20profile%20set%20to%20auto-connect%20(if%20there%20is%20no%0A%23%20%20%20alternate%20configured%20profile%20for%20a%20device%20it%20makes%20no%20sense%20to%0A%23%20%20%20de-activate%20anything)%0A%23%0A%23%20Although%20this%20can%20theoretically%20happen%20on%20any%20deployment%20type%2C%20need%20has%0A%23%20mostly%20come%20from%20IPI%20bare%20metal%20deployments.%20For%20the%20time%20being%2C%20this%0A%23%20should%20be%20opt-in%20in%20any%20other%20deploment%20type.%0A%23%0A%23%20There%20is%20an%20RFE%20filed%20against%20NM%20that%20once%20implemented%20would%20make%20this%0A%23%20script%20unnecessary%3A%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D2089707%0A%0Afor%20device%20in%20%22%24%7BNM_DEVICES_DIR%7D%22%2F*%3B%20do%0A%20%20if%20%5B%20!%20-e%20%22%24device%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20the%20device%20file%20name%20is%20the%20ifindex%0A%20%20ifindex%3D%24(basename%20%22%24device%22)%0A%20%20%0A%20%20%23%20get%20the%20interface%20name%20by%20ifindex%0A%20%20ifname%3D%24(ip%20-j%20link%20show%20%7C%20jq%20-r%20%22.%5B%5D%20%7C%20select(.ifindex%20%3D%3D%20%24%7Bifindex%7D)%20%7C%20.ifname%20%2F%2F%20empty%22)%0A%0A%20%20%23%20no%20interface%20name%20found%2C%20ignore%0A%20%20if%20%5B%20-z%20%22%24ifname%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20get%20the%20uuid%20of%20the%20profile%20the%20device%20has%20been%20activated%20with%0A%20%20active_profile_uuid%3D%24(sed%20-nr%20'%2F%5E%5C%5Bdevice%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Econnection-uuid%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24device%22)%0A%0A%20%20%23%20the%20device%20was%20not%20activated%20with%20any%20profile%2C%20ignore%0A%20%20if%20%5B%20-z%20%22%24active_profile_uuid%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20find%20the%20generated%20profile%20by%20uuid%0A%20%20for%20profile%20in%20%22%24%7BNM_RUN_CONN_DIR%7D%22%2F*%3B%20do%0A%20%20%20%20generated_profile_uuid%3D%24(sed%20-nr%20'%2F%5E%5C%5Bconnection%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Euuid%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20%20%20if%20%5B%20%22%24active_profile_uuid%22%20%3D%20%22%24generated_profile_uuid%22%20%5D%3B%20then%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20done%0A%0A%20%20%23%20generated%20profile%20not%20found%2C%20ignore%0A%20%20if%20%5B%20%22%24active_profile_uuid%22%20!%3D%20%22%24generated_profile_uuid%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20check%20that%20it%20is%20not%20specific%20for%20the%20device%2C%20otherwise%20ignore%0A%20%20profile_ifname%3D%24(sed%20-nr%20'%2F%5E%5C%5Bconnection%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Einterface-name%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20if%20%5B%20-n%20%22%24profile_ifname%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20profile%20not%20generated%20by%20nm-initrd-generator%2C%20ignore%0A%20%20%23%20only%20check%20it%20if%20the%20key%20is%20set%20(from%20NM%201.32.4)%0A%20%20origin%3D%24(sed%20-nr%20'%2F%5E%5C%5Buser%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Eorg.freedesktop.NetworkManager.origin%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20if%20%5B%20-n%20%22%24origin%22%20%5D%20%26%26%20%5B%20%22%24origin%22%20!%3D%20%22nm-initrd-generator%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20find%20the%20configured%20profile%20by%20name%20with%20auto-connect%20set%0A%20%20for%20profile%20in%20%22%24%7BNM_ETC_CONN_DIR%7D%22%2F*%3B%20do%0A%20%20%20%20profile_ifname%3D%24(sed%20-nr%20'%2F%5E%5C%5Bconnection%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Einterface-name%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20%20%20autoconnect%3D%24(sed%20-nr%20'%2F%5E%5C%5Bconnection%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Eautoconnect%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20%20%20if%20%5B%20%22%24profile_ifname%22%20%3D%20%22%24ifname%22%20%5D%20%26%26%20%5B%20%22%24autoconnect%22%20!%3D%20%22false%22%20%5D%3B%20then%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20done%0A%0A%20%20%23%20configured%20profile%20not%20found%2C%20ignore%0A%20%20if%20%5B%20%22%24profile_ifname%22%20!%3D%20%22%24ifname%22%20%5D%20%7C%7C%20%5B%20%22%24autoconnect%22%20%3D%20%22false%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20configured_profile_uuid%3D%24(sed%20-nr%20'%2F%5E%5C%5Bconnection%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Euuid%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22%24ifname%20activated%20with%20default%20generated%20profile%20%24generated_profile_uuid%22%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22%24ifname%20has%20different%20configured%20specific%20profile%20%24configured_profile_uuid%22%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22%24ifname%3A%20removing%20state...%22%0A%20%20%0A%20%20%23%20NM%20can%20still%20generate%20internal%20profiles%20from%20the%20IP%20address%0A%20%20%23%20configuration%20of%20devices%2C%20so%20flush%20addresses%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22Flushing%20IP%20addresses%20from%20%24ifname%22%0A%20%20ip%20addr%20flush%20%22%24ifname%22%0A%20%20ip%20-6%20addr%20flush%20%22%24ifname%22%0A%0A%20%20%23%20remove%20device%20state%20file%20to%20prevent%20NM%20to%20unilaterally%20connect%20with%20the%0A%20%20%23%20latest%20activated%20profile%20without%20evaluating%20other%20profiles%20%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22Removing%20%24device%22%0A%20%20rm%20-f%20--%20%22%24device%22%0A%0Adone%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/nm-clean-initrd-state.sh
        - contents:
            source: data:,%5Bconnection%5D%0Aipv6.dhcp-duid%3Dll%0Aipv6.dhcp-iaid%3Dmac%0A
          mode: 420
          overwrite: true
          path: /etc/NetworkManager/conf.d/01-ipv6.conf
        - contents:
            source: data:,%5Bmain%5D%0Aplugins%3Dkeyfile%2Cifcfg-rh%0A%5Bkeyfile%5D%0Apath%3D%2Fetc%2FNetworkManager%2Fsystem-connections%0A
          mode: 420
          overwrite: true
          path: /etc/NetworkManager/conf.d/20-keyfiles.conf
        - contents:
            source: data:,%5Bmain%5D%0Arc-manager%3Dunmanaged%0A
          mode: 420
          overwrite: true
          path: /etc/NetworkManager/conf.d/99-kni.conf
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-eo%20pipefail%0AIFACE%3D%241%0ASTATUS%3D%242%0A%0Afunction%20resolv_prepender%20%7B%0A%20%20mkdir%20-p%20%2Frun%2Fresolv-prepender%0A%20%20echo%20%22IP4_DOMAINS%3D%24IP4_DOMAINS%22%20%3E%20%2Frun%2Fresolv-prepender%2Fenv.new%0A%20%20echo%20%22IP6_DOMAINS%3D%24IP6_DOMAINS%22%20%3E%3E%20%2Frun%2Fresolv-prepender%2Fenv.new%0A%0A%20%20if%20!%20diff%20-q%20%2Frun%2Fresolv-prepender%2Fenv%20%2Frun%2Fresolv-prepender%2Fenv.new%3B%20then%0A%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Environment%20variable(s)%20changed.%20Systemd%20path%20unit%20will%20pick%20the%20change.%22%0A%20%20%20%20mv%20-f%20%2Frun%2Fresolv-prepender%2Fenv.new%20%2Frun%2Fresolv-prepender%2Fenv%0A%20%20fi%0A%7D%0A%0Aexport%20IP4_DOMAINS%20IP6_DOMAINS%0Aexport%20-f%20resolv_prepender%0A%0A%23%20For%20RHEL8%20with%20NetworkManager%20%3E%3D%201.36%20and%20RHEL9%20with%20NetworkManager%20%3E%3D1.42%20we%20can%20use%20simplified%20logic%0A%23%20of%20observing%20only%20a%20single%20%22dns-change%22%20event.%20Older%20version%20of%20NetworkManager%20require%20however%20that%20we%0A%23%20react%20on%20a%20set%20of%20multiple%20events.%20Once%20dns-change%20event%20is%20detected%20we%20create%20a%20flag%20file%20to%20ignore%0A%23%20subsequent%20up%26co.%20events%20as%20undesired.%0A%23%0A%23%20Given%20an%20overall%20Network%20Manager%20dispatcher%20timeout%20of%2090%20seconds%2C%20we%20are%20enforcing%20a%20slightly%20shorter%0A%23%20timeout%20for%20the%20observed%20events.%20It%20is%20not%20really%20required%20because%20all%20we%20do%20in%20this%20function%20is%20to%20write%20a%20file.%0A%23%20We%20could%20get%20rid%20of%20this%20timeout%20completely%2C%20but%20it%20also%20does%20not%20cost%20much%20to%20keep%20it.%0Acase%20%22%24STATUS%22%20in%0A%20%20dns-change)%0A%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%20triggered%20by%20%24%7BIFACE%7D%20%24%7BSTATUS%7D.%22%0A%20%20%20%20if%20%5B%20!%20-f%20%22%2Frun%2Fnetworkmanager-dns-event-detected%22%20%5D%3B%20then%0A%20%20%20%20%20%20touch%20%2Frun%2Fnetworkmanager-dns-event-detected%0A%20%20%20%20fi%0A%20%20%20%20if%20!%20timeout%2060s%20bash%20-c%20resolv_prepender%3B%20then%0A%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Timeout%20occurred%22%0A%20%20%20%20%20%20exit%201%0A%20%20%20%20fi%0A%20%20%3B%3B%0A%0A%20%20up%7Cdhcp4-change%7Cdhcp6-change%7Creapply)%0A%20%20%20%20if%20%5B%20!%20-f%20%22%2Frun%2Fnetworkmanager-dns-event-detected%22%20%5D%3B%20then%0A%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%20triggered%20by%20%24%7BIFACE%7D%20%24%7BSTATUS%7D.%22%0A%20%20%20%20%20%20if%20!%20timeout%2030s%20bash%20-c%20resolv_prepender%3B%20then%0A%20%20%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Timeout%20occurred%22%0A%20%20%20%20%20%20%20%20exit%201%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20If%20%24DHCP6_FQDN_FQDN%20is%20not%20empty%20and%20is%20not%20localhost.localdomain%20and%20static%20hostname%20was%20not%20already%20set%0A%20%20%20%20if%20%5B%5B%20-n%20%22%24DHCP6_FQDN_FQDN%22%20%26%26%20%22%24DHCP6_FQDN_FQDN%22%20!%3D%20%22localhost.localdomain%22%20%26%26%20%22%24DHCP6_FQDN_FQDN%22%20%3D~%20%22.%22%20%5D%5D%20%3B%20then%0A%20%20%20%20%20%20%20STATIC_HOSTNAME%3D%22%24(test%20!%20-e%20%2Fetc%2Fhostname%20%26%26%20echo%20-n%20%7C%7C%20cat%20%2Fetc%2Fhostname%20%7C%20xargs)%22%0A%0A%20%20%20%20%20%20%20if%20%5B%5B%20-z%20%22%24STATIC_HOSTNAME%22%20%7C%7C%20%22%24STATIC_HOSTNAME%22%20%3D%3D%20%22localhost.localdomain%22%20%5D%5D%20%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%23%20run%20with%20systemd-run%20to%20avoid%20selinux%20problems%0A%20%20%20%20%20%20%20%20%20%20systemd-run%20--property%3DType%3Doneshot%20--unit%20resolve-prepender-hostnamectl%20-Pq%20%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20hostnamectl%20set-hostname%20--static%20--transient%20%24DHCP6_FQDN_FQDN%0A%20%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20if%20%5B%5B%20%22%24STATUS%22%20%3D%3D%20%22up%22%20%5D%5D%20%26%26%20%5B%5B%20%24IFACE%20%3D%3D%20%22br-ex%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20%2Fbin%2Fmkdir%20-p%20%2Frun%2Fnodeip-configuration%0A%20%20%20%20%20%20%20%20touch%20%2Frun%2Fnodeip-configuration%2Fbr-ex-up%0A%20%20%20%20fi%0A%20%20%3B%3B%0A%20%20*)%0A%20%20%3B%3B%0Aesac%0A
          mode: 493
          overwrite: true
          path: /etc/NetworkManager/dispatcher.d/30-resolv-prepender
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-ex%20-o%20pipefail%0A%0Aif%20%5B%5B%20%22OVNKubernetes%22%20%3D%3D%20%22OVNKubernetes%22%20%26%26%20%22%24CONNECTION_ID%22%20%3D%3D%20%22Wired%20Connection%22%20%5D%5D%0Athen%0A%20%20%20%20%3E%262%20echo%20%22Refusing%20to%20modify%20default%20connection.%22%0A%20%20%20%20exit%200%0Afi%0A%0Aif%20%5B%20-z%20%24%7BDHCP4_IP_ADDRESS%3A-%7D%20%5D%0Athen%0A%20%20%20%20%3E%262%20echo%20%22Not%20a%20DHCP4%20address.%20Ignoring.%22%0A%20%20%20%20exit%200%0Afi%0A%0Aif%20%5B%20%24%7BDHCP4_DHCP_LEASE_TIME%3A-0%7D%20-lt%204294967295%20%5D%0Athen%0A%20%20%20%20%3E%262%20echo%20%22Not%20an%20infinite%20DHCP4%20lease.%20Ignoring.%22%0A%20%20%20%20exit%200%0Afi%0A%0AIPS%3D(%24IP4_ADDRESS_0)%0ACIDR%3D%24%7BIPS%5B0%5D%7D%0AGATEWAY%3D%24%7BIPS%5B1%5D%7D%0A%0ATYPE%3D%24(nmcli%20--get-values%20connection.type%20connection%20show%20%22%24CONNECTION_ID%22)%0A%0A%23%20Modifying%20the%20default%20connection%20id%20directly%20doesn't%20do%20what%20we%20want.%0A%23%20If%20we%20see%20that%2C%20then%20we%20need%20to%20create%20a%20new%20connection.%0Aif%20%5B%20%22%24CONNECTION_ID%22%20%3D%3D%20%22Wired%20Connection%22%20%5D%0Athen%0A%20%20%20%20if%20!%20nmcli%20con%20show%20inf-lease-to-static%0A%20%20%20%20then%0A%20%20%20%20%20%20%20%20nmcli%20con%20add%20type%20%22%24TYPE%22%20con-name%20inf-lease-to-static%0A%20%20%20%20fi%0A%20%20%20%20STATIC_INT_NAME%3Dinf-lease-to-static%0Aelse%0A%20%20%20%20STATIC_INT_NAME%3D%22%24CONNECTION_ID%22%0Afi%0Anmcli%20con%20mod%20%22%24STATIC_INT_NAME%22%20%5C%0A%20%20conn.interface%20%22%241%22%20%5C%0A%20%20connection.autoconnect%20yes%20%5C%0A%20%20ipv4.addresses%20%22%24CIDR%22%20%5C%0A%20%20ipv4.method%20manual%20%5C%0A%20%20ipv4.gateway%20%22%24GATEWAY%22%20%5C%0A%20%20ipv4.dns%20%22%24IP4_NAMESERVERS%22%0A%0Aif%20%5B%20-n%20%22%24IP4_DOMAINS%22%20%5D%3B%20then%0A%20%20%20%20nmcli%20con%20mod%20%22%24STATIC_INT_NAME%22%20ipv4.dns-search%20%22%24IP4_DOMAINS%22%0Afi%0Aplus%3D''%0Afor%20i%20in%20%24(seq%200%20%24((%24IP4_NUM_ROUTES-1))%20)%0Ado%0A%20%20%20%20varname%3D%22IP4_ROUTE_%24i%22%0A%20%20%20%20nmcli%20con%20mod%20%22%24STATIC_INT_NAME%22%20%24%7Bplus%7Dipv4.routes%20%22%24%7B!varname%7D%22%0A%20%20%20%20plus%3D'%2B'%0Adone%0A%0Anmcli%20con%20up%20%22%24STATIC_INT_NAME%22%0A%0Aif%20%5B%20-n%20%22%24%7BDHCP4_HOST_NAME%3A-%7D%22%20%5D%0Athen%0A%20%20%20%20systemd-run%20--property%3DType%3Doneshot%20--unit%20static-dhcp-hostnamectl%20-Pq%20%5C%0A%20%20%20%20%20%20hostnamectl%20set-hostname%20--static%20--transient%20%22%24DHCP4_HOST_NAME%22%0Afi%0A
          mode: 493
          overwrite: true
          path: /etc/NetworkManager/dispatcher.d/30-static-dhcp
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-ex%20-o%20pipefail%0A%0Aif%20%5B%20-z%20%22%24DHCP6_IP6_ADDRESS%22%20%5D%0Athen%0A%20%20%20%20%3E%262%20echo%20%22Not%20a%20DHCP6%20address.%20Ignoring.%22%0A%20%20%20%20exit%200%0Afi%0A%0ALEASE_TIME%3D%24(ip%20-j%20-6%20a%20show%20%22%24DEVICE_IFACE%22%20%7C%20jq%20-r%20%22.%5B%5D.addr_info%5B%5D%20%7C%20select(.scope%3D%3D%5C%22global%5C%22)%20%7C%20select(.deprecated!%3Dtrue)%20%7C%20select(.local%3D%3D%5C%22%24DHCP6_IP6_ADDRESS%5C%22)%20%7C%20.preferred_life_time%22)%0APREFIX_LEN%3D%24(ip%20-j%20-6%20a%20show%20%22%24DEVICE_IFACE%22%20%7C%20jq%20-r%20%22.%5B%5D.addr_info%5B%5D%20%7C%20select(.scope%3D%3D%5C%22global%5C%22)%20%7C%20select(.deprecated!%3Dtrue)%20%7C%20select(.local%3D%3D%5C%22%24DHCP6_IP6_ADDRESS%5C%22)%20%7C%20.prefixlen%22)%0A%0Aif%20%5B%20%24%7BLEASE_TIME%3A-0%7D%20-lt%204294967295%20%5D%0Athen%0A%20%20%20%20%3E%262%20echo%20%22Not%20an%20infinite%20DHCP6%20lease.%20Ignoring.%22%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20We%20don't%20want%20this%20to%20run%20before%20OVNKubernetes%20creates%20its%20bridge.%20If%20we%0A%23%20see%20the%20default%20CONNECTION_ID%20we%20know%20to%20wait.%0Aif%20%5B%20%22%24CONNECTION_ID%22%20%3D%3D%20%22Wired%20Connection%22%20%5D%0Athen%0A%20%20%20%20%3E%262%20echo%20%22Refusing%20to%20modify%20default%20connection.%22%0A%20%20%20%20exit%200%0Afi%0A%0ACIDR%3D%22%24DHCP6_IP6_ADDRESS%2F%24PREFIX_LEN%22%0Anmcli%20con%20mod%20%22%24CONNECTION_ID%22%20ipv6.addresses%20%22%24CIDR%22%0Anmcli%20con%20mod%20%22%24CONNECTION_ID%22%20connection.autoconnect%20%22yes%22%0Anmcli%20con%20mod%20%22%24CONNECTION_ID%22%20ipv6.method%20%22manual%22%0Anmcli%20con%20mod%20%22%24CONNECTION_ID%22%20ipv6.gateway%20%22%24IP6_GATEWAY%22%0Anmcli%20con%20mod%20%22%24CONNECTION_ID%22%20ipv6.dns%20%22%24IP6_NAMESERVERS%22%0ASEARCH_DOMAIN%3D%22%24%7BDHCP6_FQDN_FQDN%23*.%7D%22%0Aif%20%5B%20-n%20%22%24SEARCH_DOMAIN%22%20%5D%3B%20then%0A%20%20%20%20nmcli%20con%20mod%20%22%24CONNECTION_ID%22%20ipv6.dns-search%20%22%24SEARCH_DOMAIN%22%0Afi%0Aplus%3D''%0Afor%20i%20in%20%24(seq%200%20%24((%24IP6_NUM_ROUTES-1))%20)%0Ado%0A%20%20%20%20varname%3D%22IP6_ROUTE_%24i%22%0A%20%20%20%20nmcli%20con%20mod%20%22%24CONNECTION_ID%22%20%24%7Bplus%7Dipv6.routes%20%22%24%7B!varname%7D%22%0A%20%20%20%20plus%3D'%2B'%0Adone%0A%0A%23%20Copy%20it%20from%20the%20OverlayFS%20mount%20to%20the%20persistent%20lowerdir%0Acp%20%22%24CONNECTION_FILENAME%22%20%2Fetc%2FNetworkManager%2Fsystem-connections%0A
          mode: 493
          overwrite: true
          path: /etc/NetworkManager/dispatcher.d/30-static-dhcpv6
        - contents:
            source: data:,
          mode: 384
          overwrite: true
          path: /etc/pki/ca-trust/source/anchors/openshift-config-user-ca-bundle.crt
        - contents:
            source: data:,KUBERNETES_SERVICE_HOST%3D'api-int.comp-poc-rh01.rhpoc.int'%0AKUBERNETES_SERVICE_PORT%3D'6443'%0A
          mode: 420
          overwrite: true
          path: /etc/kubernetes/apiserver-url.env
        - contents:
            source: data:,%23%20This%20file%20is%20managed%20by%20machine-config-operator.%0A%23%20Suppress%20audit%20rules%20which%20always%20trigger%20for%20container%0A%23%20workloads%2C%20as%20they%20spam%20the%20audit%20log.%20%20Workloads%20are%20expected%0A%23%20to%20be%20dynamic%2C%20and%20the%20networking%20stack%20uses%20iptables.%0A-a%20exclude%2Calways%20-F%20msgtype%3DNETFILTER_CFG%0A%23%20The%20default%20bridged%20networking%20enables%20promiscuous%20on%20the%20veth%0A%23%20device.%20%20Ideally%2C%20we'd%20teach%20audit%20to%20ignore%20only%20veth%20devices%2C%0A%23%20since%20one%20might%20legitimately%20care%20about%20promiscuous%20on%20real%20physical%0A%23%20devices.%20%20But%20we%20can't%20currently%20differentiate.%0A-a%20exclude%2Calways%20-F%20msgtype%3DANOM_PROMISCUOUS%0A
          mode: 420
          overwrite: true
          path: /etc/audit/rules.d/mco-audit-quiet-containers.rules
        - contents:
            source: data:,mode%3A%20unicast%0A
          mode: 420
          overwrite: true
          path: /etc/keepalived/monitor.conf
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%0A%23%20ESP%20offload%2C%20either%20in%20actual%20hardware%20or%20as%20part%20as%20GRO%20(generic%0A%23%20recieve%20offload)%20does%20not%20work%20for%20interfaces%20attached%20to%20an%20OVS%20bridge%0A%23%20so%20turn%20it%20off%20for%20the%20time%20being.%0A%23%20https%3A%2F%2Fissues.redhat.com%2Fbrowse%2FRHEL-58811%0A%0A%23%20Depends%20on%20ipsec%20service%20drop-in%20to%20start%20it%20after%20configure-ovs%20to%20make%0A%23%20sure%20offloads%20are%20disabled%20before%20ipsec%20starts.%0A%0Aif%20%5B%5B%20%22%242%22%20!%3D%20%22up%22%20%5D%5D%3B%20then%0A%20%20exit%0Afi%0A%0Adevice%3D%24DEVICE_IFACE%0Akind_slave%3D%24(ip%20-j%20-d%20link%20show%20%22%24device%22%20%7C%20jq%20-r%20'.%5B0%5D%20%7C%20.linkinfo.info_slave_kind%20%2F%2F%20empty')%0A%0Aif%20%5B%20%22%24kind_slave%22%20%3D%20%22openvswitch%22%20%5D%3B%20then%0A%20%20for%20feature%20in%20tx-esp-segmentation%20esp-hw-offload%20esp-tx-csum-hw-offload%3B%20do%0A%20%20%20%20if%20ethtool%20-k%20%22%24device%22%20%7C%20grep%20-qE%20%22%5E%24%7Bfeature%7D%3A%20off%22%3B%20then%0A%20%20%20%20%20%20%23%20already%20disabled%2C%20nothing%20to%20do%0A%20%20%20%20%20%20continue%0A%20%20%20%20fi%0A%20%20%20%20%0A%20%20%20%20logger%20-t%2099-esp-offload%20-s%20%22Setting%20%24feature%20off%20for%20%24device%3A%20unsupported%20when%20attached%20to%20Open%20vSwitch%20bridge%22%0A%20%20%20%20ethtool%20-K%20%22%24device%22%20%22%24feature%22%20off%0A%20%20done%0Afi%0A
          mode: 484
          overwrite: true
          path: /etc/NetworkManager/dispatcher.d/99-esp-offload
        - contents:
            source: data:,r%20%2Fetc%2Fkubernetes%2Fcni%2Fnet.d%2F80-openshift-network.conf%0Ar%20%2Fetc%2Fkubernetes%2Fcni%2Fnet.d%2F10-ovn-kubernetes.conf%0Ad%20%2Frun%2Fmultus%2Fcni%2Fnet.d%2F%200755%20root%20root%20-%20-%0AD%20%2Fvar%2Flib%2Fcni%2Fnetworks%2Fopenshift-sdn%2F%200755%20root%20root%20-%20-%0A
          mode: 420
          overwrite: true
          path: /etc/tmpfiles.d/cleanup-cni.conf
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-ex%0A%0A%23%20Used%20for%20on-prem%20deployments%20to%20enable%20ip%20forwarding%20as%20part%20of%20nodeip-configuration%20service.%0A%23%20IP%20forwarding%20is%20required%20on%20the%20node%20IP%20(k8s%20API)%20interface%20in%20order%20for%20keepalived%20to%20function.%0A%0Aecho%20%22Configuring%20IP%20Forwarding...%22%0Aovnk_config_dir%3D'%2Fetc%2Fovnk'%0Aip_hint_file%3D%22%2Frun%2Fnodeip-configuration%2Fprimary-ip%22%0A%0Aget_ip_from_ip_hint_file()%20%7B%0A%20%20local%20ip_hint_file%3D%22%241%22%0A%20%20if%20%5B%5B%20!%20-f%20%22%24%7Bip_hint_file%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22error%3A%20unable%20to%20enable%20IP%20forwarding.%20IP%20hint%20file%3A%20%24%7Bip_hint_file%7D%20does%20not%20exist!%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%20%20ip_hint%3D%24(cat%20%22%24%7Bip_hint_file%7D%22)%0A%20%20echo%20%22%24%7Bip_hint%7D%22%0A%7D%0A%0Aget_nodeip_hint_interface()%20%7B%0A%20%20local%20ip_hint%3D%22%22%0A%20%20local%20ip_hint_file%3D%22%241%22%0A%20%20local%20iface%3D%22%22%0A%0A%20%20ip_hint%3D%24(get_ip_from_ip_hint_file%20%22%24%7Bip_hint_file%7D%22)%0A%20%20if%20%5B%5B%20-z%20%22%24%7Bip_hint%7D%22%20%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22error%3A%20unable%20to%20enable%20IP%20forwarding.%20IP%20hint%20file%3A%20%24%7Bip_hint_file%7D%20is%20empty!%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%0A%20%20iface%3D%24(ip%20-j%20addr%20%7C%20jq%20-r%20%22first(.%5B%5D%20%7C%20select(any(.addr_info%5B%5D%3B%20.local%3D%3D%5C%22%24%7Bip_hint%7D%5C%22)))%20%7C%20.ifname%22)%0A%20%20if%20%5B%5B%20-z%20%22%24%7Biface%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22error%3A%20unable%20to%20enable%20IP%20forwarding.%20Cannot%20detect%20valid%20interface%20within%20file%3A%20%24%7Bip_hint_file%7D%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%20%20echo%20%22%24%7Biface%7D%22%0A%7D%0A%0Aiface%3D%24(get_nodeip_hint_interface%20%22%24%7Bip_hint_file%7D%22)%0A%0Aecho%20%22Node%20IP%20interface%20determined%20as%3A%20%24%7Biface%7D.%20Enabling%20IP%20forwarding...%22%0Afile_paths%3D(%22%2Fproc%2Fsys%2Fnet%2Fipv4%2Fconf%2F%24%7Biface%7D%2Fforwarding%22%20%22%2Fproc%2Fsys%2Fnet%2Fipv6%2Fconf%2F%24%7Biface%7D%2Fforwarding%22)%0Afor%20file_path%20in%20%22%24%7Bfile_paths%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20if%20%5B%20-f%20%22%24%7Bfile_path%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%221%22%20%3E%20%22%24%7Bfile_path%7D%22%0A%20%20%20%20fi%0Adone%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/configure-ip-forwarding.sh
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-x%0A%0Aif%20%5B%20-e%20%2Fetc%2Fnmstate%2Fopenshift%2Fapplied%20%5D%3B%20then%0A%20%20echo%20%22Skipping%20configure-ovs%20due%20to%20manual%20network%20configuration%22%0A%20%20exit%200%0Afi%0A%0A%23%20This%20file%20is%20not%20needed%20anymore%20in%204.7%2B%2C%20but%20when%20rolling%20back%20to%204.6%0A%23%20the%20ovs%20pod%20needs%20it%20to%20know%20ovs%20is%20running%20on%20the%20host.%0Atouch%20%2Fvar%2Frun%2Fovs-config-executed%0A%0A%23%20These%20are%20well%20knwon%20NM%20default%20paths%0ANM_CONN_ETC_PATH%3D%22%2Fetc%2FNetworkManager%2Fsystem-connections%22%0ANM_CONN_RUN_PATH%3D%22%2Frun%2FNetworkManager%2Fsystem-connections%22%0A%0A%23%20This%20is%20the%20path%20where%20NM%20is%20known%20to%20be%20configured%20to%20store%20user%20keyfiles%20%0ANM_CONN_CONF_PATH%3D%22%24NM_CONN_ETC_PATH%22%0A%0A%23%20This%20is%20where%20we%20want%20our%20keyfiles%20to%20finally%20reside.%20configure-ovs%0A%23%20operates%20with%20temporary%20keyfiles%20in%20NM_CONN_RUN_PATH%20and%20then%20as%20a%20last%0A%23%20step%20moves%20those%20keyfiles%20to%20NM_CONN_SET_PATH%20if%20it%20is%20a%20different%20path%0A%23%20(not%20by%20default).%20This%20mitigates%20hard%20interruptions%20(SIGKILL%2C%20hard%20reboot)%0A%23%20of%20configure-ovs%20leaving%20the%20machine%20with%20a%20half-baked%20set%20of%20keyfiles%0A%23%20that%20might%20prevent%20machine%20networking%20from%20working%20correctly.%0ANM_CONN_SET_PATH%3D%22%24%7BNM_CONN_SET_PATH%3A-%24NM_CONN_RUN_PATH%7D%22%0A%0AMANAGED_NM_CONN_SUFFIX%3D%22-slave-ovs-clone%22%0A%23%20Workaround%20to%20ensure%20OVS%20is%20installed%20due%20to%20bug%20in%20systemd%20Requires%3A%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1888017%0Acopy_nm_conn_files()%20%7B%0A%20%20local%20dst_path%3D%22%241%22%0A%20%20for%20src%20in%20%22%24%7BMANAGED_NM_CONN_FILES%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20src_path%3D%24(dirname%20%22%24src%22)%0A%20%20%20%20file%3D%24(basename%20%22%24src%22)%0A%20%20%20%20if%20%5B%20-f%20%22%24src_path%2F%24file%22%20%5D%3B%20then%0A%20%20%20%20%20%20if%20%5B%20!%20-f%20%22%24dst_path%2F%24file%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22Copying%20configuration%20%24file%22%0A%20%20%20%20%20%20%20%20cp%20%22%24src_path%2F%24file%22%20%22%24dst_path%2F%24file%22%0A%20%20%20%20%20%20elif%20!%20cmp%20--silent%20%22%24src_path%2F%24file%22%20%22%24dst_path%2F%24file%22%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22Copying%20updated%20configuration%20%24file%22%0A%20%20%20%20%20%20%20%20cp%20-f%20%22%24src_path%2F%24file%22%20%22%24dst_path%2F%24file%22%0A%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20echo%20%22Skipping%20%24file%20since%20it's%20equal%20at%20destination%22%0A%20%20%20%20%20%20fi%0A%20%20%20%20else%0A%20%20%20%20%20%20echo%20%22Skipping%20%24file%20since%20it%20does%20not%20exist%20at%20source%22%0A%20%20%20%20fi%0A%20%20done%0A%7D%0A%0Aupdate_nm_conn_files_base()%20%7B%0A%20%20base_path%3D%24%7B1%7D%0A%20%20bridge_name%3D%24%7B2%7D%0A%20%20port_name%3D%24%7B3%7D%0A%20%20ovs_port%3D%22ovs-port-%24%7Bbridge_name%7D%22%0A%20%20ovs_interface%3D%22ovs-if-%24%7Bbridge_name%7D%22%0A%20%20default_port_name%3D%22ovs-port-%24%7Bport_name%7D%22%20%23%20ovs-port-phys0%0A%20%20bridge_interface_name%3D%22ovs-if-%24%7Bport_name%7D%22%20%23%20ovs-if-phys0%0A%20%20%23%20In%20RHEL7%20files%20in%20%2F%7Betc%2Crun%7D%2FNetworkManager%2Fsystem-connections%20end%20without%20the%20suffix%20'.nmconnection'%2C%20whereas%20in%20RHCOS%20they%20end%20with%20the%20suffix.%0A%20%20MANAGED_NM_CONN_FILES%3D(%24(echo%20%22%24%7Bbase_path%7D%22%2F%7B%22%24bridge_name%22%2C%22%24ovs_interface%22%2C%22%24ovs_port%22%2C%22%24bridge_interface_name%22%2C%22%24default_port_name%22%7D%7B%2C.nmconnection%7D))%0A%20%20shopt%20-s%20nullglob%0A%20%20MANAGED_NM_CONN_FILES%2B%3D(%24%7Bbase_path%7D%2F*%24%7BMANAGED_NM_CONN_SUFFIX%7D.nmconnection%20%24%7Bbase_path%7D%2F*%24%7BMANAGED_NM_CONN_SUFFIX%7D)%0A%20%20shopt%20-u%20nullglob%0A%7D%0A%0Aupdate_nm_conn_run_files()%20%7B%0A%20%20update_nm_conn_files_base%20%22%24%7BNM_CONN_RUN_PATH%7D%22%20%22%24%7B1%7D%22%20%22%24%7B2%7D%22%0A%7D%0A%0Aupdate_nm_conn_set_files()%20%7B%0A%20%20update_nm_conn_files_base%20%22%24%7BNM_CONN_SET_PATH%7D%22%20%22%24%7B1%7D%22%20%22%24%7B2%7D%22%0A%7D%0A%0Aupdate_nm_conn_etc_files()%20%7B%0A%20%20update_nm_conn_files_base%20%22%24%7BNM_CONN_ETC_PATH%7D%22%20%22%24%7B1%7D%22%20%22%24%7B2%7D%22%0A%7D%0A%0A%23%20Move%20and%20reload%20keyfiles%20at%20their%20final%20destination%0Aset_nm_conn_files()%20%7B%0A%20%20if%20%5B%20%22%24NM_CONN_RUN_PATH%22%20!%3D%20%22%24NM_CONN_SET_PATH%22%20%5D%3B%20then%0A%20%20%20%20update_nm_conn_run_files%20br-ex%20phys0%0A%20%20%20%20copy_nm_conn_files%20%22%24NM_CONN_SET_PATH%22%0A%20%20%20%20rm_nm_conn_files%0A%20%20%20%20update_nm_conn_run_files%20br-ex1%20phys1%0A%20%20%20%20copy_nm_conn_files%20%22%24NM_CONN_SET_PATH%22%0A%20%20%20%20rm_nm_conn_files%0A%0A%20%20%20%20%23%20reload%20keyfiles%0A%20%20%20%20nmcli%20connection%20reload%0A%20%20fi%0A%7D%0A%0A%23%20Used%20to%20remove%20files%20managed%20by%20configure-ovs%20and%20temporary%20leftover%20files%20from%20network%20manager%0Arm_nm_conn_files()%20%7B%0A%20%20for%20file%20in%20%22%24%7BMANAGED_NM_CONN_FILES%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20if%20%5B%20-f%20%22%24file%22%20%5D%3B%20then%0A%20%20%20%20%20%20rm%20-f%20%22%24file%22%0A%20%20%20%20%20%20echo%20%22Removed%20nmconnection%20file%20%24file%22%0A%20%20%20%20%20%20nm_config_changed%3D1%0A%20%20%20%20fi%0A%20%20done%0A%20%20for%20file%20in%20%22%24%7BMANAGED_NM_CONN_FILES%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20for%20temp%20in%20%24(compgen%20-G%20%22%24%7Bfile%7D.*%22)%3B%20do%0A%20%20%20%20%20%20rm%20-f%20%22%24temp%22%0A%20%20%20%20%20%20echo%20%22Removed%20nmconnection%20temporary%20file%20%24temp%22%0A%20%20%20%20%20%20nm_config_changed%3D1%0A%20%20%20%20done%0A%20%20done%0A%7D%0A%0A%23%20Used%20to%20clone%20a%20slave%20connection%20by%20uuid%2C%20returns%20new%20name%0Aclone_slave_connection()%20%7B%0A%20%20local%20uuid%3D%22%241%22%0A%20%20local%20old_name%0A%20%20old_name%3D%22%24(nmcli%20-g%20connection.id%20connection%20show%20uuid%20%22%24uuid%22)%22%0A%20%20local%20new_name%3D%22%24%7Bold_name%7D%24%7BMANAGED_NM_CONN_SUFFIX%7D%22%0A%20%20if%20nmcli%20connection%20show%20id%20%22%24%7Bnew_name%7D%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20echo%20%22WARNING%3A%20existing%20ovs%20slave%20%24%7Bnew_name%7D%20connection%20profile%20file%20found%2C%20overwriting...%22%20%3E%262%0A%20%20%20%20nmcli%20connection%20delete%20id%20%22%24%7Bnew_name%7D%22%20%26%3E%20%2Fdev%2Fnull%0A%20%20fi%0A%20%20clone_nm_conn%20%24uuid%20%22%24%7Bnew_name%7D%22%0A%20%20echo%20%22%24%7Bnew_name%7D%22%0A%7D%0A%0A%23%20Used%20to%20replace%20an%20old%20master%20connection%20uuid%20with%20a%20new%20one%20on%20all%20connections%0Areplace_connection_master()%20%7B%0A%20%20local%20old%3D%22%241%22%0A%20%20local%20new%3D%22%242%22%0A%20%20for%20conn_uuid%20in%20%24(nmcli%20-g%20UUID%20connection%20show)%20%3B%20do%0A%20%20%20%20if%20%5B%20%22%24(nmcli%20-g%20connection.master%20connection%20show%20uuid%20%22%24conn_uuid%22)%22%20!%3D%20%22%24old%22%20%5D%3B%20then%0A%20%20%20%20%20%20continue%0A%20%20%20%20fi%0A%0A%20%20%20%20local%20active_state%3D%24(nmcli%20-g%20GENERAL.STATE%20connection%20show%20%22%24conn_uuid%22)%0A%20%20%20%20local%20autoconnect%3D%24(nmcli%20-g%20connection.autoconnect%20connection%20show%20%22%24conn_uuid%22)%0A%20%20%20%20if%20%5B%20%22%24active_state%22%20!%3D%20%22activated%22%20%5D%20%26%26%20%5B%20%22%24autoconnect%22%20!%3D%20%22yes%22%20%5D%3B%20then%0A%20%20%20%20%20%20%23%20Assume%20that%20slave%20profiles%20intended%20to%20be%20used%20are%20those%20that%20are%3A%0A%20%20%20%20%20%20%23%20-%20active%0A%20%20%20%20%20%20%23%20-%20or%20inactive%20(which%20might%20be%20due%20to%20link%20being%20down)%20but%20to%20be%20autoconnected.%0A%20%20%20%20%20%20%23%20Otherwise%2C%20ignore%20them.%0A%20%20%20%20%20%20continue%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20make%20changes%20for%20slave%20profiles%20in%20a%20new%20clone%0A%20%20%20%20local%20new_name%0A%20%20%20%20new_name%3D%24(clone_slave_connection%20%24conn_uuid)%0A%0A%20%20%20%20mod_nm_conn%20%22%24new_name%22%20connection.master%20%22%24new%22%20connection.autoconnect-priority%20100%20connection.autoconnect%20no%20%0A%20%20%20%20echo%20%22Replaced%20master%20%24old%20with%20%24new%20for%20slave%20profile%20%24new_name%22%0A%20%20done%0A%7D%0A%0A%23%20when%20creating%20the%20bridge%2C%20we%20use%20a%20value%20lower%20than%20NM's%20ethernet%20device%20default%20route%20metric%0A%23%20(we%20pick%2048%20and%2049%20to%20be%20lower%20than%20anything%20that%20NM%20chooses%20by%20default)%0ABRIDGE_METRIC%3D%2248%22%0ABRIDGE1_METRIC%3D%2249%22%0A%23%20Given%20an%20interface%2C%20generates%20NM%20configuration%20to%20add%20to%20an%20OVS%20bridge%0Aconvert_to_bridge()%20%7B%0A%20%20local%20iface%3D%24%7B1%7D%0A%20%20local%20bridge_name%3D%24%7B2%7D%0A%20%20local%20port_name%3D%24%7B3%7D%0A%20%20local%20bridge_metric%3D%24%7B4%7D%0A%20%20local%20ovs_port%3D%22ovs-port-%24%7Bbridge_name%7D%22%0A%20%20local%20ovs_interface%3D%22ovs-if-%24%7Bbridge_name%7D%22%0A%20%20local%20default_port_name%3D%22ovs-port-%24%7Bport_name%7D%22%20%23%20ovs-port-phys0%0A%20%20local%20bridge_interface_name%3D%22ovs-if-%24%7Bport_name%7D%22%20%23%20ovs-if-phys0%0A%0A%20%20if%20%5B%20%22%24iface%22%20%3D%20%22%24bridge_name%22%20%5D%3B%20then%0A%20%20%20%20%23%20handle%20vlans%20and%20bonds%20etc%20if%20they%20have%20already%20been%0A%20%20%20%20%23%20configured%20via%20nm%20key%20files%20and%20br-ex%20is%20already%20up%0A%20%20%20%20ifaces%3D%24(ovs-vsctl%20list-ifaces%20%24%7Biface%7D)%0A%20%20%20%20for%20intf%20in%20%24ifaces%3B%20do%20configure_driver_options%20%24intf%3B%20done%0A%20%20%20%20echo%20%22Networking%20already%20configured%20and%20up%20for%20%24%7Bbridge-name%7D!%22%0A%20%20%20%20return%0A%20%20fi%0A%0A%20%20%23%20flag%20to%20reload%20NM%20to%20account%20for%20all%20the%20configuration%20changes%0A%20%20%23%20going%20forward%0A%20%20nm_config_changed%3D1%0A%0A%20%20if%20%5B%20-z%20%22%24iface%22%20%5D%3B%20then%0A%20%20%20%20echo%20%22ERROR%3A%20Unable%20to%20find%20default%20gateway%20interface%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%20%20%23%20find%20the%20MAC%20from%20OVS%20config%20or%20the%20default%20interface%20to%20use%20for%20OVS%20internal%20port%0A%20%20%23%20this%20prevents%20us%20from%20getting%20a%20different%20DHCP%20lease%20and%20dropping%20connection%0A%20%20if%20!%20iface_mac%3D%24(%3C%22%2Fsys%2Fclass%2Fnet%2F%24%7Biface%7D%2Faddress%22)%3B%20then%0A%20%20%20%20echo%20%22Unable%20to%20determine%20default%20interface%20MAC%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%0A%20%20echo%20%22MAC%20address%20found%20for%20iface%3A%20%24%7Biface%7D%3A%20%24%7Biface_mac%7D%22%0A%0A%20%20%23%20find%20MTU%20from%20original%20iface%0A%20%20iface_mtu%3D%24(ip%20link%20show%20%22%24iface%22%20%7C%20awk%20'%7Bprint%20%245%3B%20exit%7D')%0A%20%20if%20%5B%5B%20-z%20%22%24iface_mtu%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22Unable%20to%20determine%20default%20interface%20MTU%2C%20defaulting%20to%201500%22%0A%20%20%20%20iface_mtu%3D1500%0A%20%20else%0A%20%20%20%20echo%20%22MTU%20found%20for%20iface%3A%20%24%7Biface%7D%3A%20%24%7Biface_mtu%7D%22%0A%20%20fi%0A%0A%20%20%23%20store%20old%20conn%20for%20later%0A%20%20old_conn%3D%24(nmcli%20--fields%20UUID%2CDEVICE%20conn%20show%20--active%20%7C%20awk%20%22%2F%5Cs%24%7Biface%7D%5Cs*%5C%24%2F%20%7Bprint%20%5C%241%7D%22)%0A%0A%20%20if%20%5B%5B%20-z%20%22%24old_conn%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22ERROR%3A%20cannot%20find%20connection%20for%20interface%3A%20%24%7Biface%7D%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%0A%20%20%23%20create%20bridge%0A%20%20if%20!%20nmcli%20connection%20show%20%22%24bridge_name%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-br%20%22%24bridge_name%22%0A%20%20%20%20add_nm_conn%20%22%24bridge_name%22%20type%20ovs-bridge%20conn.interface%20%22%24bridge_name%22%20802-3-ethernet.mtu%20%24%7Biface_mtu%7D%20%5C%0A%20%20%20%20connection.autoconnect-slaves%201%0A%20%20fi%0A%0A%20%20%23%20find%20default%20port%20to%20add%20to%20bridge%0A%20%20if%20!%20nmcli%20connection%20show%20%22%24default_port_name%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-port%20%22%24bridge_name%22%20%24%7Biface%7D%0A%20%20%20%20add_nm_conn%20%22%24default_port_name%22%20type%20ovs-port%20conn.interface%20%24%7Biface%7D%20slave-type%20ovs-bridge%20master%20%22%24bridge_name%22%20%5C%0A%20%20%20%20connection.autoconnect-slaves%201%0A%20%20fi%0A%0A%20%20if%20!%20nmcli%20connection%20show%20%22%24ovs_port%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-port%20%22%24bridge_name%22%20%22%24bridge_name%22%0A%20%20%20%20add_nm_conn%20%22%24ovs_port%22%20type%20ovs-port%20conn.interface%20%22%24bridge_name%22%20slave-type%20ovs-bridge%20master%20%22%24bridge_name%22%0A%20%20fi%0A%0A%20%20extra_phys_args%3D()%0A%20%20%23%20check%20if%20this%20interface%20is%20a%20vlan%2C%20bond%2C%20team%2C%20or%20ethernet%20type%0A%20%20if%20%5B%20%22%24(nmcli%20--get-values%20connection.type%20conn%20show%20%24%7Bold_conn%7D)%22%20%3D%3D%20%22vlan%22%20%5D%3B%20then%0A%20%20%20%20iface_type%3Dvlan%0A%20%20%20%20vlan_id%3D%24(nmcli%20--get-values%20vlan.id%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20if%20%5B%20-z%20%22%24vlan_id%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22ERROR%3A%20unable%20to%20determine%20vlan_id%20for%20vlan%20connection%3A%20%24%7Bold_conn%7D%22%0A%20%20%20%20%20%20exit%201%0A%20%20%20%20fi%0A%20%20%20%20vlan_parent%3D%24(nmcli%20--get-values%20vlan.parent%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20if%20%5B%20-z%20%22%24vlan_parent%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22ERROR%3A%20unable%20to%20determine%20vlan_parent%20for%20vlan%20connection%3A%20%24%7Bold_conn%7D%22%0A%20%20%20%20%20%20exit%201%0A%20%20%20%20fi%0A%0A%20%20%20%20if%20nmcli%20connection%20show%20uuid%20%22%24vlan_parent%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20%20%20%23%20if%20the%20VLAN%20connection%20is%20configured%20with%20a%20connection%20UUID%20as%20parent%2C%20we%20need%20to%20find%20the%20underlying%20device%0A%20%20%20%20%20%20%23%20and%20create%20the%20bridge%20against%20it%2C%20as%20the%20parent%20connection%20can%20be%20replaced%20by%20another%20bridge.%0A%20%20%20%20%20%20vlan_parent%3D%24(nmcli%20--get-values%20GENERAL.DEVICES%20conn%20show%20uuid%20%24%7Bvlan_parent%7D)%0A%20%20%20%20fi%0A%0A%20%20%20%20extra_phys_args%3D(%20dev%20%22%24%7Bvlan_parent%7D%22%20id%20%22%24%7Bvlan_id%7D%22%20)%0A%20%20elif%20%5B%20%22%24(nmcli%20--get-values%20connection.type%20conn%20show%20%24%7Bold_conn%7D)%22%20%3D%3D%20%22bond%22%20%5D%3B%20then%0A%20%20%20%20iface_type%3Dbond%0A%20%20%20%20%23%20check%20bond%20options%0A%20%20%20%20bond_opts%3D%24(nmcli%20--get-values%20bond.options%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20if%20%5B%20-n%20%22%24bond_opts%22%20%5D%3B%20then%0A%20%20%20%20%20%20extra_phys_args%2B%3D(%20bond.options%20%22%24%7Bbond_opts%7D%22%20)%0A%20%20%20%20%20%20MODE_REGEX%3D%22(%5E%7C%2C)mode%3Dactive-backup(%2C%7C%24)%22%0A%20%20%20%20%20%20MAC_REGEX%3D%22(%5E%7C%2C)fail_over_mac%3D(1%7Cactive%7C2%7Cfollow)(%2C%7C%24)%22%0A%20%20%20%20%20%20if%20%5B%5B%20%24bond_opts%20%3D~%20%24MODE_REGEX%20%5D%5D%20%26%26%20%5B%5B%20%24bond_opts%20%3D~%20%24MAC_REGEX%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20clone_mac%3D0%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%20%20elif%20%5B%20%22%24(nmcli%20--get-values%20connection.type%20conn%20show%20%24%7Bold_conn%7D)%22%20%3D%3D%20%22team%22%20%5D%3B%20then%0A%20%20%20%20iface_type%3Dteam%0A%20%20%20%20%23%20check%20team%20config%20options%0A%20%20%20%20team_config_opts%3D%24(nmcli%20--get-values%20team.config%20-e%20no%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20if%20%5B%20-n%20%22%24team_config_opts%22%20%5D%3B%20then%0A%20%20%20%20%20%20%23%20team.config%20is%20json%2C%20remove%20spaces%20to%20avoid%20problems%20later%20on%0A%20%20%20%20%20%20extra_phys_args%2B%3D(%20team.config%20%22%24%7Bteam_config_opts%2F%2F%5B%5B%3Aspace%3A%5D%5D%2F%7D%22%20)%0A%20%20%20%20%20%20team_mode%3D%24(echo%20%22%24%7Bteam_config_opts%7D%22%20%7C%20jq%20-r%20%22.runner.name%20%2F%2F%20empty%22)%0A%20%20%20%20%20%20team_mac_policy%3D%24(echo%20%22%24%7Bteam_config_opts%7D%22%20%7C%20jq%20-r%20%22.runner.hwaddr_policy%20%2F%2F%20empty%22)%0A%20%20%20%20%20%20MAC_REGEX%3D%22(by_active%7Conly_active)%22%0A%20%20%20%20%20%20if%20%5B%20%22%24team_mode%22%20%3D%20%22activebackup%22%20%5D%20%26%26%20%5B%5B%20%22%24team_mac_policy%22%20%3D~%20%24MAC_REGEX%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20clone_mac%3D0%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%20%20elif%20%5B%20%22%24(nmcli%20--get-values%20connection.type%20conn%20show%20%24%7Bold_conn%7D)%22%20%3D%3D%20%22tun%22%20%5D%3B%20then%0A%20%20%20%20iface_type%3Dtun%0A%20%20%20%20tun_mode%3D%24(nmcli%20--get-values%20tun.mode%20-e%20no%20connection%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20extra_phys_args%2B%3D(%20tun.mode%20%22%24%7Btun_mode%7D%22%20)%0A%20%20elif%20%5B%20%22%24(nmcli%20--get-values%20connection.type%20conn%20show%20%24%7Bold_conn%7D)%22%20%3D%3D%20%22bridge%22%20%5D%3B%20then%0A%20%20%20%20iface_type%3Dbridge%0A%20%20else%0A%20%20%20%20iface_type%3D802-3-ethernet%0A%20%20fi%0A%0A%20%20if%20%5B%20!%20%22%24%7Bclone_mac%3A-%7D%22%20%3D%20%220%22%20%5D%3B%20then%0A%20%20%20%20%23%20In%20active-backup%20link%20aggregation%2C%20with%20fail_over_mac%20mode%20enabled%2C%0A%20%20%20%20%23%20cloning%20the%20mac%20address%20is%20not%20supported.%20It%20is%20possible%20then%20that%0A%20%20%20%20%23%20br-ex%20has%20a%20different%20mac%20address%20than%20the%20bond%20which%20might%20be%0A%20%20%20%20%23%20troublesome%20on%20some%20platforms%20where%20the%20nic%20won't%20accept%20packets%20with%0A%20%20%20%20%23%20a%20different%20destination%20mac.%20But%20nobody%20has%20complained%20so%20far%20so%20go%20on%0A%20%20%20%20%23%20with%20what%20we%20got.%20%0A%20%20%20%20%0A%20%20%20%20%23%20Do%20set%20it%20though%20for%20other%20link%20aggregation%20configurations%20where%20the%0A%20%20%20%20%23%20mac%20address%20would%20otherwise%20depend%20on%20enslave%20order%20for%20which%20we%20have%0A%20%20%20%20%23%20no%20control%20going%20forward.%0A%20%20%20%20extra_phys_args%2B%3D(%20802-3-ethernet.cloned-mac-address%20%22%24%7Biface_mac%7D%22%20)%0A%20%20fi%0A%0A%20%20%23%20use%20%24%7Bextra_phys_args%5B%40%5D%2B%22%24%7Bextra_phys_args%5B%40%5D%7D%22%7D%20instead%20of%20%24%7Bextra_phys_args%5B%40%5D%7D%20to%20be%20compatible%20with%20bash%204.2%20in%20RHEL7.9%0A%20%20if%20!%20nmcli%20connection%20show%20%22%24bridge_interface_name%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20destroy%20interface%20%24%7Biface%7D%0A%20%20%20%20ovs_default_port_conn%3D%24(nmcli%20-g%20connection.uuid%20conn%20show%20%22%24default_port_name%22)%0A%20%20%20%20add_nm_conn%20%22%24bridge_interface_name%22%20type%20%24%7Biface_type%7D%20conn.interface%20%24%7Biface%7D%20master%20%22%24ovs_default_port_conn%22%20%5C%0A%20%20%20%20%20%20slave-type%20ovs-port%20connection.autoconnect-priority%20100%20connection.autoconnect-slaves%201%20802-3-ethernet.mtu%20%24%7Biface_mtu%7D%20%5C%0A%20%20%20%20%20%20%24%7Bextra_phys_args%5B%40%5D%2B%22%24%7Bextra_phys_args%5B%40%5D%7D%22%7D%0A%20%20fi%0A%0A%20%20%23%20Get%20the%20new%20connection%20uuids%0A%20%20new_conn%3D%24(nmcli%20-g%20connection.uuid%20conn%20show%20%22%24bridge_interface_name%22)%0A%20%20ovs_port_conn%3D%24(nmcli%20-g%20connection.uuid%20conn%20show%20%22%24ovs_port%22)%0A%0A%20%20%23%20Update%20connections%20with%20master%20property%20set%20to%20use%20the%20new%20connection%0A%20%20replace_connection_master%20%24old_conn%20%24new_conn%0A%20%20replace_connection_master%20%24iface%20%24new_conn%0A%0A%20%20ipv4_method%3D%24(nmcli%20-g%20ipv4.method%20conn%20show%20%22%24old_conn%22)%0A%20%20ipv6_method%3D%24(nmcli%20-g%20ipv6.method%20conn%20show%20%22%24old_conn%22)%0A%0A%20%20ipv4_addresses%3D%24(nmcli%20-g%20ipv4.addresses%20conn%20show%20%22%24old_conn%22)%0A%20%20ipv6_addresses%3D%24(nmcli%20-g%20ipv6.addresses%20conn%20show%20%22%24old_conn%22)%0A%0A%20%20%23%20Warn%20about%20an%20invalid%20MTU%20that%20will%20most%20likely%20fail%20in%20one%20way%20or%0A%20%20%23%20another%0A%20%20if%20%5B%20%24%7Biface_mtu%7D%20-lt%201280%20%5D%20%26%26%20%5B%20%22%24%7Bipv6_method%7D%22%20!%3D%20%22disabled%22%20%5D%3B%20then%0A%20%20%20%20echo%20%22WARNING%3A%20MTU%20%24%7Biface_mtu%7D%20is%20lower%20than%20the%20minimum%20required%20of%201280%20for%20IPv6%22%0A%20%20fi%0A%0A%20%20if%20!%20nmcli%20connection%20show%20%22%24ovs_interface%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20destroy%20interface%20%22%24bridge_name%22%0A%20%20%20%20%23%20Clone%20the%20connection%20in%20case%20the%20method%20is%20manual%20or%20in%20case%20the%20an%20address%20is%20set%20(DHCP%20%2B%20static%20IP)%0A%20%20%20%20if%20%5B%20%22%24%7Bipv4_method%7D%22%20%3D%20%22manual%22%20%5D%20%7C%7C%20%5B%20%22%24%7Bipv4_addresses%7D%22%20!%3D%20%22%22%20%5D%20%7C%7C%20%5B%20%22%24%7Bipv6_method%7D%22%20%3D%20%22manual%22%20%5D%20%7C%7C%20%5B%20%22%24%7Bipv6_addresses%7D%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22Static%20IP%20addressing%20detected%20on%20default%20gateway%20connection%3A%20%24%7Bold_conn%7D%22%0A%20%20%20%20%20%20%23%20clone%20the%20old%20connection%20to%20get%20the%20address%20settings%0A%20%20%20%20%20%20%23%20prefer%20cloning%20vs%20copying%20the%20connection%20file%20to%20avoid%20problems%20with%20selinux%0A%20%20%20%20%20%20clone_nm_conn%20%22%24%7Bold_conn%7D%22%20%22%24%7Bovs_interface%7D%22%0A%20%20%20%20%20%20shopt%20-s%20nullglob%0A%20%20%20%20%20%20new_conn_files%3D(%24%7BNM_CONN_RUN_PATH%7D%2F%22%24%7Bovs_interface%7D%22*)%0A%20%20%20%20%20%20shopt%20-u%20nullglob%0A%20%20%20%20%20%20if%20%5B%20%24%7B%23new_conn_files%5B%40%5D%7D%20-ne%201%20%5D%20%7C%7C%20%5B%20!%20-f%20%22%24%7Bnew_conn_files%5B0%5D%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22ERROR%3A%20could%20not%20find%20%24%7Bovs_interface%7D%20conn%20file%20after%20cloning%20from%20%24%7Bold_conn%7D%22%0A%20%20%20%20%20%20%20%20exit%201%0A%20%20%20%20%20%20fi%0A%20%20%20%20%20%20new_conn_file%3D%22%24%7Bnew_conn_files%5B0%5D%7D%22%0A%0A%20%20%20%20%20%20%23%20modify%20the%20connection%20type%20directly%20because%20it%20can't%20be%20modified%0A%20%20%20%20%20%20%23%20through%20nmcli%0A%20%20%20%20%20%20sed%20-i%20'%2F%5E%5C%5Bconnection%5C%5D%24%2F%2C%2F%5E%5C%5B%2F%20s%2F%5Etype%3D.*%24%2Ftype%3Dovs-interface%2F'%20%24%7Bnew_conn_file%7D%0A%0A%20%20%20%20%20%20%23%20modify%20some%20more%20settings%20through%20nmcli%0A%20%20%20%20%20%20mod_nm_conn%20%22%24%7Bovs_interface%7D%22%20conn.interface%20%22%24bridge_name%22%20%5C%0A%20%20%20%20%20%20%20%20connection.multi-connect%20%22%22%20connection.autoconnect%20no%20%5C%0A%20%20%20%20%20%20%20%20connection.master%20%22%24ovs_port_conn%22%20connection.slave-type%20ovs-port%20%5C%0A%20%20%20%20%20%20%20%20ovs-interface.type%20internal%20%5C%0A%20%20%20%20%20%20%20%20802-3-ethernet.mtu%20%24%7Biface_mtu%7D%20802-3-ethernet.cloned-mac-address%20%24%7Biface_mac%7D%20%5C%0A%20%20%20%20%20%20%20%20ipv4.route-metric%20%22%24%7Bbridge_metric%7D%22%20ipv6.route-metric%20%22%24%7Bbridge_metric%7D%22%0A%0A%20%20%20%20%20%20echo%20%22Loaded%20new%20%24ovs_interface%20connection%20file%3A%20%24%7Bnew_conn_file%7D%22%0A%20%20%20%20else%0A%20%20%20%20%20%20extra_if_brex_args%3D%22%22%0A%20%20%20%20%20%20%23%20check%20if%20interface%20had%20ipv4%2Fipv6%20addresses%20assigned%0A%20%20%20%20%20%20num_ipv4_addrs%3D%24(ip%20-j%20a%20show%20dev%20%24%7Biface%7D%20%7C%20jq%20%22.%5B0%5D.addr_info%20%7C%20map(.%20%7C%20select(.family%20%3D%3D%20%5C%22inet%5C%22))%20%7C%20length%22)%0A%20%20%20%20%20%20if%20%5B%20%22%24num_ipv4_addrs%22%20-gt%200%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20extra_if_brex_args%2B%3D%22ipv4.may-fail%20no%20%22%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20%23%20IPV6%20should%20have%20at%20least%20a%20link%20local%20address.%20Check%20for%20more%20than%201%20to%20see%20if%20there%20is%20an%0A%20%20%20%20%20%20%23%20assigned%20address.%0A%20%20%20%20%20%20num_ip6_addrs%3D%24(ip%20-j%20a%20show%20dev%20%24%7Biface%7D%20%7C%20jq%20%22.%5B0%5D.addr_info%20%7C%20map(.%20%7C%20select(.family%20%3D%3D%20%5C%22inet6%5C%22%20and%20.scope%20!%3D%20%5C%22link%5C%22))%20%7C%20length%22)%0A%20%20%20%20%20%20if%20%5B%20%22%24num_ip6_addrs%22%20-gt%200%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20extra_if_brex_args%2B%3D%22ipv6.may-fail%20no%20%22%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20%23%20check%20for%20dhcp%20client%20ids%0A%20%20%20%20%20%20dhcp_client_id%3D%24(nmcli%20--get-values%20ipv4.dhcp-client-id%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20%20%20if%20%5B%20-n%20%22%24dhcp_client_id%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20extra_if_brex_args%2B%3D%22ipv4.dhcp-client-id%20%24%7Bdhcp_client_id%7D%20%22%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20dhcp6_client_id%3D%24(nmcli%20--get-values%20ipv6.dhcp-duid%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20%20%20if%20%5B%20-n%20%22%24dhcp6_client_id%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20extra_if_brex_args%2B%3D%22ipv6.dhcp-duid%20%24%7Bdhcp6_client_id%7D%20%22%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20ipv6_addr_gen_mode%3D%24(nmcli%20--get-values%20ipv6.addr-gen-mode%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20%20%20if%20%5B%20-n%20%22%24ipv6_addr_gen_mode%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20extra_if_brex_args%2B%3D%22ipv6.addr-gen-mode%20%24%7Bipv6_addr_gen_mode%7D%20%22%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20add_nm_conn%20%22%24ovs_interface%22%20type%20ovs-interface%20slave-type%20ovs-port%20conn.interface%20%22%24bridge_name%22%20master%20%22%24ovs_port_conn%22%20%5C%0A%20%20%20%20%20%20%20%20802-3-ethernet.mtu%20%24%7Biface_mtu%7D%20802-3-ethernet.cloned-mac-address%20%24%7Biface_mac%7D%20%5C%0A%20%20%20%20%20%20%20%20ipv4.method%20%22%24%7Bipv4_method%7D%22%20ipv4.route-metric%20%22%24%7Bbridge_metric%7D%22%20%5C%0A%20%20%20%20%20%20%20%20ipv6.method%20%22%24%7Bipv6_method%7D%22%20ipv6.route-metric%20%22%24%7Bbridge_metric%7D%22%20%5C%0A%20%20%20%20%20%20%20%20%24%7Bextra_if_brex_args%7D%0A%20%20%20%20fi%0A%20%20fi%0A%0A%20%20configure_driver_options%20%22%24%7Biface%7D%22%0A%7D%0A%0A%23%20Used%20to%20remove%20a%20bridge%0Aremove_ovn_bridges()%20%7B%0A%20%20bridge_name%3D%24%7B1%7D%0A%20%20port_name%3D%24%7B2%7D%0A%0A%20%20%23%20Remove%20the%20keyfiles%20from%20known%20configuration%20paths%0A%20%20update_nm_conn_run_files%20%24%7Bbridge_name%7D%20%24%7Bport_name%7D%0A%20%20rm_nm_conn_files%0A%20%20update_nm_conn_set_files%20%24%7Bbridge_name%7D%20%24%7Bport_name%7D%0A%20%20rm_nm_conn_files%0A%20%20%23%20Shouldn't%20be%20necessary%2C%20workaround%20for%20https%3A%2F%2Fissues.redhat.com%2Fbrowse%2FOCPBUGS-41489%0A%20%20update_nm_conn_etc_files%20%24%7Bbridge_name%7D%20%24%7Bport_name%7D%0A%20%20rm_nm_conn_files%0A%0A%20%20%23%20NetworkManager%20will%20not%20remove%20%24%7Bbridge_name%7D%20if%20it%20has%20the%20patch%20port%20created%20by%20ovn-kubernetes%0A%20%20%23%20so%20remove%20explicitly%0A%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-br%20%24%7Bbridge_name%7D%0A%7D%0A%0A%23%20Removes%20any%20previous%20ovs%20configuration%0Aremove_all_ovn_bridges()%20%7B%0A%20%20echo%20%22Reverting%20any%20previous%20OVS%20configuration%22%0A%20%20%0A%20%20remove_ovn_bridges%20br-ex%20phys0%0A%20%20remove_ovn_bridges%20br-ex1%20phys1%0A%20%20%0A%20%20echo%20%22OVS%20configuration%20successfully%20reverted%22%0A%7D%0A%0A%23%20Reloads%20NM%20NetworkManager%20profiles%20if%20any%20configuration%20change%20was%20done.%0A%23%20Accepts%20a%20list%20of%20devices%20that%20should%20be%20re-connect%20after%20reload.%0Areload_profiles_nm()%20%7B%0A%20%20if%20%5B%20%24%7Bnm_config_changed%3A-0%7D%20-eq%200%20%5D%3B%20then%0A%20%20%20%20%23%20no%20config%20was%20changed%2C%20no%20need%20to%20reload%0A%20%20%20%20return%0A%20%20fi%0A%0A%20%20%23%20reload%20profiles%0A%20%20nmcli%20connection%20reload%0A%0A%20%20%23%20precautionary%20sleep%20of%2010s%20(default%20timeout%20of%20NM%20to%20bring%20down%20devices)%0A%20%20sleep%2010%0A%0A%20%20%23%20After%20reload%2C%20devices%20that%20were%20already%20connected%20should%20connect%20again%0A%20%20%23%20if%20any%20profile%20is%20available.%20If%20no%20profile%20is%20available%2C%20a%20device%20can%0A%20%20%23%20remain%20disconnected%20and%20we%20have%20to%20explicitly%20connect%20it%20so%20that%20a%0A%20%20%23%20profile%20is%20generated.%20This%20can%20happen%20for%20physical%20devices%20but%20should%0A%20%20%23%20not%20happen%20for%20software%20devices%20as%20those%20always%20require%20a%20profile.%0A%20%20for%20dev%20in%20%24%40%3B%20do%0A%20%20%20%20%23%20Only%20attempt%20to%20connect%20a%20disconnected%20device%0A%20%20%20%20local%20connected_state%3D%24(nmcli%20-g%20GENERAL.STATE%20device%20show%20%22%24dev%22%20%7C%7C%20echo%20%22%22)%0A%20%20%20%20if%20%5B%5B%20%22%24connected_state%22%20%3D~%20%22disconnected%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%23%20keep%20track%20if%20a%20profile%20by%20the%20same%20name%20as%20the%20device%20existed%20%0A%20%20%20%20%20%20%23%20before%20we%20attempt%20activation%0A%20%20%20%20%20%20local%20named_profile_existed%3D%24(%5B%20-f%20%22%24%7BNM_CONN_CONF_PATH%7D%2F%24%7Bdev%7D%22%20%5D%20%7C%7C%20%5B%20-f%20%22%24%7BNM_CONN_CONF_PATH%7D%2F%24%7Bdev%7D.nmconnection%22%20%5D%20%26%26%20echo%20%22yes%22)%0A%20%20%20%20%20%20%0A%20%20%20%20%20%20for%20i%20in%20%7B1..10%7D%3B%20do%0A%20%20%20%20%20%20%20%20%20%20echo%20%22Attempt%20%24i%20to%20connect%20device%20%24dev%22%0A%20%20%20%20%20%20%20%20%20%20nmcli%20device%20connect%20%22%24dev%22%20%26%26%20break%0A%20%20%20%20%20%20%20%20%20%20sleep%205%0A%20%20%20%20%20%20done%0A%0A%20%20%20%20%20%20%23%20if%20a%20profile%20did%20not%20exist%20before%20but%20does%20now%2C%20it%20was%20generated%0A%20%20%20%20%20%20%23%20but%20we%20want%20it%20to%20be%20ephemeral%2C%20so%20move%20it%20back%20to%20%2Frun%0A%20%20%20%20%20%20if%20%5B%20!%20%22%24named_profile_existed%22%20%3D%20%22yes%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20MANAGED_NM_CONN_FILES%3D(%22%24%7BNM_CONN_CONF_PATH%7D%2F%24%7Bdev%7D%22%20%22%24%7BNM_CONN_CONF_PATH%7D%2F%24%7Bdev%7D.nmconnection%22)%0A%20%20%20%20%20%20%20%20copy_nm_conn_files%20%22%24%7BNM_CONN_RUN_PATH%7D%22%0A%20%20%20%20%20%20%20%20rm_nm_conn_files%0A%20%20%20%20%20%20%20%20%23%20reload%20profiles%20so%20that%20NM%20notices%20that%20some%20might%20have%20been%20moved%0A%20%20%20%20%20%20%20%20nmcli%20connection%20reload%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20echo%20%22Waiting%20for%20interface%20%24dev%20to%20activate...%22%0A%20%20%20%20if%20!%20timeout%2060%20bash%20-c%20%22while%20!%20nmcli%20-g%20DEVICE%2CSTATE%20c%20%7C%20grep%20%22'%22'%22%24dev%22%3Aactivated'%22'%22%3B%20do%20sleep%205%3B%20done%22%3B%20then%0A%20%20%20%20%20%20echo%20%22WARNING%3A%20%24dev%20did%20not%20activate%22%0A%20%20%20%20fi%0A%20%20done%0A%0A%20%20nm_config_changed%3D0%0A%7D%0A%0A%23%20Removes%20all%20configuration%20and%20reloads%20NM%20if%20necessary%0Arollback_nm()%20%7B%0A%20%20phys0%3D%24(get_bridge_physical_interface%20ovs-if-phys0)%0A%20%20phys1%3D%24(get_bridge_physical_interface%20ovs-if-phys1)%0A%20%20%0A%20%20%23%20Revert%20changes%20made%20by%20%2Fusr%2Flocal%2Fbin%2Fconfigure-ovs.sh%20during%20SDN%20migration.%0A%20%20remove_all_ovn_bridges%0A%20%20%0A%20%20%23%20reload%20profiles%20so%20that%20NM%20notices%20that%20some%20were%20removed%0A%20%20reload_profiles_nm%20%22%24phys0%22%20%22%24phys1%22%0A%7D%0A%0A%23%20Add%20a%20temporary%20deactivated%20connection%20profile%20%0A%23%20First%20argument%20is%20the%20connection%20name%20folowed%20by%20arguments%20passed%20to%0A%23%20%60nmcli%20connection%20add%60%0Aadd_nm_conn()%20%7B%0A%20%20%23%20Use%20%60save%20no%60%20to%20add%20a%20temporary%20profile%0A%20%20nmcli%20c%20add%20save%20no%20con-name%20%22%24%40%22%20connection.autoconnect%20no%0A%7D%0A%0A%23%20Modify%20a%20temporary%20connection%20profile%20%0A%23%20First%20argument%20is%20the%20connection%20name%20followed%20by%20arguments%20passed%20to%0A%23%20%60nmcli%20connection%20modify%60%0Amod_nm_conn()%20%7B%0A%20%20%23%20the%20easiest%20thing%20to%20do%20here%20would%20be%20to%20use%20%60nmcli%20c%20mod%20--temporary%60%0A%20%20%23%20but%20there%20is%20a%20bug%20in%20selinux%20profiles%20that%20denies%20NM%20from%20performing%0A%20%20%23%20the%20operation%0A%20%20local%20dst_path%3D%24%7BNM_CONN_RUN_PATH%7D%2F%241.nmconnection%0A%20%20local%20src_path%0A%20%20src_path%3D%24(mktemp)%0A%20%20shift%0A%20%20cat%20%22%24dst_path%22%20%3E%20%22%24src_path%22%0A%20%20rm%20-f%20%22%24dst_path%22%0A%20%20nmcli%20--offline%20c%20mod%20%22%24%40%22%20%3C%20%22%24src_path%22%20%3E%20%22%24dst_path%22%0A%20%20rm%20-f%20%22%24src_path%22%0A%20%20chmod%20600%20%22%24dst_path%22%0A%20%20nmcli%20c%20load%20%22%24dst_path%22%0A%7D%0A%0A%23%20Clone%20to%20a%20temporary%20connection%20profile%20%0A%23%20First%20argument%20is%20the%20connection%20to%20clone%2C%20second%20argument%20is%20the%20clone%20name%0Aclone_nm_conn()%20%7B%0A%20%20%23%20clone%20as%20temporary%20so%20that%20it%20is%20generated%20in%20NM_CONN_RUN_PATH%0A%20%20nmcli%20connection%20clone%20--temporary%20%22%241%22%20%22%242%22%20%26%3E%20%2Fdev%2Fnull%0A%7D%0A%0A%23%20Activates%20an%20ordered%20set%20of%20NM%20connection%20profiles%0Aactivate_nm_connections()%20%7B%0A%20%20local%20connections%3D(%22%24%40%22)%0A%0A%20%20%23%20We%20want%20autoconnect%20set%20for%20our%20cloned%20slave%20profiles%20so%20that%20they%20are%0A%20%20%23%20used%20over%20the%20original%20profiles%20if%20implicitly%20re-activated%20with%20other%0A%20%20%23%20dependant%20profiles.%20Otherwise%20if%20a%20slave%20activates%20with%20an%20old%20profile%2C%0A%20%20%23%20the%20old%20master%20profile%20might%20activate%20as%20well%2C%20interfering%20and%20causing%0A%20%20%23%20further%20activations%20to%20fail.%0A%20%20%23%20Slave%20interfaces%20should%20already%20be%20active%20so%20setting%20autoconnect%20here%0A%20%20%23%20won't%20implicitly%20activate%20them%20but%20there%20is%20an%20edge%20case%20where%20a%20slave%0A%20%20%23%20might%20be%20inactive%20(link%20down%20for%20example)%20and%20in%20that%20case%20setting%0A%20%20%23%20autoconnect%20will%20cause%20an%20implicit%20activation.%20This%20is%20not%20necessarily%20a%0A%20%20%23%20problem%20and%20hopefully%20we%20can%20make%20sure%20everything%20is%20activated%20as%20we%0A%20%20%23%20want%20next.%0A%20%20for%20conn%20in%20%22%24%7Bconnections%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20local%20slave_type%3D%24(nmcli%20-g%20connection.slave-type%20connection%20show%20%22%24conn%22)%0A%20%20%20%20if%20%5B%20%22%24slave_type%22%20%3D%20%22team%22%20%5D%20%7C%7C%20%5B%20%22%24slave_type%22%20%3D%20%22bond%22%20%5D%3B%20then%0A%20%20%20%20%20%20mod_nm_conn%20%22%24conn%22%20connection.autoconnect%20yes%0A%20%20%20%20fi%0A%20%20done%0A%0A%20%20%23%20Activate%20all%20connections%20and%20fail%20if%20activation%20fails%0A%20%20%23%20For%20slave%20connections%20-%20for%20as%20long%20as%20at%20least%20one%20slave%20that%20belongs%20to%20a%20bond%2Fteam%0A%20%20%23%20comes%20up%2C%20we%20should%20not%20fail%0A%20%20declare%20-A%20master_interfaces%0A%20%20for%20conn%20in%20%22%24%7Bconnections%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20%23%20Get%20the%20slave%20type%0A%20%20%20%20local%20slave_type%3D%24(nmcli%20-g%20connection.slave-type%20connection%20show%20%22%24conn%22)%0A%20%20%20%20local%20is_slave%3Dfalse%0A%20%20%20%20if%20%5B%20%22%24slave_type%22%20%3D%20%22team%22%20%5D%20%7C%7C%20%5B%20%22%24slave_type%22%20%3D%20%22bond%22%20%5D%3B%20then%0A%20%20%20%20%20%20is_slave%3Dtrue%0A%20%20%20%20fi%20%0A%0A%20%20%20%20%23%20For%20slave%20interfaces%2C%20initialize%20the%20master%20interface%20to%20false%20if%20the%20key%20is%20not%20yet%20in%20the%20array%0A%20%20%20%20local%20master_interface%0A%20%20%20%20if%20%24is_slave%3B%20then%0A%20%20%20%20%20%20master_interface%3D%24(nmcli%20-g%20connection.master%20connection%20show%20%22%24conn%22)%0A%20%20%20%20%20%20if%20!%20%5B%5B%20-v%20%22master_interfaces%5B%24master_interface%5D%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20master_interfaces%5B%22%24master_interface%22%5D%3Dfalse%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20slaves%20should%20implicitly%20activate%2C%20give%20them%20a%20chance%20to%20do%20so%0A%20%20%20%20if%20%24is_slave%3B%20then%0A%20%20%20%20%20%20if%20!%20timeout%205%20bash%20-c%20%22while%20!%20nmcli%20-g%20GENERAL.STATE%20conn%20show%20%22%24conn%22%20%7C%20grep%20activated%3B%20do%20sleep%201%3B%20done%22%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22WARNING%3A%20slave%20%24conn%20did%20not%20implicitly%20activate%20in%205s%2C%20activating%20explicitly.%22%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Do%20not%20activate%20interfaces%20that%20are%20already%20active%0A%20%20%20%20%23%20But%20set%20the%20entry%20in%20master_interfaces%20to%20true%20if%20this%20is%20a%20slave%0A%20%20%20%20%23%20Also%20set%20autoconnect%20to%20yes%0A%20%20%20%20local%20active_state%3D%24(nmcli%20-g%20GENERAL.STATE%20conn%20show%20%22%24conn%22)%0A%20%20%20%20if%20%5B%20%22%24active_state%22%20%3D%3D%20%22activated%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22Connection%20%24conn%20already%20activated%22%0A%20%20%20%20%20%20if%20%24is_slave%3B%20then%0A%20%20%20%20%20%20%20%20master_interfaces%5B%24master_interface%5D%3Dtrue%0A%20%20%20%20%20%20fi%0A%20%20%20%20%20%20mod_nm_conn%20%22%24conn%22%20connection.autoconnect%20yes%0A%20%20%20%20%20%20continue%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Activate%20all%20interfaces%20that%20are%20not%20yet%20active%0A%20%20%20%20for%20i%20in%20%7B1..10%7D%3B%20do%0A%20%20%20%20%20%20echo%20%22Attempt%20%24i%20to%20bring%20up%20connection%20%24conn%22%0A%20%20%20%20%20%20nmcli%20conn%20up%20%22%24conn%22%20%26%26%20s%3D0%20%26%26%20break%20%7C%7C%20s%3D%24%3F%0A%20%20%20%20%20%20sleep%205%0A%20%20%20%20done%0A%20%20%20%20if%20%5B%20%24s%20-eq%200%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22Brought%20up%20connection%20%24conn%20successfully%22%0A%20%20%20%20%20%20if%20%24is_slave%3B%20then%0A%20%20%20%20%20%20%20%20master_interfaces%5B%22%24master_interface%22%5D%3Dtrue%0A%20%20%20%20%20%20fi%0A%20%20%20%20elif%20!%20%24is_slave%3B%20then%0A%20%20%20%20%20%20echo%20%22ERROR%3A%20Cannot%20bring%20up%20connection%20%24conn%20after%20%24i%20attempts%22%0A%20%20%20%20%20%20return%20%24s%0A%20%20%20%20fi%0A%20%20%20%20mod_nm_conn%20%22%24conn%22%20connection.autoconnect%20yes%0A%20%20done%0A%20%20%23%20Check%20that%20all%20master%20interfaces%20report%20at%20least%20a%20single%20active%20slave%0A%20%20%23%20Note%3A%20associative%20arrays%20require%20an%20exclamation%20mark%20when%20looping%0A%20%20for%20i%20in%20%22%24%7B!master_interfaces%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20if%20!%20%24%7Bmaster_interfaces%5B%22%24i%22%5D%7D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22ERROR%3A%20Cannot%20bring%20up%20any%20slave%20interface%20for%20master%20interface%3A%20%24i%22%0A%20%20%20%20%20%20%20%20return%201%0A%20%20%20%20fi%0A%20%20done%0A%7D%0A%0A%23%20Accepts%20parameters%20%24iface_default_hint_file%2C%20%24iface%0A%23%20Writes%20content%20of%20%24iface%20into%20%24iface_default_hint_file%0Awrite_iface_default_hint()%20%7B%0A%20%20local%20iface_default_hint_file%3D%22%241%22%0A%20%20local%20iface%3D%22%242%22%0A%0A%20%20echo%20%22%24%7Biface%7D%22%20%3E%7C%20%22%24%7Biface_default_hint_file%7D%22%0A%7D%0A%0A%23%20Accepts%20parameters%20%24iface_default_hint_file%0A%23%20Returns%20the%20stored%20interface%20default%20hint%20if%20the%20hint%20is%20non-empty%2C%0A%23%20not%20br-ex%2C%20not%20br-ex1%20and%20if%20the%20interface%20can%20be%20found%20in%20%2Fsys%2Fclass%2Fnet%0Aget_iface_default_hint()%20%7B%0A%20%20local%20iface_default_hint_file%3D%241%0A%20%20if%20%5B%20-f%20%22%24%7Biface_default_hint_file%7D%22%20%5D%3B%20then%0A%20%20%20%20local%20iface_default_hint%3D%24(cat%20%22%24%7Biface_default_hint_file%7D%22)%0A%20%20%20%20if%20%5B%20%22%24%7Biface_default_hint%7D%22%20!%3D%20%22%22%20%5D%20%26%26%0A%20%20%20%20%20%20%20%20%5B%20%22%24%7Biface_default_hint%7D%22%20!%3D%20%22br-ex%22%20%5D%20%26%26%0A%20%20%20%20%20%20%20%20%5B%20%22%24%7Biface_default_hint%7D%22%20!%3D%20%22br-ex1%22%20%5D%20%26%26%0A%20%20%20%20%20%20%20%20%5B%20-d%20%22%2Fsys%2Fclass%2Fnet%2F%24%7Biface_default_hint%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22%24%7Biface_default_hint%7D%22%0A%20%20%20%20%20%20%20%20return%0A%20%20%20%20fi%0A%20%20fi%0A%20%20echo%20%22%22%0A%7D%0A%0Aget_ip_from_ip_hint_file()%20%7B%0A%20%20local%20ip_hint_file%3D%22%241%22%0A%20%20if%20%5B%5B%20!%20-f%20%22%24%7Bip_hint_file%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20return%0A%20%20fi%0A%20%20ip_hint%3D%24(cat%20%22%24%7Bip_hint_file%7D%22)%0A%20%20echo%20%22%24%7Bip_hint%7D%22%0A%7D%0A%0A%23%20This%20function%20waits%20for%20ip%20address%20of%20br-ex%20to%20be%20bindable%20only%20in%20case%20of%20ipv6%0A%23%20This%20is%20workaround%20for%20OCPBUGS-673%20as%20it%20will%20not%20allow%20starting%20crio%0A%23%20before%20address%20is%20bindable%0Atry_to_bind_ipv6_address()%20%7B%0A%20%20%23%20Retry%20for%201%20minute%0A%20%20retries%3D60%0A%20%20until%20%5B%5B%20%24%7Bretries%7D%20-eq%200%20%5D%5D%3B%20do%0A%20%20%20%20ip%3D%24(ip%20-6%20-j%20addr%20%7C%20jq%20-r%20%22first(.%5B%5D%20%7C%20select(.ifname%3D%3D%5C%22br-ex%5C%22)%20%7C%20.addr_info%5B%5D%20%7C%20select(.scope%3D%3D%5C%22global%5C%22)%20%7C%20.local)%22)%0A%20%20%20%20if%20%5B%5B%20%22%24%7Bip%7D%22%20%3D%3D%20%22%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22No%20ipv6%20ip%20to%20bind%20was%20found%22%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20%20%20random_port%3D%24(shuf%20-i%2050000-60000%20-n%201)%0A%20%20%20%20echo%20%22Trying%20to%20bind%20%24%7Bip%7D%20on%20port%20%24%7Brandom_port%7D%22%0A%20%20%20%20exit_code%3D%24(timeout%202s%20nc%20-l%20%22%24%7Bip%7D%22%20%24%7Brandom_port%7D%3B%20echo%20%24%3F)%0A%20%20%20%20if%20%5B%5B%20exit_code%20-eq%20124%20%5D%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22Address%20bound%20successfully%22%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20%20%20sleep%201%0A%20%20%20%20((%20retries--%20))%0A%20%20done%0A%20%20if%20%5B%5B%20%24%7Bretries%7D%20-eq%200%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22Failed%20to%20bind%20ip%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%7D%0A%0A%23%20Get%20interface%20that%20matches%20ip%20from%20node%20ip%20hint%20file%0A%23%20in%20case%20file%20not%20exists%20return%20nothing%20and%0A%23%20fallback%20to%20default%20interface%20search%20flow%0Aget_nodeip_hint_interface()%20%7B%0A%20%20local%20ip_hint%3D%22%22%0A%20%20local%20ip_hint_file%3D%22%241%22%0A%20%20local%20extra_bridge%3D%22%242%22%0A%20%20local%20iface%3D%22%22%0A%0A%20%20ip_hint%3D%24(get_ip_from_ip_hint_file%20%22%24%7Bip_hint_file%7D%22)%0A%20%20if%20%5B%5B%20-z%20%22%24%7Bip_hint%7D%22%20%20%5D%5D%3B%20then%0A%20%20%20%20return%0A%20%20fi%0A%0A%20%20iface%3D%24(ip%20-j%20addr%20%7C%20jq%20-r%20%22first(.%5B%5D%20%7C%20select(any(.addr_info%5B%5D%3B%20.local%3D%3D%5C%22%24%7Bip_hint%7D%5C%22)%20and%20.ifname!%3D%5C%22br-ex1%5C%22%20and%20.ifname!%3D%5C%22%24%7Bextra_bridge%7D%5C%22))%20%7C%20.ifname%22)%0A%20%20if%20%5B%5B%20-n%20%22%24%7Biface%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22%24%7Biface%7D%22%0A%20%20fi%0A%7D%0A%0A%23%20Accepts%20parameters%20%24bridge_interface%20(e.g.%20ovs-port-phys0)%0A%23%20Returns%20the%20physical%20interface%20name%20if%20%24bridge_interface%20exists%2C%20%22%22%20otherwise%0Aget_bridge_physical_interface()%20%7B%0A%20%20local%20bridge_interface%3D%22%241%22%0A%20%20local%20physical_interface%3D%22%22%0A%20%20physical_interface%3D%24(nmcli%20-g%20connection.interface-name%20conn%20show%20%22%24%7Bbridge_interface%7D%22%202%3E%2Fdev%2Fnull%20%7C%7C%20echo%20%22%22)%0A%20%20echo%20%22%24%7Bphysical_interface%7D%22%0A%7D%0A%0A%23%20Accepts%20parameters%20%24iface_default_hint_file%2C%20%24extra_bridge_file%2C%20%24ip_hint_file%2C%20%24default_bridge_file%0A%23%20Determines%20the%20interface%20to%20be%20used%20for%20br-ex.%20Order%20of%20priority%20is%3A%0A%23%201.%20Use%20the%20user%20specified%20interface%20if%20provided%20in%20the%20default%20bridge%20file%0A%23%202.%20Use%20the%20node%20IP%20hint%20interface%0A%23%203.%20Use%20the%20previously%20selected%20interface%0A%23%204.%20Use%20the%20interface%20detected%20as%20default%20gateway%0A%23%0A%23%20Read%20%24default_bridge_file%20and%20return%20the%20contained%20interface.%20Otherwise%2C%0A%23%20read%20%24ip_hint_file%20and%20return%20the%20interface%20that%20matches%20this%20ip.%20Otherwise%2C%0A%23%20if%20the%20default%20interface%20is%20br-ex%2C%20use%20that%20and%20return.%0A%23%20If%20the%20default%20interface%20is%20not%20br-ex%3A%0A%23%20Check%20if%20there%20is%20a%20valid%20hint%20inside%20%24iface_default_hint_file.%20If%20so%2C%20use%20that%20hint.%0A%23%20If%20there%20is%20no%20valid%20hint%2C%20use%20the%20default%20interface%20that%20we%20found%20during%20the%20step%0A%23%20earlier.%0A%23%20Never%20use%20the%20interface%20that%20is%20provided%20inside%20%24extra_bridge_file%20for%20br-ex1.%0A%23%20Never%20use%20br-ex1.%0A%23%20Write%20the%20default%20interface%20to%20%24iface_default_hint_file%0Aget_default_bridge_interface()%20%7B%0A%20%20local%20iface%3D%22%22%0A%20%20local%20counter%3D0%0A%20%20local%20iface_default_hint_file%3D%22%241%22%0A%20%20local%20extra_bridge_file%3D%22%242%22%0A%20%20local%20ip_hint_file%3D%22%243%22%0A%20%20local%20default_bridge_file%3D%22%244%22%0A%20%20local%20extra_bridge%3D%22%22%0A%0A%20%20if%20%5B%20-f%20%22%24%7Bextra_bridge_file%7D%22%20%5D%3B%20then%0A%20%20%20%20extra_bridge%3D%24(cat%20%24%7Bextra_bridge_file%7D)%0A%20%20fi%0A%0A%20%20%23%20try%20to%20use%20user%20specified%20file%20first%0A%20%20if%20%5B%20-f%20%22%24default_bridge_file%22%20%5D%3B%20then%0A%20%20%20%20iface%3D%24(cat%20%22%24%7Bdefault_bridge_file%7D%22)%0A%20%20%20%20if%20%5B%20-z%20%22%24iface%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22ERROR%3A%20User%20specified%20bridge%20file%20detected%20without%20any%20data%22%0A%20%20%20%20%20%20exit%201%0A%20%20%20%20fi%0A%20%20%20%20echo%20%22%24%7Biface%7D%22%0A%20%20%20%20return%0A%20%20fi%0A%0A%20%20%23%20if%20node%20ip%20was%20set%2C%20we%20should%20search%20for%20interface%20that%20matches%20it%0A%20%20iface%3D%24(get_nodeip_hint_interface%20%22%24%7Bip_hint_file%7D%22%20%22%24%7Bextra_bridge%7D%22)%0A%20%20if%20%5B%5B%20-n%20%22%24%7Biface%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22%24%7Biface%7D%22%0A%20%20%20%20return%0A%20%20fi%0A%0A%20%20%23%20find%20default%20interface%0A%20%20%23%20the%20default%20interface%20might%20be%20br-ex%2C%20so%20check%20this%20before%20looking%20at%20the%20hint%0A%20%20while%20%5B%20%24%7Bcounter%7D%20-lt%2012%20%5D%3B%20do%0A%20%20%20%20%23%20check%20ipv4%0A%20%20%20%20%23%20never%20use%20the%20interface%20that's%20specified%20in%20extra_bridge_file%0A%20%20%20%20%23%20never%20use%20br-ex1%0A%20%20%20%20if%20%5B%20%22%24%7Bextra_bridge%7D%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20iface%3D%24(ip%20route%20show%20default%20%7C%20grep%20-v%20%22br-ex1%22%20%7C%20grep%20-v%20%22%24%7Bextra_bridge%7D%22%20%7C%20awk%20'%7B%20if%20(%244%20%3D%3D%20%22dev%22)%20%7B%20print%20%245%3B%20exit%20%7D%20%7D')%0A%20%20%20%20else%0A%20%20%20%20%20%20iface%3D%24(ip%20route%20show%20default%20%7C%20grep%20-v%20%22br-ex1%22%20%7C%20awk%20'%7B%20if%20(%244%20%3D%3D%20%22dev%22)%20%7B%20print%20%245%3B%20exit%20%7D%20%7D')%0A%20%20%20%20fi%0A%20%20%20%20if%20%5B%5B%20-n%20%22%24%7Biface%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20%20%20%23%20check%20ipv6%0A%20%20%20%20%23%20never%20use%20the%20interface%20that's%20specified%20in%20extra_bridge_file%0A%20%20%20%20%23%20never%20use%20br-ex1%0A%20%20%20%20if%20%5B%20%22%24%7Bextra_bridge%7D%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20iface%3D%24(ip%20-6%20route%20show%20default%20%7C%20grep%20-v%20%22br-ex1%22%20%7C%20grep%20-v%20%22%24%7Bextra_bridge%7D%22%20%7C%20awk%20'%7B%20if%20(%244%20%3D%3D%20%22dev%22)%20%7B%20print%20%245%3B%20exit%20%7D%20%7D')%0A%20%20%20%20else%0A%20%20%20%20%20%20iface%3D%24(ip%20-6%20route%20show%20default%20%7C%20grep%20-v%20%22br-ex1%22%20%7C%20awk%20'%7B%20if%20(%244%20%3D%3D%20%22dev%22)%20%7B%20print%20%245%3B%20exit%20%7D%20%7D')%0A%20%20%20%20fi%0A%20%20%20%20if%20%5B%5B%20-n%20%22%24%7Biface%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20%20%20counter%3D%24((counter%2B1))%0A%20%20%20%20sleep%205%0A%20%20done%0A%0A%20%20%23%20if%20the%20default%20interface%20does%20not%20point%20out%20of%20br-ex%20or%20br-ex1%0A%20%20if%20%5B%20%22%24%7Biface%7D%22%20!%3D%20%22br-ex%22%20%5D%20%26%26%20%5B%20%22%24%7Biface%7D%22%20!%3D%20%22br-ex1%22%20%5D%3B%20then%0A%20%20%20%20%23%20determine%20if%20an%20interface%20default%20hint%20exists%20from%20a%20previous%20run%0A%20%20%20%20%23%20and%20if%20the%20interface%20has%20a%20valid%20default%20route%0A%20%20%20%20iface_default_hint%3D%24(get_iface_default_hint%20%22%24%7Biface_default_hint_file%7D%22)%0A%20%20%20%20if%20%5B%20%22%24%7Biface_default_hint%7D%22%20!%3D%20%22%22%20%5D%20%26%26%0A%20%20%20%20%20%20%20%20%5B%20%22%24%7Biface_default_hint%7D%22%20!%3D%20%22%24%7Biface%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%23%20start%20wherever%20count%20left%20off%20in%20the%20previous%20loop%0A%20%20%20%20%20%20%23%20allow%20this%20for%20one%20more%20iteration%20than%20the%20previous%20loop%0A%20%20%20%20%20%20while%20%5B%20%24%7Bcounter%7D%20-le%2012%20%5D%3B%20do%0A%20%20%20%20%20%20%20%20%23%20check%20ipv4%0A%20%20%20%20%20%20%20%20if%20%5B%20%22%24(ip%20route%20show%20default%20dev%20%22%24%7Biface_default_hint%7D%22)%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20iface%3D%22%24%7Biface_default_hint%7D%22%0A%20%20%20%20%20%20%20%20%20%20break%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20%23%20check%20ipv6%0A%20%20%20%20%20%20%20%20if%20%5B%20%22%24(ip%20-6%20route%20show%20default%20dev%20%22%24%7Biface_default_hint%7D%22)%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20iface%3D%22%24%7Biface_default_hint%7D%22%0A%20%20%20%20%20%20%20%20%20%20break%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20counter%3D%24((counter%2B1))%0A%20%20%20%20%20%20%20%20sleep%205%0A%20%20%20%20%20%20done%0A%20%20%20%20fi%0A%20%20%20%20%23%20store%20what%20was%20determined%20was%20the%20(new)%20default%20interface%20inside%0A%20%20%20%20%23%20the%20default%20hint%20file%20for%20future%20reference%0A%20%20%20%20if%20%5B%20%22%24%7Biface%7D%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20write_iface_default_hint%20%22%24%7Biface_default_hint_file%7D%22%20%22%24%7Biface%7D%22%0A%20%20%20%20fi%0A%20%20fi%0A%20%20echo%20%22%24%7Biface%7D%22%0A%7D%0A%0A%23%20Used%20to%20print%20network%20state%0Aprint_state()%20%7B%0A%20%20echo%20%22Current%20device%2C%20connection%2C%20interface%20and%20routing%20state%3A%22%0A%20%20nmcli%20-g%20all%20device%20%7C%20grep%20-v%20unmanaged%0A%20%20nmcli%20-g%20all%20connection%0A%20%20ip%20-d%20address%20show%0A%20%20ip%20route%20show%0A%20%20ip%20-6%20route%20show%0A%7D%0A%0A%23%20Setup%20an%20exit%20trap%20to%20rollback%20on%20error%0Ahandle_exit()%20%7B%0A%20%20e%3D%24%3F%0A%20%20tdir%3D%24(mktemp%20-u%20-d%20-t%20%22configure-ovs-%24(date%20%2B%25Y-%25m-%25d-%25H-%25M-%25S)-XXXXXXXXXX%22)%0A%20%20%0A%20%20if%20%5B%20%24e%20-eq%200%20%5D%3B%20then%0A%20%20%20%20print_state%0A%20%20%20%20%23%20remove%20previous%20troubleshooting%20information%0A%20%20%20%20rm%20-rf%20%22%24(dirname%20%22%24tdir%22)%2Fconfigure-ovs-*%22%0A%20%20%20%20exit%200%0A%20%20fi%0A%0A%20%20echo%20%22ERROR%3A%20configure-ovs%20exited%20with%20error%3A%20%24e%22%0A%20%20print_state%0A%0A%20%20%23%20remove%20previous%20troubleshooting%20information%20except%20the%20oldest%20one%0A%20%20mapfile%20-t%20tdirs%20%3C%20%3C(compgen%20-G%20%22%24(dirname%20%22%24tdir%22)%2Fconfigure-ovs-*%22)%0A%20%20unset%20-v%20%22tdirs%5B0%5D%22%0A%20%20for%20dir%20in%20%22%24%7Btdirs%5B%40%5D%7D%22%3B%20do%20rm%20-rf%20%22%24dir%22%3B%20done%0A%0A%20%20%23%20copy%20configuration%20to%20tmp%20for%20troubleshooting%0A%20%20mkdir%20-p%20%22%24tdir%22%0A%20%20update_nm_conn_run_files%20br-ex%20phys0%0A%20%20copy_nm_conn_files%20%22%24tdir%22%0A%20%20update_nm_conn_run_files%20br-ex1%20phys1%0A%20%20copy_nm_conn_files%20%22%24tdir%22%0A%20%20echo%20%22Copied%20OVS%20configuration%20to%20%24tdir%20for%20troubleshooting%22%0A%0A%20%20%23%20attempt%20to%20restore%20the%20previous%20network%20state%0A%20%20echo%20%22Attempting%20to%20restore%20previous%20configuration...%22%0A%20%20rollback_nm%0A%20%20print_state%0A%0A%20%20exit%20%24e%0A%7D%0A%0A%23%20Setup%20a%20signal%20trap%20to%20rollback%0Ahandle_termination()%20%7B%0A%20%20echo%20%22WARNING%3A%20configure-ovs%20has%20been%20requested%20to%20terminate%2C%20quitting...%22%0A%20%20%0A%20%20%23%20by%20exiting%20with%20an%20error%20we%20will%20cleanup%20after%20ourselves%20in%20a%0A%20%20%23%20subsequent%20call%20to%20handle_exit%0A%20%20exit%201%0A%7D%0A%0A%23%20main%20function%0Aconfigure_ovs()%20%7B%0A%20%20set%20-eu%0A%0A%20%20%23%20setup%20traps%20to%20handle%20signals%20and%20other%20abnormal%20exits%0A%20%20trap%20'handle_termination'%20TERM%20INT%0A%20%20trap%20'handle_exit'%20EXIT%0A%0A%20%20%23%20this%20flag%20tracks%20if%20any%20config%20change%20was%20made%0A%20%20nm_config_changed%3D0%0A%0A%20%20%23%20Check%20that%20we%20are%20provided%20a%20valid%20NM%20connection%20path%0A%20%20if%20%5B%20%22%24NM_CONN_SET_PATH%22%20!%3D%20%22%24NM_CONN_CONF_PATH%22%20%5D%20%26%26%20%5B%20%22%24NM_CONN_SET_PATH%22%20!%3D%20%22%24NM_CONN_RUN_PATH%22%20%5D%3B%20then%0A%20%20%20%20echo%20%22Error%3A%20Incorrect%20NM%20connection%20path%3A%20%24NM_CONN_SET_PATH%20is%20not%20%24NM_CONN_CONF_PATH%20nor%20%24NM_CONN_RUN_PATH%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%0A%20%20%23%20Clean%20up%20old%20config%20on%20behalf%20of%20mtu-migration%0A%20%20if%20!%20systemctl%20-q%20is-enabled%20mtu-migration%3B%20then%0A%20%20%20%20echo%20%22Cleaning%20up%20left%20over%20mtu%20migration%20configuration%22%0A%20%20%20%20rm%20-rf%20%2Fetc%2Fcno%2Fmtu-migration%0A%20%20fi%0A%0A%20%20if%20!%20rpm%20-qa%20%7C%20grep%20-q%20openvswitch%3B%20then%0A%20%20%20%20echo%20%22WARNING%3A%20Openvswitch%20package%20is%20not%20installed!%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%0A%20%20%23%20print%20initial%20state%0A%20%20print_state%0A%0A%20%20if%20%5B%20%22%241%22%20%3D%3D%20%22OVNKubernetes%22%20%5D%3B%20then%0A%20%20%20%20%23%20Configures%20NICs%20onto%20OVS%20bridge%20%22br-ex%22%0A%20%20%20%20%23%20Configuration%20is%20either%20auto-detected%20or%20provided%20through%20a%20config%20file%20written%20already%20in%20Network%20Manager%0A%20%20%20%20%23%20key%20files%20under%20%2Fetc%2FNetworkManager%2Fsystem-connections%2F%0A%20%20%20%20%23%20Managing%20key%20files%20is%20outside%20of%20the%20scope%20of%20this%20script%0A%0A%20%20%20%20%23%20if%20the%20interface%20is%20of%20type%20vmxnet3%20add%20multicast%20capability%20for%20that%20driver%0A%20%20%20%20%23%20History%3A%20BZ%3A1854355%0A%20%20%20%20function%20configure_driver_options%20%7B%0A%20%20%20%20%20%20intf%3D%241%0A%20%20%20%20%20%20if%20%5B%20!%20-f%20%22%2Fsys%2Fclass%2Fnet%2F%24%7Bintf%7D%2Fdevice%2Fuevent%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22Device%20file%20doesn't%20exist%2C%20skipping%20setting%20multicast%20mode%22%0A%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20driver%3D%24(cat%20%22%2Fsys%2Fclass%2Fnet%2F%24%7Bintf%7D%2Fdevice%2Fuevent%22%20%7C%20grep%20DRIVER%20%7C%20awk%20-F%20%22%3D%22%20'%7Bprint%20%242%7D')%0A%20%20%20%20%20%20%20%20echo%20%22Driver%20name%20is%22%20%24driver%0A%20%20%20%20%20%20%20%20if%20%5B%20%22%24driver%22%20%3D%20%22vmxnet3%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20ip%20link%20set%20dev%20%22%24%7Bintf%7D%22%20allmulticast%20on%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20fi%0A%20%20%20%20%7D%0A%0A%20%20%20%20ovnk_config_dir%3D'%2Fetc%2Fovnk'%0A%20%20%20%20ovnk_var_dir%3D'%2Fvar%2Flib%2Fovnk'%0A%20%20%20%20extra_bridge_file%3D%22%24%7Bovnk_config_dir%7D%2Fextra_bridge%22%0A%20%20%20%20iface_default_hint_file%3D%22%24%7Bovnk_var_dir%7D%2Fiface_default_hint%22%0A%20%20%20%20ip_hint_file%3D%22%2Frun%2Fnodeip-configuration%2Fprimary-ip%22%0A%20%20%20%20%23%20explicitly%20specify%20which%20interface%20should%20be%20used%20with%20the%20default%20bridge%0A%20%20%20%20default_bridge_file%3D%22%24%7Bovnk_config_dir%7D%2Fdefault_bridge%22%0A%0A%20%20%20%20%23%20make%20sure%20to%20create%20ovnk_config_dir%20if%20it%20does%20not%20exist%2C%20yet%0A%20%20%20%20mkdir%20-p%20%22%24%7Bovnk_config_dir%7D%22%0A%20%20%20%20%23%20make%20sure%20to%20create%20ovnk_var_dir%20if%20it%20does%20not%20exist%2C%20yet%0A%20%20%20%20mkdir%20-p%20%22%24%7Bovnk_var_dir%7D%22%0A%0A%20%20%20%20%23%20For%20upgrade%20scenarios%2C%20make%20sure%20that%20we%20stabilize%20what%20we%20already%20configured%0A%20%20%20%20%23%20before.%20If%20we%20do%20not%20have%20a%20valid%20interface%20hint%2C%20find%20the%20physical%20interface%0A%20%20%20%20%23%20that's%20attached%20to%20ovs-if-phys0.%0A%20%20%20%20%23%20If%20we%20find%20such%20an%20interface%2C%20write%20it%20to%20the%20hint%20file.%0A%20%20%20%20iface_default_hint%3D%24(get_iface_default_hint%20%22%24%7Biface_default_hint_file%7D%22)%0A%20%20%20%20if%20%5B%20%22%24%7Biface_default_hint%7D%22%20%3D%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20current_interface%3D%24(get_bridge_physical_interface%20ovs-if-phys0)%0A%20%20%20%20%20%20if%20%5B%20%22%24%7Bcurrent_interface%7D%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20write_iface_default_hint%20%22%24%7Biface_default_hint_file%7D%22%20%22%24%7Bcurrent_interface%7D%22%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20delete%20iface_default_hint_file%20if%20it%20has%20the%20same%20content%20as%20extra_bridge_file%0A%20%20%20%20%23%20in%20that%20case%2C%20we%20must%20also%20force%20a%20reconfiguration%20of%20our%20network%20interfaces%0A%20%20%20%20%23%20to%20make%20sure%20that%20we%20reconcile%20this%20conflict%0A%20%20%20%20if%20%5B%20-f%20%22%24%7Biface_default_hint_file%7D%22%20%5D%20%26%26%0A%20%20%20%20%20%20%5B%20-f%20%22%24%7Bextra_bridge_file%7D%22%20%5D%20%26%26%0A%20%20%20%20%20%20%5B%20%22%24(cat%20%22%24%7Biface_default_hint_file%7D%22)%22%20%3D%3D%20%22%24(cat%20%22%24%7Bextra_bridge_file%7D%22)%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22%24%7Biface_default_hint_file%7D%20and%20%24%7Bextra_bridge_file%7D%20share%20the%20same%20content%22%0A%20%20%20%20%20%20echo%20%22Deleting%20file%20%24%7Biface_default_hint_file%7D%20to%20choose%20a%20different%20interface%22%0A%20%20%20%20%20%20rm%20-f%20%22%24%7Biface_default_hint_file%7D%22%0A%20%20%20%20%20%20rm%20-f%20%2Frun%2Fconfigure-ovs-boot-done%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20on%20every%20boot%20we%20rollback%20and%20generate%20the%20configuration%20again%2C%20to%20take%0A%20%20%20%20%23%20in%20any%20changes%20that%20have%20possibly%20been%20applied%20in%20the%20standard%0A%20%20%20%20%23%20configuration%20sources%0A%20%20%20%20if%20%5B%20!%20-f%20%2Frun%2Fconfigure-ovs-boot-done%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22Running%20on%20boot%2C%20restoring%20previous%20configuration%20before%20proceeding...%22%0A%20%20%20%20%20%20rollback_nm%0A%20%20%20%20%20%20print_state%0A%20%20%20%20fi%0A%20%20%20%20touch%20%2Frun%2Fconfigure-ovs-boot-done%0A%0A%20%20%20%20iface%3D%24(get_default_bridge_interface%20%22%24%7Biface_default_hint_file%7D%22%20%22%24%7Bextra_bridge_file%7D%22%20%22%24%7Bip_hint_file%7D%22%20%22%24%7Bdefault_bridge_file%7D%22)%0A%0A%20%20%20%20if%20%5B%20%22%24iface%22%20!%3D%20%22br-ex%22%20%5D%3B%20then%0A%20%20%20%20%20%20%23%20Specified%20interface%20is%20not%20br-ex.%0A%20%20%20%20%20%20%23%20Some%20deployments%20use%20a%20temporary%20solution%20where%20br-ex%20is%20moved%20out%20from%20the%20default%20gateway%20interface%0A%20%20%20%20%20%20%23%20and%20bound%20to%20a%20different%20nic%20(https%3A%2F%2Fgithub.com%2Ftrozet%2Fopenshift-ovn-migration).%0A%20%20%20%20%20%20%23%20This%20is%20now%20supported%20through%20an%20extra%20bridge%20if%20requested.%20If%20that%20is%20the%20case%2C%20we%20rollback.%0A%20%20%20%20%20%20%23%20We%20also%20rollback%20if%20it%20looks%20like%20we%20need%20to%20configure%20things%2C%20just%20in%20case%20there%20are%20any%20leftovers%0A%20%20%20%20%20%20%23%20from%20previous%20attempts.%0A%20%20%20%20%20%20if%20%5B%20-f%20%22%24extra_bridge_file%22%20%5D%20%7C%7C%20%5B%20-z%20%22%24(nmcli%20connection%20show%20--active%20br-ex%202%3E%20%2Fdev%2Fnull)%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22Bridge%20br-ex%20is%20not%20active%2C%20restoring%20previous%20configuration%20before%20proceeding...%22%0A%20%20%20%20%20%20%20%20rollback_nm%0A%20%20%20%20%20%20%20%20print_state%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20convert_to_bridge%20%22%24iface%22%20%22br-ex%22%20%22phys0%22%20%22%24%7BBRIDGE_METRIC%7D%22%0A%0A%20%20%20%20%23%20Check%20if%20we%20need%20to%20configure%20the%20second%20bridge%0A%20%20%20%20if%20%5B%20-f%20%22%24extra_bridge_file%22%20%5D%20%26%26%20(!%20nmcli%20connection%20show%20br-ex1%20%26%3E%20%2Fdev%2Fnull%20%7C%7C%20!%20nmcli%20connection%20show%20ovs-if-phys1%20%26%3E%20%2Fdev%2Fnull)%3B%20then%0A%20%20%20%20%20%20interface%3D%24(head%20-n%201%20%24extra_bridge_file)%0A%20%20%20%20%20%20convert_to_bridge%20%22%24interface%22%20%22br-ex1%22%20%22phys1%22%20%22%24%7BBRIDGE1_METRIC%7D%22%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Check%20if%20we%20need%20to%20remove%20the%20second%20bridge%0A%20%20%20%20if%20%5B%20!%20-f%20%22%24extra_bridge_file%22%20%5D%20%26%26%20(nmcli%20connection%20show%20br-ex1%20%26%3E%20%2Fdev%2Fnull%20%7C%7C%20nmcli%20connection%20show%20ovs-if-phys1%20%26%3E%20%2Fdev%2Fnull)%3B%20then%0A%20%20%20%20%20%20remove_ovn_bridges%20br-ex1%20phys1%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Remove%20bridges%20created%20by%20openshift-sdn%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-br%20br0%0A%0A%20%20%20%20%23%20Make%20sure%20everything%20is%20activated.%20Do%20it%20in%20a%20specific%20order%3A%0A%20%20%20%20%23%20-%20activate%20br-ex%20first%2C%20due%20to%20autoconnect-slaves%20this%20will%20also%0A%20%20%20%20%23%20%20%20activate%20ovs-port-br-ex%2C%20ovs-port-phys0%20and%20ovs-if-phys0.%20It%20is%0A%20%20%20%20%23%20%20%20important%20that%20ovs-if-phys0%20activates%20with%20br-ex%20to%20avoid%20the%0A%20%20%20%20%23%20%20%20ovs-if-phys0%20profile%20being%20overridden%20with%20a%20profile%20generated%20from%0A%20%20%20%20%23%20%20%20kargs.%20The%20activation%20of%20ovs-if-phys0%2C%20if%20a%20bond%2C%20might%20cause%20the%0A%20%20%20%20%23%20%20%20slaves%20to%20re-activate%2C%20but%20it%20should%20be%20with%20our%20profiles%20since%20they%0A%20%20%20%20%23%20%20%20have%20higher%20priority%0A%20%20%20%20%23%20-%20make%20sure%20that%20ovs-if-phys0%20and%20its%20slaves%2C%20if%20any%2C%20are%20activated.%0A%20%20%20%20%23%20-%20finally%20activate%20ovs-if-br-ex%20which%20holds%20the%20IP%20configuration.%0A%20%20%20%20connections%3D(br-ex%20ovs-if-phys0)%0A%20%20%20%20if%20%5B%20-f%20%22%24extra_bridge_file%22%20%5D%3B%20then%0A%20%20%20%20%20%20connections%2B%3D(br-ex1%20ovs-if-phys1)%0A%20%20%20%20fi%0A%20%20%20%20while%20IFS%3D%20read%20-r%20connection%3B%20do%0A%20%20%20%20%20%20if%20%5B%5B%20%24connection%20%3D%3D%20*%22%24MANAGED_NM_CONN_SUFFIX%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20connections%2B%3D(%22%24connection%22)%0A%20%20%20%20%20%20fi%0A%20%20%20%20done%20%3C%20%3C(nmcli%20-g%20NAME%20c)%0A%20%20%20%20connections%2B%3D(ovs-if-br-ex)%0A%20%20%20%20if%20%5B%20-f%20%22%24extra_bridge_file%22%20%5D%3B%20then%0A%20%20%20%20%20%20connections%2B%3D(ovs-if-br-ex1)%0A%20%20%20%20fi%0A%20%20%20%20activate_nm_connections%20%22%24%7Bconnections%5B%40%5D%7D%22%0A%20%20%20%20try_to_bind_ipv6_address%0A%20%20%20%20set_nm_conn_files%0A%20%20elif%20%5B%20%22%241%22%20%3D%3D%20%22OpenShiftSDN%22%20%5D%3B%20then%0A%20%20%20%20%23%20Revert%20changes%20made%20by%20%2Fusr%2Flocal%2Fbin%2Fconfigure-ovs.sh%20during%20SDN%20migration.%0A%20%20%20%20rollback_nm%0A%20%20%20%20%0A%20%20%20%20%23%20Remove%20bridges%20created%20by%20ovn-kubernetes%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-br%20br-int%20--%20--if-exists%20del-br%20br-local%0A%20%20fi%0A%7D%0A%0A%23%20Retry%20configure_ovs%20until%20it%20succeeds.%0A%23%20By%20default%2C%20retry%20every%2015%20minutes%20to%20give%20enough%20time%20to%20gather%0A%23%20troubleshooting%20information%20in%20between.%20Note%20that%20configure_ovs%20has%20other%0A%23%20internal%20retry%20mechanisms.%20This%20retry%20is%20intended%20to%20give%20some%0A%23%20self-healing%20capabilities%20to%20temporary%20but%20not%20necessarily%20short-lived%0A%23%20infrastructure%20problems.%0ARETRY%3D%22%24%7BRETRY-15m%7D%22%0Awhile%20true%3B%20do%0A%0A%20%20%23%20Disable%20retries%20if%20termination%20signal%20is%20received.%20Note%20that%20systemd%0A%20%20%23%20sends%20the%20signals%20to%20all%20processes%20in%20the%20group%20by%20default%20so%20we%20expect%0A%20%20%23%20configure_ovs%20to%20get%20its%20own%20signals.%0A%20%20trap%20'echo%20%22WARNING%3A%20termination%20requested%2C%20disabling%20retries%22%3B%20RETRY%3D%22%22'%20INT%20TERM%0A%20%20%0A%20%20%23%20Run%20configure_ovs%20in%20a%20sub-shell.%20%0A%20%20(%20configure_ovs%20%22%24%40%22%20)%0A%20%20e%3D%24%3F%0A%0A%20%20%23%20Handle%20signals%20while%20we%20sleep%0A%20%20trap%20'handle_termination'%20INT%20TERM%0A%20%20%0A%20%20%23%20Exit%20if%20succesful%20and%20not%20configured%20to%20retry%0A%20%20%5B%20%22%24e%22%20-eq%200%20%5D%20%7C%7C%20%5B%20-z%20%22%24RETRY%22%20%5D%20%26%26%20exit%20%22%24e%22%0A%20%20%0A%20%20echo%20%22configure-ovs%20failed%2C%20will%20retry%20after%20%24RETRY%22%0A%20%20%23%20flag%20that%20a%20retry%20has%20happened%0A%20%20touch%20%2Ftmp%2Fconfigure-ovs-retry%0A%20%20sleep%20%22%24RETRY%22%0A%0Adone%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/configure-ovs.sh
        - contents:
            source: data:,%23%20This%20file%20is%20generated%20by%20the%20Machine%20Config%20Operator's%20containerruntimeconfig%20controller.%0A%23%0A%23%20storage.conf%20is%20the%20configuration%20file%20for%20all%20tools%0A%23%20that%20share%20the%20containers%2Fstorage%20libraries%0A%23%20See%20man%205%20containers-storage.conf%20for%20more%20information%0A%23%20The%20%22container%20storage%22%20table%20contains%20all%20of%20the%20server%20options.%0A%5Bstorage%5D%0A%0A%23%20Default%20storage%20driver%2C%20must%20be%20set%20for%20proper%20operation.%0Adriver%20%3D%20%22overlay%22%0A%0A%23%20Temporary%20storage%20location%0Arunroot%20%3D%20%22%2Frun%2Fcontainers%2Fstorage%22%0A%0A%23%20Primary%20Read%2FWrite%20location%20of%20container%20storage%0Agraphroot%20%3D%20%22%2Fvar%2Flib%2Fcontainers%2Fstorage%22%0A%0A%5Bstorage.options%5D%0A%23%20Storage%20options%20to%20be%20passed%20to%20underlying%20storage%20drivers%0A%0A%23%20AdditionalImageStores%20is%20used%20to%20pass%20paths%20to%20additional%20Read%2FOnly%20image%20stores%0A%23%20Must%20be%20comma%20separated%20list.%0Aadditionalimagestores%20%3D%20%5B%0A%5D%0A%0A%23%20Remap-UIDs%2FGIDs%20is%20the%20mapping%20from%20UIDs%2FGIDs%20as%20they%20should%20appear%20inside%20of%0A%23%20a%20container%2C%20to%20UIDs%2FGIDs%20as%20they%20should%20appear%20outside%20of%20the%20container%2C%20and%0A%23%20the%20length%20of%20the%20range%20of%20UIDs%2FGIDs.%20%20Additional%20mapped%20sets%20can%20be%20listed%0A%23%20and%20will%20be%20heeded%20by%20libraries%2C%20but%20there%20are%20limits%20to%20the%20number%20of%0A%23%20mappings%20which%20the%20kernel%20will%20allow%20when%20you%20later%20attempt%20to%20run%20a%0A%23%20container.%0A%23%0A%23%20remap-uids%20%3D%200%3A1668442479%3A65536%0A%23%20remap-gids%20%3D%200%3A1668442479%3A65536%0A%0A%23%20Remap-User%2FGroup%20is%20a%20name%20which%20can%20be%20used%20to%20look%20up%20one%20or%20more%20UID%2FGID%0A%23%20ranges%20in%20the%20%2Fetc%2Fsubuid%20or%20%2Fetc%2Fsubgid%20file.%20%20Mappings%20are%20set%20up%20starting%0A%23%20with%20an%20in-container%20ID%20of%200%20and%20the%20a%20host-level%20ID%20taken%20from%20the%20lowest%0A%23%20range%20that%20matches%20the%20specified%20name%2C%20and%20using%20the%20length%20of%20that%20range.%0A%23%20Additional%20ranges%20are%20then%20assigned%2C%20using%20the%20ranges%20which%20specify%20the%0A%23%20lowest%20host-level%20IDs%20first%2C%20to%20the%20lowest%20not-yet-mapped%20container-level%20ID%2C%0A%23%20until%20all%20of%20the%20entries%20have%20been%20used%20for%20maps.%20This%20setting%20overrides%20the%0A%23%20Remap-UIDs%2FGIDs%20setting.%0A%23%0A%23%20remap-user%20%3D%20%22storage%22%0A%23%20remap-group%20%3D%20%22storage%22%0A%0A%5Bstorage.options.pull_options%5D%0A%23%20Options%20controlling%20how%20storage%20is%20populated%20when%20pulling%20images.%0A%0A%23%20Enable%20the%20%22zstd%3Achunked%22%20feature%2C%20which%20allows%20partial%20pulls%2C%20reusing%0A%23%20content%20that%20already%20exists%20on%20the%20system.%20This%20is%20disabled%20by%20default%2C%0A%23%20and%20must%20be%20explicitly%20enabled%20to%20be%20used.%20For%20more%20on%20zstd%3Achunked%2C%20see%0A%23%20https%3A%2F%2Fgithub.com%2Fcontainers%2Fstorage%2Fblob%2Fmain%2Fdocs%2Fcontainers-storage-zstd-chunked.md%0Aenable_partial_images%20%3D%20%22false%22%0A%0A%23%20Tells%20containers%2Fstorage%20to%20use%20hard%20links%20rather%20then%20create%20new%20files%20in%0A%23%20the%20image%2C%20if%20an%20identical%20file%20already%20existed%20in%20storage.%0Ause_hard_links%20%3D%20%22false%22%0A%0A%23%20Path%20to%20an%20ostree%20repository%20that%20might%20have%0A%23%20previously%20pulled%20content%20which%20can%20be%20used%20when%20attempting%20to%20avoid%0A%23%20pulling%20content%20from%20the%20container%20registry.%0Aostree_repos%20%3D%20%22%22%0A%0A%5Bstorage.options.overlay%5D%0A%23%20Storage%20Options%20for%20overlay%0A%0A%23%20Do%20not%20create%20a%20PRIVATE%20bind%20mount%20on%20the%20home%20directory.%0Askip_mount_home%20%3D%20%22true%22%0A%0A%23%20Size%20is%20used%20to%20set%20a%20maximum%20size%20of%20the%20container%20image.%20%20Only%20supported%20by%0A%23%20certain%20container%20storage%20drivers.%0Asize%20%3D%20%22%22%0A
          mode: 420
          overwrite: true
          path: /etc/containers/storage.conf
        - contents:
            source: data:,.%20%7B%0A%20%20%20%20errors%0A%20%20%20%20bufsize%20512%0A%20%20%20%20health%20%3A18080%0A%20%20%20%20forward%20.%20%7B%7B-%20range%20%24upstream%20%3A%3D%20.DNSUpstreams%7D%7D%20%7B%7B%24upstream%7D%7D%7B%7B-%20end%7D%7D%20%7B%0A%20%20%20%20%20%20%20%20policy%20sequential%0A%20%20%20%20%7D%0A%20%20%20%20cache%2030%0A%20%20%20%20reload%0A%20%20%20%20template%20IN%20%7B%7B%20.Cluster.IngressVIPRecordType%20%7D%7D%20comp-poc-rh01.rhpoc.int%20%7B%0A%20%20%20%20%20%20%20%20match%20.*%5B.%5Dapps.comp-poc-rh01.rhpoc.int%0A%20%20%20%20%20%20%20%20answer%20%22%7B%7B%22%7B%7B%20.Name%20%7D%7D%22%7D%7D%2060%20in%20%7B%7B%22%7B%7B%20.Type%20%7D%7D%22%7D%7D%2010.100.0.51%22%0A%20%20%20%20%20%20%20%20fallthrough%0A%20%20%20%20%7D%0A%20%20%20%20template%20IN%20%7B%7B%20.Cluster.IngressVIPEmptyType%20%7D%7D%20comp-poc-rh01.rhpoc.int%20%7B%0A%20%20%20%20%20%20%20%20match%20.*%5B.%5Dapps.comp-poc-rh01.rhpoc.int%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20fallthrough%0A%20%20%20%20%7D%0A%20%20%20%20template%20IN%20%7B%7B%20.Cluster.APIVIPRecordType%20%7D%7D%20comp-poc-rh01.rhpoc.int%20%7B%0A%20%20%20%20%20%20%20%20match%20%5Eapi.comp-poc-rh01.rhpoc.int%0A%20%20%20%20%20%20%20%20answer%20%22%7B%7B%22%7B%7B%20.Name%20%7D%7D%22%7D%7D%2060%20in%20%7B%7B%22%7B%7B%20.Type%20%7D%7D%22%7D%7D%2010.100.0.50%22%0A%20%20%20%20%20%20%20%20fallthrough%0A%20%20%20%20%7D%0A%20%20%20%20template%20IN%20%7B%7B%20.Cluster.APIVIPEmptyType%20%7D%7D%20comp-poc-rh01.rhpoc.int%20%7B%0A%20%20%20%20%20%20%20%20match%20%5Eapi.comp-poc-rh01.rhpoc.int%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20fallthrough%0A%20%20%20%20%7D%0A%20%20%20%20template%20IN%20%7B%7B%20.Cluster.APIVIPRecordType%20%7D%7D%20comp-poc-rh01.rhpoc.int%20%7B%0A%20%20%20%20%20%20%20%20match%20%5Eapi-int.comp-poc-rh01.rhpoc.int%0A%20%20%20%20%20%20%20%20answer%20%22%7B%7B%22%7B%7B%20.Name%20%7D%7D%22%7D%7D%2060%20in%20%7B%7B%22%7B%7B%20.Type%20%7D%7D%22%7D%7D%2010.100.0.50%22%0A%20%20%20%20%20%20%20%20fallthrough%0A%20%20%20%20%7D%0A%20%20%20%20template%20IN%20%7B%7B%20.Cluster.APIVIPEmptyType%20%7D%7D%20comp-poc-rh01.rhpoc.int%20%7B%0A%20%20%20%20%20%20%20%20match%20%5Eapi-int.comp-poc-rh01.rhpoc.int%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20fallthrough%0A%20%20%20%20%7D%0A%20%20%20%20hosts%20%7B%0A%20%20%20%20%20%20%20%20%7B%7B-%20range%20.Cluster.NodeAddresses%20%7D%7D%0A%20%20%20%20%20%20%20%20%7B%7B%20.Address%20%7D%7D%20%7B%7B%20.Name%20%7D%7D%20%7B%7B%20.Name%20%7D%7D.%7B%7B%20%24.Cluster.Name%20%7D%7D.%7B%7B%20%24.Cluster.Domain%20%7D%7D%0A%20%20%20%20%20%20%20%20%7B%7B-%20end%20%7D%7D%0A%20%20%20%20%20%20%20%20fallthrough%0A%20%20%20%20%7D%0A%7D%0A
          mode: 420
          overwrite: true
          path: /etc/kubernetes/static-pod-resources/coredns/Corefile.tmpl
        - contents:
            source: data:,kind%3A%20Pod%0AapiVersion%3A%20v1%0Ametadata%3A%0A%20%20name%3A%20coredns%0A%20%20namespace%3A%20openshift-kni-infra%0A%20%20creationTimestamp%3A%0A%20%20deletionGracePeriodSeconds%3A%2065%0A%20%20labels%3A%0A%20%20%20%20app%3A%20kni-infra-coredns%0A%20%20annotations%3A%0A%20%20%20%20target.workload.openshift.io%2Fmanagement%3A%20'%7B%22effect%22%3A%20%22PreferredDuringScheduling%22%7D'%0A%20%20%20%20openshift.io%2Frequired-scc%3A%20privileged%0Aspec%3A%0A%20%20volumes%3A%0A%20%20-%20name%3A%20resource-dir%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fetc%2Fkubernetes%2Fstatic-pod-resources%2Fcoredns%22%0A%20%20-%20name%3A%20kubeconfig%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20-%20name%3A%20conf-dir%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fetc%2Fcoredns%22%0A%20%20-%20name%3A%20nm-resolv%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fvar%2Frun%2FNetworkManager%22%0A%20%20-%20name%3A%20nodeip-configuration%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Frun%2Fnodeip-configuration%22%0A%20%20initContainers%3A%0A%20%20-%20name%3A%20render-config-coredns%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A93e7b8c870261726d44bddc7ba0a702d3720d1838141dac837fb8c3be7c6e1a1%0A%20%20%20%20command%3A%0A%20%20%20%20-%20runtimecfg%0A%20%20%20%20-%20render%0A%20%20%20%20-%20%22%2Fvar%2Flib%2Fkubelet%2Fkubeconfig%22%0A%20%20%20%20-%20%22--api-vips%22%0A%20%20%20%20-%20%2210.100.0.50%22%0A%20%20%20%20-%20%22--ingress-vips%22%0A%20%20%20%20-%20%2210.100.0.51%22%0A%20%20%20%20-%20%22%2Fconfig%22%0A%20%20%20%20-%20%22--out-dir%22%0A%20%20%20%20-%20%22%2Fetc%2Fcoredns%22%0A%20%20%20%20-%20%22--resolvconf-path%22%0A%20%20%20%20-%20%22%2Fvar%2Frun%2FNetworkManager%2Fresolv.conf%22%0A%20%20%20%20resources%3A%20%7B%7D%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20kubeconfig%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20resource-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fconfig%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20conf-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fcoredns%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20nm-resolv%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Frun%2FNetworkManager%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20nodeip-configuration%0A%20%20%20%20%20%20mountPath%3A%20%22%2Frun%2Fnodeip-configuration%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20imagePullPolicy%3A%20IfNotPresent%0A%20%20containers%3A%0A%20%20-%20name%3A%20coredns%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A4f6294ed30ab476019aaaa77874157facc77413988f82ffc46f94d3a98d2e4f1%0A%20%20%20%20args%3A%0A%20%20%20%20-%20%22--conf%22%0A%20%20%20%20-%20%22%2Fetc%2Fcoredns%2FCorefile%22%0A%20%20%20%20resources%3A%0A%20%20%20%20%20%20requests%3A%0A%20%20%20%20%20%20%20%20cpu%3A%20100m%0A%20%20%20%20%20%20%20%20memory%3A%20200Mi%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20conf-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fcoredns%22%0A%20%20%20%20-%20name%3A%20nodeip-configuration%0A%20%20%20%20%20%20mountPath%3A%20%22%2Frun%2Fnodeip-configuration%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20livenessProbe%3A%0A%20%20%20%20%20%20httpGet%3A%0A%20%20%20%20%20%20%20%20path%3A%20%2Fhealth%0A%20%20%20%20%20%20%20%20port%3A%2018080%0A%20%20%20%20%20%20%20%20scheme%3A%20HTTP%0A%20%20%20%20%20%20initialDelaySeconds%3A%2060%0A%20%20%20%20%20%20timeoutSeconds%3A%205%0A%20%20%20%20%20%20successThreshold%3A%201%0A%20%20%20%20%20%20failureThreshold%3A%205%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20imagePullPolicy%3A%20IfNotPresent%0A%20%20-%20name%3A%20coredns-monitor%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A93e7b8c870261726d44bddc7ba0a702d3720d1838141dac837fb8c3be7c6e1a1%0A%20%20%20%20command%3A%0A%20%20%20%20-%20corednsmonitor%0A%20%20%20%20-%20%22%2Fvar%2Flib%2Fkubelet%2Fkubeconfig%22%0A%20%20%20%20-%20%22%2Fconfig%2FCorefile.tmpl%22%0A%20%20%20%20-%20%22%2Fetc%2Fcoredns%2FCorefile%22%0A%20%20%20%20-%20%22--api-vips%22%0A%20%20%20%20-%20%2210.100.0.50%22%0A%20%20%20%20-%20%22--ingress-vips%22%0A%20%20%20%20-%20%2210.100.0.51%22%0A%20%20%20%20resources%3A%0A%20%20%20%20%20%20requests%3A%0A%20%20%20%20%20%20%20%20cpu%3A%20100m%0A%20%20%20%20%20%20%20%20memory%3A%20200Mi%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20kubeconfig%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20resource-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fconfig%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20conf-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fcoredns%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20nm-resolv%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Frun%2FNetworkManager%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20nodeip-configuration%0A%20%20%20%20%20%20mountPath%3A%20%22%2Frun%2Fnodeip-configuration%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20imagePullPolicy%3A%20IfNotPresent%0A%20%20hostNetwork%3A%20true%0A%20%20tolerations%3A%0A%20%20-%20operator%3A%20Exists%0A%20%20priorityClassName%3A%20system-node-critical%0Astatus%3A%20%7B%7D%0A
          mode: 420
          overwrite: true
          path: /etc/kubernetes/manifests/coredns.yaml
        - contents:
            source: data:,Initial%20Creation%0A
          mode: 384
          overwrite: true
          path: /etc/docker/certs.d/.create
        - contents:
            source: data:,%23%20Proxy%20environment%20variables%20will%20be%20populated%20in%20this%20file.%20Properly%0A%23%20url%20encoded%20passwords%20with%20special%20characters%20will%20use%20'%25%3CHEX%3E%3CHEX%3E'.%0A%23%20Systemd%20requires%20that%20any%20%25%20used%20in%20a%20password%20be%20represented%20as%0A%23%20%25%25%20in%20a%20unit%20file%20since%20%25%20is%20a%20prefix%20for%20macros%3B%20this%20restriction%20does%20not%0A%23%20apply%20for%20environment%20files.%20Templates%20that%20need%20the%20proxy%20set%20should%20use%0A%23%20'EnvironmentFile%3D%2Fetc%2Fmco%2Fproxy.env'.%0A
          mode: 420
          overwrite: true
          path: /etc/mco/proxy.env
        - contents:
            source: data:,%5BManager%5D%0ADefaultEnvironment%3DGODEBUG%3Dx509ignoreCN%3D0%0A
          mode: 420
          overwrite: true
          path: /etc/systemd/system.conf.d/10-default-env-godebug.conf
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%23%20Workaround%3A%0A%23%20https%3A%2F%2Fissues.redhat.com%2Fbrowse%2FOCPBUGS-38779%0A%0Adriver%3D%24(nmcli%20-t%20-m%20tabular%20-f%20general.driver%20dev%20show%20%22%24%7BDEVICE_IFACE%7D%22)%0A%0Aif%20%5B%5B%20%22%242%22%20%3D%3D%20%22up%22%20%26%26%20%22%24%7Bdriver%7D%22%20%3D%3D%20%22idpf%22%20%5D%5D%3B%20then%0A%20%20ethtool%20-K%20%24%7BDEVICE_IFACE%7D%20tx-checksumming%20off%0Afi
          mode: 484
          overwrite: true
          path: /etc/NetworkManager/dispatcher.d/99-gcp-disable-idpf-tx-checksum-off
        - contents:
            source: data:,%23%20Force-load%20legacy%20iptables%20so%20it%20is%20usable%20from%20pod%20network%20namespaces%0Aip_tables%0A
          mode: 420
          overwrite: true
          path: /etc/modules-load.d/iptables.conf
        - contents:
            source: data:,global_defs%20%7B%0A%20%20%20%20enable_script_security%0A%20%20%20%20script_user%20root%0A%20%20%20%20max_auto_priority%20-1%0A%20%20%20%20vrrp_garp_master_refresh%2060%0A%7D%0A%0A%23%20TODO%3A%20Improve%20this%20check.%20The%20port%20is%20assumed%20to%20be%20alive.%0A%23%20Need%20to%20assess%20what%20is%20the%20ramification%20if%20the%20port%20is%20not%20there.%0Avrrp_script%20chk_ingress_ready%20%7B%0A%20%20%20%20script%20%22%2Fusr%2Fbin%2Ftimeout%200.9%20%2Fusr%2Fbin%2Fcurl%20-o%20%2Fdev%2Fnull%20-Lfs%20http%3A%2F%2Flocalhost%3A1936%2Fhealthz%2Fready%22%0A%20%20%20%20interval%201%0A%20%20%20%20weight%2010%0A%20%20%20%20rise%203%0A%20%20%20%20fall%202%0A%7D%0A%0Avrrp_script%20chk_ingress%20%7B%0A%20%20%20%20script%20%22%2Fusr%2Fbin%2Ftimeout%200.9%20%2Fusr%2Fbin%2Fcurl%20-o%20%2Fdev%2Fnull%20-Lfs%20http%3A%2F%2Flocalhost%3A1936%2Fhealthz%22%0A%20%20%20%20interval%201%0A%20%20%20%20rise%203%0A%20%20%20%20fall%202%0A%7D%0A%0Avrrp_script%20chk_default_ingress%20%7B%0A%20%20%20%20script%20%22%2Fusr%2Fbin%2Ftimeout%204.9%20%2Fetc%2Fkeepalived%2Fchk_default_ingress.sh%22%0A%20%20%20%20interval%205%0A%20%20%20%20weight%2050%0A%20%20%20%20rise%203%0A%20%20%20%20fall%202%0A%7D%0A%0A%7B%7B%20range%20%24i%2C%20%24config%20%3A%3D%20.Configs%20%7D%7D%0A%7B%7B%24nonVirtualIP%20%3A%3D%20.NonVirtualIP%7D%7D%0A%0A%7B%7B%24participateInIngressVRPP%20%3A%3D%20not%20.EnableUnicast%7D%7D%0A%7B%7B-%20if%20.EnableUnicast%7D%7D%0A%7B%7B-%20range%20.IngressConfig.Peers%7D%7D%0A%7B%7B-%20if%20eq%20%24nonVirtualIP%20.%7D%7D%0A%7B%7B%24participateInIngressVRPP%20%3D%20true%7D%7D%0A%7B%7B-%20end%7D%7D%0A%7B%7B-%20end%7D%7D%0A%7B%7B-%20end%7D%7D%0A%0A%7B%7Bif%20%24participateInIngressVRPP%7D%7D%0Avrrp_instance%20%7B%7B%20.Cluster.Name%20%7D%7D_INGRESS_%7B%7B%24i%7D%7D%20%7B%0A%20%20%20%20state%20BACKUP%0A%20%20%20%20interface%20%7B%7B%20.VRRPInterface%20%7D%7D%0A%20%20%20%20virtual_router_id%20%7B%7B%20.Cluster.IngressVirtualRouterID%20%7D%7D%0A%20%20%20%20priority%2020%0A%20%20%20%20advert_int%201%0A%20%20%20%20%7B%7Bif%20.EnableUnicast%7D%7D%0A%20%20%20%20unicast_src_ip%20%7B%7B.NonVirtualIP%7D%7D%0A%20%20%20%20unicast_peer%20%7B%0A%20%20%20%20%20%20%20%20%7B%7B-%20range%20.IngressConfig.Peers%7D%7D%0A%20%20%20%20%20%20%20%20%7B%7B-%20if%20ne%20%24nonVirtualIP%20.%7D%7D%0A%20%20%20%20%20%20%20%20%7B%7B.%7D%7D%0A%20%20%20%20%20%20%20%20%7B%7B-%20end%7D%7D%0A%20%20%20%20%20%20%20%20%7B%7B-%20end%7D%7D%0A%20%20%20%20%7D%0A%20%20%20%20%7B%7Bend%7D%7D%0A%20%20%20%20authentication%20%7B%0A%20%20%20%20%20%20%20%20auth_type%20PASS%0A%20%20%20%20%20%20%20%20auth_pass%20%7B%7B%20.Cluster.Name%20%7D%7D_ingress_vip%0A%20%20%20%20%7D%0A%20%20%20%20virtual_ipaddress%20%7B%0A%20%20%20%20%20%20%20%20%7B%7B%20.Cluster.IngressVIP%20%7D%7D%2F%7B%7B%20.Cluster.VIPNetmask%20%7D%7D%20label%20vip%0A%20%20%20%20%7D%0A%20%20%20%20track_script%20%7B%0A%20%20%20%20%20%20%20%20chk_ingress%0A%20%20%20%20%20%20%20%20chk_ingress_ready%0A%20%20%20%20%20%20%20%20chk_default_ingress%0A%20%20%20%20%7D%0A%7D%0A%7B%7B%20end%20%7D%7D%0A%7B%7B%20end%20%7D%7D%0A
          mode: 420
          overwrite: true
          path: /etc/kubernetes/static-pod-resources/keepalived/keepalived.conf.tmpl
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Achroot%20%2Fhost%20%2Fbin%2Fcrictl%20pods%20--namespace%20openshift-ingress%20--state%20Ready%20%7C%20grep%20-qE%20'router-default-%5B%5B%3Aalnum%3A%5D%5D%7B5%2C%7D-%5B%5B%3Aalnum%3A%5D%5D%7B5%2C%7D'%0A
          mode: 493
          overwrite: true
          path: /etc/kubernetes/static-pod-resources/keepalived/scripts/chk_default_ingress.sh.tmpl
        - contents:
            source: data:,kind%3A%20Pod%0AapiVersion%3A%20v1%0Ametadata%3A%0A%20%20name%3A%20keepalived%0A%20%20namespace%3A%20openshift-kni-infra%0A%20%20creationTimestamp%3A%0A%20%20deletionGracePeriodSeconds%3A%2065%0A%20%20labels%3A%0A%20%20%20%20app%3A%20kni-infra-vrrp%0A%20%20annotations%3A%0A%20%20%20%20target.workload.openshift.io%2Fmanagement%3A%20'%7B%22effect%22%3A%20%22PreferredDuringScheduling%22%7D'%0A%20%20%20%20openshift.io%2Frequired-scc%3A%20privileged%0Aspec%3A%0A%20%20volumes%3A%0A%20%20-%20name%3A%20resource-dir%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fetc%2Fkubernetes%2Fstatic-pod-resources%2Fkeepalived%22%0A%20%20-%20name%3A%20script-dir%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fetc%2Fkubernetes%2Fstatic-pod-resources%2Fkeepalived%2Fscripts%22%0A%20%20-%20name%3A%20kubeconfig%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fetc%2Fkubernetes%22%0A%20%20-%20name%3A%20kubeconfigvarlib%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20-%20name%3A%20conf-dir%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fetc%2Fkeepalived%22%0A%20%20-%20name%3A%20run-dir%0A%20%20%20%20empty-dir%3A%20%7B%7D%0A%20%20-%20name%3A%20chroot-host%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2F%22%0A%20%20-%20name%3A%20nodeip-configuration%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Frun%2Fnodeip-configuration%22%0A%20%20initContainers%3A%0A%20%20-%20name%3A%20render-config-keepalived%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A93e7b8c870261726d44bddc7ba0a702d3720d1838141dac837fb8c3be7c6e1a1%0A%20%20%20%20command%3A%0A%20%20%20%20-%20runtimecfg%0A%20%20%20%20-%20render%0A%20%20%20%20-%20%22%2Fetc%2Fkubernetes%2Fkubeconfig%22%0A%20%20%20%20-%20%22--api-vips%22%0A%20%20%20%20-%20%2210.100.0.50%22%0A%20%20%20%20-%20%22--ingress-vips%22%0A%20%20%20%20-%20%2210.100.0.51%22%0A%20%20%20%20-%20%22%2Fconfig%22%0A%20%20%20%20-%20%22--out-dir%22%0A%20%20%20%20-%20%22%2Fetc%2Fkeepalived%22%0A%20%20%20%20resources%3A%20%7B%7D%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20kubeconfig%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fkubernetes%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20script-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fconfig%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20conf-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fkeepalived%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20nodeip-configuration%0A%20%20%20%20%20%20mountPath%3A%20%22%2Frun%2Fnodeip-configuration%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20imagePullPolicy%3A%20IfNotPresent%0A%20%20containers%3A%0A%20%20-%20name%3A%20keepalived%0A%20%20%20%20securityContext%3A%0A%20%20%20%20%20%20capabilities%3A%0A%20%20%20%20%20%20%20%20add%3A%20%5B%22NET_ADMIN%22%2C%20%22NET_RAW%22%2C%20%22SYS_CHROOT%22%5D%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A3b0561a80561d95854d5f364f8cd6c3458d27cfb798bf93e09ffcfab97609216%0A%20%20%20%20env%3A%0A%20%20%20%20%20%20-%20name%3A%20NSS_SDB_USE_CACHE%0A%20%20%20%20%20%20%20%20value%3A%20%22no%22%0A%20%20%20%20command%3A%0A%20%20%20%20-%20%2Fbin%2Fbash%0A%20%20%20%20-%20-c%0A%20%20%20%20-%20%7C%0A%20%20%20%20%20%20%23%2Fbin%2Fbash%0A%20%20%20%20%20%20sigterm_handler()%0A%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20if%20pid%3D%24(pgrep%20-o%20keepalived)%3B%20then%0A%20%20%20%20%20%20%20%20%20%20kill%20-s%20SIGTERM%20%22%24pid%22%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%7D%0A%0A%20%20%20%20%20%20reload_keepalived()%0A%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20if%20pid%3D%24(pgrep%20-o%20keepalived)%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20kill%20-s%20SIGHUP%20%22%24pid%22%0A%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20%2Fusr%2Fsbin%2Fkeepalived%20-f%20%2Fetc%2Fkeepalived%2Fkeepalived.conf%20--dont-fork%20--vrrp%20--log-detail%20--log-console%20%26%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%7D%0A%0A%20%20%20%20%20%20msg_handler()%0A%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20while%20read%20-r%20line%3B%20do%0A%20%20%20%20%20%20%20%20%20%20echo%20%22The%20client%20sent%3A%20%24line%22%20%3E%262%0A%20%20%20%20%20%20%20%20%20%20%23%20currently%20only%20'reload'%20msg%20is%20supported%0A%20%20%20%20%20%20%20%20%20%20if%20%5B%20%22%24line%22%20%3D%20reload%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20reload_keepalived%0A%20%20%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20done%0A%20%20%20%20%20%20%7D%0A%0A%20%20%20%20%20%20remove_vip()%0A%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20address%3D%241%0A%20%20%20%20%20%20%20%20interface%3D%24(ip%20-o%20a%20%7C%20awk%20%22%2F%5Cs%24%7Baddress%7D%5C%2F%2F%20%7Bprint%20%5C%242%7D%22)%0A%20%20%20%20%20%20%20%20cidr%3D%24(ip%20-o%20a%20%7C%20awk%20%22%2F%5Cs%24%7Baddress%7D%5C%2F%2F%20%7Bprint%20%5C%244%7D%22)%0A%20%20%20%20%20%20%20%20if%20%5B%20-n%20%22%24interface%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20ip%20a%20del%20%24cidr%20dev%20%24interface%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%7D%0A%0A%20%20%20%20%20%20set%20-ex%0A%20%20%20%20%20%20%23%20Ensure%20that%20we%20don't%20have%20stale%20VIPs%20configured%0A%20%20%20%20%20%20%23%20See%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1931505%0A%20%20%20%20%20%20remove_vip%20%2210.100.0.50%22%0A%20%20%20%20%20%20remove_vip%20%2210.100.0.51%22%0A%20%20%20%20%20%20declare%20-r%20keepalived_sock%3D%22%2Fvar%2Frun%2Fkeepalived%2Fkeepalived.sock%22%0A%20%20%20%20%20%20export%20-f%20msg_handler%0A%20%20%20%20%20%20export%20-f%20reload_keepalived%0A%20%20%20%20%20%20export%20-f%20sigterm_handler%0A%0A%20%20%20%20%20%20%23%20in%20remote%20worker%20case%20sleep%20forever%0A%20%20%20%20%20%20if%20%5B%20-f%20%22%2Frun%2Fnodeip-configuration%2Fremote-worker%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20sleep%20infinity%0A%20%20%20%20%20%20%20%20%20exit%200%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20trap%20sigterm_handler%20SIGTERM%0A%20%20%20%20%20%20if%20%5B%20-s%20%22%2Fetc%2Fkeepalived%2Fkeepalived.conf%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%2Fusr%2Fsbin%2Fkeepalived%20-f%20%2Fetc%2Fkeepalived%2Fkeepalived.conf%20--dont-fork%20--vrrp%20--log-detail%20--log-console%20%26%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20rm%20-f%20%22%24keepalived_sock%22%0A%20%20%20%20%20%20socat%20UNIX-LISTEN%3A%24%7Bkeepalived_sock%7D%2Cfork%20system%3A'bash%20-c%20msg_handler'%0A%20%20%20%20resources%3A%0A%20%20%20%20%20%20requests%3A%0A%20%20%20%20%20%20%20%20cpu%3A%20100m%0A%20%20%20%20%20%20%20%20memory%3A%20200Mi%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20conf-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fkeepalived%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20run-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Frun%2Fkeepalived%22%0A%20%20%20%20-%20name%3A%20chroot-host%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fhost%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20kubeconfigvarlib%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20nodeip-configuration%0A%20%20%20%20%20%20mountPath%3A%20%22%2Frun%2Fnodeip-configuration%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20livenessProbe%3A%0A%20%20%20%20%20%20exec%3A%0A%20%20%20%20%20%20%20%20command%3A%0A%20%20%20%20%20%20%20%20-%20%2Fbin%2Fbash%0A%20%20%20%20%20%20%20%20-%20-c%0A%20%20%20%20%20%20%20%20-%20%7C%0A%20%20%20%20%20%20%20%20%20%20%5B%20!%20-s%20%22%2Fetc%2Fkeepalived%2Fkeepalived.conf%22%20%5D%20%7C%7C%20(echo%20%22%22%20%3E%20%2Ftmp%2Fkeepalived.data%20%26%26%20kill%20-s%20SIGUSR1%20%22%24(pgrep%20-o%20keepalived)%22%20%26%26%20for%20i%20in%20%24(seq%205)%3B%20do%20grep%20-q%20%22VRRP%20Instance%22%20%2Ftmp%2Fkeepalived.data%20%26%26%20exit%200%20%7C%7C%20sleep%201%3B%20done%20%26%26%20exit%201)%0A%20%20%20%20%20%20initialDelaySeconds%3A%2020%0A%20%20%20%20%20%20timeoutSeconds%3A%205%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20imagePullPolicy%3A%20IfNotPresent%0A%20%20-%20name%3A%20keepalived-monitor%0A%20%20%20%20securityContext%3A%0A%20%20%20%20%20%20capabilities%3A%0A%20%20%20%20%20%20%20%20add%3A%20%5B%22NET_ADMIN%22%2C%20%22SYS_CHROOT%22%5D%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A93e7b8c870261726d44bddc7ba0a702d3720d1838141dac837fb8c3be7c6e1a1%0A%20%20%20%20env%3A%0A%20%20%20%20%20%20-%20name%3A%20ENABLE_UNICAST%0A%20%20%20%20%20%20%20%20value%3A%20%22yes%22%0A%20%20%20%20%20%20-%20name%3A%20IS_BOOTSTRAP%0A%20%20%20%20%20%20%20%20value%3A%20%22no%22%0A%20%20%20%20%20%20-%20name%3A%20POD_NAMESPACE%0A%20%20%20%20%20%20%20%20valueFrom%3A%0A%20%20%20%20%20%20%20%20%20%20fieldRef%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20fieldPath%3A%20metadata.namespace%0A%20%20%20%20command%3A%0A%20%20%20%20-%20%2Fbin%2Fbash%0A%20%20%20%20-%20-c%0A%20%20%20%20-%20%7C%0A%20%20%20%20%20%20%23%2Fbin%2Fbash%0A%20%20%20%20%20%20%23%20in%20remote%20worker%20case%20sleep%20forever%0A%20%20%20%20%20%20if%20%5B%20-f%20%22%2Frun%2Fnodeip-configuration%2Fremote-worker%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20sleep%20infinity%0A%20%20%20%20%20%20%20%20%20%20exit%200%0A%20%20%20%20%20%20fi%0A%20%20%20%20%20%20api_vips%3D10.100.0.50%0A%20%20%20%20%20%20ingress_vips%3D10.100.0.51%0A%20%20%20%20%20%20dynkeepalived%20%2Fvar%2Flib%2Fkubelet%2Fkubeconfig%20%2Fconfig%2Fkeepalived.conf.tmpl%20%2Fetc%2Fkeepalived%2Fkeepalived.conf%20--api-vips%20%22%24%7Bapi_vips%7D%22%20--ingress-vips%20%22%24%7Bingress_vips%7D%22%0A%20%20%20%20resources%3A%0A%20%20%20%20%20%20requests%3A%0A%20%20%20%20%20%20%20%20cpu%3A%20100m%0A%20%20%20%20%20%20%20%20memory%3A%20200Mi%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20resource-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fconfig%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20kubeconfigvarlib%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20conf-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fkeepalived%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20run-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Frun%2Fkeepalived%22%0A%20%20%20%20-%20name%3A%20chroot-host%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fhost%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20nodeip-configuration%0A%20%20%20%20%20%20mountPath%3A%20%22%2Frun%2Fnodeip-configuration%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20imagePullPolicy%3A%20IfNotPresent%0A%20%20hostNetwork%3A%20true%0A%20%20tolerations%3A%0A%20%20-%20operator%3A%20Exists%0A%20%20priorityClassName%3A%20system-node-critical%0Astatus%3A%20%7B%7D%0A
          mode: 420
          overwrite: true
          path: /etc/kubernetes/manifests/keepalived.yaml
        - contents:
            source: data:,NODE_SIZING_ENABLED%3Dfalse%0ASYSTEM_RESERVED_MEMORY%3D1Gi%0ASYSTEM_RESERVED_CPU%3D500m%0ASYSTEM_RESERVED_ES%3D1Gi
          mode: 420
          overwrite: true
          path: /etc/node-sizing-enabled.env
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-e%0ANODE_SIZES_ENV%3D%24%7BNODE_SIZES_ENV%3A-%2Fetc%2Fnode-sizing.env%7D%0AVERSION_1%3D1%0AVERSION_2%3D2%0ANODE_AUTO_SIZING_VERSION%3D%24%7BNODE_AUTO_SIZING_VERSION%3A-%24VERSION_2%7D%0ANODE_AUTO_SIZING_VERSION_FILE%3D%24%7BNODE_AUTO_SIZING_VERSION_FILE%3A-%2Fetc%2Fnode-sizing-version.json%7D%0Afunction%20dynamic_memory_sizing%20%7B%0A%20%20%20%20total_memory%3D%24(free%20-g%7Cawk%20'%2F%5EMem%3A%2F%7Bprint%20%242%7D')%0A%20%20%20%20%23%20total_memory%3D8%20test%20the%20recommended%20values%20by%20modifying%20this%20value%0A%20%20%20%20recommended_systemreserved_memory%3D0%0A%20%20%20%20if%20((%24total_memory%20%3C%3D%204))%3B%20then%20%23%2025%25%20of%20the%20first%204GB%20of%20memory%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24total_memory%200.25%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D0%0A%20%20%20%20else%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D1%0A%20%20%20%20%20%20%20%20total_memory%3D%24((total_memory-4))%0A%20%20%20%20fi%0A%20%20%20%20if%20((%24total_memory%20%3C%3D%204))%3B%20then%20%23%2020%25%20of%20the%20next%204GB%20of%20memory%20(up%20to%208GB)%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%20%24(echo%20%24total_memory%200.20%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D0%0A%20%20%20%20else%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%200.80%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D%24((total_memory-4))%0A%20%20%20%20fi%0A%20%20%20%20if%20((%24total_memory%20%3C%3D%208))%3B%20then%20%23%2010%25%20of%20the%20next%208GB%20of%20memory%20(up%20to%2016GB)%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%20%24(echo%20%24total_memory%200.10%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D0%0A%20%20%20%20else%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%200.80%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D%24((total_memory-8))%0A%20%20%20%20fi%0A%20%20%20%20if%20((%24total_memory%20%3C%3D%20112))%3B%20then%20%23%206%25%20of%20the%20next%20112GB%20of%20memory%20(up%20to%20128GB)%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%20%24(echo%20%24total_memory%200.06%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D0%0A%20%20%20%20else%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%206.72%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D%24((total_memory-112))%0A%20%20%20%20fi%0A%20%20%20%20if%20((%24total_memory%20%3E%3D%200))%3B%20then%20%23%202%25%20of%20any%20memory%20above%20128GB%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%20%24(echo%20%24total_memory%200.02%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20fi%0A%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%20%7C%20awk%20'%7Bprintf(%22%25d%5Cn%22%2C%241%20%2B%200.5)%7D')%20%23%20Round%20off%20so%20we%20avoid%20float%20conversions%0A%20%20%20%20echo%20%22SYSTEM_RESERVED_MEMORY%3D%24%7Brecommended_systemreserved_memory%7DGi%22%3E%3E%20%24%7BNODE_SIZES_ENV%7D%0A%7D%0Afunction%20dynamic_cpu_sizing%20%7B%0A%20%20%20%20total_cpu%3D%24(getconf%20_NPROCESSORS_ONLN)%0A%20%20%20%20if%20%5B%20%22%241%22%20-eq%20%22%24VERSION_1%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D0%0A%20%20%20%20%20%20%20%20if%20((%24total_cpu%20%3C%3D%201))%3B%20then%20%23%206%25%20of%20the%20first%20core%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24total_cpu%200.06%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D0%0A%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D0.06%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D%24((total_cpu-1))%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20if%20((%24total_cpu%20%3C%3D%201))%3B%20then%20%23%201%25%20of%20the%20next%20core%20(up%20to%202%20cores)%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24recommended_systemreserved_cpu%20%24(echo%20%24total_cpu%200.01%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D0%0A%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24recommended_systemreserved_cpu%200.01%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D%24((total_cpu-1))%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20if%20((%24total_cpu%20%3C%3D%202))%3B%20then%20%23%200.5%25%20of%20the%20next%202%20cores%20(up%20to%204%20cores)%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24recommended_systemreserved_cpu%20%24(echo%20%24total_cpu%200.005%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D0%0A%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24recommended_systemreserved_cpu%200.01%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D%24((total_cpu-2))%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20if%20((%24total_cpu%20%3E%3D%200))%3B%20then%20%23%200.25%25%20of%20any%20cores%20above%204%20cores%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24recommended_systemreserved_cpu%20%24(echo%20%24total_cpu%200.0025%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20else%0A%20%20%20%20%20%20%20%20%23%20Base%20allocation%20for%201%20CPU%20in%20fractions%20of%20a%20core%20(60%20millicores%20%3D%200.06%20CPU%20core)%0A%20%20%20%20%20%20%20%20base_allocation_fraction%3D0.06%0A%20%20%20%20%20%20%20%20%23%20Increment%20per%20additional%20CPU%20in%20fractions%20of%20a%20core%20(12%20millicores%20%3D%200.012%20CPU%20core)%0A%20%20%20%20%20%20%20%20increment_per_cpu_fraction%3D0.012%0A%20%20%20%20%20%20%20%20if%20((total_cpu%20%3E%201))%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Calculate%20the%20total%20system-reserved%20CPU%20in%20fractions%2C%20starting%20with%20the%20base%20allocation%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20and%20adding%20the%20incremental%20fraction%20for%20each%20additional%20CPU%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(awk%20-v%20base%3D%22%24base_allocation_fraction%22%20-v%20increment%3D%22%24increment_per_cpu_fraction%22%20-v%20cpus%3D%22%24total_cpu%22%20'BEGIN%20%7Bprintf%20%22%25.2f%5Cn%22%2C%20base%20%2B%20increment%20*%20(cpus%20-%201)%7D')%0A%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20For%20a%20single%20CPU%2C%20use%20the%20base%20allocation%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24base_allocation_fraction%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Enforce%20minimum%20threshold%20of%200.5%20CPU%0A%20%20%20%20recommended_systemreserved_cpu%3D%24(awk%20-v%20val%3D%22%24recommended_systemreserved_cpu%22%20'BEGIN%20%7Bif%20(val%20%3C%200.5)%20print%200.5%3B%20else%20print%20val%7D')%0A%0A%20%20%20%20echo%20%22SYSTEM_RESERVED_CPU%3D%24%7Brecommended_systemreserved_cpu%7D%22%3E%3E%20%24%7BNODE_SIZES_ENV%7D%0A%7D%0Afunction%20dynamic_ephemeral_sizing%20%7B%0A%20%20%20%20echo%20%22Not%20implemented%20yet%22%0A%7D%0Afunction%20dynamic_pid_sizing%20%7B%0A%20%20%20%20echo%20%22Not%20implemented%20yet%22%0A%7D%0Afunction%20set_memory%20%7B%0A%20%20%20%20SYSTEM_RESERVED_MEMORY%3D%241%0A%20%20%20%20if%20%5B%20-z%20%22%24%7BSYSTEM_RESERVED_MEMORY%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20SYSTEM_RESERVED_MEMORY%3D%221Gi%22%0A%20%20%20%20fi%0A%20%20%20%20echo%20%22SYSTEM_RESERVED_MEMORY%3D%24%7BSYSTEM_RESERVED_MEMORY%7D%22%20%3E%3E%20%24%7BNODE_SIZES_ENV%7D%0A%7D%0Afunction%20set_cpu%20%7B%0A%20%20%20%20SYSTEM_RESERVED_CPU%3D%241%0A%20%20%20%20if%20%5B%20-z%20%22%24%7BSYSTEM_RESERVED_CPU%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20SYSTEM_RESERVED_CPU%3D%22500m%22%0A%20%20%20%20fi%0A%20%20%20%20echo%20%22SYSTEM_RESERVED_CPU%3D%24%7BSYSTEM_RESERVED_CPU%7D%22%20%3E%3E%20%24%7BNODE_SIZES_ENV%7D%0A%7D%0Afunction%20set_es%20%7B%0A%20%20%20%20SYSTEM_RESERVED_ES%3D%241%0A%20%20%20%20if%20%5B%20-z%20%22%24%7BSYSTEM_RESERVED_ES%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20SYSTEM_RESERVED_ES%3D%221Gi%22%0A%20%20%20%20fi%0A%20%20%20%20echo%20%22SYSTEM_RESERVED_ES%3D%24%7BSYSTEM_RESERVED_ES%7D%22%20%3E%3E%20%24%7BNODE_SIZES_ENV%7D%0A%7D%0Afunction%20dynamic_node_sizing%20%7B%0A%20%20%20%20rm%20-f%20%24%7BNODE_SIZES_ENV%7D%0A%20%20%20%20dynamic_memory_sizing%0A%20%20%20%20dynamic_cpu_sizing%20%241%0A%20%20%20%20set_es%20%242%0A%20%20%20%20%23dynamic_ephemeral_sizing%0A%20%20%20%20%23dynamic_pid_sizing%0A%7D%0Afunction%20static_node_sizing%20%7B%0A%20%20%20%20rm%20-f%20%24%7BNODE_SIZES_ENV%7D%0A%20%20%20%20set_memory%20%241%0A%20%20%20%20set_cpu%20%242%0A%20%20%20%20set_es%20%243%0A%7D%0Afunction%20create_version_file%20%7B%0A%20%20%20%20echo%20%22%7B%5C%22version%5C%22%3A%20%241%7D%22%20%3E%20%242%0A%7D%0Aif%20!%20%5B%20-f%20%24NODE_AUTO_SIZING_VERSION_FILE%20%5D%3B%20then%0A%20%20%20%20create_version_file%20%24NODE_AUTO_SIZING_VERSION%20%24NODE_AUTO_SIZING_VERSION_FILE%0Afi%0Anew_version%3D%24(jq%20.version%20%24NODE_AUTO_SIZING_VERSION_FILE)%0Aif%20%5B%20%241%20%3D%3D%20%22true%22%20%5D%3B%20then%0A%20%20%20%20dynamic_node_sizing%20%24new_version%20%244%0Aelif%20%5B%20%241%20%3D%3D%20%22false%22%20%5D%3B%20then%0A%20%20%20%20static_node_sizing%20%242%20%243%20%244%0Aelse%0A%20%20%20%20echo%20%22Unrecognized%20command%20line%20option.%20Valid%20options%20are%20%5C%22true%5C%22%20or%20%5C%22false%5C%22%22%0Afi%0A
          mode: 493
          overwrite: true
          path: /usr/local/sbin/dynamic-system-reserved-calc.sh
        - contents:
            source: data:,%23%20Turning%20on%20Accounting%20helps%20track%20down%20performance%20issues.%0A%5BManager%5D%0ADefaultCPUAccounting%3Dyes%0ADefaultMemoryAccounting%3Dyes%0ADefaultBlockIOAccounting%3Dyes%0A
          mode: 420
          overwrite: true
          path: /etc/systemd/system.conf.d/kubelet-cgroups.conf
        - contents:
            source: data:,%5BService%5D%0AEnvironment%3D%22KUBELET_LOG_LEVEL%3D2%22%0A
          mode: 420
          overwrite: true
          path: /etc/systemd/system/kubelet.service.d/20-logging.conf
        - contents:
            source: data:,%23%20ignore%20known%20SDN-managed%20devices%0A%5Bdevice%5D%0Amatch-device%3Dinterface-name%3Abr-int%3Binterface-name%3Abr-local%3Binterface-name%3Abr-nexthop%3Binterface-name%3Aovn-k8s-*%3Binterface-name%3Ak8s-*%3Binterface-name%3Atun0%3Binterface-name%3Abr0%3Binterface-name%3Apatch-br-*%3Binterface-name%3Abr-ext%3Binterface-name%3Aext-vxlan%3Binterface-name%3Aext%3Binterface-name%3Aint%3Binterface-name%3Avxlan_sys_*%3Binterface-name%3Agenev_sys_*%3Bdriver%3Aveth%0Amanaged%3D0%0A
          mode: 420
          overwrite: true
          path: /etc/NetworkManager/conf.d/sdn.conf
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-eux%0A%0A%23%20Clean%20up%20old%20config%20on%20behalf%20of%20mtu-migration%0Aif%20!%20systemctl%20-q%20is-enabled%20mtu-migration%3B%20then%0A%20%20echo%20%22Cleaning%20up%20left%20over%20mtu%20migration%20configuration%22%0A%20%20rm%20-rf%20%2Fetc%2Fcno%2Fmtu-migration%0Afi%0A%0Aif%20%5B%20-e%20%2Fetc%2Fnmstate%2Fopenshift%2Fapplied%20%5D%3B%20then%0A%20%20echo%20%22Configuration%20already%20applied%2C%20exiting%22%0A%20%20exit%200%0Afi%0A%0Asrc_path%3D%22%2Fetc%2Fnmstate%2Fopenshift%22%0Adst_path%3D%22%2Fetc%2Fnmstate%22%0Ahostname%3D%24(hostname%20-s)%0Ahost_file%3D%22%24%7Bhostname%7D.yml%22%0Acluster_file%3D%22cluster.yml%22%0Aconfig_file%3D%22%22%0Aif%20%5B%20-s%20%22%24src_path%2F%24host_file%22%20%5D%3B%20then%0A%20%20config_file%3D%24host_file%0Aelif%20%5B%20-s%20%22%24src_path%2F%24cluster_file%22%20%5D%3B%20then%0A%20%20config_file%3D%24cluster_file%0Aelse%0A%20%20echo%20%22No%20configuration%20found%20at%20%24src_path%2F%24host_file%20or%20%24src_path%2F%24cluster_file%22%0A%20%20exit%200%0Afi%0A%0Aif%20%5B%20-e%20%22%24dst_path%2F%24config_file%22%20%5D%3B%20then%0A%20%20echo%20%22ERROR%3A%20File%20%24dst_path%2F%24config_file%20exists.%20Refusing%20to%20overwrite.%22%0A%20%20exit%201%0Afi%0A%0A%23%20Handle%20the%20case%20where%20we're%20migrating%20from%20configure-ovs%0Aovs-vsctl%20--timeout%3D30%20--if-exists%20del-br%20br-ex%0A%0A%23%20Handle%20the%20case%20where%20we're%20migrating%20from%20OpenShift%20SDN%0Aovs-vsctl%20--timeout%3D30%20--if-exists%20del-br%20br0%0A%0Acp%20%22%24src_path%2F%24config_file%22%20%2Fetc%2Fnmstate%0Atouch%20%2Fetc%2Fnmstate%2Fopenshift%2Fapplied%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/nmstate-configuration.sh
        - contents:
            source: data:,%5Bservice%5D%0Akeep_state_file_after_apply%20%3D%20true%0A
          mode: 420
          overwrite: true
          path: /etc/nmstate/nmstate.conf
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%23%20Set%20interface%20ofport_request%20to%20guarantee%20stable%20ofport%20numbers.%20This%20is%20important%20for%20flow%20matches.%0A%23%20Otherwise%2C%20another%20ofport%20number%20is%20assigned%20to%20the%20interface%20on%20every%20restart%20of%20NetworkManager.%0A%23%20This%20script%20will%20build%20an%20associative%20array%20INTERFACE_NAME-%3Eofport_request%20and%20will%20save%20it%20to%20file%20CONFIGURATION_FILE.%0A%23%20When%20an%20interface%20is%20brought%20up%2C%20this%20will%20reuse%20the%20value%20from%20the%20associative%20array%20if%20such%20a%20value%20exists.%0A%23%20Otherwise%2C%20this%20will%20try%20to%20use%20the%20current%20ofport%20value.%20If%20the%20ofport%20value%20is%20already%20reserved%2C%20then%0A%23%20this%20uses%20the%20lowest%20available%20numerical%20value%2C%20instead.%0Aset%20-eux%20-o%20pipefail%0Aif%20%5B%5B%20%22OVNKubernetes%22%20!%3D%20%22OVNKubernetes%22%20%5D%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0AINTERFACE_NAME%3D%241%0AOPERATION%3D%242%0A%0A%23%20Only%20execute%20this%20on%20pre-up%0Aif%20%5B%20%22%24%7BOPERATION%7D%22%20!%3D%20%22pre-up%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20interface's%20NM%20uuid%0AINTERFACE_CONNECTION_UUID%3D%24(nmcli%20-t%20-f%20device%2Ctype%2Cuuid%20conn%20%7C%20awk%20-F%20'%3A'%20'%7Bif(%241%3D%3D%22'%24%7BINTERFACE_NAME%7D'%22%20%26%26%20%242!~%2F%5Eovs*%2F)%20print%20%24NF%7D')%0Aif%20%5B%20%22%24%7BINTERFACE_CONNECTION_UUID%7D%22%20%3D%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20interface's%20slave-type.%20If%20this%20is%20not%20an%20ovs-port%2C%20then%20exit%0AINTERFACE_OVS_SLAVE_TYPE%3D%24(nmcli%20-t%20-f%20connection.slave-type%20conn%20show%20%22%24%7BINTERFACE_CONNECTION_UUID%7D%22%20%7C%20awk%20-F%20'%3A'%20'%7Bprint%20%24NF%7D')%0Aif%20%5B%20%22%24%7BINTERFACE_OVS_SLAVE_TYPE%7D%22%20!%3D%20%22ovs-port%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20This%20is%20not%20necessarily%20a%20UUID%20(can%20be%20a%20name%20in%20case%20of%20bonds)%20but%20this%20should%20be%20unique%0APORT%3D%24(nmcli%20-t%20-f%20connection.master%20conn%20show%20%22%24%7BINTERFACE_CONNECTION_UUID%7D%22%20%7C%20awk%20-F%20'%3A'%20'%7Bprint%20%24NF%7D')%0Aif%20%5B%20%22%24%7BPORT%7D%22%20%3D%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20interface's%20NM%20uuid%0APORT_CONNECTION_UUID%3D%24(nmcli%20-t%20-f%20device%2Ctype%2Cuuid%20conn%20%7C%20awk%20-F%20'%3A'%20'%7Bif(%20(%241%3D%3D%22'%24%7BPORT%7D'%22%20%7C%7C%20%243%3D%3D%22'%24%7BPORT%7D'%22)%20%26%26%20%242~%2F%5Eovs*%2F)%20print%20%24NF%7D')%0Aif%20%5B%20%22%24%7BPORT_CONNECTION_UUID%7D%22%20%3D%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20port's%20slave-type.%20If%20this%20is%20not%20an%20ovs-bridge%2C%20then%20exit%0APORT_OVS_SLAVE_TYPE%3D%24(nmcli%20-t%20-f%20connection.slave-type%20conn%20show%20%22%24%7BPORT_CONNECTION_UUID%7D%22%20%7C%20awk%20-F%20'%3A'%20'%7Bprint%20%24NF%7D')%0Aif%20%5B%20%22%24%7BPORT_OVS_SLAVE_TYPE%7D%22%20!%3D%20%22ovs-bridge%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20port's%20master.%20If%20it%20doesn't%20have%20any%2C%20assume%20it's%20not%20our%20bridge%0ABRIDGE_ID%3D%24(nmcli%20-t%20-f%20connection.master%20conn%20show%20%22%24%7BPORT_CONNECTION_UUID%7D%22%20%7C%20awk%20-F%20'%3A'%20'%7Bprint%20%24NF%7D')%0Aif%20%5B%20%22%24%7BBRIDGE_ID%7D%22%20%3D%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20bridge%20name%0ABRIDGE_NAME%3D%24(nmcli%20-t%20-f%20connection.interface-name%20conn%20show%20%22%24%7BBRIDGE_ID%7D%22%20%7C%20awk%20-F%20'%3A'%20'%7Bprint%20%24NF%7D')%0A%23%20Limit%20this%20to%20br-ex%20and%20br-ex1%20only.%20If%20one%20wanted%20to%20enable%20this%20for%20all%20OVS%20bridges%2C%0A%23%20the%20condition%20would%20be%3A%20if%20%5B%20%22%24BRIDGE_NAME%22%20%3D%3D%20%22%22%20%5D%3B%20then%0Aif%20%5B%20%22%24%7BBRIDGE_NAME%7D%22%20!%3D%20%22br-ex%22%20%5D%20%26%26%20%5B%20%22%24%7BBRIDGE_NAME%7D%22%20!%3D%20%22br-ex1%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Make%20sure%20that%20the%20interface%20is%20plugged%20into%20OVS%0A%23%20This%20should%20always%20be%20the%20case%20given%20that%20we%20are%20in%20pre-up%2C%20but%20exit%20gracefully%20in%20the%20odd%20case%20that%20it's%20not%0Aif%20!%20ovs-vsctl%20list%20interface%20%22%24%7BINTERFACE_NAME%7D%22%20%3E%2Fdev%2Fnull%202%3E%261%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0ACONFIGURATION_FILE%3D%22%2Frun%2Fofport_requests.%24%7BBRIDGE_NAME%7D%22%0A%0A%23%20Declare%20a%20new%20associative%20array.%20If%20CONFIGURATION_FILE%20exists%2C%20source%20entries%20from%20there%0Adeclare%20-A%20INTERFACES%0Aif%20%5B%20-f%20%22%24%7BCONFIGURATION_FILE%7D%22%20%5D%3B%20then%0A%20%20%20%20echo%20%22Sourcing%20configuration%20file%20'%24%7BCONFIGURATION_FILE%7D'%20with%20contents%3A%22%0A%20%20%20%20cat%20%22%24%7BCONFIGURATION_FILE%7D%22%0A%20%20%20%20source%20%22%24%7BCONFIGURATION_FILE%7D%22%0Afi%0A%0A%23%20get_interface_ofport_request%20will%20return%0A%23%20*%20either%3A%20the%20current%20ofport%20assignment%20for%20the%20port%20if%20no%20interface%20has%20claimed%20this%20ofport%20number%2C%20yet%0A%23%20*%20or%3A%20%20%20%20%20the%20lowest%20available%20free%20ofport%20number%0Afunction%20get_interface_ofport_request()%20%7B%0A%20%20%20%20%23%20Build%20an%20array%20that%20only%20contains%20the%20currently%20reserved%20ofport_requests%0A%20%20%20%20declare%20-A%20ofport_requests%0A%20%20%20%20for%20interface_name%20in%20%22%24%7B!INTERFACES%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20%20%20%20%20ofport_requests%5B%24%7BINTERFACES%5B%24interface_name%5D%7D%5D%3D%24%7BINTERFACES%5B%24interface_name%5D%7D%0A%20%20%20%20done%0A%0A%20%20%20%20%23%20Get%20the%20current%20ofport%20number%20assignment%0A%20%20%20%20local%20current_ofport%3D%24(ovs-vsctl%20get%20Interface%20%22%24%7BINTERFACE_NAME%7D%22%20ofport)%0A%0A%20%20%20%20%23%20If%20the%20current%20ofport%20number%20is%20still%20free%2C%20use%20it%0A%20%20%20%20if%20!%20%5B%20%22%24%7Bofport_requests%5B%24current_ofport%5D%2Ba%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%24current_ofport%0A%20%20%20%20%20%20%20%20return%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20If%20the%20current%20ofport%20number%20is%20not%20free%2C%20return%20the%20lowest%20free%20entry%0A%20%20%20%20i%3D0%0A%20%20%20%20for%20i%20in%20%7B1..65000%7D%3B%20do%0A%20%20%20%20%20%20%20%20if%20!%20%5B%20%22%24%7Bofport_requests%5B%24i%5D%2Ba%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20echo%20%24i%0A%20%20%20%20%20%20%20%20%20%20%20%20return%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20done%0A%0A%20%20%20%20%23%20if%20we%20still%20cannot%20find%20an%20ID%2C%20exit%20with%20an%20error%0A%20%20%20%20echo%20%22Impossible%20to%20find%20an%20ofport%20ID%20for%20interface%20%24%7BINTERFACE_NAME%7D%22%20%3E%262%0A%20%20%20%20exit%201%0A%7D%0A%0A%23%20If%20INTERFACES%5BINTERFACE_NAME%5D%20exists%2C%20use%20that%20value%0A%23%20If%20INTERFACES%5BINTERFACE_NAME%5D%20does%20not%20exists%2C%20use%20the%20value%20from%20get_interface_ofport_request%0Aif%20!%20%5B%20%22%24%7BINTERFACES%5B%24INTERFACE_NAME%5D%2Ba%7D%22%20%5D%3B%20then%0A%20%20%20%20INTERFACES%5B%24INTERFACE_NAME%5D%3D%24(get_interface_ofport_request)%0Afi%0A%23%20Set%20ofport_request%20according%20to%20INTERFACES%5BINTERFACE_NAME%5D%0Aovs-vsctl%20set%20Interface%20%22%24%7BINTERFACE_NAME%7D%22%20ofport_request%3D%24%7BINTERFACES%5B%24INTERFACE_NAME%5D%7D%0A%0A%23%20Save%20current%20state%20of%20INTERFACES%20to%20CONFIGURATION_FILE%0Adeclare%20-p%20INTERFACES%20%3E%7C%20%22%24%7BCONFIGURATION_FILE%7D%22%0A
          mode: 493
          overwrite: true
          path: /etc/NetworkManager/dispatcher.d/pre-up.d/10-ofport-request.sh
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%0A%23%20Extract%20Podman%20version%20and%20determine%20the%20signature%20policy%0A%2Fusr%2Fbin%2Fpodman%20-v%20%7C%20%2Fbin%2Fawk%20'%7B%0A%20%20%20%20split(%243%2C%20version%2C%20%22-%22)%3B%0A%20%20%20%20clean_version%20%3D%20version%5B1%5D%3B%0A%0A%20%20%20%20split(clean_version%2C%20current%2C%20%2F%5C.%2F)%3B%0A%20%20%20%20split(%224.4.1%22%2C%20target%2C%20%2F%5C.%2F)%3B%0A%0A%20%20%20%20for%20(i%20%3D%201%3B%20i%20%3C%3D%203%3B%20i%2B%2B)%20%7B%0A%20%20%20%20%20%20%20%20if%20((current%5Bi%5D%20%2B%200)%20%3C%20(target%5Bi%5D%20%2B%200))%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20print%20%22--signature-policy%20%2Fetc%2Fmachine-config-daemon%2Fpolicy-for-old-podman.json%22%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20exit%3B%0A%20%20%20%20%20%20%20%20%7D%20else%20if%20((current%5Bi%5D%20%2B%200)%20%3E%20(target%5Bi%5D%20%2B%200))%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20exit%3B%0A%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%7D%0A%7D'%20%3E%20%2Ftmp%2Fpodman_policy_args%0A
          mode: 493
          overwrite: true
          path: /etc/machine-config-daemon/generate_podman_policy_args.sh
        - contents:
            source: data:,%7B%22auths%22%3A%7B%22cloud.openshift.com%22%3A%7B%22auth%22%3A%22b3BlbnNoaWZ0LXJlbGVhc2UtZGV2K29jbV9hY2Nlc3NfOTRmZDViZTMwOTM3NGU5NDlkM2Q5NzhmOTQzZGFlYTI6TDc0UlozWjNEUUM1U0RFMjBUUUU3UDRZR1RNSDRIRUdMUkMySzk3MjJMSE1PMlBPVUNaUDJFVVo0UDc1N1RLQw%3D%3D%22%2C%22email%22%3A%22jgoldberg%40allcovered.com%22%7D%2C%22quay.io%22%3A%7B%22auth%22%3A%22b3BlbnNoaWZ0LXJlbGVhc2UtZGV2K29jbV9hY2Nlc3NfOTRmZDViZTMwOTM3NGU5NDlkM2Q5NzhmOTQzZGFlYTI6TDc0UlozWjNEUUM1U0RFMjBUUUU3UDRZR1RNSDRIRUdMUkMySzk3MjJMSE1PMlBPVUNaUDJFVVo0UDc1N1RLQw%3D%3D%22%2C%22email%22%3A%22jgoldberg%40allcovered.com%22%7D%2C%22registry.connect.redhat.com%22%3A%7B%22auth%22%3A%22fHVoYy1wb29sLTljZTJiZWU4LTUwYWQtNDVlNC04NDExLTNkNjQ1NWNkODI1NjpleUpoYkdjaU9pSlNVelV4TWlKOS5leUp6ZFdJaU9pSTNaakppTldOallXWXhZVEEwWXpZMVlUSTFaRGN6TjJSa05UVXlNbVJqWWlKOS5NZHFkUUgzenYyMHFzQ0dfR2hGYy1WSzFRNGRsOW05TFhqcmhQNjNjUDh0dDVGX25Wc1U5NGxlcmVVSEQ4R1FXRUxDZlIzeE5HQ2dOSXFPNWUyNC02U3NGOFNTQV9RSnZIODVzLTBBWXlWMHY2QnJxV21CRHNLSWdnSzE2SFhWUzd4cTlSZ05hN200RFRMdUF2RUdtVkRSQ05VUVNFN1FMTWMxaUVhSVI4RVdrT0pPUklQd3hQM3YyUDlsTHpSRWtKYl82WVRjUWRjQUR3T0d1OWkzUHIwMWRHX1d4QU90NkFxcFZBX0JSaHRhNFRjWTFwSHk1bXBlWWVIVnE3Q3hzZWFRV3FzR01Oc0lObkFFNGdjV0MyekVXVl9NZHpIQXVad203WWsxMjg5VVhfYnhVMWhDUkVzdG5zdGdCSERheFRpSTFjalZSZkJ4X05hb0RMU01GVXBzNmlDVXhTTUxzVmc3Mi04LVJHal9nVmMxRDZPNjJkODJoakdaaW5HekJsendzMkZLYlFnNDRjb1VWcWpDdUMwdktCdVJRbDhkX0taVGZTWFVSTS0wOE91YjBNdDRIMjVjZmx6bjNERWdDcUtlSVlUYVdMS3ZranRKVy1MaGdLRjlDUHFqWmozUjhwN2xja2ZkR0lPbHRvY0hZY0xXVlM3QURjdmRNaWVLa3p5STRHb2RPamp2NU5OVF9UWDdjRHBRRVdWUnlENkxkOElXODA4SHVoSmtfa2R0MWVDSkxSTTVUdFBSRHVxZ3UwODlqcWM4WXRVWFhfcm9KcFhoSE5iMUlnekZTdFJqZktTSVJ6YTdlV2g4VWxvRmNwNXJZOV9VeDFTaFVnZ3JlQXFmQ1Y4NXF5Wjlya2RibVNZUE5PRVdzTmtUeGJoY0Q4YWpkYlJrWkFCRQ%3D%3D%22%2C%22email%22%3A%22jgoldberg%40allcovered.com%22%7D%2C%22registry.redhat.io%22%3A%7B%22auth%22%3A%22fHVoYy1wb29sLTljZTJiZWU4LTUwYWQtNDVlNC04NDExLTNkNjQ1NWNkODI1NjpleUpoYkdjaU9pSlNVelV4TWlKOS5leUp6ZFdJaU9pSTNaakppTldOallXWXhZVEEwWXpZMVlUSTFaRGN6TjJSa05UVXlNbVJqWWlKOS5NZHFkUUgzenYyMHFzQ0dfR2hGYy1WSzFRNGRsOW05TFhqcmhQNjNjUDh0dDVGX25Wc1U5NGxlcmVVSEQ4R1FXRUxDZlIzeE5HQ2dOSXFPNWUyNC02U3NGOFNTQV9RSnZIODVzLTBBWXlWMHY2QnJxV21CRHNLSWdnSzE2SFhWUzd4cTlSZ05hN200RFRMdUF2RUdtVkRSQ05VUVNFN1FMTWMxaUVhSVI4RVdrT0pPUklQd3hQM3YyUDlsTHpSRWtKYl82WVRjUWRjQUR3T0d1OWkzUHIwMWRHX1d4QU90NkFxcFZBX0JSaHRhNFRjWTFwSHk1bXBlWWVIVnE3Q3hzZWFRV3FzR01Oc0lObkFFNGdjV0MyekVXVl9NZHpIQXVad203WWsxMjg5VVhfYnhVMWhDUkVzdG5zdGdCSERheFRpSTFjalZSZkJ4X05hb0RMU01GVXBzNmlDVXhTTUxzVmc3Mi04LVJHal9nVmMxRDZPNjJkODJoakdaaW5HekJsendzMkZLYlFnNDRjb1VWcWpDdUMwdktCdVJRbDhkX0taVGZTWFVSTS0wOE91YjBNdDRIMjVjZmx6bjNERWdDcUtlSVlUYVdMS3ZranRKVy1MaGdLRjlDUHFqWmozUjhwN2xja2ZkR0lPbHRvY0hZY0xXVlM3QURjdmRNaWVLa3p5STRHb2RPamp2NU5OVF9UWDdjRHBRRVdWUnlENkxkOElXODA4SHVoSmtfa2R0MWVDSkxSTTVUdFBSRHVxZ3UwODlqcWM4WXRVWFhfcm9KcFhoSE5iMUlnekZTdFJqZktTSVJ6YTdlV2g4VWxvRmNwNXJZOV9VeDFTaFVnZ3JlQXFmQ1Y4NXF5Wjlya2RibVNZUE5PRVdzTmtUeGJoY0Q4YWpkYlJrWkFCRQ%3D%3D%22%2C%22email%22%3A%22jgoldberg%40allcovered.com%22%7D%7D%7D%0A
          mode: 384
          overwrite: true
          path: /var/lib/kubelet/config.json
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-eo%20pipefail%0A%0Afunction%20pull_baremetal_runtime_cfg_image%20%7B%0A%20%20%20%20%23%20By%20default%20podman%20retries%20to%20pull%20an%20image%203%20times%20with%201%20second%20back-off.%20It%20is%20not%20configurable.%20For%20this%0A%20%20%20%20%23%20reason%20we%20are%20implementing%20our%20own%20logic%20of%20pulling%20image%20and%20retrying%20indefinitely.%0A%20%20%20%20%23%20Ref.%3A%20https%3A%2F%2Fgithub.com%2Fcontainers%2Fcommon%2Fblob%2Fe028741ef77fdfa3ae261b9d23cdd50253d586c4%2Flibimage%2Fcopier.go%23L27-L30%0A%0A%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Checking%20if%20baremetal%20runtime%20cfg%20image%20already%20exists%22%0A%20%20%20%20if%20!%20%2Fusr%2Fbin%2Fpodman%20image%20exists%20%22quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A93e7b8c870261726d44bddc7ba0a702d3720d1838141dac837fb8c3be7c6e1a1%22%3B%20then%0A%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Starting%20download%20of%20baremetal%20runtime%20cfg%20image%22%0A%20%20%20%20%20%20while%20!%20%2Fusr%2Fbin%2Fpodman%20pull%20--authfile%20%2Fvar%2Flib%2Fkubelet%2Fconfig.json%20%22quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A93e7b8c870261726d44bddc7ba0a702d3720d1838141dac837fb8c3be7c6e1a1%22%3B%20do%20sleep%201%3B%20done%0A%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Download%20of%20baremetal%20runtime%20cfg%20image%20completed%22%0A%20%20%20%20else%0A%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Image%20exists%2C%20no%20need%20to%20download%22%0A%20%20%20%20fi%0A%7D%0A%0Afunction%20resolv_prepender%20%7B%0A%20%20%20%20%20%20%20%20%23%20In%20DHCP%20connections%2C%20the%20resolv.conf%20content%20may%20be%20late%2C%20thus%20we%20wait%20for%20nameservers%0A%20%20%20%20%20%20%20%20while%20!%20grep%20nameserver%20%2Fvar%2Frun%2FNetworkManager%2Fresolv.conf%3B%20do%0A%20%20%20%20%20%20%20%20%20%20%20%20%3E%262%20echo%20%20%22NM%20resolv-prepender%3A%20NM%20resolv.conf%20still%20empty%20of%20nameserver%22%0A%20%20%20%20%20%20%20%20%20%20%20%20sleep%200.5%0A%20%20%20%20%20%20%20%20done%0A%0A%20%20%20%20%20%20%20%20%23%20Ensure%20resolv.conf%20exists%20and%20contains%20nameservers%20before%20we%20try%20to%20pull%20image%20or%20run%20podman%0A%20%20%20%20%20%20%20%20if%20%5B%5B%20!%20-e%20%2Fetc%2Fresolv.conf%20%5D%5D%20%7C%7C%20!%20grep%20-q%20nameserver%20%2Fetc%2Fresolv.conf%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20cp%20%2Fvar%2Frun%2FNetworkManager%2Fresolv.conf%20%2Fetc%2Fresolv.conf%0A%20%20%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20%20%20%23%20Ensure%20baremetalRuntimeCfgImage%20is%20pulled%20in%20a%20reliable%20way%20before%20trying%20to%20use%20it%0A%20%20%20%20%20%20%20%20%23%20in%20the%20subsequent%20code%0A%20%20%20%20%20%20%20%20pull_baremetal_runtime_cfg_image%0A%0A%20%20%20%20%20%20%20%20NAMESERVER_IP%3D%22%24(%2Fusr%2Fbin%2Fpodman%20run%20--rm%20%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20--authfile%20%2Fvar%2Flib%2Fkubelet%2Fconfig.json%20%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20--net%3Dhost%20%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A93e7b8c870261726d44bddc7ba0a702d3720d1838141dac837fb8c3be7c6e1a1%20%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20node-ip%20%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20show%20%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%2210.100.0.50%22%20%20%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%2210.100.0.51%22%20)%22%0A%20%20%20%20%20%20%20%20DOMAINS%3D%22%24%7BIP4_DOMAINS%3A-%7D%20%24%7BIP6_DOMAINS%3A-%7D%20comp-poc-rh01.rhpoc.int%22%0A%20%20%20%20%20%20%20%20if%20%5B%5B%20-n%20%22%24NAMESERVER_IP%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20KNICONFDONEPATH%3D%22%2Frun%2Fresolv-prepender-kni-conf-done%22%0A%20%20%20%20%20%20%20%20%20%20%20%20if%20systemctl%20-q%20is-enabled%20systemd-resolved%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Configure%20for%20OKD%20domain%20and%20local%20IP%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20mkdir%20-p%20%2Fetc%2Fsystemd%2Fresolved.conf.d%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20KNICONFTMPPATH%3D%22%24(mktemp)%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20KNICONFPATH%3D%22%2Fetc%2Fsystemd%2Fresolved.conf.d%2F60-kni.conf%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20echo%20%22%5BResolve%5D%22%20%3E%20%22%24%7BKNICONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20echo%20%22DNS%3D%24NAMESERVER_IP%22%20%3E%3E%20%22%24%7BKNICONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20echo%20%22Domains%3D%24%7BDOMAINS%7D%22%20%3E%3E%20%22%24%7BKNICONFTMPPATH%7D%22%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20If%20KNI%20conf%20is%20not%20created%20or%20doesn't%20match%20what%20is%20generated%20or%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20if%20we%20haven't%20completed%20a%20full%20update%20-%20create%20or%20update%20it%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20%5B%5B%20!%20-f%20%22%24%7BKNICONFPATH%7D%22%20%5D%5D%20%7C%7C%20%5B%5B%20!%20-f%20%22%24%7BKNICONFDONEPATH%7D%22%20%5D%5D%20%7C%7C%20!%20cmp%20--silent%20%22%24%7BKNICONFPATH%7D%22%20%22%24%7BKNICONFTMPPATH%7D%22%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Creating%2Fupdating%20%2Fetc%2Fsystemd%2Fresolved.conf.d%2F60-kni.conf%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Remove%20the%20done%20file%20flag%20before%20writing%20the%20config%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20This%20would%20guard%20against%20interruptions%20and%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20prevent%20double%20restart%20of%20systemd-resolved%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20rm%20-f%20%22%24%7BKNICONFDONEPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Copy%20tmp%20file%20contents%20to%20preserve%20permissions%20and%20SELinux%20label%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20cat%20%22%24%7BKNICONFTMPPATH%7D%22%20%3E%20%22%24%7BKNICONFPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20%5B%5B%20!%20-f%20%22%24%7BKNICONFDONEPATH%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20systemctl%20-q%20is-active%20systemd-resolved%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Restarting%20systemd-resolved%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20systemctl%20restart%20systemd-resolved%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20touch%20%22%24%7BKNICONFDONEPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20rm%20-rf%20%22%24%7BKNICONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Prepending%20'nameserver%20%24NAMESERVER_IP'%20to%20%2Fetc%2Fresolv.conf%20(other%20nameservers%20from%20%2Fvar%2Frun%2FNetworkManager%2Fresolv.conf)%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20RESOLVCONFTMPPATH%3D%22%24(mktemp)%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20sed%20-e%20%22%2FGenerated%20by%2Fc%23%20Generated%20by%20KNI%20resolv%20prepender%20NM%20dispatcher%20script%22%20%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%2Fvar%2Frun%2FNetworkManager%2Fresolv.conf%20%3E%20%22%24%7BRESOLVCONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20sed%20-i%20%220%2C%2F%5Enameserver.*%2Fs%2F%2Fnameserver%20%24NAMESERVER_IP%5Cn%5C0%2F%22%20%22%24%7BRESOLVCONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20!%20grep%20-q%20search%20%22%24%7BRESOLVCONFTMPPATH%7D%22%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Make%20sure%20we%20have%20a%20search%20entry%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20echo%20%22search%20comp-poc-rh01.rhpoc.int%22%20%3E%3E%20%22%24%7BRESOLVCONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Make%20sure%20cluster%20domain%20is%20first%20in%20the%20search%20list%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20sed%20-i%20%22s%2F%5Esearch%20%5C(.*%5C)%2Fsearch%20comp-poc-rh01.rhpoc.int%20%5C1%2F%22%20%22%24%7BRESOLVCONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Remove%20duplicate%20cluster%20domain%20entries%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20sed%20-i%20%22s%2F%5C(search%20comp-poc-rh01.rhpoc.int.*%5C)%20comp-poc-rh01.rhpoc.int%5C(%20.*%5C%7C%24%5C)%2F%5C1%5C2%2F%22%20%22%24%7BRESOLVCONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Only%20leave%20the%20first%203%20nameservers%20in%20%2Fetc%2Fresolv.conf%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20sed%20-i%20'%3Aa%20%24!%7BN%3B%20ba%7D%3B%20s%2F%5C(%5E%5C%7C%5Cn%5C)nameserver%2F%5Cn%23%20nameserver%2F4g'%20%22%24%7BRESOLVCONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Only%20touch%20existing%20resolv.conf%20if%20files%20actually%20differ%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20!%20cmp%20-s%20%22%24%7BRESOLVCONFTMPPATH%7D%22%20%2Fetc%2Fresolv.conf%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20chmod%20644%20%22%24%7BRESOLVCONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20mv%20-Zf%20%22%24%7BRESOLVCONFTMPPATH%7D%22%20%2Fetc%2Fresolv.conf%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Workaround%20for%20bz%201929160.%20Reload%20NetworkManager%20to%20force%20it%20to%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20re-run%20the%20lookup%20of%20the%20hostname%20now%20that%20we%20know%20we%20have%20DNS%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20servers%20configured%20correctly%20in%20resolv.conf.%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20nmcli%20general%20reload%20dns-rc%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20touch%20%22%24%7BKNICONFDONEPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20rm%20-rf%20%22%24%7BRESOLVCONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20fi%0A%7D%0A%0Aresolv_prepender%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/resolv-prepender.sh
        - contents:
            source: data:,%23%20Needed%20by%20the%20OpenShift%20SDN.%20See%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1758552%0Anet.ipv4.conf.all.arp_announce%20%3D%202%0A
          mode: 420
          overwrite: true
          path: /etc/sysctl.d/arp.conf
        - contents:
            source: data:,%23%20See%3A%20rhbz%231384746%2C%20OCPBUGS-24012%0Anet.ipv4.neigh.default.gc_thresh1%3D8192%0Anet.ipv4.neigh.default.gc_thresh2%3D32768%0Anet.ipv4.neigh.default.gc_thresh3%3D65536%0Anet.ipv6.neigh.default.gc_thresh1%3D8192%0Anet.ipv6.neigh.default.gc_thresh2%3D32768%0Anet.ipv6.neigh.default.gc_thresh3%3D65536%0A
          mode: 420
          overwrite: true
          path: /etc/sysctl.d/gc-thresh.conf
        - contents:
            source: data:,%0Afs.inotify.max_user_watches%20%3D%2065536%0Afs.inotify.max_user_instances%20%3D%208192%0A
          mode: 420
          overwrite: true
          path: /etc/sysctl.d/inotify.conf
        - contents:
            source: data:,vm.unprivileged_userfaultfd%20%3D%201
          mode: 420
          overwrite: true
          path: /etc/sysctl.d/enable-userfaultfd.conf
        - contents:
            source: data:,%23%20Needed%20for%20OpenShift%20Logging%20(ElasticSearch).%20See%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1793714%0Avm.max_map_count%20%3D%20262144%0A
          mode: 420
          overwrite: true
          path: /etc/sysctl.d/vm-max-map.conf
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-euo%20pipefail%0A%0A%23%20First%2C%20we%20need%20to%20wait%20until%20DHCP%20finishes%20and%20the%20node%20has%20a%20non-%60localhost%60%0A%23%20hostname%20before%20%60kubelet.service%60%20starts.%0A%23%20That's%20the%20%60--wait%60%20argument%20as%20used%20by%20%60node-valid-hostname.service%60.%0A%23%0A%23%20Second%2C%20on%20GCP%20specifically%20we%20truncate%20the%20hostname%20if%20it's%20%3E63%20characters.%0A%23%20That's%20%60gcp-hostname.service%60.%0A%0A%23%20Block%20indefinitely%20until%20the%20host%20gets%20a%20non-localhost%20name.%0A%23%20Note%20node-valid-hostname.service%20uses%20systemd%20to%20abort%20if%20this%20takes%20too%20long.%0Await_localhost()%20%7B%0A%20%20%20%20echo%20%22waiting%20for%20non-localhost%20hostname%20to%20be%20assigned%22%0A%20%20%20%20while%20%5B%5B%20%22%24(%3C%20%2Fproc%2Fsys%2Fkernel%2Fhostname)%22%20%3D~%20(localhost%7Clocalhost.localdomain)%20%5D%5D%3B%0A%20%20%20%20do%0A%20%20%20%20%20%20%20%20sleep%201%0A%20%20%20%20done%0A%20%20%20%20echo%20%22node%20identified%20as%20%24(%3C%2Fproc%2Fsys%2Fkernel%2Fhostname)%22%0A%20%20%20%20echo%20%22saving%20hostname%20to%20prevent%20NetworkManager%20from%20ever%20unsetting%20it%22%0A%20%20%20%20hostnamectl%20set-hostname%20--static%20--transient%20%24(%3C%2Fproc%2Fsys%2Fkernel%2Fhostname)%0A%20%20%20%20exit%200%0A%7D%0A%0Aset_gcp_hostname()%20%7B%0A%20%20%20%20%2Fusr%2Fbin%2Fafterburn%20--provider%20gcp%20--hostname%3D%2Frun%2Fafterburn.hostname%0A%0A%20%20%20%20local%20host_name%3D%24(cat%20%2Frun%2Fafterburn.hostname)%0A%20%20%20%20local%20type_arg%3D%22transient%22%0A%0A%20%20%20%20%23%20%2Fetc%2Fhostname%20is%20used%20for%20static%20hostnames%20and%20is%20authoritative.%0A%20%20%20%20%23%20This%20will%20check%20to%20make%20sure%20that%20the%20static%20hostname%20is%20the%0A%20%20%20%20%23%20less%20than%20or%20equal%20to%2063%20characters%20in%20length.%0A%20%20%20%20if%20%5B%20-f%20%2Fetc%2Fhostname%20%5D%20%26%26%20%5B%20%22%24(cat%20%2Fetc%2Fhostname%20%7C%20wc%20-m)%22%20-gt%200%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20etc_name%3D%22%24(%3C%20%2Fetc%2Fhostname)%22%0A%20%20%20%20%20%20%20%20type_arg%3D%22static%22%0A%20%20%20%20%20%20%20%20if%20%5B%20%22%24%7Betc_name%7D%22%20!%3D%20%22%24%7Bhost_name%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20echo%20%22%2Fetc%2Fhostname%20is%20set%20to%20%24%7Betc_name%7D%20but%20does%20not%20match%20%24%7Bhost_name%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20echo%20%22using%20%2Fetc%2Fhostname%20as%20the%20authoritative%20name%22%0A%20%20%20%20%20%20%20%20%20%20%20%20host_name%3D%22%24%7Betc_name%7D%22%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Only%20mutate%20the%20hostname%20if%20the%20length%20is%20longer%20than%2063%20characters.%20The%0A%20%20%20%20%23%20hostname%20will%20be%20the%20lesser%20of%2063%20characters%20after%20the%20first%20dot%20in%20the%0A%20%20%20%20%23%20FQDN.%20%20This%20algorithm%20is%20only%20known%20to%20work%20in%20GCP%2C%20and%20hence%20is%20only%0A%20%20%20%20%23%20executed%20in%20GCP.%0A%20%20%20%20if%20%5B%20%22%24%7B%23host_name%7D%22%20-gt%2063%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20alt_name%3D%24(printf%20%22%24%7Bhost_name%7D%22%20%7C%20cut%20-f1%20-d'.'%20%7C%20cut%20-c%20-63)%0A%20%20%20%20%20%20%20%20echo%20%22%24%7Bhost_name%7D%20is%20longer%20than%2063%20characters%2C%20using%20truncated%20hostname%22%0A%20%20%20%20%20%20%20%20host_name%3D%22%24%7Balt_name%7D%22%0A%20%20%20%20fi%0A%20%20%20%20echo%20%22setting%20%24%7Btype_arg%7D%20hostname%20to%20%24%7Bhost_name%7D%22%0A%20%20%20%20%2Fbin%2Fhostnamectl%20%22--%24%7Btype_arg%7D%22%20set-hostname%20%22%24%7Bhost_name%7D%22%0A%20%20%20%20exit%200%0A%7D%0A%0Aset_openstack_hostname()%20%7B%0A%20%20%20%20%23%20Read%20metadata%20written%20by%20afterburn%20service%0A%20%20%20%20.%20%2Frun%2Fmetadata%2Fafterburn%0A%0A%20%20%20%20%23%20node-valid-hostname%20sets%20persistent%20hostname%20from%20%2Fproc%2Fsys%2Fkernel%2Fhostname%0A%20%20%20%20echo%20%22%24AFTERBURN_OPENSTACK_HOSTNAME%22%20%3E%20%2Fproc%2Fsys%2Fkernel%2Fhostname%0A%7D%0A%0Aset_powervs_hostname()%20%7B%0A%20%20%20%20%23%20Read%20metadata%20written%20by%20afterburn%20service%0A%20%20%20%20.%20%2Frun%2Fmetadata%2Fafterburn%0A%0A%20%20%20%20%23%20node-valid-hostname%20sets%20persistent%20hostname%20from%20%2Fproc%2Fsys%2Fkernel%2Fhostname%0A%20%20%20%20echo%20%22%24AFTERBURN_POWERVS_LOCAL_HOSTNAME%22%20%3E%20%2Fproc%2Fsys%2Fkernel%2Fhostname%0A%7D%0A%0Aarg%3D%24%7B1%7D%3B%20shift%3B%0Acase%20%22%24%7Barg%7D%22%20in%0A%20%20%20%20--wait)%20wait_localhost%3B%3B%0A%20%20%20%20--gcp)%20set_gcp_hostname%3B%3B%0A%20%20%20%20--openstack)%20set_openstack_hostname%3B%3B%0A%20%20%20%20--powervs)%20set_powervs_hostname%3B%3B%0A%20%20%20%20*)%20echo%20%22Unhandled%20arg%20%24arg%22%3B%20exit%201%0Aesac%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/mco-hostname
        - contents:
            source: data:,
          mode: 493
          overwrite: true
          path: /etc/kubernetes/kubelet-plugins/volume/exec/.dummy
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%23%20Workaround%3A%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1941714%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1935539%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1987108%0A%0Adriver%3D%24(nmcli%20-t%20-m%20tabular%20-f%20general.driver%20dev%20show%20%22%24%7BDEVICE_IFACE%7D%22)%0A%0Aif%20%5B%5B%20%22%242%22%20%3D%3D%20%22up%22%20%26%26%20%22%24%7Bdriver%7D%22%20%3D%3D%20%22vmxnet3%22%20%5D%5D%3B%20then%0A%20%20logger%20-s%20%2299-vsphere-disable-tx-udp-tnl%20triggered%20by%20%24%7B2%7D%20on%20device%20%24%7BDEVICE_IFACE%7D.%22%0A%20%20ethtool%20-K%20%24%7BDEVICE_IFACE%7D%20tx-udp_tnl-segmentation%20off%0A%20%20ethtool%20-K%20%24%7BDEVICE_IFACE%7D%20tx-udp_tnl-csum-segmentation%20off%0A%20%20ethtool%20-K%20%24%7BDEVICE_IFACE%7D%20tx-checksum-ip-generic%20off%0Afi%0A
          mode: 484
          overwrite: true
          path: /etc/NetworkManager/dispatcher.d/99-vsphere-disable-tx-udp-tnl
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%0Auntil%20%5B%20-e%20%2Frun%2Fnodeip-configuration%2Fbr-ex-up%20%5D%0Ado%0A%20%20sleep%201%0Adone%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/wait-for-br-ex-up.sh
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-x%0A%0Aif%20%5B%20!%20-e%20%22%2Fetc%2Fipsec.d%2Fopenshift.conf%22%20%5D%3B%20then%0A%20%20exit%200%0Afi%0A%0A%23%20Modify%20existing%20IPsec%20connection%20entries%20with%20%22auto%3Dstart%22%0A%23%20option%20and%20restart%20ipsec%20systemd%20service.%20This%20helps%20to%0A%23%20establish%20IKE%20SAs%20for%20the%20existing%20IPsec%20connections%20with%0A%23%20peer%20nodes.%20This%20option%20will%20be%20deleted%20from%20connections%0A%23%20once%20ovs-monitor-ipsec%20process%20spinned%20up%20on%20the%20node%20by%0A%23%20ovn-ipsec-host%20pod%2C%20but%20still%20it%20won't%20reestablish%20IKE%20SAs%0A%23%20again%20with%20peer%20nodes%2C%20so%20it%20shouldn't%20be%20a%20problem.%0Aif%20!%20grep%20-q%20%22auto%3Dstart%22%20%2Fetc%2Fipsec.d%2Fopenshift.conf%3B%20then%0A%20%20sed%20-i%20'%2F%5E.*conn%20ovn.*%24%2Fa%5C%20%20%20%20auto%3Dstart'%20%2Fetc%2Fipsec.d%2Fopenshift.conf%0Afi%0Achroot%20%2Fproc%2F1%2Froot%20ipsec%20restart%0A%0A%23%20Wait%20for%20upto%2060s%20to%20get%20IPsec%20SAs%20to%20establish%20with%20peer%20nodes.%0Atimeout%3D60%0Aelapsed%3D0%0Adesiredconn%3D%22%22%0Aestablishedsa%3D%22%22%0Awhile%20%5B%5B%20%24elapsed%20-lt%20%24timeout%20%5D%5D%3B%20do%0A%20%20desiredconn%3D%24(grep%20-E%20'%5E%5Cs*conn%5Cs%2B'%20%2Fetc%2Fipsec.d%2Fopenshift.conf%20%7C%20grep%20-v%20'%25default'%20%7C%20awk%20'%7Bprint%20%242%7D'%20%7C%20tr%20'%20'%20'%5Cn'%20%7C%20sort%20%7C%20tr%20'%5Cn'%20'%20')%0A%20%20establishedsa%3D%24(ipsec%20showstates%20%7C%20grep%20STATE_V2_ESTABLISHED_CHILD_SA%20%7C%20grep%20-o%20'%22%5B%5E%22%5D*%22'%20%7C%20sed%20's%2F%22%2F%2Fg'%20%7C%20tr%20'%20'%20'%5Cn'%20%7C%20sort%20%7C%20uniq%20%7C%20tr%20'%5Cn'%20'%20')%0A%20%20if%20%5B%20%22%24desiredconn%22%20%3D%3D%20%22%24establishedsa%22%20%5D%3B%20then%0A%20%20%20%20echo%20%22IPsec%20SAs%20are%20established%20for%20desired%20connections%20after%20%24%7Belapsed%7Ds%22%0A%20%20%20%20break%0A%20%20else%0A%20%20%20%20echo%20%22IPsec%20SAs%20are%20not%20established%20yet%2C%20total%20waited%20time%20%24%7Belapsed%7Ds%22%0A%20%20%20%20sleep%202s%0A%20%20fi%0A%20%20elapsed%3D%24((elapsed%20%2B%202))%0Adone%0A%0Aif%20%5B%5B%20%24elapsed%20-ge%20%24timeout%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22Timed%20out%20waiting%2C%20some%20connections%20are%20not%20established%2C%20desired%20conns%20%24desiredconn%2C%20established%20conns%20%24establishedsa%22%0Afi%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/ipsec-connect-wait.sh
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-eux%0A%0Aif%20%5B%20!%20-e%20%2Fetc%2Fnmstate%2Fopenshift%2Fapplied%20%5D%3B%20then%0A%20%20%23%20No%20need%20to%20do%20this%20if%20no%20NMState%20configuration%20was%20applied%0A%20%20exit%200%0Afi%0A%0A%23%20This%20logic%20is%20borrowed%20from%20configure-ovs.sh%0A%23%20TODO%3A%20Find%20a%20platform-agnostic%20way%20to%20do%20this.%20It%20won't%20work%20on%20platforms%20where%0A%23%20nodeip-configuration%20is%20not%20used.%0Aip%3D%24(cat%20%2Frun%2Fnodeip-configuration%2Fprimary-ip)%0Aif%20%5B%5B%20%22%24%7Bip%7D%22%20%3D%3D%20%22%22%20%5D%5D%3B%20then%0A%20%20echo%20%22No%20ip%20to%20bind%20was%20found%22%0A%20%20exit%201%0Afi%0Awhile%20%3A%0Ado%0A%20%20random_port%3D%24(shuf%20-i%2050000-60000%20-n%201)%0A%20%20echo%20%22Trying%20to%20bind%20%24%7Bip%7D%20on%20port%20%24%7Brandom_port%7D%22%0A%20%20exit_code%3D%24(timeout%202s%20nc%20-l%20%22%24%7Bip%7D%22%20%24%7Brandom_port%7D%3B%20echo%20%24%3F)%0A%20%20if%20%5B%5B%20exit_code%20-eq%20124%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22Address%20bound%20successfully%22%0A%20%20%20%20exit%200%0A%20%20fi%0A%20%20sleep%2010%0Adone%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/wait-for-primary-ip.sh
      systemd:
        units:
        - contents: |
            [Unit]
            Description=Cleans NetworkManager state generated by dracut
            # Removal of this file signals firstboot completion
            ConditionPathExists=!/etc/ignition-machine-config-encapsulated.json
            # This is opt-in for some deployment types, and opt-out for others.
            ConditionPathExists=/var/lib/mco/nm-clean-initrd-state
            Wants=network-pre.target
            Before=network-pre.target

            [Service]
            Type=oneshot
            # Remove any existing state possibly generated NM run by dracut. We want NM to
            # consider all profiles autoconnect priority when it starts instead of
            # remembering which profile was a device activated with when NM is run by
            # dracut.
            ExecStart=/usr/local/bin/nm-clean-initrd-state.sh
            StandardOutput=journal+console
            StandardError=journal+console

            [Install]
            WantedBy=network-online.target
          enabled: true
          name: NetworkManager-clean-initrd-state.service
        - dropins:
          - contents: |
              # vim:set ft=systemd :
              #
              # This drop-in will enable any service built with this
              # github.com/containers/kubemntns library to properly join the mount namespace
              # managed by kubens.service
              #

              [Unit]
              After=kubens.service

              [Service]
              EnvironmentFile=-/run/kubens/env
            name: 01-kubens.conf
          - contents: ""
            name: 10-mco-default-env.conf
          - contents: |
              [Service]
              Environment="ENABLE_PROFILE_UNIX_SOCKET=true"
            name: 10-mco-profile-unix-socket.conf
          - contents: |
              [Unit]
              After=kubelet-dependencies.target
              Requires=kubelet-dependencies.target
            name: 05-mco-ordering.conf
          - contents: |
              [Service]
              Environment="GODEBUG=x509ignoreCN=0,madvdontneed=1"
            name: 10-mco-default-madv.conf
          name: crio.service
        - dropins:
          - contents: |
              [Unit]
              ConditionPathExists=/enoent
            name: mco-disabled.conf
          name: docker.socket
        - contents: |
            [Unit]
            Description=The firstboot OS update has completed
            Documentation=https://github.com/openshift/machine-config-operator/
            Requires=basic.target

            [Install]
            WantedBy=default.target
          enabled: true
          name: firstboot-osupdate.target
        - dropins:
          - contents: |
              [Unit]
              After=ovs-configuration.service
              Before=crio.service
            name: 01-after-configure-ovs.conf
          name: ipsec.service
        - contents: |
            [Unit]
            Description=Dynamically sets the system reserved for the kubelet
            Wants=network-online.target
            After=network-online.target firstboot-osupdate.target
            Before=kubelet-dependencies.target

            [Service]
            # Need oneshot to delay kubelet
            Type=oneshot
            RemainAfterExit=yes
            EnvironmentFile=/etc/node-sizing-enabled.env
            ExecStart=/bin/bash /usr/local/sbin/dynamic-system-reserved-calc.sh ${NODE_SIZING_ENABLED} ${SYSTEM_RESERVED_MEMORY} ${SYSTEM_RESERVED_CPU} ${SYSTEM_RESERVED_ES}
            [Install]
            RequiredBy=kubelet-dependencies.target
          enabled: true
          name: kubelet-auto-node-size.service
        - contents: |
            [Unit]
            Description=Dependencies necessary to run kubelet
            Documentation=https://github.com/openshift/machine-config-operator/
            Requires=basic.target network-online.target
            Wants=NetworkManager-wait-online.service crio-wipe.service
            Wants=rpc-statd.service chrony-wait.service
          name: kubelet-dependencies.target
        - dropins:
          - contents: |
              # vim:set ft=systemd :
              #
              # This drop-in will enable any service built with this
              # github.com/containers/kubemntns library to properly join the mount namespace
              # managed by kubens.service
              #

              [Unit]
              After=kubens.service

              [Service]
              EnvironmentFile=-/run/kubens/env
            name: 01-kubens.conf
          - contents: ""
            name: 10-mco-default-env.conf
          - contents: |
              [Service]
              # Wait for resolv-prepender to configure nameservers, exit 255 otherwise
              # to mark the unit as failed and retry later
              ExecCondition=/bin/bash -c '[ -f /run/resolv-prepender-kni-conf-done ] || { echo "NM resolv-prepender failed"; exit 255; }'
            name: 10-mco-on-prem-wait-resolv.conf
          - contents: |
              [Service]
              Environment="GODEBUG=x509ignoreCN=0,madvdontneed=1"
            name: 10-mco-default-madv.conf
          name: kubelet.service
        - contents: |
            [Unit]
            Description=Manages a mount namespace for kubernetes-specific mounts

            [Service]
            Type=oneshot
            RemainAfterExit=yes
            RuntimeDirectory=kubens
            Environment=RUNTIME_DIRECTORY=%t/kubens
            Environment=BIND_POINT=%t/kubens/mnt
            Environment=ENVFILE=%t/kubens/env

            # Set up the runtime directory as an unbindable mountpoint
            ExecStartPre=bash -c "findmnt ${RUNTIME_DIRECTORY} || mount --make-unbindable --bind ${RUNTIME_DIRECTORY} ${RUNTIME_DIRECTORY}"
            # Ensure the bind point exists
            ExecStartPre=touch ${BIND_POINT}
            # Use 'unshare' to create the new mountpoint, then 'mount --make-rshared' so it cascades internally
            ExecStart=unshare --mount=${BIND_POINT} --propagation slave mount --make-rshared /
            # Finally, set an env pointer for ease-of-use
            ExecStartPost=bash -c 'echo "KUBENSMNT=${BIND_POINT}" > "${ENVFILE}"'

            # On stop, a recursive unmount cleans up the namespace and bind-mounted unbindable parent directory
            ExecStop=umount -R ${RUNTIME_DIRECTORY}

            [Install]
            WantedBy=multi-user.target
          enabled: false
          name: kubens.service
        - contents: |
            [Unit]
            Description=Machine Config Daemon Firstboot
            # Make sure it runs only on OSTree booted system
            ConditionPathExists=/run/ostree-booted
            # Removal of this file signals firstboot completion
            ConditionPathExists=/etc/ignition-machine-config-encapsulated.json
            After=machine-config-daemon-pull.service
            Before=kubelet-dependencies.target

            [Service]
            Type=oneshot
            RemainAfterExit=yes
            # Disable existing repos (if any) so that OS extensions would use embedded RPMs only
            ExecStartPre=-/usr/bin/sh -c "sed -i 's/enabled=1/enabled=0/' /etc/yum.repos.d/*.repo"
            # Run this via podman because we want to use the nmstatectl binary in our container
            ExecStart=/usr/bin/podman run --rm --privileged --net=host -v /:/rootfs  --entrypoint machine-config-daemon 'quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:94bac6c3782cf6579032c7c9dabca74146753d9a44591125acd30d606d7d340c' firstboot-complete-machineconfig --persist-nics
            ExecStart=/usr/bin/podman run --rm --privileged --pid=host --net=host -v /:/rootfs  --entrypoint machine-config-daemon 'quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:94bac6c3782cf6579032c7c9dabca74146753d9a44591125acd30d606d7d340c' firstboot-complete-machineconfig
            [Install]
            RequiredBy=firstboot-osupdate.target
          enabled: true
          name: machine-config-daemon-firstboot.service
        - contents: |
            [Unit]
            Description=Machine Config Daemon Pull
            # Make sure it runs only on OSTree booted system
            ConditionPathExists=/run/ostree-booted
            # This "stamp file" is unlinked when we complete
            # machine-config-daemon-firstboot.service
            ConditionPathExists=/etc/ignition-machine-config-encapsulated.json
            # Run after crio-wipe so the pulled MCD image is protected against a corrupted storage from a forced shutdown
            Wants=crio-wipe.service NetworkManager-wait-online.service
            After=crio-wipe.service NetworkManager-wait-online.service network.service

            [Service]
            Type=oneshot
            RemainAfterExit=yes
            ExecStartPre=/etc/machine-config-daemon/generate_podman_policy_args.sh
            ExecStart=/bin/sh -c "while ! /usr/bin/podman pull $(cat /tmp/podman_policy_args) --authfile=/var/lib/kubelet/config.json 'quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:94bac6c3782cf6579032c7c9dabca74146753d9a44591125acd30d606d7d340c'; do sleep 1; done"

            [Install]
            RequiredBy=machine-config-daemon-firstboot.service
          enabled: true
          name: machine-config-daemon-pull.service
        - contents: |
            [Unit]
            Description=Applies per-node NMState network configuration
            Requires=openvswitch.service
            Wants=NetworkManager-wait-online.service
            After=NetworkManager-wait-online.service openvswitch.service network.service nodeip-configuration.service
            Before=nmstate.service kubelet-dependencies.target ovs-configuration.service node-valid-hostname.service

            [Service]
            Type=oneshot
            # Would prefer to do Restart=on-failure instead of this bash retry loop, but
            # the version of systemd we have right now doesn't support it. It should be
            # available in systemd v244 and higher.
            ExecStart=/usr/local/bin/nmstate-configuration.sh
            StandardOutput=journal+console
            StandardError=journal+console

            [Install]
            WantedBy=network-online.target
          enabled: true
          name: nmstate-configuration.service
        - contents: |
            [Unit]
            Description=Apply nmstate on-disk state
            Documentation=man:nmstate.service(8) https://www.nmstate.io
            After=NetworkManager-wait-online.service
            Before=network-online.target
            Wants=NetworkManager-wait-online.service
            Requires=NetworkManager.service

            [Service]
            Type=oneshot
            ExecStart=/usr/bin/nmstatectl service
            RemainAfterExit=yes

            [Install]
            WantedBy=NetworkManager.service
          enabled: true
          name: nmstate.service
        - contents: |
            [Unit]
            Description=Wait for a non-localhost hostname
            Before=kubelet-dependencies.target

            [Service]
            Type=oneshot
            RemainAfterExit=yes
            User=root
            ExecStart=/usr/local/bin/mco-hostname --wait

            # Wait up to 5min for the node to get a non-localhost name
            TimeoutSec=300

            [Install]
            # TODO: Change this to RequiredBy after we fix https://github.com/openshift/machine-config-operator/pull/3865#issuecomment-1746963115
            WantedBy=kubelet-dependencies.target
          enabled: true
          name: node-valid-hostname.service
        - contents: |
            [Unit]
            Description=Writes IP address configuration so that kubelet and crio services select a valid node IP
            # This only applies to VIP managing environments where the kubelet and crio IP
            # address picking logic is flawed and may end up selecting an address from a
            # different subnet or a deprecated address
            Wants=NetworkManager-wait-online.service
            After=NetworkManager-wait-online.service firstboot-osupdate.target
            Before=kubelet-dependencies.target ovs-configuration.service

            [Service]
            # Need oneshot to delay kubelet
            Type=oneshot
            # Would prefer to do Restart=on-failure instead of this bash retry loop, but
            # the version of systemd we have right now doesn't support it. It should be
            # available in systemd v244 and higher.
            ExecStart=/bin/bash -c " \
              until \
              /usr/bin/podman run --rm \
              --authfile /var/lib/kubelet/config.json \
              --net=host \
              --security-opt label=disable \
              --volume /etc/systemd/system:/etc/systemd/system \
              --volume /run/nodeip-configuration:/run/nodeip-configuration \
              quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:93e7b8c870261726d44bddc7ba0a702d3720d1838141dac837fb8c3be7c6e1a1 \
              node-ip \
              set \
              --platform BareMetal \
              --retry-on-failure \
              ${NODEIP_HINT:-} \
              10.100.0.50  \
              10.100.0.51 ; \
              do \
              sleep 5; \
              done"
            ExecStart=/bin/systemctl daemon-reload
            ExecStartPre=/bin/mkdir -p /run/nodeip-configuration
            ExecStartPost=+/usr/local/bin/configure-ip-forwarding.sh
            StandardOutput=journal+console
            StandardError=journal+console
            EnvironmentFile=-/etc/default/nodeip-configuration

            [Install]
            RequiredBy=kubelet-dependencies.target
          enabled: true
          name: nodeip-configuration.service
        - contents: |
            [Unit]
            Description=Watches for changes in /var/run/NetworkManager/resolv.conf according to on-prem IPI needs
            [Path]
            PathModified=/var/run/NetworkManager/resolv.conf
            PathModified=/run/resolv-prepender/env
            Unit=on-prem-resolv-prepender.service
            [Install]
            WantedBy=multi-user.target
          enabled: true
          name: on-prem-resolv-prepender.path
        - contents: |
            [Unit]
            Description=Populates resolv.conf according to on-prem IPI needs
            # Per https://issues.redhat.com/browse/OCPBUGS-27162 there is a problem if this is started before crio-wipe
            After=crio-wipe.service
            StartLimitIntervalSec=0
            [Service]
            Type=oneshot
            # Would prefer to do Restart=on-failure instead of this bash retry loop, but
            # the version of systemd we have right now doesn't support it. It should be
            # available in systemd v244 and higher.
            ExecStart=/bin/bash -c " \
              until \
              /usr/local/bin/resolv-prepender.sh; \
              do \
              sleep 10; \
              done"
            EnvironmentFile=-/run/resolv-prepender/env
          enabled: false
          name: on-prem-resolv-prepender.service
        - enabled: true
          name: openvswitch.service
        - contents: |
            [Unit]
            # Kdump will generate it's initramfs based on the running state when kdump.service run
            # If OVS has already run, the kdump fails to gather a working network config,
            # which prevent network log exports, sush as SSH.
            # See https://issues.redhat.com/browse/OCPBUGS-28239
            After=kdump.service
            Description=Configures OVS with proper host networking configuration
            # This service is used to move a physical NIC into OVS and reconfigure OVS to use the host IP
            Requires=openvswitch.service
            Wants=NetworkManager-wait-online.service
            After=firstboot-osupdate.target
            After=NetworkManager-wait-online.service openvswitch.service network.service nodeip-configuration.service nmstate.service
            Before=kubelet-dependencies.target node-valid-hostname.service

            [Service]
            # Need oneshot to delay kubelet
            Type=oneshot
            ExecStart=/usr/local/bin/configure-ovs.sh OVNKubernetes
            StandardOutput=journal+console
            StandardError=journal+console

            [Install]
            RequiredBy=kubelet-dependencies.target
          enabled: true
          name: ovs-configuration.service
        - dropins:
          - contents: |
              [Service]
              Restart=always
              ExecStartPre=-/bin/sh -c '/usr/bin/chown -R :$${OVS_USER_ID##*:} /var/lib/openvswitch'
              ExecStartPre=-/bin/sh -c '/usr/bin/chown -R :$${OVS_USER_ID##*:} /etc/openvswitch'
              ExecStartPre=-/bin/sh -c '/usr/bin/chown -R :$${OVS_USER_ID##*:} /run/openvswitch'
              ExecStartPost=-/usr/bin/ovs-appctl vlog/set syslog:info
              ExecReload=-/usr/bin/ovs-appctl vlog/set syslog:info
            name: 10-ovs-vswitchd-restart.conf
          name: ovs-vswitchd.service
        - dropins:
          - contents: |
              [Service]
              Restart=always
            name: 10-ovsdb-restart.conf
          enabled: true
          name: ovsdb-server.service
        - dropins:
          - contents: ""
            name: 10-mco-default-env.conf
          name: rpm-ostreed.service
        - contents: |
            [Unit]
            Description=Wait for br-ex up event from NetworkManager
            Wants=ovs-configuration.service
            After=ovs-configuration.service
            Before=node-valid-hostname.service

            [Service]
            Type=oneshot
            ExecStart=/usr/local/bin/wait-for-br-ex-up.sh

            [Install]
            RequiredBy=node-valid-hostname.service
          enabled: true
          name: wait-for-br-ex-up.service
        - contents: |
            [Unit]
            Description=Ensure IKE SA established for existing IPsec connections.
            After=ipsec.service
            Before=kubelet-dependencies.target node-valid-hostname.service

            [Service]
            Type=oneshot
            ExecStart=/usr/local/bin/ipsec-connect-wait.sh
            StandardOutput=journal+console
            StandardError=journal+console

            [Install]
            WantedBy=ipsec.service
          enabled: true
          name: wait-for-ipsec-connect.service
        - contents: |
            [Unit]
            Description=Ensure primary IP is assigned and usable
            Requires=nmstate.service
            After=nmstate.service
            Before=kubelet-dependencies.target

            [Service]
            Type=oneshot
            # Would prefer to do Restart=on-failure instead of this bash retry loop, but
            # the version of systemd we have right now doesn't support it. It should be
            # available in systemd v244 and higher.
            ExecStart=/bin/bash -c " \
              until \
              /usr/local/bin/wait-for-primary-ip.sh; \
              do \
              sleep 10; \
              done"
            StandardOutput=journal+console
            StandardError=journal+console

            [Install]
            WantedBy=network-online.target
          enabled: true
          name: wait-for-primary-ip.service
        - dropins:
          - contents: |
              [Unit]
              ConditionPathExists=/enoent
            name: mco-disabled.conf
          name: zincati.service
    fips: false
    kernelArguments: null
    kernelType: ""
    osImageURL: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4e309dd906392e783a404b92dfd4fa4c32d74e2804ee37d1fb8a00c9355d5978
- apiVersion: machineconfiguration.openshift.io/v1
  kind: MachineConfig
  metadata:
    annotations:
      machineconfiguration.openshift.io/generated-by-controller-version: fcf8f254943cbcba1400ba55f3978cc292b6460b
    creationTimestamp: "2025-11-04T16:09:16Z"
    generation: 1
    labels:
      machineconfiguration.openshift.io/role: master
    name: 01-master-container-runtime
    ownerReferences:
    - apiVersion: machineconfiguration.openshift.io/v1
      blockOwnerDeletion: true
      controller: true
      kind: ControllerConfig
      name: machine-config-controller
      uid: 18dbcd72-fa02-401e-8486-bd239a092409
    resourceVersion: "10960"
    uid: 9d164c99-4d4e-443e-ba69-0835e07d4c8b
  spec:
    baseOSExtensionsContainerImage: ""
    config:
      ignition:
        version: 3.4.0
      storage:
        files:
        - contents:
            source: data:,unqualified-search-registries%20%3D%20%5B'registry.access.redhat.com'%2C%20'docker.io'%5D%0A
          mode: 420
          overwrite: true
          path: /etc/containers/registries.conf
        - contents:
            source: data:,%5Bcrio%5D%0Ainternal_wipe%20%3D%20true%0Ainternal_repair%20%3D%20true%0A%0A%5Bcrio.api%5D%0Astream_address%20%3D%20%22127.0.0.1%22%0Astream_port%20%3D%20%220%22%0A%0A%5Bcrio.runtime%5D%0Aselinux%20%3D%20true%0Aconmon%20%3D%20%22%22%0Aconmon_cgroup%20%3D%20%22pod%22%0Adefault_env%20%3D%20%5B%0A%20%20%20%20%22NSS_SDB_USE_CACHE%3Dno%22%2C%0A%5D%0Adefault_runtime%20%3D%20%22crun%22%0Alog_level%20%3D%20%22info%22%0Acgroup_manager%20%3D%20%22systemd%22%0Adefault_sysctls%20%3D%20%5B%0A%20%20%20%20%22net.ipv4.ping_group_range%3D0%202147483647%22%2C%0A%5D%0Ahooks_dir%20%3D%20%5B%0A%20%20%20%20%22%2Fetc%2Fcontainers%2Foci%2Fhooks.d%22%2C%0A%20%20%20%20%22%2Frun%2Fcontainers%2Foci%2Fhooks.d%22%2C%0A%20%20%20%20%22%2Fusr%2Fshare%2Fcontainers%2Foci%2Fhooks.d%22%2C%0A%5D%0Amanage_ns_lifecycle%20%3D%20true%0Aabsent_mount_sources_to_reject%20%3D%20%5B%0A%20%20%20%20%22%2Fetc%2Fhostname%22%2C%0A%5D%0Adrop_infra_ctr%20%3D%20true%0A%0A%5Bcrio.runtime.runtimes.runc%5D%0Aruntime_root%20%3D%20%22%2Frun%2Frunc%22%0Aallowed_annotations%20%3D%20%5B%0A%20%20%20%20%22io.containers.trace-syscall%22%2C%0A%20%20%20%20%22io.kubernetes.cri-o.Devices%22%2C%0A%20%20%20%20%22io.kubernetes.cri-o.LinkLogs%22%2C%0A%5D%0A%0A%5Bcrio.runtime.runtimes.crun%5D%0Aruntime_root%20%3D%20%22%2Frun%2Fcrun%22%0Aallowed_annotations%20%3D%20%5B%0A%20%20%20%20%22io.containers.trace-syscall%22%2C%0A%20%20%20%20%22io.kubernetes.cri-o.Devices%22%2C%0A%20%20%20%20%22io.kubernetes.cri-o.LinkLogs%22%2C%0A%5D%0A%23%20Based%20on%20https%3A%2F%2Fgithub.com%2Fcontainers%2Fcrun%2Fblob%2F27d7dd3a0%2FREADME.md%3Fplain%3D1%23L48%0Acontainer_min_memory%20%3D%20%22512KiB%22%0Adefault_annotations%20%3D%20%7B%22run.oci.systemd.subgroup%22%20%3D%20%22%22%7D%0A%0A%5Bcrio.runtime.workloads.openshift-builder%5D%0Aactivation_annotation%20%3D%20%22io.openshift.builder%22%0Aallowed_annotations%20%3D%20%5B%0A%20%20%22io.kubernetes.cri-o.userns-mode%22%2C%0A%20%20%22io.kubernetes.cri-o.Devices%22%0A%5D%0A%5Bcrio.runtime.workloads.openshift-builder.resources%5D%0A%0A%5Bcrio.image%5D%0Aglobal_auth_file%20%3D%20%22%2Fvar%2Flib%2Fkubelet%2Fconfig.json%22%0Apause_image%20%3D%20%22quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A2f61599219ee63c77391e05d2e02a8a5baae1c463d0ef965c49a5c470546db90%22%0Apause_image_auth_file%20%3D%20%22%2Fvar%2Flib%2Fkubelet%2Fconfig.json%22%0Apause_command%20%3D%20%22%2Fusr%2Fbin%2Fpod%22%0A%0A%5Bcrio.network%5D%0Anetwork_dir%20%3D%20%22%2Fetc%2Fkubernetes%2Fcni%2Fnet.d%2F%22%0Aplugin_dirs%20%3D%20%5B%0A%20%20%20%20%22%2Fvar%2Flib%2Fcni%2Fbin%22%2C%0A%20%20%20%20%22%2Fusr%2Flibexec%2Fcni%22%2C%0A%5D%0A%0A%5Bcrio.metrics%5D%0Aenable_metrics%20%3D%20true%0Ametrics_host%20%3D%20%22127.0.0.1%22%0Ametrics_port%20%3D%209537%0Ametrics_collectors%20%3D%20%5B%0A%20%20%22operations%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22operations_total%22%0A%20%20%22operations_latency_microseconds_total%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22operations_latency_seconds_total%22%0A%20%20%22operations_latency_microseconds%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22operations_latency_seconds%22%0A%20%20%22operations_errors%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22operations_errors_total%22%0A%20%20%22image_pulls_layer_size%22%2C%0A%20%20%22containers_oom_total%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22containers_oom_count_total%22%0A%20%20%22containers_oom%22%2C%0A%20%20%23%20Drop%20metrics%20with%20excessive%20label%20cardinality.%0A%20%20%23%20%22image_pulls_by_digest%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_pulls_bytes_total%22%0A%20%20%23%20%22image_pulls_by_name%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_pulls_bytes_total%22%0A%20%20%23%20%22image_pulls_by_name_skipped%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_pulls_skipped_bytes_total%22%0A%20%20%23%20%22image_pulls_failures%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_pulls_failure_total%22%0A%20%20%23%20%22image_pulls_successes%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_pulls_success_total%22%0A%20%20%23%20%22image_layer_reuse%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_layer_reuse_total%22%0A%20%20%22operations_total%22%2C%0A%20%20%22operations_latency_seconds_total%22%2C%0A%20%20%22operations_latency_seconds%22%2C%0A%20%20%22operations_errors_total%22%2C%0A%20%20%22image_pulls_bytes_total%22%2C%0A%20%20%22image_pulls_skipped_bytes_total%22%2C%0A%20%20%22image_pulls_success_total%22%2C%0A%20%20%22image_pulls_failure_total%22%2C%0A%20%20%22image_layer_reuse_total%22%2C%0A%20%20%22containers_oom_count_total%22%2C%0A%20%20%22processes_defunct%22%0A%5D%0A
          mode: 420
          overwrite: true
          path: /etc/crio/crio.conf.d/00-default
        - contents:
            source: data:,%7B%0A%20%20%20%20%22default%22%3A%20%5B%0A%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%22type%22%3A%20%22insecureAcceptAnything%22%0A%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%5D%2C%0A%20%20%20%20%22transports%22%3A%0A%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%22docker-daemon%22%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22%22%3A%20%5B%7B%22type%22%3A%22insecureAcceptAnything%22%7D%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20%20%20%7D%0A%7D%0A
          mode: 420
          overwrite: true
          path: /etc/machine-config-daemon/policy-for-old-podman.json
        - contents:
            source: data:,%7B%0A%20%20%20%20%22default%22%3A%20%5B%0A%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%22type%22%3A%20%22insecureAcceptAnything%22%0A%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%5D%2C%0A%20%20%20%20%22transports%22%3A%0A%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%22docker-daemon%22%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22%22%3A%20%5B%7B%22type%22%3A%22insecureAcceptAnything%22%7D%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20%20%20%7D%0A%7D
          mode: 420
          overwrite: true
          path: /etc/containers/policy.json
    fips: false
    kernelArguments: null
    kernelType: ""
    osImageURL: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4e309dd906392e783a404b92dfd4fa4c32d74e2804ee37d1fb8a00c9355d5978
- apiVersion: machineconfiguration.openshift.io/v1
  kind: MachineConfig
  metadata:
    annotations:
      machineconfiguration.openshift.io/generated-by-controller-version: fcf8f254943cbcba1400ba55f3978cc292b6460b
    creationTimestamp: "2025-11-04T16:09:16Z"
    generation: 1
    labels:
      machineconfiguration.openshift.io/role: master
    name: 01-master-kubelet
    ownerReferences:
    - apiVersion: machineconfiguration.openshift.io/v1
      blockOwnerDeletion: true
      controller: true
      kind: ControllerConfig
      name: machine-config-controller
      uid: 18dbcd72-fa02-401e-8486-bd239a092409
    resourceVersion: "10962"
    uid: 820f2391-2187-418b-8bdf-01c96774e2ed
  spec:
    baseOSExtensionsContainerImage: ""
    config:
      ignition:
        version: 3.4.0
      storage:
        files:
        - contents:
            source: data:,
          mode: 420
          overwrite: true
          path: /etc/kubernetes/cloud.conf
        - contents:
            source: data:,authorization%3A%0A%20%20static%3A%0A%20%20%20%20-%20resourceRequest%3A%20false%0A%20%20%20%20%20%20path%3A%20%2Fmetrics%0A%20%20%20%20%20%20verb%3A%20get%0A%20%20%20%20%20%20user%3A%0A%20%20%20%20%20%20%20%20name%3A%20system%3Aserviceaccount%3Aopenshift-monitoring%3Aprometheus-k8s
          mode: 420
          overwrite: true
          path: /etc/kubernetes/crio-metrics-proxy.cfg
        - contents:
            source: data:,apiVersion%3A%20v1%0Akind%3A%20Pod%0Ametadata%3A%0A%20%20name%3A%20kube-rbac-proxy-crio%0A%20%20namespace%3A%20openshift-machine-config-operator%0A%20%20annotations%3A%0A%20%20%20%20target.workload.openshift.io%2Fmanagement%3A%20'%7B%22effect%22%3A%20%22PreferredDuringScheduling%22%7D'%0A%20%20%20%20openshift.io%2Frequired-scc%3A%20privileged%0Aspec%3A%0A%20%20volumes%3A%0A%20%20-%20name%3A%20etc-kube%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fetc%2Fkubernetes%22%0A%20%20-%20name%3A%20var-lib-kubelet%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20hostNetwork%3A%20true%0A%20%20priorityClassName%3A%20system-cluster-critical%0A%20%20initContainers%3A%0A%20%20-%20name%3A%20setup%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3Ab6413e64e7d5885315b3cabc65c2af82135ee649b1664976b3d300884d302414%0A%20%20%20%20imagePullPolicy%3A%20IfNotPresent%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20var-lib-kubelet%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20command%3A%20%5B'%2Fbin%2Fbash'%2C%20'-ec'%5D%0A%20%20%20%20args%3A%0A%20%20%20%20-%20%7C%0A%20%20%20%20%20%20echo%20-n%20%22Waiting%20for%20kubelet%20key%20and%20certificate%20to%20be%20available%22%0A%20%20%20%20%20%20while%20%5B%20-n%20%22%24(test%20-e%20%2Fvar%2Flib%2Fkubelet%2Fpki%2Fkubelet-server-current.pem)%22%20%5D%20%3B%20do%0A%20%20%20%20%20%20%20%20echo%20-n%20%22.%22%0A%20%20%20%20%20%20%20%20sleep%201%0A%20%20%20%20%20%20%20%20((%20tries%20%2B%3D%201%20))%0A%20%20%20%20%20%20%20%20if%20%5B%5B%20%22%24%7Btries%7D%22%20-gt%2010%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20echo%20%22Timed%20out%20waiting%20for%20kubelet%20key%20and%20cert.%22%0A%20%20%20%20%20%20%20%20%20%20exit%201%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20done%0A%20%20%20%20securityContext%3A%0A%20%20%20%20%20%20privileged%3A%20true%0A%20%20%20%20resources%3A%0A%20%20%20%20%20%20requests%3A%0A%20%20%20%20%20%20%20%20memory%3A%2050Mi%0A%20%20%20%20%20%20%20%20cpu%3A%205m%0A%20%20containers%3A%0A%20%20-%20name%3A%20kube-rbac-proxy-crio%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3Ab6413e64e7d5885315b3cabc65c2af82135ee649b1664976b3d300884d302414%0A%20%20%20%20securityContext%3A%0A%20%20%20%20%20%20privileged%3A%20true%0A%20%20%20%20ports%3A%0A%20%20%20%20-%20containerPort%3A%209637%0A%20%20%20%20args%3A%0A%20%20%20%20-%20--secure-listen-address%3D%3A9637%0A%20%20%20%20-%20--config-file%3D%2Fetc%2Fkubernetes%2Fcrio-metrics-proxy.cfg%0A%20%20%20%20-%20--client-ca-file%3D%2Fetc%2Fkubernetes%2Fkubelet-ca.crt%0A%20%20%20%20-%20--logtostderr%3Dtrue%0A%20%20%20%20-%20--kubeconfig%3D%2Fvar%2Flib%2Fkubelet%2Fkubeconfig%0A%20%20%20%20-%20--tls-cipher-suites%3DTLS_AES_128_GCM_SHA256%2CTLS_AES_256_GCM_SHA384%2CTLS_CHACHA20_POLY1305_SHA256%2CTLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256%2CTLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256%2CTLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384%2CTLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384%2CTLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256%2CTLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256%20%0A%20%20%20%20-%20--tls-min-version%3DVersionTLS12%0A%20%20%20%20-%20--upstream%3Dhttp%3A%2F%2F127.0.0.1%3A9537%0A%20%20%20%20-%20--tls-cert-file%3D%2Fvar%2Flib%2Fkubelet%2Fpki%2Fkubelet-server-current.pem%0A%20%20%20%20-%20--tls-private-key-file%3D%2Fvar%2Flib%2Fkubelet%2Fpki%2Fkubelet-server-current.pem%0A%20%20%20%20resources%3A%0A%20%20%20%20%20%20requests%3A%0A%20%20%20%20%20%20%20%20cpu%3A%2020m%0A%20%20%20%20%20%20%20%20memory%3A%2050Mi%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20etc-kube%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fkubernetes%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20%20%20readOnly%3A%20true%0A%20%20%20%20-%20name%3A%20var-lib-kubelet%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20%20%20readOnly%3A%20true
          mode: 420
          overwrite: true
          path: /etc/kubernetes/manifests/criometricsproxy.yaml
        - contents:
            source: data:,kind%3A%20KubeletConfiguration%0AapiVersion%3A%20kubelet.config.k8s.io%2Fv1beta1%0Aauthentication%3A%0A%20%20x509%3A%0A%20%20%20%20clientCAFile%3A%20%2Fetc%2Fkubernetes%2Fkubelet-ca.crt%0A%20%20anonymous%3A%0A%20%20%20%20enabled%3A%20false%0AcgroupDriver%3A%20systemd%0AcgroupRoot%3A%20%2F%0AclusterDNS%3A%0A%20%20-%20172.30.0.10%0AclusterDomain%3A%20cluster.local%0AcontainerLogMaxSize%3A%2050Mi%0AenableSystemLogQuery%3A%20true%0AmaxPods%3A%20250%0AkubeAPIQPS%3A%2050%0AkubeAPIBurst%3A%20100%0ApodPidsLimit%3A%204096%0AprotectKernelDefaults%3A%20true%0ArotateCertificates%3A%20true%0AserializeImagePulls%3A%20false%0AstaticPodPath%3A%20%2Fetc%2Fkubernetes%2Fmanifests%0AsystemCgroups%3A%20%2Fsystem.slice%0AnodeStatusUpdateFrequency%3A%2010s%0AnodeStatusReportFrequency%3A%205m%0AserverTLSBootstrap%3A%20true%0AtlsMinVersion%3A%20VersionTLS12%0AtlsCipherSuites%3A%0A%20%20%20%20-%20TLS_AES_128_GCM_SHA256%0A%20%20%20%20-%20TLS_AES_256_GCM_SHA384%0A%20%20%20%20-%20TLS_CHACHA20_POLY1305_SHA256%0A%20%20%20%20-%20TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256%0A%20%20%20%20-%20TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256%0A%20%20%20%20-%20TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384%0A%20%20%20%20-%20TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384%0A%20%20%20%20-%20TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256%0A%20%20%20%20-%20TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256%0A
          mode: 420
          overwrite: true
          path: /etc/kubernetes/kubelet.conf
        - contents:
            source: data:,%23!%2Fbin%2Fsh%0Aif%20%5B%20-x%20%2Fusr%2Fbin%2Fkubensenter%20%5D%3B%20then%0A%20%20exec%20%2Fusr%2Fbin%2Fkubensenter%20%22%24%40%22%0Aelse%0A%20%20exec%20%22%24%40%22%0Afi%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/kubenswrapper
      systemd:
        units:
        - contents: |
            [Unit]
            Description=Kubernetes Kubelet After Reboot Cleanup
            Before=kubelet.service

            [Service]
            Type=oneshot
            ExecStart=/bin/rm -f /var/lib/kubelet/cpu_manager_state
            ExecStart=/bin/rm -f /var/lib/kubelet/memory_manager_state
            ExecStart=-/bin/rm -f /var/lib/kubelet/dra_manager_state

            [Install]
            WantedBy=multi-user.target
          enabled: true
          name: kubelet-cleanup.service
        - contents: |
            [Unit]
            Description=Kubernetes Kubelet
            Requires=crio.service kubelet-dependencies.target
            After=kubelet-dependencies.target
            After=ostree-finalize-staged.service

            [Service]
            Type=notify
            ExecStartPre=/bin/mkdir --parents /etc/kubernetes/manifests
            ExecStartPre=-/usr/sbin/restorecon -ri /var/lib/kubelet/pod-resources /usr/local/bin/kubenswrapper /usr/bin/kubensenter
            Environment="KUBELET_NODE_IP=0.0.0.0"
            EnvironmentFile=/etc/os-release
            EnvironmentFile=-/etc/kubernetes/kubelet-workaround
            EnvironmentFile=-/etc/kubernetes/kubelet-env
            EnvironmentFile=/etc/node-sizing.env

            ExecStart=/usr/local/bin/kubenswrapper \
                /usr/bin/kubelet \
                  --config=/etc/kubernetes/kubelet.conf \
                  --bootstrap-kubeconfig=/etc/kubernetes/kubeconfig \
                  --kubeconfig=/var/lib/kubelet/kubeconfig \
                  --container-runtime-endpoint=/var/run/crio/crio.sock \
                  --runtime-cgroups=/system.slice/crio.service \
                  --node-labels=node-role.kubernetes.io/control-plane,node-role.kubernetes.io/master,node.openshift.io/os_id=${ID} \
                  --node-ip=${KUBELET_NODE_IP} \
                  --address=${KUBELET_NODE_IP} \
                  --minimum-container-ttl-duration=6m0s \
                  --cloud-provider= \
                  --volume-plugin-dir=/etc/kubernetes/kubelet-plugins/volume/exec \
                  --hostname-override=${KUBELET_NODE_NAME} \
                  --register-with-taints=node-role.kubernetes.io/master=:NoSchedule \
                  --pod-infra-container-image=quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:2f61599219ee63c77391e05d2e02a8a5baae1c463d0ef965c49a5c470546db90 \
                  --system-reserved=cpu=${SYSTEM_RESERVED_CPU},memory=${SYSTEM_RESERVED_MEMORY},ephemeral-storage=${SYSTEM_RESERVED_ES} \
                  --v=${KUBELET_LOG_LEVEL}

            Restart=always
            RestartSec=10

            [Install]
            WantedBy=multi-user.target
          enabled: true
          name: kubelet.service
    fips: false
    kernelArguments: null
    kernelType: ""
    osImageURL: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4e309dd906392e783a404b92dfd4fa4c32d74e2804ee37d1fb8a00c9355d5978
- apiVersion: machineconfiguration.openshift.io/v1
  kind: MachineConfig
  metadata:
    annotations:
      machineconfiguration.openshift.io/generated-by-controller-version: fcf8f254943cbcba1400ba55f3978cc292b6460b
    creationTimestamp: "2025-11-04T16:09:16Z"
    generation: 1
    labels:
      machineconfiguration.openshift.io/role: worker
    name: 01-worker-container-runtime
    ownerReferences:
    - apiVersion: machineconfiguration.openshift.io/v1
      blockOwnerDeletion: true
      controller: true
      kind: ControllerConfig
      name: machine-config-controller
      uid: 18dbcd72-fa02-401e-8486-bd239a092409
    resourceVersion: "10977"
    uid: a9003ef2-f50e-40c9-aaf7-297aecde3d5d
  spec:
    baseOSExtensionsContainerImage: ""
    config:
      ignition:
        version: 3.4.0
      storage:
        files:
        - contents:
            source: data:,unqualified-search-registries%20%3D%20%5B'registry.access.redhat.com'%2C%20'docker.io'%5D%0A
          mode: 420
          overwrite: true
          path: /etc/containers/registries.conf
        - contents:
            source: data:,%5Bcrio%5D%0Ainternal_wipe%20%3D%20true%0Ainternal_repair%20%3D%20true%0A%0A%5Bcrio.api%5D%0Astream_address%20%3D%20%22127.0.0.1%22%0Astream_port%20%3D%20%220%22%0A%0A%5Bcrio.runtime%5D%0Aselinux%20%3D%20true%0Aconmon%20%3D%20%22%22%0Aconmon_cgroup%20%3D%20%22pod%22%0Adefault_env%20%3D%20%5B%0A%20%20%20%20%22NSS_SDB_USE_CACHE%3Dno%22%2C%0A%5D%0Alog_level%20%3D%20%22info%22%0Acgroup_manager%20%3D%20%22systemd%22%0Adefault_sysctls%20%3D%20%5B%0A%20%20%20%20%22net.ipv4.ping_group_range%3D0%202147483647%22%2C%0A%5D%0Adefault_runtime%20%3D%20%22crun%22%0Ahooks_dir%20%3D%20%5B%0A%20%20%20%20%22%2Fetc%2Fcontainers%2Foci%2Fhooks.d%22%2C%0A%20%20%20%20%22%2Frun%2Fcontainers%2Foci%2Fhooks.d%22%2C%0A%20%20%20%20%22%2Fusr%2Fshare%2Fcontainers%2Foci%2Fhooks.d%22%2C%0A%5D%0Amanage_ns_lifecycle%20%3D%20true%0Aabsent_mount_sources_to_reject%20%3D%20%5B%0A%20%20%20%20%22%2Fetc%2Fhostname%22%2C%0A%5D%0Adrop_infra_ctr%20%3D%20true%0A%0A%5Bcrio.runtime.runtimes.runc%5D%0Aruntime_root%20%3D%20%22%2Frun%2Frunc%22%0Aallowed_annotations%20%3D%20%5B%0A%20%20%20%20%22io.containers.trace-syscall%22%2C%0A%20%20%20%20%22io.kubernetes.cri-o.Devices%22%2C%0A%20%20%20%20%22io.kubernetes.cri-o.LinkLogs%22%2C%0A%5D%0A%0A%5Bcrio.runtime.runtimes.crun%5D%0Aruntime_root%20%3D%20%22%2Frun%2Fcrun%22%0Aallowed_annotations%20%3D%20%5B%0A%20%20%20%20%22io.containers.trace-syscall%22%2C%0A%20%20%20%20%22io.kubernetes.cri-o.Devices%22%2C%0A%20%20%20%20%22io.kubernetes.cri-o.LinkLogs%22%2C%0A%5D%0A%23%20Based%20on%20https%3A%2F%2Fgithub.com%2Fcontainers%2Fcrun%2Fblob%2F27d7dd3a0%2FREADME.md%3Fplain%3D1%23L48%0Acontainer_min_memory%20%3D%20%22512KiB%22%0Adefault_annotations%20%3D%20%7B%22run.oci.systemd.subgroup%22%20%3D%20%22%22%7D%0A%0A%5Bcrio.runtime.workloads.openshift-builder%5D%0Aactivation_annotation%20%3D%20%22io.openshift.builder%22%0Aallowed_annotations%20%3D%20%5B%0A%20%20%22io.kubernetes.cri-o.userns-mode%22%2C%0A%20%20%22io.kubernetes.cri-o.Devices%22%0A%5D%0A%5Bcrio.runtime.workloads.openshift-builder.resources%5D%0A%0A%5Bcrio.image%5D%0Aglobal_auth_file%20%3D%20%22%2Fvar%2Flib%2Fkubelet%2Fconfig.json%22%0Apause_image%20%3D%20%22quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A2f61599219ee63c77391e05d2e02a8a5baae1c463d0ef965c49a5c470546db90%22%0Apause_image_auth_file%20%3D%20%22%2Fvar%2Flib%2Fkubelet%2Fconfig.json%22%0Apause_command%20%3D%20%22%2Fusr%2Fbin%2Fpod%22%0A%0A%5Bcrio.network%5D%0Anetwork_dir%20%3D%20%22%2Fetc%2Fkubernetes%2Fcni%2Fnet.d%2F%22%0Aplugin_dirs%20%3D%20%5B%0A%20%20%20%20%22%2Fvar%2Flib%2Fcni%2Fbin%22%2C%0A%20%20%20%20%22%2Fusr%2Flibexec%2Fcni%22%2C%0A%5D%0A%0A%5Bcrio.metrics%5D%0Aenable_metrics%20%3D%20true%0Ametrics_host%20%3D%20%22127.0.0.1%22%0Ametrics_port%20%3D%209537%0Ametrics_collectors%20%3D%20%5B%0A%20%20%22operations%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22operations_total%22%0A%20%20%22operations_latency_microseconds_total%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22operations_latency_seconds_total%22%0A%20%20%22operations_latency_microseconds%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22operations_latency_seconds%22%0A%20%20%22operations_errors%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22operations_errors_total%22%0A%20%20%22image_pulls_layer_size%22%2C%0A%20%20%22containers_oom_total%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22containers_oom_count_total%22%0A%20%20%22containers_oom%22%2C%0A%20%20%23%20Drop%20metrics%20with%20excessive%20label%20cardinality.%0A%20%20%23%20%22image_pulls_by_digest%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_pulls_bytes_total%22%0A%20%20%23%20%22image_pulls_by_name%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_pulls_bytes_total%22%0A%20%20%23%20%22image_pulls_by_name_skipped%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_pulls_skipped_bytes_total%22%0A%20%20%23%20%22image_pulls_failures%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_pulls_failure_total%22%0A%20%20%23%20%22image_pulls_successes%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_pulls_success_total%22%0A%20%20%23%20%22image_layer_reuse%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_layer_reuse_total%22%0A%20%20%22operations_total%22%2C%0A%20%20%22operations_latency_seconds_total%22%2C%0A%20%20%22operations_latency_seconds%22%2C%0A%20%20%22operations_errors_total%22%2C%0A%20%20%22image_pulls_bytes_total%22%2C%0A%20%20%22image_pulls_skipped_bytes_total%22%2C%0A%20%20%22image_pulls_success_total%22%2C%0A%20%20%22image_pulls_failure_total%22%2C%0A%20%20%22image_layer_reuse_total%22%2C%0A%20%20%22containers_oom_count_total%22%2C%0A%20%20%22processes_defunct%22%0A%5D%0A
          mode: 420
          overwrite: true
          path: /etc/crio/crio.conf.d/00-default
        - contents:
            source: data:,%7B%0A%20%20%20%20%22default%22%3A%20%5B%0A%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%22type%22%3A%20%22insecureAcceptAnything%22%0A%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%5D%2C%0A%20%20%20%20%22transports%22%3A%0A%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%22docker-daemon%22%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22%22%3A%20%5B%7B%22type%22%3A%22insecureAcceptAnything%22%7D%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20%20%20%7D%0A%7D%0A
          mode: 420
          overwrite: true
          path: /etc/machine-config-daemon/policy-for-old-podman.json
        - contents:
            source: data:,%7B%0A%20%20%20%20%22default%22%3A%20%5B%0A%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%22type%22%3A%20%22insecureAcceptAnything%22%0A%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%5D%2C%0A%20%20%20%20%22transports%22%3A%0A%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%22docker-daemon%22%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22%22%3A%20%5B%7B%22type%22%3A%22insecureAcceptAnything%22%7D%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20%20%20%7D%0A%7D
          mode: 420
          overwrite: true
          path: /etc/containers/policy.json
    fips: false
    kernelArguments: null
    kernelType: ""
    osImageURL: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4e309dd906392e783a404b92dfd4fa4c32d74e2804ee37d1fb8a00c9355d5978
- apiVersion: machineconfiguration.openshift.io/v1
  kind: MachineConfig
  metadata:
    annotations:
      machineconfiguration.openshift.io/generated-by-controller-version: fcf8f254943cbcba1400ba55f3978cc292b6460b
    creationTimestamp: "2025-11-04T16:09:16Z"
    generation: 1
    labels:
      machineconfiguration.openshift.io/role: worker
    name: 01-worker-kubelet
    ownerReferences:
    - apiVersion: machineconfiguration.openshift.io/v1
      blockOwnerDeletion: true
      controller: true
      kind: ControllerConfig
      name: machine-config-controller
      uid: 18dbcd72-fa02-401e-8486-bd239a092409
    resourceVersion: "10995"
    uid: ce2e5d9f-23be-4908-aa19-fe0c378719e1
  spec:
    baseOSExtensionsContainerImage: ""
    config:
      ignition:
        version: 3.4.0
      storage:
        files:
        - contents:
            source: data:,
          mode: 420
          overwrite: true
          path: /etc/kubernetes/cloud.conf
        - contents:
            source: data:,authorization%3A%0A%20%20static%3A%0A%20%20%20%20-%20resourceRequest%3A%20false%0A%20%20%20%20%20%20path%3A%20%2Fmetrics%0A%20%20%20%20%20%20verb%3A%20get%0A%20%20%20%20%20%20user%3A%0A%20%20%20%20%20%20%20%20name%3A%20system%3Aserviceaccount%3Aopenshift-monitoring%3Aprometheus-k8s
          mode: 420
          overwrite: true
          path: /etc/kubernetes/crio-metrics-proxy.cfg
        - contents:
            source: data:,apiVersion%3A%20v1%0Akind%3A%20Pod%0Ametadata%3A%0A%20%20name%3A%20kube-rbac-proxy-crio%0A%20%20namespace%3A%20openshift-machine-config-operator%0A%20%20annotations%3A%0A%20%20%20%20target.workload.openshift.io%2Fmanagement%3A%20'%7B%22effect%22%3A%20%22PreferredDuringScheduling%22%7D'%0A%20%20%20%20openshift.io%2Frequired-scc%3A%20privileged%0Aspec%3A%0A%20%20volumes%3A%0A%20%20-%20name%3A%20etc-kube%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fetc%2Fkubernetes%22%0A%20%20-%20name%3A%20var-lib-kubelet%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20hostNetwork%3A%20true%0A%20%20priorityClassName%3A%20system-cluster-critical%0A%20%20initContainers%3A%0A%20%20-%20name%3A%20setup%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3Ab6413e64e7d5885315b3cabc65c2af82135ee649b1664976b3d300884d302414%0A%20%20%20%20imagePullPolicy%3A%20IfNotPresent%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20var-lib-kubelet%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20command%3A%20%5B'%2Fbin%2Fbash'%2C%20'-ec'%5D%0A%20%20%20%20args%3A%0A%20%20%20%20-%20%7C%0A%20%20%20%20%20%20echo%20-n%20%22Waiting%20for%20kubelet%20key%20and%20certificate%20to%20be%20available%22%0A%20%20%20%20%20%20while%20%5B%20-n%20%22%24(test%20-e%20%2Fvar%2Flib%2Fkubelet%2Fpki%2Fkubelet-server-current.pem)%22%20%5D%20%3B%20do%0A%20%20%20%20%20%20%20%20echo%20-n%20%22.%22%0A%20%20%20%20%20%20%20%20sleep%201%0A%20%20%20%20%20%20%20%20((%20tries%20%2B%3D%201%20))%0A%20%20%20%20%20%20%20%20if%20%5B%5B%20%22%24%7Btries%7D%22%20-gt%2010%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20echo%20%22Timed%20out%20waiting%20for%20kubelet%20key%20and%20cert.%22%0A%20%20%20%20%20%20%20%20%20%20exit%201%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20done%0A%20%20%20%20securityContext%3A%0A%20%20%20%20%20%20privileged%3A%20true%0A%20%20%20%20resources%3A%0A%20%20%20%20%20%20requests%3A%0A%20%20%20%20%20%20%20%20memory%3A%2050Mi%0A%20%20%20%20%20%20%20%20cpu%3A%205m%0A%20%20containers%3A%0A%20%20-%20name%3A%20kube-rbac-proxy-crio%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3Ab6413e64e7d5885315b3cabc65c2af82135ee649b1664976b3d300884d302414%0A%20%20%20%20securityContext%3A%0A%20%20%20%20%20%20privileged%3A%20true%0A%20%20%20%20ports%3A%0A%20%20%20%20-%20containerPort%3A%209637%0A%20%20%20%20args%3A%0A%20%20%20%20-%20--secure-listen-address%3D%3A9637%0A%20%20%20%20-%20--config-file%3D%2Fetc%2Fkubernetes%2Fcrio-metrics-proxy.cfg%0A%20%20%20%20-%20--client-ca-file%3D%2Fetc%2Fkubernetes%2Fkubelet-ca.crt%0A%20%20%20%20-%20--logtostderr%3Dtrue%0A%20%20%20%20-%20--kubeconfig%3D%2Fvar%2Flib%2Fkubelet%2Fkubeconfig%0A%20%20%20%20-%20--tls-cipher-suites%3DTLS_AES_128_GCM_SHA256%2CTLS_AES_256_GCM_SHA384%2CTLS_CHACHA20_POLY1305_SHA256%2CTLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256%2CTLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256%2CTLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384%2CTLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384%2CTLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256%2CTLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256%20%0A%20%20%20%20-%20--tls-min-version%3DVersionTLS12%0A%20%20%20%20-%20--upstream%3Dhttp%3A%2F%2F127.0.0.1%3A9537%0A%20%20%20%20-%20--tls-cert-file%3D%2Fvar%2Flib%2Fkubelet%2Fpki%2Fkubelet-server-current.pem%0A%20%20%20%20-%20--tls-private-key-file%3D%2Fvar%2Flib%2Fkubelet%2Fpki%2Fkubelet-server-current.pem%0A%20%20%20%20resources%3A%0A%20%20%20%20%20%20requests%3A%0A%20%20%20%20%20%20%20%20cpu%3A%2020m%0A%20%20%20%20%20%20%20%20memory%3A%2050Mi%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20etc-kube%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fkubernetes%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20%20%20readOnly%3A%20true%0A%20%20%20%20-%20name%3A%20var-lib-kubelet%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20%20%20readOnly%3A%20true
          mode: 420
          overwrite: true
          path: /etc/kubernetes/manifests/criometricsproxy.yaml
        - contents:
            source: data:,kind%3A%20KubeletConfiguration%0AapiVersion%3A%20kubelet.config.k8s.io%2Fv1beta1%0Aauthentication%3A%0A%20%20x509%3A%0A%20%20%20%20clientCAFile%3A%20%2Fetc%2Fkubernetes%2Fkubelet-ca.crt%0A%20%20anonymous%3A%0A%20%20%20%20enabled%3A%20false%0AcgroupDriver%3A%20systemd%0AcgroupRoot%3A%20%2F%0AclusterDNS%3A%0A%20%20-%20172.30.0.10%0AclusterDomain%3A%20cluster.local%0AcontainerLogMaxSize%3A%2050Mi%0AenableSystemLogQuery%3A%20true%0AmaxPods%3A%20250%0AkubeAPIQPS%3A%2050%0AkubeAPIBurst%3A%20100%0ApodPidsLimit%3A%204096%0AprotectKernelDefaults%3A%20true%0ArotateCertificates%3A%20true%0AserializeImagePulls%3A%20false%0AstaticPodPath%3A%20%2Fetc%2Fkubernetes%2Fmanifests%0AsystemCgroups%3A%20%2Fsystem.slice%0AnodeStatusUpdateFrequency%3A%2010s%0AnodeStatusReportFrequency%3A%205m%0AserverTLSBootstrap%3A%20true%0AtlsMinVersion%3A%20VersionTLS12%0AtlsCipherSuites%3A%0A%20%20%20%20-%20TLS_AES_128_GCM_SHA256%0A%20%20%20%20-%20TLS_AES_256_GCM_SHA384%0A%20%20%20%20-%20TLS_CHACHA20_POLY1305_SHA256%0A%20%20%20%20-%20TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256%0A%20%20%20%20-%20TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256%0A%20%20%20%20-%20TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384%0A%20%20%20%20-%20TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384%0A%20%20%20%20-%20TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256%0A%20%20%20%20-%20TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256%0A
          mode: 420
          overwrite: true
          path: /etc/kubernetes/kubelet.conf
        - contents:
            source: data:,%23!%2Fbin%2Fsh%0Aif%20%5B%20-x%20%2Fusr%2Fbin%2Fkubensenter%20%5D%3B%20then%0A%20%20exec%20%2Fusr%2Fbin%2Fkubensenter%20%22%24%40%22%0Aelse%0A%20%20exec%20%22%24%40%22%0Afi%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/kubenswrapper
      systemd:
        units:
        - contents: |
            [Unit]
            Description=Kubernetes Kubelet After Reboot Cleanup
            Before=kubelet.service

            [Service]
            Type=oneshot
            ExecStart=/bin/rm -f /var/lib/kubelet/cpu_manager_state
            ExecStart=/bin/rm -f /var/lib/kubelet/memory_manager_state
            ExecStart=-/bin/rm -f /var/lib/kubelet/dra_manager_state

            [Install]
            WantedBy=multi-user.target
          enabled: true
          name: kubelet-cleanup.service
        - contents: |
            [Unit]
            Description=Kubernetes Kubelet
            Requires=crio.service kubelet-dependencies.target
            After=kubelet-dependencies.target
            After=ostree-finalize-staged.service

            [Service]
            Type=notify
            ExecStartPre=/bin/mkdir --parents /etc/kubernetes/manifests
            ExecStartPre=-/usr/sbin/restorecon -ri /var/lib/kubelet/pod-resources /usr/local/bin/kubenswrapper /usr/bin/kubensenter
            Environment="KUBELET_NODE_IP=0.0.0.0"
            EnvironmentFile=/etc/os-release
            EnvironmentFile=-/etc/kubernetes/kubelet-workaround
            EnvironmentFile=-/etc/kubernetes/kubelet-env
            EnvironmentFile=/etc/node-sizing.env

            ExecStart=/usr/local/bin/kubenswrapper \
                /usr/bin/kubelet \
                  --config=/etc/kubernetes/kubelet.conf \
                  --bootstrap-kubeconfig=/etc/kubernetes/kubeconfig \
                  --kubeconfig=/var/lib/kubelet/kubeconfig \
                  --container-runtime-endpoint=/var/run/crio/crio.sock \
                  --runtime-cgroups=/system.slice/crio.service \
                  --node-labels=node-role.kubernetes.io/worker,node.openshift.io/os_id=${ID},${CUSTOM_KUBELET_LABELS} \
                  --node-ip=${KUBELET_NODE_IP} \
                  --address=${KUBELET_NODE_IP} \
                  --minimum-container-ttl-duration=6m0s \
                  --volume-plugin-dir=/etc/kubernetes/kubelet-plugins/volume/exec \
                  --cloud-provider= \
                  --hostname-override=${KUBELET_NODE_NAME} \
                  --pod-infra-container-image=quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:2f61599219ee63c77391e05d2e02a8a5baae1c463d0ef965c49a5c470546db90 \
                  --system-reserved=cpu=${SYSTEM_RESERVED_CPU},memory=${SYSTEM_RESERVED_MEMORY},ephemeral-storage=${SYSTEM_RESERVED_ES} \
                  --v=${KUBELET_LOG_LEVEL}

            Restart=always
            RestartSec=10

            [Install]
            WantedBy=multi-user.target
          enabled: true
          name: kubelet.service
    fips: false
    kernelArguments: null
    kernelType: ""
    osImageURL: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4e309dd906392e783a404b92dfd4fa4c32d74e2804ee37d1fb8a00c9355d5978
- apiVersion: machineconfiguration.openshift.io/v1
  kind: MachineConfig
  metadata:
    creationTimestamp: "2025-11-04T15:48:26Z"
    generation: 1
    labels:
      machineconfiguration.openshift.io/role: master
    name: 50-masters-chrony-configuration
    resourceVersion: "2577"
    uid: 58be4e02-0806-40b0-9971-bab5c178109b
  spec:
    config:
      ignition:
        version: 3.1.0
      storage:
        files:
        - contents:
            source: data:text/plain;charset=utf-8;base64,CnBvb2wgMC5yaGVsLnBvb2wubnRwLm9yZyBpYnVyc3QKZHJpZnRmaWxlIC92YXIvbGliL2Nocm9ueS9kcmlmdAptYWtlc3RlcCAxLjAgMwpydGNzeW5jCmxvZ2RpciAvdmFyL2xvZy9jaHJvbnkKc2VydmVyIDc0LjIwOC4yNS40NiBpYnVyc3QKc2VydmVyIHRpbWUubG10bGFicy5jb20gaWJ1cnN0CnNlcnZlciBsaXRoaXVtLmNvbnN0YW50LmNvbSBpYnVyc3QKc2VydmVyIDY5LjE3Ni44NC4zOCBpYnVyc3QKc2VydmVyIGFybTEubWF4aG9zdC5pbyBpYnVyc3QKc2VydmVyIG50cDEubGF4LnVzLmhvam1hcmsubmV0IGlidXJzdApzZXJ2ZXIgbnRwMTEua2VybmZ1c2lvbi5hdCBpYnVyc3QKc2VydmVyIHRyaWFuZ2xlLmthbnNhcy5uZXQgaWJ1cnN0
          mode: 420
          overwrite: true
          path: /etc/chrony.conf
- apiVersion: machineconfiguration.openshift.io/v1
  kind: MachineConfig
  metadata:
    creationTimestamp: "2025-11-04T15:48:14Z"
    generation: 1
    labels:
      machineconfiguration.openshift.io/role: master
    name: 50-masters-enable-schedstats
    resourceVersion: "2016"
    uid: f6b95321-6c3b-491b-8ab5-e6bece5dfb7e
  spec:
    kernelArguments:
    - schedstats=enable
- apiVersion: machineconfiguration.openshift.io/v1
  kind: MachineConfig
  metadata:
    creationTimestamp: "2025-11-04T15:48:26Z"
    generation: 1
    labels:
      machineconfiguration.openshift.io/role: worker
    name: 50-workers-chrony-configuration
    resourceVersion: "2582"
    uid: 637493a8-5281-458a-873e-028a3029a29e
  spec:
    config:
      ignition:
        version: 3.1.0
      storage:
        files:
        - contents:
            source: data:text/plain;charset=utf-8;base64,CnBvb2wgMC5yaGVsLnBvb2wubnRwLm9yZyBpYnVyc3QKZHJpZnRmaWxlIC92YXIvbGliL2Nocm9ueS9kcmlmdAptYWtlc3RlcCAxLjAgMwpydGNzeW5jCmxvZ2RpciAvdmFyL2xvZy9jaHJvbnkKc2VydmVyIDc0LjIwOC4yNS40NiBpYnVyc3QKc2VydmVyIHRpbWUubG10bGFicy5jb20gaWJ1cnN0CnNlcnZlciBsaXRoaXVtLmNvbnN0YW50LmNvbSBpYnVyc3QKc2VydmVyIDY5LjE3Ni44NC4zOCBpYnVyc3QKc2VydmVyIGFybTEubWF4aG9zdC5pbyBpYnVyc3QKc2VydmVyIG50cDEubGF4LnVzLmhvam1hcmsubmV0IGlidXJzdApzZXJ2ZXIgbnRwMTEua2VybmZ1c2lvbi5hdCBpYnVyc3QKc2VydmVyIHRyaWFuZ2xlLmthbnNhcy5uZXQgaWJ1cnN0
          mode: 420
          overwrite: true
          path: /etc/chrony.conf
- apiVersion: machineconfiguration.openshift.io/v1
  kind: MachineConfig
  metadata:
    creationTimestamp: "2025-11-04T15:48:15Z"
    generation: 1
    labels:
      machineconfiguration.openshift.io/role: worker
    name: 50-workers-enable-schedstats
    resourceVersion: "2039"
    uid: 4f40da28-e72e-429d-8297-9491a7b477bd
  spec:
    kernelArguments:
    - schedstats=enable
- apiVersion: machineconfiguration.openshift.io/v1
  kind: MachineConfig
  metadata:
    annotations:
      machineconfiguration.openshift.io/generated-by-controller-version: fcf8f254943cbcba1400ba55f3978cc292b6460b
    creationTimestamp: "2025-11-04T16:09:17Z"
    generation: 1
    labels:
      machineconfiguration.openshift.io/role: master
    name: 97-master-generated-kubelet
    resourceVersion: "11016"
    uid: 307e5281-013d-438a-a859-53dddb1da6cc
  spec:
    baseOSExtensionsContainerImage: ""
    config:
      ignition:
        version: 3.4.0
      storage:
        files:
        - contents:
            compression: ""
            source: data:text/plain;charset=utf-8;base64,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
          mode: 420
          overwrite: true
          path: /etc/kubernetes/kubelet.conf
    fips: false
    kernelArguments:
    - systemd.unified_cgroup_hierarchy=1
    - cgroup_no_v1="all"
    - psi=0
    kernelType: ""
    osImageURL: ""
- apiVersion: machineconfiguration.openshift.io/v1
  kind: MachineConfig
  metadata:
    annotations:
      machineconfiguration.openshift.io/generated-by-controller-version: fcf8f254943cbcba1400ba55f3978cc292b6460b
    creationTimestamp: "2025-11-04T16:09:18Z"
    generation: 1
    labels:
      machineconfiguration.openshift.io/role: worker
    name: 97-worker-generated-kubelet
    resourceVersion: "11055"
    uid: 475522d6-a336-47b6-8dec-b9a9a0fab2be
  spec:
    baseOSExtensionsContainerImage: ""
    config:
      ignition:
        version: 3.4.0
      storage:
        files:
        - contents:
            compression: ""
            source: data:text/plain;charset=utf-8;base64,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
          mode: 420
          overwrite: true
          path: /etc/kubernetes/kubelet.conf
    fips: false
    kernelArguments:
    - systemd.unified_cgroup_hierarchy=1
    - cgroup_no_v1="all"
    - psi=0
    kernelType: ""
    osImageURL: ""
- apiVersion: machineconfiguration.openshift.io/v1
  kind: MachineConfig
  metadata:
    annotations:
      machineconfiguration.openshift.io/generated-by-controller-version: fcf8f254943cbcba1400ba55f3978cc292b6460b
    creationTimestamp: "2025-11-04T16:09:16Z"
    generation: 1
    labels:
      machineconfiguration.openshift.io/role: master
    name: 98-master-generated-kubelet
    resourceVersion: "10963"
    uid: a018f5cf-70b0-4166-94e1-cf42001f8fa2
  spec:
    baseOSExtensionsContainerImage: ""
    config:
      ignition:
        version: 3.4.0
      storage:
        files:
        - contents:
            compression: ""
            source: data:text/plain;charset=utf-8;base64,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
          mode: 420
          overwrite: true
          path: /etc/kubernetes/kubelet.conf
    fips: false
    kernelArguments: null
    kernelType: ""
    osImageURL: ""
- apiVersion: machineconfiguration.openshift.io/v1
  kind: MachineConfig
  metadata:
    annotations:
      machineconfiguration.openshift.io/generated-by-controller-version: fcf8f254943cbcba1400ba55f3978cc292b6460b
    creationTimestamp: "2025-11-04T16:09:16Z"
    generation: 1
    labels:
      machineconfiguration.openshift.io/role: worker
    name: 98-worker-generated-kubelet
    resourceVersion: "10985"
    uid: d1dd2bfd-1825-44c3-91a3-5d88f9261349
  spec:
    baseOSExtensionsContainerImage: ""
    config:
      ignition:
        version: 3.4.0
      storage:
        files:
        - contents:
            compression: ""
            source: data:text/plain;charset=utf-8;base64,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
          mode: 420
          overwrite: true
          path: /etc/kubernetes/kubelet.conf
    fips: false
    kernelArguments: null
    kernelType: ""
    osImageURL: ""
- apiVersion: machineconfiguration.openshift.io/v1
  kind: MachineConfig
  metadata:
    creationTimestamp: "2025-11-04T15:48:21Z"
    generation: 1
    labels:
      machineconfiguration.openshift.io/role: master
    name: 99-assisted-installer-master-ssh
    resourceVersion: "2369"
    uid: 29515194-0d8e-41b8-b955-7f0ac6007927
  spec:
    config:
      ignition:
        version: 3.1.0
      passwd:
        users:
        - name: core
          sshAuthorizedKeys:
          - ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQD7F2mFgxGcyTmG/KTR+D0wnMAM1rlaaaqGMz5ueugnUjlWxtssJLq1TIQSwOdllxWgzJt9LXHQZNVqxpLk/imx7UqnRYohX+10WNtxRQ8O/HqMpdngMgYlBVHwmgsQeDle441kUv/NFAwLGpRK4zvNwxcUMu2z4sajxqxc0sGqvqpVYsOq7jnFbWELgRX+JyZmWGhGfdHwySraydgV0NtSEANksJO1H0220vnrpMnGtyyOkiqDi4LnT1iAs+VvqZl0EaPxOzCMPTVQqqeH19bBKKnbmQABRZxlI7o4vvRH8p/YXG301cCgfVXfdbFuU7OLiHDA73nd9zk+AyEm/8ssq9rSAzleFaP3I9RqNvK/YWLoC/DHwZeCGrvva/JpPdw3TY3eE9mVVlonz59SjSi3V8Go8bveYSUHm/2oGfCn9ziCH40htpYLllQZfSBqH0IF1BrsQ62o9LWwKyp1vrmlEiijQy5mClTOHbeC2EHSP04u8+v5EC8UA1Jh2f1kers=
            root@localhost.localdomain
- apiVersion: machineconfiguration.openshift.io/v1
  kind: MachineConfig
  metadata:
    annotations:
      machineconfiguration.openshift.io/generated-by-controller-version: fcf8f254943cbcba1400ba55f3978cc292b6460b
    creationTimestamp: "2025-11-04T16:09:16Z"
    generation: 1
    labels:
      machineconfiguration.openshift.io/role: master
    name: 99-master-generated-registries
    ownerReferences:
    - apiVersion: config.openshift.io/v1
      kind: Image
      name: cluster
      uid: 86dc34c0-2b62-4ce3-be04-c01fdfc4a0e9
    resourceVersion: "10965"
    uid: cd9f96a2-4512-4693-a8ff-ba44fcc962ea
  spec:
    baseOSExtensionsContainerImage: ""
    config:
      ignition:
        version: 3.4.0
    fips: false
    kernelArguments: null
    kernelType: ""
    osImageURL: ""
- apiVersion: machineconfiguration.openshift.io/v1
  kind: MachineConfig
  metadata:
    creationTimestamp: "2025-12-18T20:53:40Z"
    generation: 1
    labels:
      machineconfiguration.openshift.io/role: master
    name: 99-master-idmapd-conf
    resourceVersion: "54724114"
    uid: c7af99d0-1576-4615-be72-51c22ece341d
  spec:
    config:
      ignition:
        version: 3.4.0
      storage:
        files:
        - contents:
            source: data:text/plain;charset=utf-8;base64,W0dlbmVyYWxdCkRvbWFpbiA9IHJocG9jLmludAoKW01hcHBpbmddCgpOb2JvZHktVXNlciA9IG5vYm9keQpOb2JvZHktR3JvdXAgPSBub2JvZHkK
            verification: {}
          mode: 420
          overwrite: true
          path: /etc/idmapd.conf
- apiVersion: machineconfiguration.openshift.io/v1
  kind: MachineConfig
  metadata:
    creationTimestamp: "2025-11-04T15:48:21Z"
    generation: 1
    labels:
      machineconfiguration.openshift.io/role: master
    name: 99-master-ssh
    resourceVersion: "2394"
    uid: 12aeb998-dd80-4f38-85db-389baa0f230e
  spec:
    baseOSExtensionsContainerImage: ""
    config:
      ignition:
        version: 3.2.0
      passwd:
        users:
        - name: core
          sshAuthorizedKeys:
          - ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQDaG45aoa4HpJ+V029gSYKSv5IenhVmZcJvicGrs+D0PgzzwNIGG52iK4r3YOoEYJn4nX80OHf4ob23avJ1ruDPR9inD1c+oiAk5BLRE7CNdU1mllWE0l6pYRHfpIuCOXC6iWpX1kXbVPJZk3ytVZOgff7LkaIIzbAjDjJ+N1MQSUmKvnioh8c6WtFfQNAZ2gFBCRWPLxcjHdyTYvy+oB0qR10WpQYHrGVB0LawtudQrO/8zHcfZJpI0uFwSAvYqspgiO3hPfuT0Fx8xzAb66AK/2vF/WrMOH3AbBu5S954B+xZI4apPJN/Yy5ENRVIoL7w9V5pV5FENtsSvQ+fpFat9yoVewvy5CMo8qJHrvAqlBJ9JriVX2mnigJRkshG0F+Z7BLZUjMcueSIIzasQ2igc8nbpfElSnTmoyweiMbFIXNJJwaV/tKbFkF3J7A3fz1qbfSQ7AIHAigoUf/CnCr+j+BQs1ZZMoWGQOPwFo00OBDICnP0Pc6wBr4iN6gnDFs=
            jnakamura@JNakamura-22
    fips: false
    kernelArguments: null
    kernelType: ""
    osImageURL: ""
- apiVersion: machineconfiguration.openshift.io/v1
  kind: MachineConfig
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"machineconfiguration.openshift.io/v1","kind":"MachineConfig","metadata":{"annotations":{},"labels":{"machineconfiguration.openshift.io/role":"master"},"name":"99-openshift-machineconfig-master-psi-karg"},"spec":{"kernelArguments":["psi=1"]}}
    creationTimestamp: "2025-11-04T16:32:07Z"
    generation: 1
    labels:
      machineconfiguration.openshift.io/role: master
    name: 99-openshift-machineconfig-master-psi-karg
    resourceVersion: "42415"
    uid: 2ec03100-20e6-47f2-b9b3-2dfe1bfe1c73
  spec:
    kernelArguments:
    - psi=1
- apiVersion: machineconfiguration.openshift.io/v1
  kind: MachineConfig
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"machineconfiguration.openshift.io/v1","kind":"MachineConfig","metadata":{"annotations":{},"labels":{"machineconfiguration.openshift.io/role":"worker"},"name":"99-openshift-machineconfig-worker-psi-karg"},"spec":{"kernelArguments":["psi=1"]}}
    creationTimestamp: "2025-11-04T16:32:07Z"
    generation: 1
    labels:
      machineconfiguration.openshift.io/role: worker
    name: 99-openshift-machineconfig-worker-psi-karg
    resourceVersion: "42413"
    uid: a369e93e-f492-4baa-9268-4e909d07a28d
  spec:
    kernelArguments:
    - psi=1
- apiVersion: machineconfiguration.openshift.io/v1
  kind: MachineConfig
  metadata:
    annotations:
      machineconfiguration.openshift.io/generated-by-controller-version: fcf8f254943cbcba1400ba55f3978cc292b6460b
    creationTimestamp: "2025-11-04T16:09:16Z"
    generation: 1
    labels:
      machineconfiguration.openshift.io/role: worker
    name: 99-worker-generated-registries
    ownerReferences:
    - apiVersion: config.openshift.io/v1
      kind: Image
      name: cluster
      uid: 86dc34c0-2b62-4ce3-be04-c01fdfc4a0e9
    resourceVersion: "10976"
    uid: e8c4c8a0-8acd-4d26-a5fa-2212ca46ba7b
  spec:
    baseOSExtensionsContainerImage: ""
    config:
      ignition:
        version: 3.4.0
    fips: false
    kernelArguments: null
    kernelType: ""
    osImageURL: ""
- apiVersion: machineconfiguration.openshift.io/v1
  kind: MachineConfig
  metadata:
    creationTimestamp: "2025-12-18T20:53:40Z"
    generation: 1
    labels:
      machineconfiguration.openshift.io/role: worker
    name: 99-worker-idmapd-conf
    resourceVersion: "54724115"
    uid: 885c7e93-d74f-44d5-aa48-2c76ab593cac
  spec:
    config:
      ignition:
        version: 3.4.0
      storage:
        files:
        - contents:
            source: data:text/plain;charset=utf-8;base64,W0dlbmVyYWxdCkRvbWFpbiA9IHJocG9jLmludAoKW01hcHBpbmddCgpOb2JvZHktVXNlciA9IG5vYm9keQpOb2JvZHktR3JvdXAgPSBub2JvZHkK
            verification: {}
          mode: 420
          overwrite: true
          path: /etc/idmapd.conf
- apiVersion: machineconfiguration.openshift.io/v1
  kind: MachineConfig
  metadata:
    creationTimestamp: "2025-11-04T15:48:22Z"
    generation: 1
    labels:
      machineconfiguration.openshift.io/role: worker
    name: 99-worker-ssh
    resourceVersion: "2424"
    uid: 49d166dd-b248-4e19-8d35-c85bc85e83d6
  spec:
    baseOSExtensionsContainerImage: ""
    config:
      ignition:
        version: 3.2.0
      passwd:
        users:
        - name: core
          sshAuthorizedKeys:
          - ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQDaG45aoa4HpJ+V029gSYKSv5IenhVmZcJvicGrs+D0PgzzwNIGG52iK4r3YOoEYJn4nX80OHf4ob23avJ1ruDPR9inD1c+oiAk5BLRE7CNdU1mllWE0l6pYRHfpIuCOXC6iWpX1kXbVPJZk3ytVZOgff7LkaIIzbAjDjJ+N1MQSUmKvnioh8c6WtFfQNAZ2gFBCRWPLxcjHdyTYvy+oB0qR10WpQYHrGVB0LawtudQrO/8zHcfZJpI0uFwSAvYqspgiO3hPfuT0Fx8xzAb66AK/2vF/WrMOH3AbBu5S954B+xZI4apPJN/Yy5ENRVIoL7w9V5pV5FENtsSvQ+fpFat9yoVewvy5CMo8qJHrvAqlBJ9JriVX2mnigJRkshG0F+Z7BLZUjMcueSIIzasQ2igc8nbpfElSnTmoyweiMbFIXNJJwaV/tKbFkF3J7A3fz1qbfSQ7AIHAigoUf/CnCr+j+BQs1ZZMoWGQOPwFo00OBDICnP0Pc6wBr4iN6gnDFs=
            jnakamura@JNakamura-22
    fips: false
    kernelArguments: null
    kernelType: ""
    osImageURL: ""
- apiVersion: machineconfiguration.openshift.io/v1
  kind: MachineConfig
  metadata:
    annotations:
      machineconfiguration.openshift.io/generated-by-controller-version: fcf8f254943cbcba1400ba55f3978cc292b6460b
      machineconfiguration.openshift.io/release-image-version: 4.18.26
    creationTimestamp: "2025-11-04T16:32:12Z"
    generation: 1
    name: rendered-master-3929e4d1809a31c23ae29612e0f345b6
    ownerReferences:
    - apiVersion: machineconfiguration.openshift.io/v1
      blockOwnerDeletion: true
      controller: true
      kind: MachineConfigPool
      name: master
      uid: 94ee58c6-d020-4644-985a-6daad3eb3116
    resourceVersion: "43349"
    uid: 4da2aa36-fb5e-449e-b1cc-eb27997812fc
  spec:
    baseOSExtensionsContainerImage: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:7033f46996eddcbad8c8b8aeb18e601bdeef3d04bd7f79cd194db5e6346a7fc4
    config:
      ignition:
        version: 3.4.0
      passwd:
        users:
        - name: core
          sshAuthorizedKeys:
          - ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQD7F2mFgxGcyTmG/KTR+D0wnMAM1rlaaaqGMz5ueugnUjlWxtssJLq1TIQSwOdllxWgzJt9LXHQZNVqxpLk/imx7UqnRYohX+10WNtxRQ8O/HqMpdngMgYlBVHwmgsQeDle441kUv/NFAwLGpRK4zvNwxcUMu2z4sajxqxc0sGqvqpVYsOq7jnFbWELgRX+JyZmWGhGfdHwySraydgV0NtSEANksJO1H0220vnrpMnGtyyOkiqDi4LnT1iAs+VvqZl0EaPxOzCMPTVQqqeH19bBKKnbmQABRZxlI7o4vvRH8p/YXG301cCgfVXfdbFuU7OLiHDA73nd9zk+AyEm/8ssq9rSAzleFaP3I9RqNvK/YWLoC/DHwZeCGrvva/JpPdw3TY3eE9mVVlonz59SjSi3V8Go8bveYSUHm/2oGfCn9ziCH40htpYLllQZfSBqH0IF1BrsQ62o9LWwKyp1vrmlEiijQy5mClTOHbeC2EHSP04u8+v5EC8UA1Jh2f1kers=
            root@localhost.localdomain
          - ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQDaG45aoa4HpJ+V029gSYKSv5IenhVmZcJvicGrs+D0PgzzwNIGG52iK4r3YOoEYJn4nX80OHf4ob23avJ1ruDPR9inD1c+oiAk5BLRE7CNdU1mllWE0l6pYRHfpIuCOXC6iWpX1kXbVPJZk3ytVZOgff7LkaIIzbAjDjJ+N1MQSUmKvnioh8c6WtFfQNAZ2gFBCRWPLxcjHdyTYvy+oB0qR10WpQYHrGVB0LawtudQrO/8zHcfZJpI0uFwSAvYqspgiO3hPfuT0Fx8xzAb66AK/2vF/WrMOH3AbBu5S954B+xZI4apPJN/Yy5ENRVIoL7w9V5pV5FENtsSvQ+fpFat9yoVewvy5CMo8qJHrvAqlBJ9JriVX2mnigJRkshG0F+Z7BLZUjMcueSIIzasQ2igc8nbpfElSnTmoyweiMbFIXNJJwaV/tKbFkF3J7A3fz1qbfSQ7AIHAigoUf/CnCr+j+BQs1ZZMoWGQOPwFo00OBDICnP0Pc6wBr4iN6gnDFs=
            jnakamura@JNakamura-22
      storage:
        files:
        - contents:
            source: data:,%23%20This%20file%20signals%20NetworkManager-clean-initrd-state%20service%20to%20run%20on%0A%23%20boot.%20This%20service%20is%20used%20to%20clean%20up%20the%20network%20activation%20state%0A%23%20generated%20by%20dracut%20so%20that%20other%20network%20configuration%20deployed%20by%20the%0A%23%20user%20can%20be%20activated.%20This%20only%20happens%20if%20dracut%20activated%20a%20default%0A%23%20network%20configuration%20and%20there%20is%20an%20alternate%20configuration%20available%20in%0A%23%20the%20root%20filesystem.%20Otherwise%2C%20it%20is%20assumed%20that%20the%20network%0A%23%20configuration%20activated%20by%20dracut%20is%20the%20one%20that%20is%20intended%20to%20be%20used%0A%23%20throughout%20the%20life%20of%20the%20system.%0A%23%20Opt-out%20for%20baremetal%20IPI%20deplyments%2C%20opt-in%20otherwise.%0A
          mode: 493
          overwrite: true
          path: /var/lib/mco/nm-clean-initrd-state
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-ex%20-o%20pipefail%0A%0ANM_DEVICES_DIR%3D%2Frun%2FNetworkManager%2Fdevices%0ANM_RUN_CONN_DIR%3D%2Frun%2FNetworkManager%2Fsystem-connections%0ANM_ETC_CONN_DIR%3D%2Fetc%2FNetworkManager%2Fsystem-connections%0A%0Alogger%20-t%20nm-clean-initrd-state%20%22Cleaning%20network%20activation%20state%20generated%20by%20dracut...%22%0Alogger%20-t%20nm-clean-initrd-state%20%22To%20disable%2C%20remove%20%2Fvar%2Flib%2Fmco%2Fnm-clean-initrd-state%22%0A%0Aif%20%5B%20!%20-e%20%22%24NM_DEVICES_DIR%22%20%5D%20%7C%7C%20%5B%20!%20-e%20%22%24NM_RUN_CONN_DIR%22%20%5D%20%7C%7C%20%5B%20!%20-e%20%22%24NM_ETC_CONN_DIR%22%20%5D%3B%20then%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22There%20is%20no%20network%20activation%20state%20to%20clean%22%0A%20%20exit%0Afi%0A%0A%23%20Some%20deployments%20require%20an%20active%20network%20early%20in%20the%20boot%20process.%20To%0A%23%20achieve%20this%2C%20dracut%20runs%20specific%20NetworkManager%20modules.%20This%20results%20in%0A%23%20NetworkManager%20keyfiles%20being%20generated%20(either%20default%20or%20from%20ip%20kernel%0A%23%20arguments)%20and%20activated.%20This%20activation%20generates%20state%20that%20makes%20those%0A%23%20profiles%20to%20be%20re-activated%20by%20the%20NetworkManager%20service%20later%20in%20the%0A%23%20boot%20process.%20And%20this%20has%20the%20effect%20that%20other%20profiles%20deployed%20by%20the%0A%23%20user%20for%20the%20same%20set%20of%20devices%20are%20ignored.%0A%0A%23%20Most%20of%20the%20time%20this%20is%20the%20desired%20behavior.%20The%20exception%20to%20this%20rule%0A%23%20is%20when%20the%20user%20wants%20to%20run%20the%20boot%20process%20with%20a%20different%20network%0A%23%20setup%20than%20the%20real%20root%20which%20is%20usually%20related%20to%20the%20fact%20that%0A%23%20generating%20images%20with%20customized%20kernel%20arguments%20is%20a%20complication%20in%0A%23%20the%20deployment%20pipeline.%0A%0A%23%20This%20need%20has%20been%20exacerbated%20by%20past%20NetworkManager%20bugs%20that%20activated%0A%23%20the%20network%20on%20boot%20when%20it%20was%20not%20really%20needed.%20Most%20notably%20when%20ip%0A%23%20kernel%20argument%20is%20present%2C%20something%20that%20the%20baremetal%20installer%20adds%20by%0A%23%20default.%0A%0A%23%20The%20intention%20here%20is%20to%20remove%20the%20state%20that%20was%20generated%20with%20the%0A%23%20activation%20of%20those%20profiles%20during%20dracut%20execution.%20Then%20when%0A%23%20NetworkManager%20service%20runs%2C%20the%20profiles%20generated%20by%20dracut%2C%20along%20with%0A%23%20other%20profiles%20configured%20by%20the%20user%2C%20are%20evaluated%20towards%20finding%20the%0A%23%20most%20appropriate%20profile%20to%20connect%20a%20device%20with.%20As%20a%20precaution%2C%20clean%0A%23%20state%20only%20for%20devices%20that%3A%0A%23%20-%20have%20been%20activated%20with%20a%20default%20profile%20(assume%20that%20a%20non-default%0A%23%20%20%20configuration%20expresses%20intention%20by%20user%20to%20run%20with%20it%20permanently)%0A%23%20-%20have%20a%20specific%20configured%20profile%20set%20to%20auto-connect%20(if%20there%20is%20no%0A%23%20%20%20alternate%20configured%20profile%20for%20a%20device%20it%20makes%20no%20sense%20to%0A%23%20%20%20de-activate%20anything)%0A%23%0A%23%20Although%20this%20can%20theoretically%20happen%20on%20any%20deployment%20type%2C%20need%20has%0A%23%20mostly%20come%20from%20IPI%20bare%20metal%20deployments.%20For%20the%20time%20being%2C%20this%0A%23%20should%20be%20opt-in%20in%20any%20other%20deploment%20type.%0A%23%0A%23%20There%20is%20an%20RFE%20filed%20against%20NM%20that%20once%20implemented%20would%20make%20this%0A%23%20script%20unnecessary%3A%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D2089707%0A%0Afor%20device%20in%20%22%24%7BNM_DEVICES_DIR%7D%22%2F*%3B%20do%0A%20%20if%20%5B%20!%20-e%20%22%24device%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20the%20device%20file%20name%20is%20the%20ifindex%0A%20%20ifindex%3D%24(basename%20%22%24device%22)%0A%20%20%0A%20%20%23%20get%20the%20interface%20name%20by%20ifindex%0A%20%20ifname%3D%24(ip%20-j%20link%20show%20%7C%20jq%20-r%20%22.%5B%5D%20%7C%20select(.ifindex%20%3D%3D%20%24%7Bifindex%7D)%20%7C%20.ifname%20%2F%2F%20empty%22)%0A%0A%20%20%23%20no%20interface%20name%20found%2C%20ignore%0A%20%20if%20%5B%20-z%20%22%24ifname%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20get%20the%20uuid%20of%20the%20profile%20the%20device%20has%20been%20activated%20with%0A%20%20active_profile_uuid%3D%24(sed%20-nr%20'%2F%5E%5C%5Bdevice%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Econnection-uuid%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24device%22)%0A%0A%20%20%23%20the%20device%20was%20not%20activated%20with%20any%20profile%2C%20ignore%0A%20%20if%20%5B%20-z%20%22%24active_profile_uuid%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20find%20the%20generated%20profile%20by%20uuid%0A%20%20for%20profile%20in%20%22%24%7BNM_RUN_CONN_DIR%7D%22%2F*%3B%20do%0A%20%20%20%20generated_profile_uuid%3D%24(sed%20-nr%20'%2F%5E%5C%5Bconnection%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Euuid%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20%20%20if%20%5B%20%22%24active_profile_uuid%22%20%3D%20%22%24generated_profile_uuid%22%20%5D%3B%20then%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20done%0A%0A%20%20%23%20generated%20profile%20not%20found%2C%20ignore%0A%20%20if%20%5B%20%22%24active_profile_uuid%22%20!%3D%20%22%24generated_profile_uuid%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20check%20that%20it%20is%20not%20specific%20for%20the%20device%2C%20otherwise%20ignore%0A%20%20profile_ifname%3D%24(sed%20-nr%20'%2F%5E%5C%5Bconnection%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Einterface-name%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20if%20%5B%20-n%20%22%24profile_ifname%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20profile%20not%20generated%20by%20nm-initrd-generator%2C%20ignore%0A%20%20%23%20only%20check%20it%20if%20the%20key%20is%20set%20(from%20NM%201.32.4)%0A%20%20origin%3D%24(sed%20-nr%20'%2F%5E%5C%5Buser%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Eorg.freedesktop.NetworkManager.origin%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20if%20%5B%20-n%20%22%24origin%22%20%5D%20%26%26%20%5B%20%22%24origin%22%20!%3D%20%22nm-initrd-generator%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20find%20the%20configured%20profile%20by%20name%20with%20auto-connect%20set%0A%20%20for%20profile%20in%20%22%24%7BNM_ETC_CONN_DIR%7D%22%2F*%3B%20do%0A%20%20%20%20profile_ifname%3D%24(sed%20-nr%20'%2F%5E%5C%5Bconnection%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Einterface-name%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20%20%20autoconnect%3D%24(sed%20-nr%20'%2F%5E%5C%5Bconnection%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Eautoconnect%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20%20%20if%20%5B%20%22%24profile_ifname%22%20%3D%20%22%24ifname%22%20%5D%20%26%26%20%5B%20%22%24autoconnect%22%20!%3D%20%22false%22%20%5D%3B%20then%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20done%0A%0A%20%20%23%20configured%20profile%20not%20found%2C%20ignore%0A%20%20if%20%5B%20%22%24profile_ifname%22%20!%3D%20%22%24ifname%22%20%5D%20%7C%7C%20%5B%20%22%24autoconnect%22%20%3D%20%22false%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20configured_profile_uuid%3D%24(sed%20-nr%20'%2F%5E%5C%5Bconnection%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Euuid%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22%24ifname%20activated%20with%20default%20generated%20profile%20%24generated_profile_uuid%22%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22%24ifname%20has%20different%20configured%20specific%20profile%20%24configured_profile_uuid%22%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22%24ifname%3A%20removing%20state...%22%0A%20%20%0A%20%20%23%20NM%20can%20still%20generate%20internal%20profiles%20from%20the%20IP%20address%0A%20%20%23%20configuration%20of%20devices%2C%20so%20flush%20addresses%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22Flushing%20IP%20addresses%20from%20%24ifname%22%0A%20%20ip%20addr%20flush%20%22%24ifname%22%0A%20%20ip%20-6%20addr%20flush%20%22%24ifname%22%0A%0A%20%20%23%20remove%20device%20state%20file%20to%20prevent%20NM%20to%20unilaterally%20connect%20with%20the%0A%20%20%23%20latest%20activated%20profile%20without%20evaluating%20other%20profiles%20%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22Removing%20%24device%22%0A%20%20rm%20-f%20--%20%22%24device%22%0A%0Adone%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/nm-clean-initrd-state.sh
        - contents:
            source: data:,%5Bconnection%5D%0Aipv6.dhcp-duid%3Dll%0Aipv6.dhcp-iaid%3Dmac%0A
          mode: 420
          overwrite: true
          path: /etc/NetworkManager/conf.d/01-ipv6.conf
        - contents:
            source: data:,%5Bmain%5D%0Aplugins%3Dkeyfile%2Cifcfg-rh%0A%5Bkeyfile%5D%0Apath%3D%2Fetc%2FNetworkManager%2Fsystem-connections%0A
          mode: 420
          overwrite: true
          path: /etc/NetworkManager/conf.d/20-keyfiles.conf
        - contents:
            source: data:,%5Bmain%5D%0Arc-manager%3Dunmanaged%0A
          mode: 420
          overwrite: true
          path: /etc/NetworkManager/conf.d/99-kni.conf
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-eo%20pipefail%0AIFACE%3D%241%0ASTATUS%3D%242%0A%0Afunction%20resolv_prepender%20%7B%0A%20%20mkdir%20-p%20%2Frun%2Fresolv-prepender%0A%20%20echo%20%22IP4_DOMAINS%3D%24IP4_DOMAINS%22%20%3E%20%2Frun%2Fresolv-prepender%2Fenv.new%0A%20%20echo%20%22IP6_DOMAINS%3D%24IP6_DOMAINS%22%20%3E%3E%20%2Frun%2Fresolv-prepender%2Fenv.new%0A%0A%20%20if%20!%20diff%20-q%20%2Frun%2Fresolv-prepender%2Fenv%20%2Frun%2Fresolv-prepender%2Fenv.new%3B%20then%0A%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Environment%20variable(s)%20changed.%20Systemd%20path%20unit%20will%20pick%20the%20change.%22%0A%20%20%20%20mv%20-f%20%2Frun%2Fresolv-prepender%2Fenv.new%20%2Frun%2Fresolv-prepender%2Fenv%0A%20%20fi%0A%7D%0A%0Aexport%20IP4_DOMAINS%20IP6_DOMAINS%0Aexport%20-f%20resolv_prepender%0A%0A%23%20For%20RHEL8%20with%20NetworkManager%20%3E%3D%201.36%20and%20RHEL9%20with%20NetworkManager%20%3E%3D1.42%20we%20can%20use%20simplified%20logic%0A%23%20of%20observing%20only%20a%20single%20%22dns-change%22%20event.%20Older%20version%20of%20NetworkManager%20require%20however%20that%20we%0A%23%20react%20on%20a%20set%20of%20multiple%20events.%20Once%20dns-change%20event%20is%20detected%20we%20create%20a%20flag%20file%20to%20ignore%0A%23%20subsequent%20up%26co.%20events%20as%20undesired.%0A%23%0A%23%20Given%20an%20overall%20Network%20Manager%20dispatcher%20timeout%20of%2090%20seconds%2C%20we%20are%20enforcing%20a%20slightly%20shorter%0A%23%20timeout%20for%20the%20observed%20events.%20It%20is%20not%20really%20required%20because%20all%20we%20do%20in%20this%20function%20is%20to%20write%20a%20file.%0A%23%20We%20could%20get%20rid%20of%20this%20timeout%20completely%2C%20but%20it%20also%20does%20not%20cost%20much%20to%20keep%20it.%0Acase%20%22%24STATUS%22%20in%0A%20%20dns-change)%0A%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%20triggered%20by%20%24%7BIFACE%7D%20%24%7BSTATUS%7D.%22%0A%20%20%20%20if%20%5B%20!%20-f%20%22%2Frun%2Fnetworkmanager-dns-event-detected%22%20%5D%3B%20then%0A%20%20%20%20%20%20touch%20%2Frun%2Fnetworkmanager-dns-event-detected%0A%20%20%20%20fi%0A%20%20%20%20if%20!%20timeout%2060s%20bash%20-c%20resolv_prepender%3B%20then%0A%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Timeout%20occurred%22%0A%20%20%20%20%20%20exit%201%0A%20%20%20%20fi%0A%20%20%3B%3B%0A%0A%20%20up%7Cdhcp4-change%7Cdhcp6-change%7Creapply)%0A%20%20%20%20if%20%5B%20!%20-f%20%22%2Frun%2Fnetworkmanager-dns-event-detected%22%20%5D%3B%20then%0A%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%20triggered%20by%20%24%7BIFACE%7D%20%24%7BSTATUS%7D.%22%0A%20%20%20%20%20%20if%20!%20timeout%2030s%20bash%20-c%20resolv_prepender%3B%20then%0A%20%20%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Timeout%20occurred%22%0A%20%20%20%20%20%20%20%20exit%201%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20If%20%24DHCP6_FQDN_FQDN%20is%20not%20empty%20and%20is%20not%20localhost.localdomain%20and%20static%20hostname%20was%20not%20already%20set%0A%20%20%20%20if%20%5B%5B%20-n%20%22%24DHCP6_FQDN_FQDN%22%20%26%26%20%22%24DHCP6_FQDN_FQDN%22%20!%3D%20%22localhost.localdomain%22%20%26%26%20%22%24DHCP6_FQDN_FQDN%22%20%3D~%20%22.%22%20%5D%5D%20%3B%20then%0A%20%20%20%20%20%20%20STATIC_HOSTNAME%3D%22%24(test%20!%20-e%20%2Fetc%2Fhostname%20%26%26%20echo%20-n%20%7C%7C%20cat%20%2Fetc%2Fhostname%20%7C%20xargs)%22%0A%0A%20%20%20%20%20%20%20if%20%5B%5B%20-z%20%22%24STATIC_HOSTNAME%22%20%7C%7C%20%22%24STATIC_HOSTNAME%22%20%3D%3D%20%22localhost.localdomain%22%20%5D%5D%20%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%23%20run%20with%20systemd-run%20to%20avoid%20selinux%20problems%0A%20%20%20%20%20%20%20%20%20%20systemd-run%20--property%3DType%3Doneshot%20--unit%20resolve-prepender-hostnamectl%20-Pq%20%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20hostnamectl%20set-hostname%20--static%20--transient%20%24DHCP6_FQDN_FQDN%0A%20%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20if%20%5B%5B%20%22%24STATUS%22%20%3D%3D%20%22up%22%20%5D%5D%20%26%26%20%5B%5B%20%24IFACE%20%3D%3D%20%22br-ex%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20%2Fbin%2Fmkdir%20-p%20%2Frun%2Fnodeip-configuration%0A%20%20%20%20%20%20%20%20touch%20%2Frun%2Fnodeip-configuration%2Fbr-ex-up%0A%20%20%20%20fi%0A%20%20%3B%3B%0A%20%20*)%0A%20%20%3B%3B%0Aesac%0A
          mode: 493
          overwrite: true
          path: /etc/NetworkManager/dispatcher.d/30-resolv-prepender
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-ex%20-o%20pipefail%0A%0Aif%20%5B%5B%20%22OVNKubernetes%22%20%3D%3D%20%22OVNKubernetes%22%20%26%26%20%22%24CONNECTION_ID%22%20%3D%3D%20%22Wired%20Connection%22%20%5D%5D%0Athen%0A%20%20%20%20%3E%262%20echo%20%22Refusing%20to%20modify%20default%20connection.%22%0A%20%20%20%20exit%200%0Afi%0A%0Aif%20%5B%20-z%20%24%7BDHCP4_IP_ADDRESS%3A-%7D%20%5D%0Athen%0A%20%20%20%20%3E%262%20echo%20%22Not%20a%20DHCP4%20address.%20Ignoring.%22%0A%20%20%20%20exit%200%0Afi%0A%0Aif%20%5B%20%24%7BDHCP4_DHCP_LEASE_TIME%3A-0%7D%20-lt%204294967295%20%5D%0Athen%0A%20%20%20%20%3E%262%20echo%20%22Not%20an%20infinite%20DHCP4%20lease.%20Ignoring.%22%0A%20%20%20%20exit%200%0Afi%0A%0AIPS%3D(%24IP4_ADDRESS_0)%0ACIDR%3D%24%7BIPS%5B0%5D%7D%0AGATEWAY%3D%24%7BIPS%5B1%5D%7D%0A%0ATYPE%3D%24(nmcli%20--get-values%20connection.type%20connection%20show%20%22%24CONNECTION_ID%22)%0A%0A%23%20Modifying%20the%20default%20connection%20id%20directly%20doesn't%20do%20what%20we%20want.%0A%23%20If%20we%20see%20that%2C%20then%20we%20need%20to%20create%20a%20new%20connection.%0Aif%20%5B%20%22%24CONNECTION_ID%22%20%3D%3D%20%22Wired%20Connection%22%20%5D%0Athen%0A%20%20%20%20if%20!%20nmcli%20con%20show%20inf-lease-to-static%0A%20%20%20%20then%0A%20%20%20%20%20%20%20%20nmcli%20con%20add%20type%20%22%24TYPE%22%20con-name%20inf-lease-to-static%0A%20%20%20%20fi%0A%20%20%20%20STATIC_INT_NAME%3Dinf-lease-to-static%0Aelse%0A%20%20%20%20STATIC_INT_NAME%3D%22%24CONNECTION_ID%22%0Afi%0Anmcli%20con%20mod%20%22%24STATIC_INT_NAME%22%20%5C%0A%20%20conn.interface%20%22%241%22%20%5C%0A%20%20connection.autoconnect%20yes%20%5C%0A%20%20ipv4.addresses%20%22%24CIDR%22%20%5C%0A%20%20ipv4.method%20manual%20%5C%0A%20%20ipv4.gateway%20%22%24GATEWAY%22%20%5C%0A%20%20ipv4.dns%20%22%24IP4_NAMESERVERS%22%0A%0Aif%20%5B%20-n%20%22%24IP4_DOMAINS%22%20%5D%3B%20then%0A%20%20%20%20nmcli%20con%20mod%20%22%24STATIC_INT_NAME%22%20ipv4.dns-search%20%22%24IP4_DOMAINS%22%0Afi%0Aplus%3D''%0Afor%20i%20in%20%24(seq%200%20%24((%24IP4_NUM_ROUTES-1))%20)%0Ado%0A%20%20%20%20varname%3D%22IP4_ROUTE_%24i%22%0A%20%20%20%20nmcli%20con%20mod%20%22%24STATIC_INT_NAME%22%20%24%7Bplus%7Dipv4.routes%20%22%24%7B!varname%7D%22%0A%20%20%20%20plus%3D'%2B'%0Adone%0A%0Anmcli%20con%20up%20%22%24STATIC_INT_NAME%22%0A%0Aif%20%5B%20-n%20%22%24%7BDHCP4_HOST_NAME%3A-%7D%22%20%5D%0Athen%0A%20%20%20%20systemd-run%20--property%3DType%3Doneshot%20--unit%20static-dhcp-hostnamectl%20-Pq%20%5C%0A%20%20%20%20%20%20hostnamectl%20set-hostname%20--static%20--transient%20%22%24DHCP4_HOST_NAME%22%0Afi%0A
          mode: 493
          overwrite: true
          path: /etc/NetworkManager/dispatcher.d/30-static-dhcp
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-ex%20-o%20pipefail%0A%0Aif%20%5B%20-z%20%22%24DHCP6_IP6_ADDRESS%22%20%5D%0Athen%0A%20%20%20%20%3E%262%20echo%20%22Not%20a%20DHCP6%20address.%20Ignoring.%22%0A%20%20%20%20exit%200%0Afi%0A%0ALEASE_TIME%3D%24(ip%20-j%20-6%20a%20show%20%22%24DEVICE_IFACE%22%20%7C%20jq%20-r%20%22.%5B%5D.addr_info%5B%5D%20%7C%20select(.scope%3D%3D%5C%22global%5C%22)%20%7C%20select(.deprecated!%3Dtrue)%20%7C%20select(.local%3D%3D%5C%22%24DHCP6_IP6_ADDRESS%5C%22)%20%7C%20.preferred_life_time%22)%0APREFIX_LEN%3D%24(ip%20-j%20-6%20a%20show%20%22%24DEVICE_IFACE%22%20%7C%20jq%20-r%20%22.%5B%5D.addr_info%5B%5D%20%7C%20select(.scope%3D%3D%5C%22global%5C%22)%20%7C%20select(.deprecated!%3Dtrue)%20%7C%20select(.local%3D%3D%5C%22%24DHCP6_IP6_ADDRESS%5C%22)%20%7C%20.prefixlen%22)%0A%0Aif%20%5B%20%24%7BLEASE_TIME%3A-0%7D%20-lt%204294967295%20%5D%0Athen%0A%20%20%20%20%3E%262%20echo%20%22Not%20an%20infinite%20DHCP6%20lease.%20Ignoring.%22%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20We%20don't%20want%20this%20to%20run%20before%20OVNKubernetes%20creates%20its%20bridge.%20If%20we%0A%23%20see%20the%20default%20CONNECTION_ID%20we%20know%20to%20wait.%0Aif%20%5B%20%22%24CONNECTION_ID%22%20%3D%3D%20%22Wired%20Connection%22%20%5D%0Athen%0A%20%20%20%20%3E%262%20echo%20%22Refusing%20to%20modify%20default%20connection.%22%0A%20%20%20%20exit%200%0Afi%0A%0ACIDR%3D%22%24DHCP6_IP6_ADDRESS%2F%24PREFIX_LEN%22%0Anmcli%20con%20mod%20%22%24CONNECTION_ID%22%20ipv6.addresses%20%22%24CIDR%22%0Anmcli%20con%20mod%20%22%24CONNECTION_ID%22%20connection.autoconnect%20%22yes%22%0Anmcli%20con%20mod%20%22%24CONNECTION_ID%22%20ipv6.method%20%22manual%22%0Anmcli%20con%20mod%20%22%24CONNECTION_ID%22%20ipv6.gateway%20%22%24IP6_GATEWAY%22%0Anmcli%20con%20mod%20%22%24CONNECTION_ID%22%20ipv6.dns%20%22%24IP6_NAMESERVERS%22%0ASEARCH_DOMAIN%3D%22%24%7BDHCP6_FQDN_FQDN%23*.%7D%22%0Aif%20%5B%20-n%20%22%24SEARCH_DOMAIN%22%20%5D%3B%20then%0A%20%20%20%20nmcli%20con%20mod%20%22%24CONNECTION_ID%22%20ipv6.dns-search%20%22%24SEARCH_DOMAIN%22%0Afi%0Aplus%3D''%0Afor%20i%20in%20%24(seq%200%20%24((%24IP6_NUM_ROUTES-1))%20)%0Ado%0A%20%20%20%20varname%3D%22IP6_ROUTE_%24i%22%0A%20%20%20%20nmcli%20con%20mod%20%22%24CONNECTION_ID%22%20%24%7Bplus%7Dipv6.routes%20%22%24%7B!varname%7D%22%0A%20%20%20%20plus%3D'%2B'%0Adone%0A%0A%23%20Copy%20it%20from%20the%20OverlayFS%20mount%20to%20the%20persistent%20lowerdir%0Acp%20%22%24CONNECTION_FILENAME%22%20%2Fetc%2FNetworkManager%2Fsystem-connections%0A
          mode: 493
          overwrite: true
          path: /etc/NetworkManager/dispatcher.d/30-static-dhcpv6
        - contents:
            source: data:,
          mode: 384
          overwrite: true
          path: /etc/pki/ca-trust/source/anchors/openshift-config-user-ca-bundle.crt
        - contents:
            source: data:,KUBERNETES_SERVICE_HOST%3D'api-int.comp-poc-rh01.rhpoc.int'%0AKUBERNETES_SERVICE_PORT%3D'6443'%0A
          mode: 420
          overwrite: true
          path: /etc/kubernetes/apiserver-url.env
        - contents:
            source: data:,%23%20This%20file%20is%20managed%20by%20machine-config-operator.%0A%23%20Suppress%20audit%20rules%20which%20always%20trigger%20for%20container%0A%23%20workloads%2C%20as%20they%20spam%20the%20audit%20log.%20%20Workloads%20are%20expected%0A%23%20to%20be%20dynamic%2C%20and%20the%20networking%20stack%20uses%20iptables.%0A-a%20exclude%2Calways%20-F%20msgtype%3DNETFILTER_CFG%0A%23%20The%20default%20bridged%20networking%20enables%20promiscuous%20on%20the%20veth%0A%23%20device.%20%20Ideally%2C%20we'd%20teach%20audit%20to%20ignore%20only%20veth%20devices%2C%0A%23%20since%20one%20might%20legitimately%20care%20about%20promiscuous%20on%20real%20physical%0A%23%20devices.%20%20But%20we%20can't%20currently%20differentiate.%0A-a%20exclude%2Calways%20-F%20msgtype%3DANOM_PROMISCUOUS%0A
          mode: 420
          overwrite: true
          path: /etc/audit/rules.d/mco-audit-quiet-containers.rules
        - contents:
            source: data:,mode%3A%20unicast%0A
          mode: 420
          overwrite: true
          path: /etc/keepalived/monitor.conf
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%0A%23%20ESP%20offload%2C%20either%20in%20actual%20hardware%20or%20as%20part%20as%20GRO%20(generic%0A%23%20recieve%20offload)%20does%20not%20work%20for%20interfaces%20attached%20to%20an%20OVS%20bridge%0A%23%20so%20turn%20it%20off%20for%20the%20time%20being.%0A%23%20https%3A%2F%2Fissues.redhat.com%2Fbrowse%2FRHEL-58811%0A%0A%23%20Depends%20on%20ipsec%20service%20drop-in%20to%20start%20it%20after%20configure-ovs%20to%20make%0A%23%20sure%20offloads%20are%20disabled%20before%20ipsec%20starts.%0A%0Aif%20%5B%5B%20%22%242%22%20!%3D%20%22up%22%20%5D%5D%3B%20then%0A%20%20exit%0Afi%0A%0Adevice%3D%24DEVICE_IFACE%0Akind_slave%3D%24(ip%20-j%20-d%20link%20show%20%22%24device%22%20%7C%20jq%20-r%20'.%5B0%5D%20%7C%20.linkinfo.info_slave_kind%20%2F%2F%20empty')%0A%0Aif%20%5B%20%22%24kind_slave%22%20%3D%20%22openvswitch%22%20%5D%3B%20then%0A%20%20for%20feature%20in%20tx-esp-segmentation%20esp-hw-offload%20esp-tx-csum-hw-offload%3B%20do%0A%20%20%20%20if%20ethtool%20-k%20%22%24device%22%20%7C%20grep%20-qE%20%22%5E%24%7Bfeature%7D%3A%20off%22%3B%20then%0A%20%20%20%20%20%20%23%20already%20disabled%2C%20nothing%20to%20do%0A%20%20%20%20%20%20continue%0A%20%20%20%20fi%0A%20%20%20%20%0A%20%20%20%20logger%20-t%2099-esp-offload%20-s%20%22Setting%20%24feature%20off%20for%20%24device%3A%20unsupported%20when%20attached%20to%20Open%20vSwitch%20bridge%22%0A%20%20%20%20ethtool%20-K%20%22%24device%22%20%22%24feature%22%20off%0A%20%20done%0Afi%0A
          mode: 484
          overwrite: true
          path: /etc/NetworkManager/dispatcher.d/99-esp-offload
        - contents:
            source: data:,r%20%2Fetc%2Fkubernetes%2Fcni%2Fnet.d%2F80-openshift-network.conf%0Ar%20%2Fetc%2Fkubernetes%2Fcni%2Fnet.d%2F10-ovn-kubernetes.conf%0Ad%20%2Frun%2Fmultus%2Fcni%2Fnet.d%2F%200755%20root%20root%20-%20-%0AD%20%2Fvar%2Flib%2Fcni%2Fnetworks%2Fopenshift-sdn%2F%200755%20root%20root%20-%20-%0A
          mode: 420
          overwrite: true
          path: /etc/tmpfiles.d/cleanup-cni.conf
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-ex%0A%0A%23%20Used%20for%20on-prem%20deployments%20to%20enable%20ip%20forwarding%20as%20part%20of%20nodeip-configuration%20service.%0A%23%20IP%20forwarding%20is%20required%20on%20the%20node%20IP%20(k8s%20API)%20interface%20in%20order%20for%20keepalived%20to%20function.%0A%0Aecho%20%22Configuring%20IP%20Forwarding...%22%0Aovnk_config_dir%3D'%2Fetc%2Fovnk'%0Aip_hint_file%3D%22%2Frun%2Fnodeip-configuration%2Fprimary-ip%22%0A%0Aget_ip_from_ip_hint_file()%20%7B%0A%20%20local%20ip_hint_file%3D%22%241%22%0A%20%20if%20%5B%5B%20!%20-f%20%22%24%7Bip_hint_file%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22error%3A%20unable%20to%20enable%20IP%20forwarding.%20IP%20hint%20file%3A%20%24%7Bip_hint_file%7D%20does%20not%20exist!%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%20%20ip_hint%3D%24(cat%20%22%24%7Bip_hint_file%7D%22)%0A%20%20echo%20%22%24%7Bip_hint%7D%22%0A%7D%0A%0Aget_nodeip_hint_interface()%20%7B%0A%20%20local%20ip_hint%3D%22%22%0A%20%20local%20ip_hint_file%3D%22%241%22%0A%20%20local%20iface%3D%22%22%0A%0A%20%20ip_hint%3D%24(get_ip_from_ip_hint_file%20%22%24%7Bip_hint_file%7D%22)%0A%20%20if%20%5B%5B%20-z%20%22%24%7Bip_hint%7D%22%20%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22error%3A%20unable%20to%20enable%20IP%20forwarding.%20IP%20hint%20file%3A%20%24%7Bip_hint_file%7D%20is%20empty!%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%0A%20%20iface%3D%24(ip%20-j%20addr%20%7C%20jq%20-r%20%22first(.%5B%5D%20%7C%20select(any(.addr_info%5B%5D%3B%20.local%3D%3D%5C%22%24%7Bip_hint%7D%5C%22)))%20%7C%20.ifname%22)%0A%20%20if%20%5B%5B%20-z%20%22%24%7Biface%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22error%3A%20unable%20to%20enable%20IP%20forwarding.%20Cannot%20detect%20valid%20interface%20within%20file%3A%20%24%7Bip_hint_file%7D%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%20%20echo%20%22%24%7Biface%7D%22%0A%7D%0A%0Aiface%3D%24(get_nodeip_hint_interface%20%22%24%7Bip_hint_file%7D%22)%0A%0Aecho%20%22Node%20IP%20interface%20determined%20as%3A%20%24%7Biface%7D.%20Enabling%20IP%20forwarding...%22%0Afile_paths%3D(%22%2Fproc%2Fsys%2Fnet%2Fipv4%2Fconf%2F%24%7Biface%7D%2Fforwarding%22%20%22%2Fproc%2Fsys%2Fnet%2Fipv6%2Fconf%2F%24%7Biface%7D%2Fforwarding%22)%0Afor%20file_path%20in%20%22%24%7Bfile_paths%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20if%20%5B%20-f%20%22%24%7Bfile_path%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%221%22%20%3E%20%22%24%7Bfile_path%7D%22%0A%20%20%20%20fi%0Adone%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/configure-ip-forwarding.sh
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-x%0A%0Aif%20%5B%20-e%20%2Fetc%2Fnmstate%2Fopenshift%2Fapplied%20%5D%3B%20then%0A%20%20echo%20%22Skipping%20configure-ovs%20due%20to%20manual%20network%20configuration%22%0A%20%20exit%200%0Afi%0A%0A%23%20This%20file%20is%20not%20needed%20anymore%20in%204.7%2B%2C%20but%20when%20rolling%20back%20to%204.6%0A%23%20the%20ovs%20pod%20needs%20it%20to%20know%20ovs%20is%20running%20on%20the%20host.%0Atouch%20%2Fvar%2Frun%2Fovs-config-executed%0A%0A%23%20These%20are%20well%20knwon%20NM%20default%20paths%0ANM_CONN_ETC_PATH%3D%22%2Fetc%2FNetworkManager%2Fsystem-connections%22%0ANM_CONN_RUN_PATH%3D%22%2Frun%2FNetworkManager%2Fsystem-connections%22%0A%0A%23%20This%20is%20the%20path%20where%20NM%20is%20known%20to%20be%20configured%20to%20store%20user%20keyfiles%20%0ANM_CONN_CONF_PATH%3D%22%24NM_CONN_ETC_PATH%22%0A%0A%23%20This%20is%20where%20we%20want%20our%20keyfiles%20to%20finally%20reside.%20configure-ovs%0A%23%20operates%20with%20temporary%20keyfiles%20in%20NM_CONN_RUN_PATH%20and%20then%20as%20a%20last%0A%23%20step%20moves%20those%20keyfiles%20to%20NM_CONN_SET_PATH%20if%20it%20is%20a%20different%20path%0A%23%20(not%20by%20default).%20This%20mitigates%20hard%20interruptions%20(SIGKILL%2C%20hard%20reboot)%0A%23%20of%20configure-ovs%20leaving%20the%20machine%20with%20a%20half-baked%20set%20of%20keyfiles%0A%23%20that%20might%20prevent%20machine%20networking%20from%20working%20correctly.%0ANM_CONN_SET_PATH%3D%22%24%7BNM_CONN_SET_PATH%3A-%24NM_CONN_RUN_PATH%7D%22%0A%0AMANAGED_NM_CONN_SUFFIX%3D%22-slave-ovs-clone%22%0A%23%20Workaround%20to%20ensure%20OVS%20is%20installed%20due%20to%20bug%20in%20systemd%20Requires%3A%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1888017%0Acopy_nm_conn_files()%20%7B%0A%20%20local%20dst_path%3D%22%241%22%0A%20%20for%20src%20in%20%22%24%7BMANAGED_NM_CONN_FILES%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20src_path%3D%24(dirname%20%22%24src%22)%0A%20%20%20%20file%3D%24(basename%20%22%24src%22)%0A%20%20%20%20if%20%5B%20-f%20%22%24src_path%2F%24file%22%20%5D%3B%20then%0A%20%20%20%20%20%20if%20%5B%20!%20-f%20%22%24dst_path%2F%24file%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22Copying%20configuration%20%24file%22%0A%20%20%20%20%20%20%20%20cp%20%22%24src_path%2F%24file%22%20%22%24dst_path%2F%24file%22%0A%20%20%20%20%20%20elif%20!%20cmp%20--silent%20%22%24src_path%2F%24file%22%20%22%24dst_path%2F%24file%22%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22Copying%20updated%20configuration%20%24file%22%0A%20%20%20%20%20%20%20%20cp%20-f%20%22%24src_path%2F%24file%22%20%22%24dst_path%2F%24file%22%0A%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20echo%20%22Skipping%20%24file%20since%20it's%20equal%20at%20destination%22%0A%20%20%20%20%20%20fi%0A%20%20%20%20else%0A%20%20%20%20%20%20echo%20%22Skipping%20%24file%20since%20it%20does%20not%20exist%20at%20source%22%0A%20%20%20%20fi%0A%20%20done%0A%7D%0A%0Aupdate_nm_conn_files_base()%20%7B%0A%20%20base_path%3D%24%7B1%7D%0A%20%20bridge_name%3D%24%7B2%7D%0A%20%20port_name%3D%24%7B3%7D%0A%20%20ovs_port%3D%22ovs-port-%24%7Bbridge_name%7D%22%0A%20%20ovs_interface%3D%22ovs-if-%24%7Bbridge_name%7D%22%0A%20%20default_port_name%3D%22ovs-port-%24%7Bport_name%7D%22%20%23%20ovs-port-phys0%0A%20%20bridge_interface_name%3D%22ovs-if-%24%7Bport_name%7D%22%20%23%20ovs-if-phys0%0A%20%20%23%20In%20RHEL7%20files%20in%20%2F%7Betc%2Crun%7D%2FNetworkManager%2Fsystem-connections%20end%20without%20the%20suffix%20'.nmconnection'%2C%20whereas%20in%20RHCOS%20they%20end%20with%20the%20suffix.%0A%20%20MANAGED_NM_CONN_FILES%3D(%24(echo%20%22%24%7Bbase_path%7D%22%2F%7B%22%24bridge_name%22%2C%22%24ovs_interface%22%2C%22%24ovs_port%22%2C%22%24bridge_interface_name%22%2C%22%24default_port_name%22%7D%7B%2C.nmconnection%7D))%0A%20%20shopt%20-s%20nullglob%0A%20%20MANAGED_NM_CONN_FILES%2B%3D(%24%7Bbase_path%7D%2F*%24%7BMANAGED_NM_CONN_SUFFIX%7D.nmconnection%20%24%7Bbase_path%7D%2F*%24%7BMANAGED_NM_CONN_SUFFIX%7D)%0A%20%20shopt%20-u%20nullglob%0A%7D%0A%0Aupdate_nm_conn_run_files()%20%7B%0A%20%20update_nm_conn_files_base%20%22%24%7BNM_CONN_RUN_PATH%7D%22%20%22%24%7B1%7D%22%20%22%24%7B2%7D%22%0A%7D%0A%0Aupdate_nm_conn_set_files()%20%7B%0A%20%20update_nm_conn_files_base%20%22%24%7BNM_CONN_SET_PATH%7D%22%20%22%24%7B1%7D%22%20%22%24%7B2%7D%22%0A%7D%0A%0Aupdate_nm_conn_etc_files()%20%7B%0A%20%20update_nm_conn_files_base%20%22%24%7BNM_CONN_ETC_PATH%7D%22%20%22%24%7B1%7D%22%20%22%24%7B2%7D%22%0A%7D%0A%0A%23%20Move%20and%20reload%20keyfiles%20at%20their%20final%20destination%0Aset_nm_conn_files()%20%7B%0A%20%20if%20%5B%20%22%24NM_CONN_RUN_PATH%22%20!%3D%20%22%24NM_CONN_SET_PATH%22%20%5D%3B%20then%0A%20%20%20%20update_nm_conn_run_files%20br-ex%20phys0%0A%20%20%20%20copy_nm_conn_files%20%22%24NM_CONN_SET_PATH%22%0A%20%20%20%20rm_nm_conn_files%0A%20%20%20%20update_nm_conn_run_files%20br-ex1%20phys1%0A%20%20%20%20copy_nm_conn_files%20%22%24NM_CONN_SET_PATH%22%0A%20%20%20%20rm_nm_conn_files%0A%0A%20%20%20%20%23%20reload%20keyfiles%0A%20%20%20%20nmcli%20connection%20reload%0A%20%20fi%0A%7D%0A%0A%23%20Used%20to%20remove%20files%20managed%20by%20configure-ovs%20and%20temporary%20leftover%20files%20from%20network%20manager%0Arm_nm_conn_files()%20%7B%0A%20%20for%20file%20in%20%22%24%7BMANAGED_NM_CONN_FILES%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20if%20%5B%20-f%20%22%24file%22%20%5D%3B%20then%0A%20%20%20%20%20%20rm%20-f%20%22%24file%22%0A%20%20%20%20%20%20echo%20%22Removed%20nmconnection%20file%20%24file%22%0A%20%20%20%20%20%20nm_config_changed%3D1%0A%20%20%20%20fi%0A%20%20done%0A%20%20for%20file%20in%20%22%24%7BMANAGED_NM_CONN_FILES%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20for%20temp%20in%20%24(compgen%20-G%20%22%24%7Bfile%7D.*%22)%3B%20do%0A%20%20%20%20%20%20rm%20-f%20%22%24temp%22%0A%20%20%20%20%20%20echo%20%22Removed%20nmconnection%20temporary%20file%20%24temp%22%0A%20%20%20%20%20%20nm_config_changed%3D1%0A%20%20%20%20done%0A%20%20done%0A%7D%0A%0A%23%20Used%20to%20clone%20a%20slave%20connection%20by%20uuid%2C%20returns%20new%20name%0Aclone_slave_connection()%20%7B%0A%20%20local%20uuid%3D%22%241%22%0A%20%20local%20old_name%0A%20%20old_name%3D%22%24(nmcli%20-g%20connection.id%20connection%20show%20uuid%20%22%24uuid%22)%22%0A%20%20local%20new_name%3D%22%24%7Bold_name%7D%24%7BMANAGED_NM_CONN_SUFFIX%7D%22%0A%20%20if%20nmcli%20connection%20show%20id%20%22%24%7Bnew_name%7D%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20echo%20%22WARNING%3A%20existing%20ovs%20slave%20%24%7Bnew_name%7D%20connection%20profile%20file%20found%2C%20overwriting...%22%20%3E%262%0A%20%20%20%20nmcli%20connection%20delete%20id%20%22%24%7Bnew_name%7D%22%20%26%3E%20%2Fdev%2Fnull%0A%20%20fi%0A%20%20clone_nm_conn%20%24uuid%20%22%24%7Bnew_name%7D%22%0A%20%20echo%20%22%24%7Bnew_name%7D%22%0A%7D%0A%0A%23%20Used%20to%20replace%20an%20old%20master%20connection%20uuid%20with%20a%20new%20one%20on%20all%20connections%0Areplace_connection_master()%20%7B%0A%20%20local%20old%3D%22%241%22%0A%20%20local%20new%3D%22%242%22%0A%20%20for%20conn_uuid%20in%20%24(nmcli%20-g%20UUID%20connection%20show)%20%3B%20do%0A%20%20%20%20if%20%5B%20%22%24(nmcli%20-g%20connection.master%20connection%20show%20uuid%20%22%24conn_uuid%22)%22%20!%3D%20%22%24old%22%20%5D%3B%20then%0A%20%20%20%20%20%20continue%0A%20%20%20%20fi%0A%0A%20%20%20%20local%20active_state%3D%24(nmcli%20-g%20GENERAL.STATE%20connection%20show%20%22%24conn_uuid%22)%0A%20%20%20%20local%20autoconnect%3D%24(nmcli%20-g%20connection.autoconnect%20connection%20show%20%22%24conn_uuid%22)%0A%20%20%20%20if%20%5B%20%22%24active_state%22%20!%3D%20%22activated%22%20%5D%20%26%26%20%5B%20%22%24autoconnect%22%20!%3D%20%22yes%22%20%5D%3B%20then%0A%20%20%20%20%20%20%23%20Assume%20that%20slave%20profiles%20intended%20to%20be%20used%20are%20those%20that%20are%3A%0A%20%20%20%20%20%20%23%20-%20active%0A%20%20%20%20%20%20%23%20-%20or%20inactive%20(which%20might%20be%20due%20to%20link%20being%20down)%20but%20to%20be%20autoconnected.%0A%20%20%20%20%20%20%23%20Otherwise%2C%20ignore%20them.%0A%20%20%20%20%20%20continue%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20make%20changes%20for%20slave%20profiles%20in%20a%20new%20clone%0A%20%20%20%20local%20new_name%0A%20%20%20%20new_name%3D%24(clone_slave_connection%20%24conn_uuid)%0A%0A%20%20%20%20mod_nm_conn%20%22%24new_name%22%20connection.master%20%22%24new%22%20connection.autoconnect-priority%20100%20connection.autoconnect%20no%20%0A%20%20%20%20echo%20%22Replaced%20master%20%24old%20with%20%24new%20for%20slave%20profile%20%24new_name%22%0A%20%20done%0A%7D%0A%0A%23%20when%20creating%20the%20bridge%2C%20we%20use%20a%20value%20lower%20than%20NM's%20ethernet%20device%20default%20route%20metric%0A%23%20(we%20pick%2048%20and%2049%20to%20be%20lower%20than%20anything%20that%20NM%20chooses%20by%20default)%0ABRIDGE_METRIC%3D%2248%22%0ABRIDGE1_METRIC%3D%2249%22%0A%23%20Given%20an%20interface%2C%20generates%20NM%20configuration%20to%20add%20to%20an%20OVS%20bridge%0Aconvert_to_bridge()%20%7B%0A%20%20local%20iface%3D%24%7B1%7D%0A%20%20local%20bridge_name%3D%24%7B2%7D%0A%20%20local%20port_name%3D%24%7B3%7D%0A%20%20local%20bridge_metric%3D%24%7B4%7D%0A%20%20local%20ovs_port%3D%22ovs-port-%24%7Bbridge_name%7D%22%0A%20%20local%20ovs_interface%3D%22ovs-if-%24%7Bbridge_name%7D%22%0A%20%20local%20default_port_name%3D%22ovs-port-%24%7Bport_name%7D%22%20%23%20ovs-port-phys0%0A%20%20local%20bridge_interface_name%3D%22ovs-if-%24%7Bport_name%7D%22%20%23%20ovs-if-phys0%0A%0A%20%20if%20%5B%20%22%24iface%22%20%3D%20%22%24bridge_name%22%20%5D%3B%20then%0A%20%20%20%20%23%20handle%20vlans%20and%20bonds%20etc%20if%20they%20have%20already%20been%0A%20%20%20%20%23%20configured%20via%20nm%20key%20files%20and%20br-ex%20is%20already%20up%0A%20%20%20%20ifaces%3D%24(ovs-vsctl%20list-ifaces%20%24%7Biface%7D)%0A%20%20%20%20for%20intf%20in%20%24ifaces%3B%20do%20configure_driver_options%20%24intf%3B%20done%0A%20%20%20%20echo%20%22Networking%20already%20configured%20and%20up%20for%20%24%7Bbridge-name%7D!%22%0A%20%20%20%20return%0A%20%20fi%0A%0A%20%20%23%20flag%20to%20reload%20NM%20to%20account%20for%20all%20the%20configuration%20changes%0A%20%20%23%20going%20forward%0A%20%20nm_config_changed%3D1%0A%0A%20%20if%20%5B%20-z%20%22%24iface%22%20%5D%3B%20then%0A%20%20%20%20echo%20%22ERROR%3A%20Unable%20to%20find%20default%20gateway%20interface%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%20%20%23%20find%20the%20MAC%20from%20OVS%20config%20or%20the%20default%20interface%20to%20use%20for%20OVS%20internal%20port%0A%20%20%23%20this%20prevents%20us%20from%20getting%20a%20different%20DHCP%20lease%20and%20dropping%20connection%0A%20%20if%20!%20iface_mac%3D%24(%3C%22%2Fsys%2Fclass%2Fnet%2F%24%7Biface%7D%2Faddress%22)%3B%20then%0A%20%20%20%20echo%20%22Unable%20to%20determine%20default%20interface%20MAC%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%0A%20%20echo%20%22MAC%20address%20found%20for%20iface%3A%20%24%7Biface%7D%3A%20%24%7Biface_mac%7D%22%0A%0A%20%20%23%20find%20MTU%20from%20original%20iface%0A%20%20iface_mtu%3D%24(ip%20link%20show%20%22%24iface%22%20%7C%20awk%20'%7Bprint%20%245%3B%20exit%7D')%0A%20%20if%20%5B%5B%20-z%20%22%24iface_mtu%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22Unable%20to%20determine%20default%20interface%20MTU%2C%20defaulting%20to%201500%22%0A%20%20%20%20iface_mtu%3D1500%0A%20%20else%0A%20%20%20%20echo%20%22MTU%20found%20for%20iface%3A%20%24%7Biface%7D%3A%20%24%7Biface_mtu%7D%22%0A%20%20fi%0A%0A%20%20%23%20store%20old%20conn%20for%20later%0A%20%20old_conn%3D%24(nmcli%20--fields%20UUID%2CDEVICE%20conn%20show%20--active%20%7C%20awk%20%22%2F%5Cs%24%7Biface%7D%5Cs*%5C%24%2F%20%7Bprint%20%5C%241%7D%22)%0A%0A%20%20if%20%5B%5B%20-z%20%22%24old_conn%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22ERROR%3A%20cannot%20find%20connection%20for%20interface%3A%20%24%7Biface%7D%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%0A%20%20%23%20create%20bridge%0A%20%20if%20!%20nmcli%20connection%20show%20%22%24bridge_name%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-br%20%22%24bridge_name%22%0A%20%20%20%20add_nm_conn%20%22%24bridge_name%22%20type%20ovs-bridge%20conn.interface%20%22%24bridge_name%22%20802-3-ethernet.mtu%20%24%7Biface_mtu%7D%20%5C%0A%20%20%20%20connection.autoconnect-slaves%201%0A%20%20fi%0A%0A%20%20%23%20find%20default%20port%20to%20add%20to%20bridge%0A%20%20if%20!%20nmcli%20connection%20show%20%22%24default_port_name%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-port%20%22%24bridge_name%22%20%24%7Biface%7D%0A%20%20%20%20add_nm_conn%20%22%24default_port_name%22%20type%20ovs-port%20conn.interface%20%24%7Biface%7D%20slave-type%20ovs-bridge%20master%20%22%24bridge_name%22%20%5C%0A%20%20%20%20connection.autoconnect-slaves%201%0A%20%20fi%0A%0A%20%20if%20!%20nmcli%20connection%20show%20%22%24ovs_port%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-port%20%22%24bridge_name%22%20%22%24bridge_name%22%0A%20%20%20%20add_nm_conn%20%22%24ovs_port%22%20type%20ovs-port%20conn.interface%20%22%24bridge_name%22%20slave-type%20ovs-bridge%20master%20%22%24bridge_name%22%0A%20%20fi%0A%0A%20%20extra_phys_args%3D()%0A%20%20%23%20check%20if%20this%20interface%20is%20a%20vlan%2C%20bond%2C%20team%2C%20or%20ethernet%20type%0A%20%20if%20%5B%20%22%24(nmcli%20--get-values%20connection.type%20conn%20show%20%24%7Bold_conn%7D)%22%20%3D%3D%20%22vlan%22%20%5D%3B%20then%0A%20%20%20%20iface_type%3Dvlan%0A%20%20%20%20vlan_id%3D%24(nmcli%20--get-values%20vlan.id%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20if%20%5B%20-z%20%22%24vlan_id%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22ERROR%3A%20unable%20to%20determine%20vlan_id%20for%20vlan%20connection%3A%20%24%7Bold_conn%7D%22%0A%20%20%20%20%20%20exit%201%0A%20%20%20%20fi%0A%20%20%20%20vlan_parent%3D%24(nmcli%20--get-values%20vlan.parent%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20if%20%5B%20-z%20%22%24vlan_parent%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22ERROR%3A%20unable%20to%20determine%20vlan_parent%20for%20vlan%20connection%3A%20%24%7Bold_conn%7D%22%0A%20%20%20%20%20%20exit%201%0A%20%20%20%20fi%0A%0A%20%20%20%20if%20nmcli%20connection%20show%20uuid%20%22%24vlan_parent%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20%20%20%23%20if%20the%20VLAN%20connection%20is%20configured%20with%20a%20connection%20UUID%20as%20parent%2C%20we%20need%20to%20find%20the%20underlying%20device%0A%20%20%20%20%20%20%23%20and%20create%20the%20bridge%20against%20it%2C%20as%20the%20parent%20connection%20can%20be%20replaced%20by%20another%20bridge.%0A%20%20%20%20%20%20vlan_parent%3D%24(nmcli%20--get-values%20GENERAL.DEVICES%20conn%20show%20uuid%20%24%7Bvlan_parent%7D)%0A%20%20%20%20fi%0A%0A%20%20%20%20extra_phys_args%3D(%20dev%20%22%24%7Bvlan_parent%7D%22%20id%20%22%24%7Bvlan_id%7D%22%20)%0A%20%20elif%20%5B%20%22%24(nmcli%20--get-values%20connection.type%20conn%20show%20%24%7Bold_conn%7D)%22%20%3D%3D%20%22bond%22%20%5D%3B%20then%0A%20%20%20%20iface_type%3Dbond%0A%20%20%20%20%23%20check%20bond%20options%0A%20%20%20%20bond_opts%3D%24(nmcli%20--get-values%20bond.options%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20if%20%5B%20-n%20%22%24bond_opts%22%20%5D%3B%20then%0A%20%20%20%20%20%20extra_phys_args%2B%3D(%20bond.options%20%22%24%7Bbond_opts%7D%22%20)%0A%20%20%20%20%20%20MODE_REGEX%3D%22(%5E%7C%2C)mode%3Dactive-backup(%2C%7C%24)%22%0A%20%20%20%20%20%20MAC_REGEX%3D%22(%5E%7C%2C)fail_over_mac%3D(1%7Cactive%7C2%7Cfollow)(%2C%7C%24)%22%0A%20%20%20%20%20%20if%20%5B%5B%20%24bond_opts%20%3D~%20%24MODE_REGEX%20%5D%5D%20%26%26%20%5B%5B%20%24bond_opts%20%3D~%20%24MAC_REGEX%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20clone_mac%3D0%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%20%20elif%20%5B%20%22%24(nmcli%20--get-values%20connection.type%20conn%20show%20%24%7Bold_conn%7D)%22%20%3D%3D%20%22team%22%20%5D%3B%20then%0A%20%20%20%20iface_type%3Dteam%0A%20%20%20%20%23%20check%20team%20config%20options%0A%20%20%20%20team_config_opts%3D%24(nmcli%20--get-values%20team.config%20-e%20no%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20if%20%5B%20-n%20%22%24team_config_opts%22%20%5D%3B%20then%0A%20%20%20%20%20%20%23%20team.config%20is%20json%2C%20remove%20spaces%20to%20avoid%20problems%20later%20on%0A%20%20%20%20%20%20extra_phys_args%2B%3D(%20team.config%20%22%24%7Bteam_config_opts%2F%2F%5B%5B%3Aspace%3A%5D%5D%2F%7D%22%20)%0A%20%20%20%20%20%20team_mode%3D%24(echo%20%22%24%7Bteam_config_opts%7D%22%20%7C%20jq%20-r%20%22.runner.name%20%2F%2F%20empty%22)%0A%20%20%20%20%20%20team_mac_policy%3D%24(echo%20%22%24%7Bteam_config_opts%7D%22%20%7C%20jq%20-r%20%22.runner.hwaddr_policy%20%2F%2F%20empty%22)%0A%20%20%20%20%20%20MAC_REGEX%3D%22(by_active%7Conly_active)%22%0A%20%20%20%20%20%20if%20%5B%20%22%24team_mode%22%20%3D%20%22activebackup%22%20%5D%20%26%26%20%5B%5B%20%22%24team_mac_policy%22%20%3D~%20%24MAC_REGEX%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20clone_mac%3D0%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%20%20elif%20%5B%20%22%24(nmcli%20--get-values%20connection.type%20conn%20show%20%24%7Bold_conn%7D)%22%20%3D%3D%20%22tun%22%20%5D%3B%20then%0A%20%20%20%20iface_type%3Dtun%0A%20%20%20%20tun_mode%3D%24(nmcli%20--get-values%20tun.mode%20-e%20no%20connection%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20extra_phys_args%2B%3D(%20tun.mode%20%22%24%7Btun_mode%7D%22%20)%0A%20%20elif%20%5B%20%22%24(nmcli%20--get-values%20connection.type%20conn%20show%20%24%7Bold_conn%7D)%22%20%3D%3D%20%22bridge%22%20%5D%3B%20then%0A%20%20%20%20iface_type%3Dbridge%0A%20%20else%0A%20%20%20%20iface_type%3D802-3-ethernet%0A%20%20fi%0A%0A%20%20if%20%5B%20!%20%22%24%7Bclone_mac%3A-%7D%22%20%3D%20%220%22%20%5D%3B%20then%0A%20%20%20%20%23%20In%20active-backup%20link%20aggregation%2C%20with%20fail_over_mac%20mode%20enabled%2C%0A%20%20%20%20%23%20cloning%20the%20mac%20address%20is%20not%20supported.%20It%20is%20possible%20then%20that%0A%20%20%20%20%23%20br-ex%20has%20a%20different%20mac%20address%20than%20the%20bond%20which%20might%20be%0A%20%20%20%20%23%20troublesome%20on%20some%20platforms%20where%20the%20nic%20won't%20accept%20packets%20with%0A%20%20%20%20%23%20a%20different%20destination%20mac.%20But%20nobody%20has%20complained%20so%20far%20so%20go%20on%0A%20%20%20%20%23%20with%20what%20we%20got.%20%0A%20%20%20%20%0A%20%20%20%20%23%20Do%20set%20it%20though%20for%20other%20link%20aggregation%20configurations%20where%20the%0A%20%20%20%20%23%20mac%20address%20would%20otherwise%20depend%20on%20enslave%20order%20for%20which%20we%20have%0A%20%20%20%20%23%20no%20control%20going%20forward.%0A%20%20%20%20extra_phys_args%2B%3D(%20802-3-ethernet.cloned-mac-address%20%22%24%7Biface_mac%7D%22%20)%0A%20%20fi%0A%0A%20%20%23%20use%20%24%7Bextra_phys_args%5B%40%5D%2B%22%24%7Bextra_phys_args%5B%40%5D%7D%22%7D%20instead%20of%20%24%7Bextra_phys_args%5B%40%5D%7D%20to%20be%20compatible%20with%20bash%204.2%20in%20RHEL7.9%0A%20%20if%20!%20nmcli%20connection%20show%20%22%24bridge_interface_name%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20destroy%20interface%20%24%7Biface%7D%0A%20%20%20%20ovs_default_port_conn%3D%24(nmcli%20-g%20connection.uuid%20conn%20show%20%22%24default_port_name%22)%0A%20%20%20%20add_nm_conn%20%22%24bridge_interface_name%22%20type%20%24%7Biface_type%7D%20conn.interface%20%24%7Biface%7D%20master%20%22%24ovs_default_port_conn%22%20%5C%0A%20%20%20%20%20%20slave-type%20ovs-port%20connection.autoconnect-priority%20100%20connection.autoconnect-slaves%201%20802-3-ethernet.mtu%20%24%7Biface_mtu%7D%20%5C%0A%20%20%20%20%20%20%24%7Bextra_phys_args%5B%40%5D%2B%22%24%7Bextra_phys_args%5B%40%5D%7D%22%7D%0A%20%20fi%0A%0A%20%20%23%20Get%20the%20new%20connection%20uuids%0A%20%20new_conn%3D%24(nmcli%20-g%20connection.uuid%20conn%20show%20%22%24bridge_interface_name%22)%0A%20%20ovs_port_conn%3D%24(nmcli%20-g%20connection.uuid%20conn%20show%20%22%24ovs_port%22)%0A%0A%20%20%23%20Update%20connections%20with%20master%20property%20set%20to%20use%20the%20new%20connection%0A%20%20replace_connection_master%20%24old_conn%20%24new_conn%0A%20%20replace_connection_master%20%24iface%20%24new_conn%0A%0A%20%20ipv4_method%3D%24(nmcli%20-g%20ipv4.method%20conn%20show%20%22%24old_conn%22)%0A%20%20ipv6_method%3D%24(nmcli%20-g%20ipv6.method%20conn%20show%20%22%24old_conn%22)%0A%0A%20%20ipv4_addresses%3D%24(nmcli%20-g%20ipv4.addresses%20conn%20show%20%22%24old_conn%22)%0A%20%20ipv6_addresses%3D%24(nmcli%20-g%20ipv6.addresses%20conn%20show%20%22%24old_conn%22)%0A%0A%20%20%23%20Warn%20about%20an%20invalid%20MTU%20that%20will%20most%20likely%20fail%20in%20one%20way%20or%0A%20%20%23%20another%0A%20%20if%20%5B%20%24%7Biface_mtu%7D%20-lt%201280%20%5D%20%26%26%20%5B%20%22%24%7Bipv6_method%7D%22%20!%3D%20%22disabled%22%20%5D%3B%20then%0A%20%20%20%20echo%20%22WARNING%3A%20MTU%20%24%7Biface_mtu%7D%20is%20lower%20than%20the%20minimum%20required%20of%201280%20for%20IPv6%22%0A%20%20fi%0A%0A%20%20if%20!%20nmcli%20connection%20show%20%22%24ovs_interface%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20destroy%20interface%20%22%24bridge_name%22%0A%20%20%20%20%23%20Clone%20the%20connection%20in%20case%20the%20method%20is%20manual%20or%20in%20case%20the%20an%20address%20is%20set%20(DHCP%20%2B%20static%20IP)%0A%20%20%20%20if%20%5B%20%22%24%7Bipv4_method%7D%22%20%3D%20%22manual%22%20%5D%20%7C%7C%20%5B%20%22%24%7Bipv4_addresses%7D%22%20!%3D%20%22%22%20%5D%20%7C%7C%20%5B%20%22%24%7Bipv6_method%7D%22%20%3D%20%22manual%22%20%5D%20%7C%7C%20%5B%20%22%24%7Bipv6_addresses%7D%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22Static%20IP%20addressing%20detected%20on%20default%20gateway%20connection%3A%20%24%7Bold_conn%7D%22%0A%20%20%20%20%20%20%23%20clone%20the%20old%20connection%20to%20get%20the%20address%20settings%0A%20%20%20%20%20%20%23%20prefer%20cloning%20vs%20copying%20the%20connection%20file%20to%20avoid%20problems%20with%20selinux%0A%20%20%20%20%20%20clone_nm_conn%20%22%24%7Bold_conn%7D%22%20%22%24%7Bovs_interface%7D%22%0A%20%20%20%20%20%20shopt%20-s%20nullglob%0A%20%20%20%20%20%20new_conn_files%3D(%24%7BNM_CONN_RUN_PATH%7D%2F%22%24%7Bovs_interface%7D%22*)%0A%20%20%20%20%20%20shopt%20-u%20nullglob%0A%20%20%20%20%20%20if%20%5B%20%24%7B%23new_conn_files%5B%40%5D%7D%20-ne%201%20%5D%20%7C%7C%20%5B%20!%20-f%20%22%24%7Bnew_conn_files%5B0%5D%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22ERROR%3A%20could%20not%20find%20%24%7Bovs_interface%7D%20conn%20file%20after%20cloning%20from%20%24%7Bold_conn%7D%22%0A%20%20%20%20%20%20%20%20exit%201%0A%20%20%20%20%20%20fi%0A%20%20%20%20%20%20new_conn_file%3D%22%24%7Bnew_conn_files%5B0%5D%7D%22%0A%0A%20%20%20%20%20%20%23%20modify%20the%20connection%20type%20directly%20because%20it%20can't%20be%20modified%0A%20%20%20%20%20%20%23%20through%20nmcli%0A%20%20%20%20%20%20sed%20-i%20'%2F%5E%5C%5Bconnection%5C%5D%24%2F%2C%2F%5E%5C%5B%2F%20s%2F%5Etype%3D.*%24%2Ftype%3Dovs-interface%2F'%20%24%7Bnew_conn_file%7D%0A%0A%20%20%20%20%20%20%23%20modify%20some%20more%20settings%20through%20nmcli%0A%20%20%20%20%20%20mod_nm_conn%20%22%24%7Bovs_interface%7D%22%20conn.interface%20%22%24bridge_name%22%20%5C%0A%20%20%20%20%20%20%20%20connection.multi-connect%20%22%22%20connection.autoconnect%20no%20%5C%0A%20%20%20%20%20%20%20%20connection.master%20%22%24ovs_port_conn%22%20connection.slave-type%20ovs-port%20%5C%0A%20%20%20%20%20%20%20%20ovs-interface.type%20internal%20%5C%0A%20%20%20%20%20%20%20%20802-3-ethernet.mtu%20%24%7Biface_mtu%7D%20802-3-ethernet.cloned-mac-address%20%24%7Biface_mac%7D%20%5C%0A%20%20%20%20%20%20%20%20ipv4.route-metric%20%22%24%7Bbridge_metric%7D%22%20ipv6.route-metric%20%22%24%7Bbridge_metric%7D%22%0A%0A%20%20%20%20%20%20echo%20%22Loaded%20new%20%24ovs_interface%20connection%20file%3A%20%24%7Bnew_conn_file%7D%22%0A%20%20%20%20else%0A%20%20%20%20%20%20extra_if_brex_args%3D%22%22%0A%20%20%20%20%20%20%23%20check%20if%20interface%20had%20ipv4%2Fipv6%20addresses%20assigned%0A%20%20%20%20%20%20num_ipv4_addrs%3D%24(ip%20-j%20a%20show%20dev%20%24%7Biface%7D%20%7C%20jq%20%22.%5B0%5D.addr_info%20%7C%20map(.%20%7C%20select(.family%20%3D%3D%20%5C%22inet%5C%22))%20%7C%20length%22)%0A%20%20%20%20%20%20if%20%5B%20%22%24num_ipv4_addrs%22%20-gt%200%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20extra_if_brex_args%2B%3D%22ipv4.may-fail%20no%20%22%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20%23%20IPV6%20should%20have%20at%20least%20a%20link%20local%20address.%20Check%20for%20more%20than%201%20to%20see%20if%20there%20is%20an%0A%20%20%20%20%20%20%23%20assigned%20address.%0A%20%20%20%20%20%20num_ip6_addrs%3D%24(ip%20-j%20a%20show%20dev%20%24%7Biface%7D%20%7C%20jq%20%22.%5B0%5D.addr_info%20%7C%20map(.%20%7C%20select(.family%20%3D%3D%20%5C%22inet6%5C%22%20and%20.scope%20!%3D%20%5C%22link%5C%22))%20%7C%20length%22)%0A%20%20%20%20%20%20if%20%5B%20%22%24num_ip6_addrs%22%20-gt%200%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20extra_if_brex_args%2B%3D%22ipv6.may-fail%20no%20%22%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20%23%20check%20for%20dhcp%20client%20ids%0A%20%20%20%20%20%20dhcp_client_id%3D%24(nmcli%20--get-values%20ipv4.dhcp-client-id%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20%20%20if%20%5B%20-n%20%22%24dhcp_client_id%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20extra_if_brex_args%2B%3D%22ipv4.dhcp-client-id%20%24%7Bdhcp_client_id%7D%20%22%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20dhcp6_client_id%3D%24(nmcli%20--get-values%20ipv6.dhcp-duid%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20%20%20if%20%5B%20-n%20%22%24dhcp6_client_id%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20extra_if_brex_args%2B%3D%22ipv6.dhcp-duid%20%24%7Bdhcp6_client_id%7D%20%22%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20ipv6_addr_gen_mode%3D%24(nmcli%20--get-values%20ipv6.addr-gen-mode%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20%20%20if%20%5B%20-n%20%22%24ipv6_addr_gen_mode%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20extra_if_brex_args%2B%3D%22ipv6.addr-gen-mode%20%24%7Bipv6_addr_gen_mode%7D%20%22%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20add_nm_conn%20%22%24ovs_interface%22%20type%20ovs-interface%20slave-type%20ovs-port%20conn.interface%20%22%24bridge_name%22%20master%20%22%24ovs_port_conn%22%20%5C%0A%20%20%20%20%20%20%20%20802-3-ethernet.mtu%20%24%7Biface_mtu%7D%20802-3-ethernet.cloned-mac-address%20%24%7Biface_mac%7D%20%5C%0A%20%20%20%20%20%20%20%20ipv4.method%20%22%24%7Bipv4_method%7D%22%20ipv4.route-metric%20%22%24%7Bbridge_metric%7D%22%20%5C%0A%20%20%20%20%20%20%20%20ipv6.method%20%22%24%7Bipv6_method%7D%22%20ipv6.route-metric%20%22%24%7Bbridge_metric%7D%22%20%5C%0A%20%20%20%20%20%20%20%20%24%7Bextra_if_brex_args%7D%0A%20%20%20%20fi%0A%20%20fi%0A%0A%20%20configure_driver_options%20%22%24%7Biface%7D%22%0A%7D%0A%0A%23%20Used%20to%20remove%20a%20bridge%0Aremove_ovn_bridges()%20%7B%0A%20%20bridge_name%3D%24%7B1%7D%0A%20%20port_name%3D%24%7B2%7D%0A%0A%20%20%23%20Remove%20the%20keyfiles%20from%20known%20configuration%20paths%0A%20%20update_nm_conn_run_files%20%24%7Bbridge_name%7D%20%24%7Bport_name%7D%0A%20%20rm_nm_conn_files%0A%20%20update_nm_conn_set_files%20%24%7Bbridge_name%7D%20%24%7Bport_name%7D%0A%20%20rm_nm_conn_files%0A%20%20%23%20Shouldn't%20be%20necessary%2C%20workaround%20for%20https%3A%2F%2Fissues.redhat.com%2Fbrowse%2FOCPBUGS-41489%0A%20%20update_nm_conn_etc_files%20%24%7Bbridge_name%7D%20%24%7Bport_name%7D%0A%20%20rm_nm_conn_files%0A%0A%20%20%23%20NetworkManager%20will%20not%20remove%20%24%7Bbridge_name%7D%20if%20it%20has%20the%20patch%20port%20created%20by%20ovn-kubernetes%0A%20%20%23%20so%20remove%20explicitly%0A%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-br%20%24%7Bbridge_name%7D%0A%7D%0A%0A%23%20Removes%20any%20previous%20ovs%20configuration%0Aremove_all_ovn_bridges()%20%7B%0A%20%20echo%20%22Reverting%20any%20previous%20OVS%20configuration%22%0A%20%20%0A%20%20remove_ovn_bridges%20br-ex%20phys0%0A%20%20remove_ovn_bridges%20br-ex1%20phys1%0A%20%20%0A%20%20echo%20%22OVS%20configuration%20successfully%20reverted%22%0A%7D%0A%0A%23%20Reloads%20NM%20NetworkManager%20profiles%20if%20any%20configuration%20change%20was%20done.%0A%23%20Accepts%20a%20list%20of%20devices%20that%20should%20be%20re-connect%20after%20reload.%0Areload_profiles_nm()%20%7B%0A%20%20if%20%5B%20%24%7Bnm_config_changed%3A-0%7D%20-eq%200%20%5D%3B%20then%0A%20%20%20%20%23%20no%20config%20was%20changed%2C%20no%20need%20to%20reload%0A%20%20%20%20return%0A%20%20fi%0A%0A%20%20%23%20reload%20profiles%0A%20%20nmcli%20connection%20reload%0A%0A%20%20%23%20precautionary%20sleep%20of%2010s%20(default%20timeout%20of%20NM%20to%20bring%20down%20devices)%0A%20%20sleep%2010%0A%0A%20%20%23%20After%20reload%2C%20devices%20that%20were%20already%20connected%20should%20connect%20again%0A%20%20%23%20if%20any%20profile%20is%20available.%20If%20no%20profile%20is%20available%2C%20a%20device%20can%0A%20%20%23%20remain%20disconnected%20and%20we%20have%20to%20explicitly%20connect%20it%20so%20that%20a%0A%20%20%23%20profile%20is%20generated.%20This%20can%20happen%20for%20physical%20devices%20but%20should%0A%20%20%23%20not%20happen%20for%20software%20devices%20as%20those%20always%20require%20a%20profile.%0A%20%20for%20dev%20in%20%24%40%3B%20do%0A%20%20%20%20%23%20Only%20attempt%20to%20connect%20a%20disconnected%20device%0A%20%20%20%20local%20connected_state%3D%24(nmcli%20-g%20GENERAL.STATE%20device%20show%20%22%24dev%22%20%7C%7C%20echo%20%22%22)%0A%20%20%20%20if%20%5B%5B%20%22%24connected_state%22%20%3D~%20%22disconnected%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%23%20keep%20track%20if%20a%20profile%20by%20the%20same%20name%20as%20the%20device%20existed%20%0A%20%20%20%20%20%20%23%20before%20we%20attempt%20activation%0A%20%20%20%20%20%20local%20named_profile_existed%3D%24(%5B%20-f%20%22%24%7BNM_CONN_CONF_PATH%7D%2F%24%7Bdev%7D%22%20%5D%20%7C%7C%20%5B%20-f%20%22%24%7BNM_CONN_CONF_PATH%7D%2F%24%7Bdev%7D.nmconnection%22%20%5D%20%26%26%20echo%20%22yes%22)%0A%20%20%20%20%20%20%0A%20%20%20%20%20%20for%20i%20in%20%7B1..10%7D%3B%20do%0A%20%20%20%20%20%20%20%20%20%20echo%20%22Attempt%20%24i%20to%20connect%20device%20%24dev%22%0A%20%20%20%20%20%20%20%20%20%20nmcli%20device%20connect%20%22%24dev%22%20%26%26%20break%0A%20%20%20%20%20%20%20%20%20%20sleep%205%0A%20%20%20%20%20%20done%0A%0A%20%20%20%20%20%20%23%20if%20a%20profile%20did%20not%20exist%20before%20but%20does%20now%2C%20it%20was%20generated%0A%20%20%20%20%20%20%23%20but%20we%20want%20it%20to%20be%20ephemeral%2C%20so%20move%20it%20back%20to%20%2Frun%0A%20%20%20%20%20%20if%20%5B%20!%20%22%24named_profile_existed%22%20%3D%20%22yes%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20MANAGED_NM_CONN_FILES%3D(%22%24%7BNM_CONN_CONF_PATH%7D%2F%24%7Bdev%7D%22%20%22%24%7BNM_CONN_CONF_PATH%7D%2F%24%7Bdev%7D.nmconnection%22)%0A%20%20%20%20%20%20%20%20copy_nm_conn_files%20%22%24%7BNM_CONN_RUN_PATH%7D%22%0A%20%20%20%20%20%20%20%20rm_nm_conn_files%0A%20%20%20%20%20%20%20%20%23%20reload%20profiles%20so%20that%20NM%20notices%20that%20some%20might%20have%20been%20moved%0A%20%20%20%20%20%20%20%20nmcli%20connection%20reload%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20echo%20%22Waiting%20for%20interface%20%24dev%20to%20activate...%22%0A%20%20%20%20if%20!%20timeout%2060%20bash%20-c%20%22while%20!%20nmcli%20-g%20DEVICE%2CSTATE%20c%20%7C%20grep%20%22'%22'%22%24dev%22%3Aactivated'%22'%22%3B%20do%20sleep%205%3B%20done%22%3B%20then%0A%20%20%20%20%20%20echo%20%22WARNING%3A%20%24dev%20did%20not%20activate%22%0A%20%20%20%20fi%0A%20%20done%0A%0A%20%20nm_config_changed%3D0%0A%7D%0A%0A%23%20Removes%20all%20configuration%20and%20reloads%20NM%20if%20necessary%0Arollback_nm()%20%7B%0A%20%20phys0%3D%24(get_bridge_physical_interface%20ovs-if-phys0)%0A%20%20phys1%3D%24(get_bridge_physical_interface%20ovs-if-phys1)%0A%20%20%0A%20%20%23%20Revert%20changes%20made%20by%20%2Fusr%2Flocal%2Fbin%2Fconfigure-ovs.sh%20during%20SDN%20migration.%0A%20%20remove_all_ovn_bridges%0A%20%20%0A%20%20%23%20reload%20profiles%20so%20that%20NM%20notices%20that%20some%20were%20removed%0A%20%20reload_profiles_nm%20%22%24phys0%22%20%22%24phys1%22%0A%7D%0A%0A%23%20Add%20a%20temporary%20deactivated%20connection%20profile%20%0A%23%20First%20argument%20is%20the%20connection%20name%20folowed%20by%20arguments%20passed%20to%0A%23%20%60nmcli%20connection%20add%60%0Aadd_nm_conn()%20%7B%0A%20%20%23%20Use%20%60save%20no%60%20to%20add%20a%20temporary%20profile%0A%20%20nmcli%20c%20add%20save%20no%20con-name%20%22%24%40%22%20connection.autoconnect%20no%0A%7D%0A%0A%23%20Modify%20a%20temporary%20connection%20profile%20%0A%23%20First%20argument%20is%20the%20connection%20name%20followed%20by%20arguments%20passed%20to%0A%23%20%60nmcli%20connection%20modify%60%0Amod_nm_conn()%20%7B%0A%20%20%23%20the%20easiest%20thing%20to%20do%20here%20would%20be%20to%20use%20%60nmcli%20c%20mod%20--temporary%60%0A%20%20%23%20but%20there%20is%20a%20bug%20in%20selinux%20profiles%20that%20denies%20NM%20from%20performing%0A%20%20%23%20the%20operation%0A%20%20local%20dst_path%3D%24%7BNM_CONN_RUN_PATH%7D%2F%241.nmconnection%0A%20%20local%20src_path%0A%20%20src_path%3D%24(mktemp)%0A%20%20shift%0A%20%20cat%20%22%24dst_path%22%20%3E%20%22%24src_path%22%0A%20%20rm%20-f%20%22%24dst_path%22%0A%20%20nmcli%20--offline%20c%20mod%20%22%24%40%22%20%3C%20%22%24src_path%22%20%3E%20%22%24dst_path%22%0A%20%20rm%20-f%20%22%24src_path%22%0A%20%20chmod%20600%20%22%24dst_path%22%0A%20%20nmcli%20c%20load%20%22%24dst_path%22%0A%7D%0A%0A%23%20Clone%20to%20a%20temporary%20connection%20profile%20%0A%23%20First%20argument%20is%20the%20connection%20to%20clone%2C%20second%20argument%20is%20the%20clone%20name%0Aclone_nm_conn()%20%7B%0A%20%20%23%20clone%20as%20temporary%20so%20that%20it%20is%20generated%20in%20NM_CONN_RUN_PATH%0A%20%20nmcli%20connection%20clone%20--temporary%20%22%241%22%20%22%242%22%20%26%3E%20%2Fdev%2Fnull%0A%7D%0A%0A%23%20Activates%20an%20ordered%20set%20of%20NM%20connection%20profiles%0Aactivate_nm_connections()%20%7B%0A%20%20local%20connections%3D(%22%24%40%22)%0A%0A%20%20%23%20We%20want%20autoconnect%20set%20for%20our%20cloned%20slave%20profiles%20so%20that%20they%20are%0A%20%20%23%20used%20over%20the%20original%20profiles%20if%20implicitly%20re-activated%20with%20other%0A%20%20%23%20dependant%20profiles.%20Otherwise%20if%20a%20slave%20activates%20with%20an%20old%20profile%2C%0A%20%20%23%20the%20old%20master%20profile%20might%20activate%20as%20well%2C%20interfering%20and%20causing%0A%20%20%23%20further%20activations%20to%20fail.%0A%20%20%23%20Slave%20interfaces%20should%20already%20be%20active%20so%20setting%20autoconnect%20here%0A%20%20%23%20won't%20implicitly%20activate%20them%20but%20there%20is%20an%20edge%20case%20where%20a%20slave%0A%20%20%23%20might%20be%20inactive%20(link%20down%20for%20example)%20and%20in%20that%20case%20setting%0A%20%20%23%20autoconnect%20will%20cause%20an%20implicit%20activation.%20This%20is%20not%20necessarily%20a%0A%20%20%23%20problem%20and%20hopefully%20we%20can%20make%20sure%20everything%20is%20activated%20as%20we%0A%20%20%23%20want%20next.%0A%20%20for%20conn%20in%20%22%24%7Bconnections%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20local%20slave_type%3D%24(nmcli%20-g%20connection.slave-type%20connection%20show%20%22%24conn%22)%0A%20%20%20%20if%20%5B%20%22%24slave_type%22%20%3D%20%22team%22%20%5D%20%7C%7C%20%5B%20%22%24slave_type%22%20%3D%20%22bond%22%20%5D%3B%20then%0A%20%20%20%20%20%20mod_nm_conn%20%22%24conn%22%20connection.autoconnect%20yes%0A%20%20%20%20fi%0A%20%20done%0A%0A%20%20%23%20Activate%20all%20connections%20and%20fail%20if%20activation%20fails%0A%20%20%23%20For%20slave%20connections%20-%20for%20as%20long%20as%20at%20least%20one%20slave%20that%20belongs%20to%20a%20bond%2Fteam%0A%20%20%23%20comes%20up%2C%20we%20should%20not%20fail%0A%20%20declare%20-A%20master_interfaces%0A%20%20for%20conn%20in%20%22%24%7Bconnections%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20%23%20Get%20the%20slave%20type%0A%20%20%20%20local%20slave_type%3D%24(nmcli%20-g%20connection.slave-type%20connection%20show%20%22%24conn%22)%0A%20%20%20%20local%20is_slave%3Dfalse%0A%20%20%20%20if%20%5B%20%22%24slave_type%22%20%3D%20%22team%22%20%5D%20%7C%7C%20%5B%20%22%24slave_type%22%20%3D%20%22bond%22%20%5D%3B%20then%0A%20%20%20%20%20%20is_slave%3Dtrue%0A%20%20%20%20fi%20%0A%0A%20%20%20%20%23%20For%20slave%20interfaces%2C%20initialize%20the%20master%20interface%20to%20false%20if%20the%20key%20is%20not%20yet%20in%20the%20array%0A%20%20%20%20local%20master_interface%0A%20%20%20%20if%20%24is_slave%3B%20then%0A%20%20%20%20%20%20master_interface%3D%24(nmcli%20-g%20connection.master%20connection%20show%20%22%24conn%22)%0A%20%20%20%20%20%20if%20!%20%5B%5B%20-v%20%22master_interfaces%5B%24master_interface%5D%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20master_interfaces%5B%22%24master_interface%22%5D%3Dfalse%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20slaves%20should%20implicitly%20activate%2C%20give%20them%20a%20chance%20to%20do%20so%0A%20%20%20%20if%20%24is_slave%3B%20then%0A%20%20%20%20%20%20if%20!%20timeout%205%20bash%20-c%20%22while%20!%20nmcli%20-g%20GENERAL.STATE%20conn%20show%20%22%24conn%22%20%7C%20grep%20activated%3B%20do%20sleep%201%3B%20done%22%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22WARNING%3A%20slave%20%24conn%20did%20not%20implicitly%20activate%20in%205s%2C%20activating%20explicitly.%22%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Do%20not%20activate%20interfaces%20that%20are%20already%20active%0A%20%20%20%20%23%20But%20set%20the%20entry%20in%20master_interfaces%20to%20true%20if%20this%20is%20a%20slave%0A%20%20%20%20%23%20Also%20set%20autoconnect%20to%20yes%0A%20%20%20%20local%20active_state%3D%24(nmcli%20-g%20GENERAL.STATE%20conn%20show%20%22%24conn%22)%0A%20%20%20%20if%20%5B%20%22%24active_state%22%20%3D%3D%20%22activated%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22Connection%20%24conn%20already%20activated%22%0A%20%20%20%20%20%20if%20%24is_slave%3B%20then%0A%20%20%20%20%20%20%20%20master_interfaces%5B%24master_interface%5D%3Dtrue%0A%20%20%20%20%20%20fi%0A%20%20%20%20%20%20mod_nm_conn%20%22%24conn%22%20connection.autoconnect%20yes%0A%20%20%20%20%20%20continue%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Activate%20all%20interfaces%20that%20are%20not%20yet%20active%0A%20%20%20%20for%20i%20in%20%7B1..10%7D%3B%20do%0A%20%20%20%20%20%20echo%20%22Attempt%20%24i%20to%20bring%20up%20connection%20%24conn%22%0A%20%20%20%20%20%20nmcli%20conn%20up%20%22%24conn%22%20%26%26%20s%3D0%20%26%26%20break%20%7C%7C%20s%3D%24%3F%0A%20%20%20%20%20%20sleep%205%0A%20%20%20%20done%0A%20%20%20%20if%20%5B%20%24s%20-eq%200%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22Brought%20up%20connection%20%24conn%20successfully%22%0A%20%20%20%20%20%20if%20%24is_slave%3B%20then%0A%20%20%20%20%20%20%20%20master_interfaces%5B%22%24master_interface%22%5D%3Dtrue%0A%20%20%20%20%20%20fi%0A%20%20%20%20elif%20!%20%24is_slave%3B%20then%0A%20%20%20%20%20%20echo%20%22ERROR%3A%20Cannot%20bring%20up%20connection%20%24conn%20after%20%24i%20attempts%22%0A%20%20%20%20%20%20return%20%24s%0A%20%20%20%20fi%0A%20%20%20%20mod_nm_conn%20%22%24conn%22%20connection.autoconnect%20yes%0A%20%20done%0A%20%20%23%20Check%20that%20all%20master%20interfaces%20report%20at%20least%20a%20single%20active%20slave%0A%20%20%23%20Note%3A%20associative%20arrays%20require%20an%20exclamation%20mark%20when%20looping%0A%20%20for%20i%20in%20%22%24%7B!master_interfaces%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20if%20!%20%24%7Bmaster_interfaces%5B%22%24i%22%5D%7D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22ERROR%3A%20Cannot%20bring%20up%20any%20slave%20interface%20for%20master%20interface%3A%20%24i%22%0A%20%20%20%20%20%20%20%20return%201%0A%20%20%20%20fi%0A%20%20done%0A%7D%0A%0A%23%20Accepts%20parameters%20%24iface_default_hint_file%2C%20%24iface%0A%23%20Writes%20content%20of%20%24iface%20into%20%24iface_default_hint_file%0Awrite_iface_default_hint()%20%7B%0A%20%20local%20iface_default_hint_file%3D%22%241%22%0A%20%20local%20iface%3D%22%242%22%0A%0A%20%20echo%20%22%24%7Biface%7D%22%20%3E%7C%20%22%24%7Biface_default_hint_file%7D%22%0A%7D%0A%0A%23%20Accepts%20parameters%20%24iface_default_hint_file%0A%23%20Returns%20the%20stored%20interface%20default%20hint%20if%20the%20hint%20is%20non-empty%2C%0A%23%20not%20br-ex%2C%20not%20br-ex1%20and%20if%20the%20interface%20can%20be%20found%20in%20%2Fsys%2Fclass%2Fnet%0Aget_iface_default_hint()%20%7B%0A%20%20local%20iface_default_hint_file%3D%241%0A%20%20if%20%5B%20-f%20%22%24%7Biface_default_hint_file%7D%22%20%5D%3B%20then%0A%20%20%20%20local%20iface_default_hint%3D%24(cat%20%22%24%7Biface_default_hint_file%7D%22)%0A%20%20%20%20if%20%5B%20%22%24%7Biface_default_hint%7D%22%20!%3D%20%22%22%20%5D%20%26%26%0A%20%20%20%20%20%20%20%20%5B%20%22%24%7Biface_default_hint%7D%22%20!%3D%20%22br-ex%22%20%5D%20%26%26%0A%20%20%20%20%20%20%20%20%5B%20%22%24%7Biface_default_hint%7D%22%20!%3D%20%22br-ex1%22%20%5D%20%26%26%0A%20%20%20%20%20%20%20%20%5B%20-d%20%22%2Fsys%2Fclass%2Fnet%2F%24%7Biface_default_hint%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22%24%7Biface_default_hint%7D%22%0A%20%20%20%20%20%20%20%20return%0A%20%20%20%20fi%0A%20%20fi%0A%20%20echo%20%22%22%0A%7D%0A%0Aget_ip_from_ip_hint_file()%20%7B%0A%20%20local%20ip_hint_file%3D%22%241%22%0A%20%20if%20%5B%5B%20!%20-f%20%22%24%7Bip_hint_file%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20return%0A%20%20fi%0A%20%20ip_hint%3D%24(cat%20%22%24%7Bip_hint_file%7D%22)%0A%20%20echo%20%22%24%7Bip_hint%7D%22%0A%7D%0A%0A%23%20This%20function%20waits%20for%20ip%20address%20of%20br-ex%20to%20be%20bindable%20only%20in%20case%20of%20ipv6%0A%23%20This%20is%20workaround%20for%20OCPBUGS-673%20as%20it%20will%20not%20allow%20starting%20crio%0A%23%20before%20address%20is%20bindable%0Atry_to_bind_ipv6_address()%20%7B%0A%20%20%23%20Retry%20for%201%20minute%0A%20%20retries%3D60%0A%20%20until%20%5B%5B%20%24%7Bretries%7D%20-eq%200%20%5D%5D%3B%20do%0A%20%20%20%20ip%3D%24(ip%20-6%20-j%20addr%20%7C%20jq%20-r%20%22first(.%5B%5D%20%7C%20select(.ifname%3D%3D%5C%22br-ex%5C%22)%20%7C%20.addr_info%5B%5D%20%7C%20select(.scope%3D%3D%5C%22global%5C%22)%20%7C%20.local)%22)%0A%20%20%20%20if%20%5B%5B%20%22%24%7Bip%7D%22%20%3D%3D%20%22%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22No%20ipv6%20ip%20to%20bind%20was%20found%22%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20%20%20random_port%3D%24(shuf%20-i%2050000-60000%20-n%201)%0A%20%20%20%20echo%20%22Trying%20to%20bind%20%24%7Bip%7D%20on%20port%20%24%7Brandom_port%7D%22%0A%20%20%20%20exit_code%3D%24(timeout%202s%20nc%20-l%20%22%24%7Bip%7D%22%20%24%7Brandom_port%7D%3B%20echo%20%24%3F)%0A%20%20%20%20if%20%5B%5B%20exit_code%20-eq%20124%20%5D%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22Address%20bound%20successfully%22%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20%20%20sleep%201%0A%20%20%20%20((%20retries--%20))%0A%20%20done%0A%20%20if%20%5B%5B%20%24%7Bretries%7D%20-eq%200%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22Failed%20to%20bind%20ip%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%7D%0A%0A%23%20Get%20interface%20that%20matches%20ip%20from%20node%20ip%20hint%20file%0A%23%20in%20case%20file%20not%20exists%20return%20nothing%20and%0A%23%20fallback%20to%20default%20interface%20search%20flow%0Aget_nodeip_hint_interface()%20%7B%0A%20%20local%20ip_hint%3D%22%22%0A%20%20local%20ip_hint_file%3D%22%241%22%0A%20%20local%20extra_bridge%3D%22%242%22%0A%20%20local%20iface%3D%22%22%0A%0A%20%20ip_hint%3D%24(get_ip_from_ip_hint_file%20%22%24%7Bip_hint_file%7D%22)%0A%20%20if%20%5B%5B%20-z%20%22%24%7Bip_hint%7D%22%20%20%5D%5D%3B%20then%0A%20%20%20%20return%0A%20%20fi%0A%0A%20%20iface%3D%24(ip%20-j%20addr%20%7C%20jq%20-r%20%22first(.%5B%5D%20%7C%20select(any(.addr_info%5B%5D%3B%20.local%3D%3D%5C%22%24%7Bip_hint%7D%5C%22)%20and%20.ifname!%3D%5C%22br-ex1%5C%22%20and%20.ifname!%3D%5C%22%24%7Bextra_bridge%7D%5C%22))%20%7C%20.ifname%22)%0A%20%20if%20%5B%5B%20-n%20%22%24%7Biface%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22%24%7Biface%7D%22%0A%20%20fi%0A%7D%0A%0A%23%20Accepts%20parameters%20%24bridge_interface%20(e.g.%20ovs-port-phys0)%0A%23%20Returns%20the%20physical%20interface%20name%20if%20%24bridge_interface%20exists%2C%20%22%22%20otherwise%0Aget_bridge_physical_interface()%20%7B%0A%20%20local%20bridge_interface%3D%22%241%22%0A%20%20local%20physical_interface%3D%22%22%0A%20%20physical_interface%3D%24(nmcli%20-g%20connection.interface-name%20conn%20show%20%22%24%7Bbridge_interface%7D%22%202%3E%2Fdev%2Fnull%20%7C%7C%20echo%20%22%22)%0A%20%20echo%20%22%24%7Bphysical_interface%7D%22%0A%7D%0A%0A%23%20Accepts%20parameters%20%24iface_default_hint_file%2C%20%24extra_bridge_file%2C%20%24ip_hint_file%2C%20%24default_bridge_file%0A%23%20Determines%20the%20interface%20to%20be%20used%20for%20br-ex.%20Order%20of%20priority%20is%3A%0A%23%201.%20Use%20the%20user%20specified%20interface%20if%20provided%20in%20the%20default%20bridge%20file%0A%23%202.%20Use%20the%20node%20IP%20hint%20interface%0A%23%203.%20Use%20the%20previously%20selected%20interface%0A%23%204.%20Use%20the%20interface%20detected%20as%20default%20gateway%0A%23%0A%23%20Read%20%24default_bridge_file%20and%20return%20the%20contained%20interface.%20Otherwise%2C%0A%23%20read%20%24ip_hint_file%20and%20return%20the%20interface%20that%20matches%20this%20ip.%20Otherwise%2C%0A%23%20if%20the%20default%20interface%20is%20br-ex%2C%20use%20that%20and%20return.%0A%23%20If%20the%20default%20interface%20is%20not%20br-ex%3A%0A%23%20Check%20if%20there%20is%20a%20valid%20hint%20inside%20%24iface_default_hint_file.%20If%20so%2C%20use%20that%20hint.%0A%23%20If%20there%20is%20no%20valid%20hint%2C%20use%20the%20default%20interface%20that%20we%20found%20during%20the%20step%0A%23%20earlier.%0A%23%20Never%20use%20the%20interface%20that%20is%20provided%20inside%20%24extra_bridge_file%20for%20br-ex1.%0A%23%20Never%20use%20br-ex1.%0A%23%20Write%20the%20default%20interface%20to%20%24iface_default_hint_file%0Aget_default_bridge_interface()%20%7B%0A%20%20local%20iface%3D%22%22%0A%20%20local%20counter%3D0%0A%20%20local%20iface_default_hint_file%3D%22%241%22%0A%20%20local%20extra_bridge_file%3D%22%242%22%0A%20%20local%20ip_hint_file%3D%22%243%22%0A%20%20local%20default_bridge_file%3D%22%244%22%0A%20%20local%20extra_bridge%3D%22%22%0A%0A%20%20if%20%5B%20-f%20%22%24%7Bextra_bridge_file%7D%22%20%5D%3B%20then%0A%20%20%20%20extra_bridge%3D%24(cat%20%24%7Bextra_bridge_file%7D)%0A%20%20fi%0A%0A%20%20%23%20try%20to%20use%20user%20specified%20file%20first%0A%20%20if%20%5B%20-f%20%22%24default_bridge_file%22%20%5D%3B%20then%0A%20%20%20%20iface%3D%24(cat%20%22%24%7Bdefault_bridge_file%7D%22)%0A%20%20%20%20if%20%5B%20-z%20%22%24iface%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22ERROR%3A%20User%20specified%20bridge%20file%20detected%20without%20any%20data%22%0A%20%20%20%20%20%20exit%201%0A%20%20%20%20fi%0A%20%20%20%20echo%20%22%24%7Biface%7D%22%0A%20%20%20%20return%0A%20%20fi%0A%0A%20%20%23%20if%20node%20ip%20was%20set%2C%20we%20should%20search%20for%20interface%20that%20matches%20it%0A%20%20iface%3D%24(get_nodeip_hint_interface%20%22%24%7Bip_hint_file%7D%22%20%22%24%7Bextra_bridge%7D%22)%0A%20%20if%20%5B%5B%20-n%20%22%24%7Biface%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22%24%7Biface%7D%22%0A%20%20%20%20return%0A%20%20fi%0A%0A%20%20%23%20find%20default%20interface%0A%20%20%23%20the%20default%20interface%20might%20be%20br-ex%2C%20so%20check%20this%20before%20looking%20at%20the%20hint%0A%20%20while%20%5B%20%24%7Bcounter%7D%20-lt%2012%20%5D%3B%20do%0A%20%20%20%20%23%20check%20ipv4%0A%20%20%20%20%23%20never%20use%20the%20interface%20that's%20specified%20in%20extra_bridge_file%0A%20%20%20%20%23%20never%20use%20br-ex1%0A%20%20%20%20if%20%5B%20%22%24%7Bextra_bridge%7D%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20iface%3D%24(ip%20route%20show%20default%20%7C%20grep%20-v%20%22br-ex1%22%20%7C%20grep%20-v%20%22%24%7Bextra_bridge%7D%22%20%7C%20awk%20'%7B%20if%20(%244%20%3D%3D%20%22dev%22)%20%7B%20print%20%245%3B%20exit%20%7D%20%7D')%0A%20%20%20%20else%0A%20%20%20%20%20%20iface%3D%24(ip%20route%20show%20default%20%7C%20grep%20-v%20%22br-ex1%22%20%7C%20awk%20'%7B%20if%20(%244%20%3D%3D%20%22dev%22)%20%7B%20print%20%245%3B%20exit%20%7D%20%7D')%0A%20%20%20%20fi%0A%20%20%20%20if%20%5B%5B%20-n%20%22%24%7Biface%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20%20%20%23%20check%20ipv6%0A%20%20%20%20%23%20never%20use%20the%20interface%20that's%20specified%20in%20extra_bridge_file%0A%20%20%20%20%23%20never%20use%20br-ex1%0A%20%20%20%20if%20%5B%20%22%24%7Bextra_bridge%7D%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20iface%3D%24(ip%20-6%20route%20show%20default%20%7C%20grep%20-v%20%22br-ex1%22%20%7C%20grep%20-v%20%22%24%7Bextra_bridge%7D%22%20%7C%20awk%20'%7B%20if%20(%244%20%3D%3D%20%22dev%22)%20%7B%20print%20%245%3B%20exit%20%7D%20%7D')%0A%20%20%20%20else%0A%20%20%20%20%20%20iface%3D%24(ip%20-6%20route%20show%20default%20%7C%20grep%20-v%20%22br-ex1%22%20%7C%20awk%20'%7B%20if%20(%244%20%3D%3D%20%22dev%22)%20%7B%20print%20%245%3B%20exit%20%7D%20%7D')%0A%20%20%20%20fi%0A%20%20%20%20if%20%5B%5B%20-n%20%22%24%7Biface%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20%20%20counter%3D%24((counter%2B1))%0A%20%20%20%20sleep%205%0A%20%20done%0A%0A%20%20%23%20if%20the%20default%20interface%20does%20not%20point%20out%20of%20br-ex%20or%20br-ex1%0A%20%20if%20%5B%20%22%24%7Biface%7D%22%20!%3D%20%22br-ex%22%20%5D%20%26%26%20%5B%20%22%24%7Biface%7D%22%20!%3D%20%22br-ex1%22%20%5D%3B%20then%0A%20%20%20%20%23%20determine%20if%20an%20interface%20default%20hint%20exists%20from%20a%20previous%20run%0A%20%20%20%20%23%20and%20if%20the%20interface%20has%20a%20valid%20default%20route%0A%20%20%20%20iface_default_hint%3D%24(get_iface_default_hint%20%22%24%7Biface_default_hint_file%7D%22)%0A%20%20%20%20if%20%5B%20%22%24%7Biface_default_hint%7D%22%20!%3D%20%22%22%20%5D%20%26%26%0A%20%20%20%20%20%20%20%20%5B%20%22%24%7Biface_default_hint%7D%22%20!%3D%20%22%24%7Biface%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%23%20start%20wherever%20count%20left%20off%20in%20the%20previous%20loop%0A%20%20%20%20%20%20%23%20allow%20this%20for%20one%20more%20iteration%20than%20the%20previous%20loop%0A%20%20%20%20%20%20while%20%5B%20%24%7Bcounter%7D%20-le%2012%20%5D%3B%20do%0A%20%20%20%20%20%20%20%20%23%20check%20ipv4%0A%20%20%20%20%20%20%20%20if%20%5B%20%22%24(ip%20route%20show%20default%20dev%20%22%24%7Biface_default_hint%7D%22)%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20iface%3D%22%24%7Biface_default_hint%7D%22%0A%20%20%20%20%20%20%20%20%20%20break%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20%23%20check%20ipv6%0A%20%20%20%20%20%20%20%20if%20%5B%20%22%24(ip%20-6%20route%20show%20default%20dev%20%22%24%7Biface_default_hint%7D%22)%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20iface%3D%22%24%7Biface_default_hint%7D%22%0A%20%20%20%20%20%20%20%20%20%20break%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20counter%3D%24((counter%2B1))%0A%20%20%20%20%20%20%20%20sleep%205%0A%20%20%20%20%20%20done%0A%20%20%20%20fi%0A%20%20%20%20%23%20store%20what%20was%20determined%20was%20the%20(new)%20default%20interface%20inside%0A%20%20%20%20%23%20the%20default%20hint%20file%20for%20future%20reference%0A%20%20%20%20if%20%5B%20%22%24%7Biface%7D%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20write_iface_default_hint%20%22%24%7Biface_default_hint_file%7D%22%20%22%24%7Biface%7D%22%0A%20%20%20%20fi%0A%20%20fi%0A%20%20echo%20%22%24%7Biface%7D%22%0A%7D%0A%0A%23%20Used%20to%20print%20network%20state%0Aprint_state()%20%7B%0A%20%20echo%20%22Current%20device%2C%20connection%2C%20interface%20and%20routing%20state%3A%22%0A%20%20nmcli%20-g%20all%20device%20%7C%20grep%20-v%20unmanaged%0A%20%20nmcli%20-g%20all%20connection%0A%20%20ip%20-d%20address%20show%0A%20%20ip%20route%20show%0A%20%20ip%20-6%20route%20show%0A%7D%0A%0A%23%20Setup%20an%20exit%20trap%20to%20rollback%20on%20error%0Ahandle_exit()%20%7B%0A%20%20e%3D%24%3F%0A%20%20tdir%3D%24(mktemp%20-u%20-d%20-t%20%22configure-ovs-%24(date%20%2B%25Y-%25m-%25d-%25H-%25M-%25S)-XXXXXXXXXX%22)%0A%20%20%0A%20%20if%20%5B%20%24e%20-eq%200%20%5D%3B%20then%0A%20%20%20%20print_state%0A%20%20%20%20%23%20remove%20previous%20troubleshooting%20information%0A%20%20%20%20rm%20-rf%20%22%24(dirname%20%22%24tdir%22)%2Fconfigure-ovs-*%22%0A%20%20%20%20exit%200%0A%20%20fi%0A%0A%20%20echo%20%22ERROR%3A%20configure-ovs%20exited%20with%20error%3A%20%24e%22%0A%20%20print_state%0A%0A%20%20%23%20remove%20previous%20troubleshooting%20information%20except%20the%20oldest%20one%0A%20%20mapfile%20-t%20tdirs%20%3C%20%3C(compgen%20-G%20%22%24(dirname%20%22%24tdir%22)%2Fconfigure-ovs-*%22)%0A%20%20unset%20-v%20%22tdirs%5B0%5D%22%0A%20%20for%20dir%20in%20%22%24%7Btdirs%5B%40%5D%7D%22%3B%20do%20rm%20-rf%20%22%24dir%22%3B%20done%0A%0A%20%20%23%20copy%20configuration%20to%20tmp%20for%20troubleshooting%0A%20%20mkdir%20-p%20%22%24tdir%22%0A%20%20update_nm_conn_run_files%20br-ex%20phys0%0A%20%20copy_nm_conn_files%20%22%24tdir%22%0A%20%20update_nm_conn_run_files%20br-ex1%20phys1%0A%20%20copy_nm_conn_files%20%22%24tdir%22%0A%20%20echo%20%22Copied%20OVS%20configuration%20to%20%24tdir%20for%20troubleshooting%22%0A%0A%20%20%23%20attempt%20to%20restore%20the%20previous%20network%20state%0A%20%20echo%20%22Attempting%20to%20restore%20previous%20configuration...%22%0A%20%20rollback_nm%0A%20%20print_state%0A%0A%20%20exit%20%24e%0A%7D%0A%0A%23%20Setup%20a%20signal%20trap%20to%20rollback%0Ahandle_termination()%20%7B%0A%20%20echo%20%22WARNING%3A%20configure-ovs%20has%20been%20requested%20to%20terminate%2C%20quitting...%22%0A%20%20%0A%20%20%23%20by%20exiting%20with%20an%20error%20we%20will%20cleanup%20after%20ourselves%20in%20a%0A%20%20%23%20subsequent%20call%20to%20handle_exit%0A%20%20exit%201%0A%7D%0A%0A%23%20main%20function%0Aconfigure_ovs()%20%7B%0A%20%20set%20-eu%0A%0A%20%20%23%20setup%20traps%20to%20handle%20signals%20and%20other%20abnormal%20exits%0A%20%20trap%20'handle_termination'%20TERM%20INT%0A%20%20trap%20'handle_exit'%20EXIT%0A%0A%20%20%23%20this%20flag%20tracks%20if%20any%20config%20change%20was%20made%0A%20%20nm_config_changed%3D0%0A%0A%20%20%23%20Check%20that%20we%20are%20provided%20a%20valid%20NM%20connection%20path%0A%20%20if%20%5B%20%22%24NM_CONN_SET_PATH%22%20!%3D%20%22%24NM_CONN_CONF_PATH%22%20%5D%20%26%26%20%5B%20%22%24NM_CONN_SET_PATH%22%20!%3D%20%22%24NM_CONN_RUN_PATH%22%20%5D%3B%20then%0A%20%20%20%20echo%20%22Error%3A%20Incorrect%20NM%20connection%20path%3A%20%24NM_CONN_SET_PATH%20is%20not%20%24NM_CONN_CONF_PATH%20nor%20%24NM_CONN_RUN_PATH%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%0A%20%20%23%20Clean%20up%20old%20config%20on%20behalf%20of%20mtu-migration%0A%20%20if%20!%20systemctl%20-q%20is-enabled%20mtu-migration%3B%20then%0A%20%20%20%20echo%20%22Cleaning%20up%20left%20over%20mtu%20migration%20configuration%22%0A%20%20%20%20rm%20-rf%20%2Fetc%2Fcno%2Fmtu-migration%0A%20%20fi%0A%0A%20%20if%20!%20rpm%20-qa%20%7C%20grep%20-q%20openvswitch%3B%20then%0A%20%20%20%20echo%20%22WARNING%3A%20Openvswitch%20package%20is%20not%20installed!%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%0A%20%20%23%20print%20initial%20state%0A%20%20print_state%0A%0A%20%20if%20%5B%20%22%241%22%20%3D%3D%20%22OVNKubernetes%22%20%5D%3B%20then%0A%20%20%20%20%23%20Configures%20NICs%20onto%20OVS%20bridge%20%22br-ex%22%0A%20%20%20%20%23%20Configuration%20is%20either%20auto-detected%20or%20provided%20through%20a%20config%20file%20written%20already%20in%20Network%20Manager%0A%20%20%20%20%23%20key%20files%20under%20%2Fetc%2FNetworkManager%2Fsystem-connections%2F%0A%20%20%20%20%23%20Managing%20key%20files%20is%20outside%20of%20the%20scope%20of%20this%20script%0A%0A%20%20%20%20%23%20if%20the%20interface%20is%20of%20type%20vmxnet3%20add%20multicast%20capability%20for%20that%20driver%0A%20%20%20%20%23%20History%3A%20BZ%3A1854355%0A%20%20%20%20function%20configure_driver_options%20%7B%0A%20%20%20%20%20%20intf%3D%241%0A%20%20%20%20%20%20if%20%5B%20!%20-f%20%22%2Fsys%2Fclass%2Fnet%2F%24%7Bintf%7D%2Fdevice%2Fuevent%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22Device%20file%20doesn't%20exist%2C%20skipping%20setting%20multicast%20mode%22%0A%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20driver%3D%24(cat%20%22%2Fsys%2Fclass%2Fnet%2F%24%7Bintf%7D%2Fdevice%2Fuevent%22%20%7C%20grep%20DRIVER%20%7C%20awk%20-F%20%22%3D%22%20'%7Bprint%20%242%7D')%0A%20%20%20%20%20%20%20%20echo%20%22Driver%20name%20is%22%20%24driver%0A%20%20%20%20%20%20%20%20if%20%5B%20%22%24driver%22%20%3D%20%22vmxnet3%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20ip%20link%20set%20dev%20%22%24%7Bintf%7D%22%20allmulticast%20on%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20fi%0A%20%20%20%20%7D%0A%0A%20%20%20%20ovnk_config_dir%3D'%2Fetc%2Fovnk'%0A%20%20%20%20ovnk_var_dir%3D'%2Fvar%2Flib%2Fovnk'%0A%20%20%20%20extra_bridge_file%3D%22%24%7Bovnk_config_dir%7D%2Fextra_bridge%22%0A%20%20%20%20iface_default_hint_file%3D%22%24%7Bovnk_var_dir%7D%2Fiface_default_hint%22%0A%20%20%20%20ip_hint_file%3D%22%2Frun%2Fnodeip-configuration%2Fprimary-ip%22%0A%20%20%20%20%23%20explicitly%20specify%20which%20interface%20should%20be%20used%20with%20the%20default%20bridge%0A%20%20%20%20default_bridge_file%3D%22%24%7Bovnk_config_dir%7D%2Fdefault_bridge%22%0A%0A%20%20%20%20%23%20make%20sure%20to%20create%20ovnk_config_dir%20if%20it%20does%20not%20exist%2C%20yet%0A%20%20%20%20mkdir%20-p%20%22%24%7Bovnk_config_dir%7D%22%0A%20%20%20%20%23%20make%20sure%20to%20create%20ovnk_var_dir%20if%20it%20does%20not%20exist%2C%20yet%0A%20%20%20%20mkdir%20-p%20%22%24%7Bovnk_var_dir%7D%22%0A%0A%20%20%20%20%23%20For%20upgrade%20scenarios%2C%20make%20sure%20that%20we%20stabilize%20what%20we%20already%20configured%0A%20%20%20%20%23%20before.%20If%20we%20do%20not%20have%20a%20valid%20interface%20hint%2C%20find%20the%20physical%20interface%0A%20%20%20%20%23%20that's%20attached%20to%20ovs-if-phys0.%0A%20%20%20%20%23%20If%20we%20find%20such%20an%20interface%2C%20write%20it%20to%20the%20hint%20file.%0A%20%20%20%20iface_default_hint%3D%24(get_iface_default_hint%20%22%24%7Biface_default_hint_file%7D%22)%0A%20%20%20%20if%20%5B%20%22%24%7Biface_default_hint%7D%22%20%3D%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20current_interface%3D%24(get_bridge_physical_interface%20ovs-if-phys0)%0A%20%20%20%20%20%20if%20%5B%20%22%24%7Bcurrent_interface%7D%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20write_iface_default_hint%20%22%24%7Biface_default_hint_file%7D%22%20%22%24%7Bcurrent_interface%7D%22%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20delete%20iface_default_hint_file%20if%20it%20has%20the%20same%20content%20as%20extra_bridge_file%0A%20%20%20%20%23%20in%20that%20case%2C%20we%20must%20also%20force%20a%20reconfiguration%20of%20our%20network%20interfaces%0A%20%20%20%20%23%20to%20make%20sure%20that%20we%20reconcile%20this%20conflict%0A%20%20%20%20if%20%5B%20-f%20%22%24%7Biface_default_hint_file%7D%22%20%5D%20%26%26%0A%20%20%20%20%20%20%5B%20-f%20%22%24%7Bextra_bridge_file%7D%22%20%5D%20%26%26%0A%20%20%20%20%20%20%5B%20%22%24(cat%20%22%24%7Biface_default_hint_file%7D%22)%22%20%3D%3D%20%22%24(cat%20%22%24%7Bextra_bridge_file%7D%22)%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22%24%7Biface_default_hint_file%7D%20and%20%24%7Bextra_bridge_file%7D%20share%20the%20same%20content%22%0A%20%20%20%20%20%20echo%20%22Deleting%20file%20%24%7Biface_default_hint_file%7D%20to%20choose%20a%20different%20interface%22%0A%20%20%20%20%20%20rm%20-f%20%22%24%7Biface_default_hint_file%7D%22%0A%20%20%20%20%20%20rm%20-f%20%2Frun%2Fconfigure-ovs-boot-done%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20on%20every%20boot%20we%20rollback%20and%20generate%20the%20configuration%20again%2C%20to%20take%0A%20%20%20%20%23%20in%20any%20changes%20that%20have%20possibly%20been%20applied%20in%20the%20standard%0A%20%20%20%20%23%20configuration%20sources%0A%20%20%20%20if%20%5B%20!%20-f%20%2Frun%2Fconfigure-ovs-boot-done%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22Running%20on%20boot%2C%20restoring%20previous%20configuration%20before%20proceeding...%22%0A%20%20%20%20%20%20rollback_nm%0A%20%20%20%20%20%20print_state%0A%20%20%20%20fi%0A%20%20%20%20touch%20%2Frun%2Fconfigure-ovs-boot-done%0A%0A%20%20%20%20iface%3D%24(get_default_bridge_interface%20%22%24%7Biface_default_hint_file%7D%22%20%22%24%7Bextra_bridge_file%7D%22%20%22%24%7Bip_hint_file%7D%22%20%22%24%7Bdefault_bridge_file%7D%22)%0A%0A%20%20%20%20if%20%5B%20%22%24iface%22%20!%3D%20%22br-ex%22%20%5D%3B%20then%0A%20%20%20%20%20%20%23%20Specified%20interface%20is%20not%20br-ex.%0A%20%20%20%20%20%20%23%20Some%20deployments%20use%20a%20temporary%20solution%20where%20br-ex%20is%20moved%20out%20from%20the%20default%20gateway%20interface%0A%20%20%20%20%20%20%23%20and%20bound%20to%20a%20different%20nic%20(https%3A%2F%2Fgithub.com%2Ftrozet%2Fopenshift-ovn-migration).%0A%20%20%20%20%20%20%23%20This%20is%20now%20supported%20through%20an%20extra%20bridge%20if%20requested.%20If%20that%20is%20the%20case%2C%20we%20rollback.%0A%20%20%20%20%20%20%23%20We%20also%20rollback%20if%20it%20looks%20like%20we%20need%20to%20configure%20things%2C%20just%20in%20case%20there%20are%20any%20leftovers%0A%20%20%20%20%20%20%23%20from%20previous%20attempts.%0A%20%20%20%20%20%20if%20%5B%20-f%20%22%24extra_bridge_file%22%20%5D%20%7C%7C%20%5B%20-z%20%22%24(nmcli%20connection%20show%20--active%20br-ex%202%3E%20%2Fdev%2Fnull)%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22Bridge%20br-ex%20is%20not%20active%2C%20restoring%20previous%20configuration%20before%20proceeding...%22%0A%20%20%20%20%20%20%20%20rollback_nm%0A%20%20%20%20%20%20%20%20print_state%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20convert_to_bridge%20%22%24iface%22%20%22br-ex%22%20%22phys0%22%20%22%24%7BBRIDGE_METRIC%7D%22%0A%0A%20%20%20%20%23%20Check%20if%20we%20need%20to%20configure%20the%20second%20bridge%0A%20%20%20%20if%20%5B%20-f%20%22%24extra_bridge_file%22%20%5D%20%26%26%20(!%20nmcli%20connection%20show%20br-ex1%20%26%3E%20%2Fdev%2Fnull%20%7C%7C%20!%20nmcli%20connection%20show%20ovs-if-phys1%20%26%3E%20%2Fdev%2Fnull)%3B%20then%0A%20%20%20%20%20%20interface%3D%24(head%20-n%201%20%24extra_bridge_file)%0A%20%20%20%20%20%20convert_to_bridge%20%22%24interface%22%20%22br-ex1%22%20%22phys1%22%20%22%24%7BBRIDGE1_METRIC%7D%22%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Check%20if%20we%20need%20to%20remove%20the%20second%20bridge%0A%20%20%20%20if%20%5B%20!%20-f%20%22%24extra_bridge_file%22%20%5D%20%26%26%20(nmcli%20connection%20show%20br-ex1%20%26%3E%20%2Fdev%2Fnull%20%7C%7C%20nmcli%20connection%20show%20ovs-if-phys1%20%26%3E%20%2Fdev%2Fnull)%3B%20then%0A%20%20%20%20%20%20remove_ovn_bridges%20br-ex1%20phys1%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Remove%20bridges%20created%20by%20openshift-sdn%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-br%20br0%0A%0A%20%20%20%20%23%20Make%20sure%20everything%20is%20activated.%20Do%20it%20in%20a%20specific%20order%3A%0A%20%20%20%20%23%20-%20activate%20br-ex%20first%2C%20due%20to%20autoconnect-slaves%20this%20will%20also%0A%20%20%20%20%23%20%20%20activate%20ovs-port-br-ex%2C%20ovs-port-phys0%20and%20ovs-if-phys0.%20It%20is%0A%20%20%20%20%23%20%20%20important%20that%20ovs-if-phys0%20activates%20with%20br-ex%20to%20avoid%20the%0A%20%20%20%20%23%20%20%20ovs-if-phys0%20profile%20being%20overridden%20with%20a%20profile%20generated%20from%0A%20%20%20%20%23%20%20%20kargs.%20The%20activation%20of%20ovs-if-phys0%2C%20if%20a%20bond%2C%20might%20cause%20the%0A%20%20%20%20%23%20%20%20slaves%20to%20re-activate%2C%20but%20it%20should%20be%20with%20our%20profiles%20since%20they%0A%20%20%20%20%23%20%20%20have%20higher%20priority%0A%20%20%20%20%23%20-%20make%20sure%20that%20ovs-if-phys0%20and%20its%20slaves%2C%20if%20any%2C%20are%20activated.%0A%20%20%20%20%23%20-%20finally%20activate%20ovs-if-br-ex%20which%20holds%20the%20IP%20configuration.%0A%20%20%20%20connections%3D(br-ex%20ovs-if-phys0)%0A%20%20%20%20if%20%5B%20-f%20%22%24extra_bridge_file%22%20%5D%3B%20then%0A%20%20%20%20%20%20connections%2B%3D(br-ex1%20ovs-if-phys1)%0A%20%20%20%20fi%0A%20%20%20%20while%20IFS%3D%20read%20-r%20connection%3B%20do%0A%20%20%20%20%20%20if%20%5B%5B%20%24connection%20%3D%3D%20*%22%24MANAGED_NM_CONN_SUFFIX%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20connections%2B%3D(%22%24connection%22)%0A%20%20%20%20%20%20fi%0A%20%20%20%20done%20%3C%20%3C(nmcli%20-g%20NAME%20c)%0A%20%20%20%20connections%2B%3D(ovs-if-br-ex)%0A%20%20%20%20if%20%5B%20-f%20%22%24extra_bridge_file%22%20%5D%3B%20then%0A%20%20%20%20%20%20connections%2B%3D(ovs-if-br-ex1)%0A%20%20%20%20fi%0A%20%20%20%20activate_nm_connections%20%22%24%7Bconnections%5B%40%5D%7D%22%0A%20%20%20%20try_to_bind_ipv6_address%0A%20%20%20%20set_nm_conn_files%0A%20%20elif%20%5B%20%22%241%22%20%3D%3D%20%22OpenShiftSDN%22%20%5D%3B%20then%0A%20%20%20%20%23%20Revert%20changes%20made%20by%20%2Fusr%2Flocal%2Fbin%2Fconfigure-ovs.sh%20during%20SDN%20migration.%0A%20%20%20%20rollback_nm%0A%20%20%20%20%0A%20%20%20%20%23%20Remove%20bridges%20created%20by%20ovn-kubernetes%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-br%20br-int%20--%20--if-exists%20del-br%20br-local%0A%20%20fi%0A%7D%0A%0A%23%20Retry%20configure_ovs%20until%20it%20succeeds.%0A%23%20By%20default%2C%20retry%20every%2015%20minutes%20to%20give%20enough%20time%20to%20gather%0A%23%20troubleshooting%20information%20in%20between.%20Note%20that%20configure_ovs%20has%20other%0A%23%20internal%20retry%20mechanisms.%20This%20retry%20is%20intended%20to%20give%20some%0A%23%20self-healing%20capabilities%20to%20temporary%20but%20not%20necessarily%20short-lived%0A%23%20infrastructure%20problems.%0ARETRY%3D%22%24%7BRETRY-15m%7D%22%0Awhile%20true%3B%20do%0A%0A%20%20%23%20Disable%20retries%20if%20termination%20signal%20is%20received.%20Note%20that%20systemd%0A%20%20%23%20sends%20the%20signals%20to%20all%20processes%20in%20the%20group%20by%20default%20so%20we%20expect%0A%20%20%23%20configure_ovs%20to%20get%20its%20own%20signals.%0A%20%20trap%20'echo%20%22WARNING%3A%20termination%20requested%2C%20disabling%20retries%22%3B%20RETRY%3D%22%22'%20INT%20TERM%0A%20%20%0A%20%20%23%20Run%20configure_ovs%20in%20a%20sub-shell.%20%0A%20%20(%20configure_ovs%20%22%24%40%22%20)%0A%20%20e%3D%24%3F%0A%0A%20%20%23%20Handle%20signals%20while%20we%20sleep%0A%20%20trap%20'handle_termination'%20INT%20TERM%0A%20%20%0A%20%20%23%20Exit%20if%20succesful%20and%20not%20configured%20to%20retry%0A%20%20%5B%20%22%24e%22%20-eq%200%20%5D%20%7C%7C%20%5B%20-z%20%22%24RETRY%22%20%5D%20%26%26%20exit%20%22%24e%22%0A%20%20%0A%20%20echo%20%22configure-ovs%20failed%2C%20will%20retry%20after%20%24RETRY%22%0A%20%20%23%20flag%20that%20a%20retry%20has%20happened%0A%20%20touch%20%2Ftmp%2Fconfigure-ovs-retry%0A%20%20sleep%20%22%24RETRY%22%0A%0Adone%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/configure-ovs.sh
        - contents:
            source: data:,%23%20This%20file%20is%20generated%20by%20the%20Machine%20Config%20Operator's%20containerruntimeconfig%20controller.%0A%23%0A%23%20storage.conf%20is%20the%20configuration%20file%20for%20all%20tools%0A%23%20that%20share%20the%20containers%2Fstorage%20libraries%0A%23%20See%20man%205%20containers-storage.conf%20for%20more%20information%0A%23%20The%20%22container%20storage%22%20table%20contains%20all%20of%20the%20server%20options.%0A%5Bstorage%5D%0A%0A%23%20Default%20storage%20driver%2C%20must%20be%20set%20for%20proper%20operation.%0Adriver%20%3D%20%22overlay%22%0A%0A%23%20Temporary%20storage%20location%0Arunroot%20%3D%20%22%2Frun%2Fcontainers%2Fstorage%22%0A%0A%23%20Primary%20Read%2FWrite%20location%20of%20container%20storage%0Agraphroot%20%3D%20%22%2Fvar%2Flib%2Fcontainers%2Fstorage%22%0A%0A%5Bstorage.options%5D%0A%23%20Storage%20options%20to%20be%20passed%20to%20underlying%20storage%20drivers%0A%0A%23%20AdditionalImageStores%20is%20used%20to%20pass%20paths%20to%20additional%20Read%2FOnly%20image%20stores%0A%23%20Must%20be%20comma%20separated%20list.%0Aadditionalimagestores%20%3D%20%5B%0A%5D%0A%0A%23%20Remap-UIDs%2FGIDs%20is%20the%20mapping%20from%20UIDs%2FGIDs%20as%20they%20should%20appear%20inside%20of%0A%23%20a%20container%2C%20to%20UIDs%2FGIDs%20as%20they%20should%20appear%20outside%20of%20the%20container%2C%20and%0A%23%20the%20length%20of%20the%20range%20of%20UIDs%2FGIDs.%20%20Additional%20mapped%20sets%20can%20be%20listed%0A%23%20and%20will%20be%20heeded%20by%20libraries%2C%20but%20there%20are%20limits%20to%20the%20number%20of%0A%23%20mappings%20which%20the%20kernel%20will%20allow%20when%20you%20later%20attempt%20to%20run%20a%0A%23%20container.%0A%23%0A%23%20remap-uids%20%3D%200%3A1668442479%3A65536%0A%23%20remap-gids%20%3D%200%3A1668442479%3A65536%0A%0A%23%20Remap-User%2FGroup%20is%20a%20name%20which%20can%20be%20used%20to%20look%20up%20one%20or%20more%20UID%2FGID%0A%23%20ranges%20in%20the%20%2Fetc%2Fsubuid%20or%20%2Fetc%2Fsubgid%20file.%20%20Mappings%20are%20set%20up%20starting%0A%23%20with%20an%20in-container%20ID%20of%200%20and%20the%20a%20host-level%20ID%20taken%20from%20the%20lowest%0A%23%20range%20that%20matches%20the%20specified%20name%2C%20and%20using%20the%20length%20of%20that%20range.%0A%23%20Additional%20ranges%20are%20then%20assigned%2C%20using%20the%20ranges%20which%20specify%20the%0A%23%20lowest%20host-level%20IDs%20first%2C%20to%20the%20lowest%20not-yet-mapped%20container-level%20ID%2C%0A%23%20until%20all%20of%20the%20entries%20have%20been%20used%20for%20maps.%20This%20setting%20overrides%20the%0A%23%20Remap-UIDs%2FGIDs%20setting.%0A%23%0A%23%20remap-user%20%3D%20%22storage%22%0A%23%20remap-group%20%3D%20%22storage%22%0A%0A%5Bstorage.options.pull_options%5D%0A%23%20Options%20controlling%20how%20storage%20is%20populated%20when%20pulling%20images.%0A%0A%23%20Enable%20the%20%22zstd%3Achunked%22%20feature%2C%20which%20allows%20partial%20pulls%2C%20reusing%0A%23%20content%20that%20already%20exists%20on%20the%20system.%20This%20is%20disabled%20by%20default%2C%0A%23%20and%20must%20be%20explicitly%20enabled%20to%20be%20used.%20For%20more%20on%20zstd%3Achunked%2C%20see%0A%23%20https%3A%2F%2Fgithub.com%2Fcontainers%2Fstorage%2Fblob%2Fmain%2Fdocs%2Fcontainers-storage-zstd-chunked.md%0Aenable_partial_images%20%3D%20%22false%22%0A%0A%23%20Tells%20containers%2Fstorage%20to%20use%20hard%20links%20rather%20then%20create%20new%20files%20in%0A%23%20the%20image%2C%20if%20an%20identical%20file%20already%20existed%20in%20storage.%0Ause_hard_links%20%3D%20%22false%22%0A%0A%23%20Path%20to%20an%20ostree%20repository%20that%20might%20have%0A%23%20previously%20pulled%20content%20which%20can%20be%20used%20when%20attempting%20to%20avoid%0A%23%20pulling%20content%20from%20the%20container%20registry.%0Aostree_repos%20%3D%20%22%22%0A%0A%5Bstorage.options.overlay%5D%0A%23%20Storage%20Options%20for%20overlay%0A%0A%23%20Do%20not%20create%20a%20PRIVATE%20bind%20mount%20on%20the%20home%20directory.%0Askip_mount_home%20%3D%20%22true%22%0A%0A%23%20Size%20is%20used%20to%20set%20a%20maximum%20size%20of%20the%20container%20image.%20%20Only%20supported%20by%0A%23%20certain%20container%20storage%20drivers.%0Asize%20%3D%20%22%22%0A
          mode: 420
          overwrite: true
          path: /etc/containers/storage.conf
        - contents:
            source: data:,.%20%7B%0A%20%20%20%20errors%0A%20%20%20%20bufsize%20512%0A%20%20%20%20health%20%3A18080%0A%20%20%20%20forward%20.%20%7B%7B-%20range%20%24upstream%20%3A%3D%20.DNSUpstreams%7D%7D%20%7B%7B%24upstream%7D%7D%7B%7B-%20end%7D%7D%20%7B%0A%20%20%20%20%20%20%20%20policy%20sequential%0A%20%20%20%20%7D%0A%20%20%20%20cache%2030%0A%20%20%20%20reload%0A%20%20%20%20template%20IN%20%7B%7B%20.Cluster.IngressVIPRecordType%20%7D%7D%20comp-poc-rh01.rhpoc.int%20%7B%0A%20%20%20%20%20%20%20%20match%20.*%5B.%5Dapps.comp-poc-rh01.rhpoc.int%0A%20%20%20%20%20%20%20%20answer%20%22%7B%7B%22%7B%7B%20.Name%20%7D%7D%22%7D%7D%2060%20in%20%7B%7B%22%7B%7B%20.Type%20%7D%7D%22%7D%7D%2010.100.0.51%22%0A%20%20%20%20%20%20%20%20fallthrough%0A%20%20%20%20%7D%0A%20%20%20%20template%20IN%20%7B%7B%20.Cluster.IngressVIPEmptyType%20%7D%7D%20comp-poc-rh01.rhpoc.int%20%7B%0A%20%20%20%20%20%20%20%20match%20.*%5B.%5Dapps.comp-poc-rh01.rhpoc.int%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20fallthrough%0A%20%20%20%20%7D%0A%20%20%20%20template%20IN%20%7B%7B%20.Cluster.APIVIPRecordType%20%7D%7D%20comp-poc-rh01.rhpoc.int%20%7B%0A%20%20%20%20%20%20%20%20match%20%5Eapi.comp-poc-rh01.rhpoc.int%0A%20%20%20%20%20%20%20%20answer%20%22%7B%7B%22%7B%7B%20.Name%20%7D%7D%22%7D%7D%2060%20in%20%7B%7B%22%7B%7B%20.Type%20%7D%7D%22%7D%7D%2010.100.0.50%22%0A%20%20%20%20%20%20%20%20fallthrough%0A%20%20%20%20%7D%0A%20%20%20%20template%20IN%20%7B%7B%20.Cluster.APIVIPEmptyType%20%7D%7D%20comp-poc-rh01.rhpoc.int%20%7B%0A%20%20%20%20%20%20%20%20match%20%5Eapi.comp-poc-rh01.rhpoc.int%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20fallthrough%0A%20%20%20%20%7D%0A%20%20%20%20template%20IN%20%7B%7B%20.Cluster.APIVIPRecordType%20%7D%7D%20comp-poc-rh01.rhpoc.int%20%7B%0A%20%20%20%20%20%20%20%20match%20%5Eapi-int.comp-poc-rh01.rhpoc.int%0A%20%20%20%20%20%20%20%20answer%20%22%7B%7B%22%7B%7B%20.Name%20%7D%7D%22%7D%7D%2060%20in%20%7B%7B%22%7B%7B%20.Type%20%7D%7D%22%7D%7D%2010.100.0.50%22%0A%20%20%20%20%20%20%20%20fallthrough%0A%20%20%20%20%7D%0A%20%20%20%20template%20IN%20%7B%7B%20.Cluster.APIVIPEmptyType%20%7D%7D%20comp-poc-rh01.rhpoc.int%20%7B%0A%20%20%20%20%20%20%20%20match%20%5Eapi-int.comp-poc-rh01.rhpoc.int%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20fallthrough%0A%20%20%20%20%7D%0A%20%20%20%20hosts%20%7B%0A%20%20%20%20%20%20%20%20%7B%7B-%20range%20.Cluster.NodeAddresses%20%7D%7D%0A%20%20%20%20%20%20%20%20%7B%7B%20.Address%20%7D%7D%20%7B%7B%20.Name%20%7D%7D%20%7B%7B%20.Name%20%7D%7D.%7B%7B%20%24.Cluster.Name%20%7D%7D.%7B%7B%20%24.Cluster.Domain%20%7D%7D%0A%20%20%20%20%20%20%20%20%7B%7B-%20end%20%7D%7D%0A%20%20%20%20%20%20%20%20fallthrough%0A%20%20%20%20%7D%0A%7D%0A
          mode: 420
          overwrite: true
          path: /etc/kubernetes/static-pod-resources/coredns/Corefile.tmpl
        - contents:
            source: data:,kind%3A%20Pod%0AapiVersion%3A%20v1%0Ametadata%3A%0A%20%20name%3A%20coredns%0A%20%20namespace%3A%20openshift-kni-infra%0A%20%20creationTimestamp%3A%0A%20%20deletionGracePeriodSeconds%3A%2065%0A%20%20labels%3A%0A%20%20%20%20app%3A%20kni-infra-coredns%0A%20%20annotations%3A%0A%20%20%20%20target.workload.openshift.io%2Fmanagement%3A%20'%7B%22effect%22%3A%20%22PreferredDuringScheduling%22%7D'%0A%20%20%20%20openshift.io%2Frequired-scc%3A%20privileged%0Aspec%3A%0A%20%20volumes%3A%0A%20%20-%20name%3A%20resource-dir%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fetc%2Fkubernetes%2Fstatic-pod-resources%2Fcoredns%22%0A%20%20-%20name%3A%20kubeconfig%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20-%20name%3A%20conf-dir%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fetc%2Fcoredns%22%0A%20%20-%20name%3A%20nm-resolv%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fvar%2Frun%2FNetworkManager%22%0A%20%20-%20name%3A%20nodeip-configuration%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Frun%2Fnodeip-configuration%22%0A%20%20initContainers%3A%0A%20%20-%20name%3A%20render-config-coredns%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A93e7b8c870261726d44bddc7ba0a702d3720d1838141dac837fb8c3be7c6e1a1%0A%20%20%20%20command%3A%0A%20%20%20%20-%20runtimecfg%0A%20%20%20%20-%20render%0A%20%20%20%20-%20%22%2Fvar%2Flib%2Fkubelet%2Fkubeconfig%22%0A%20%20%20%20-%20%22--api-vips%22%0A%20%20%20%20-%20%2210.100.0.50%22%0A%20%20%20%20-%20%22--ingress-vips%22%0A%20%20%20%20-%20%2210.100.0.51%22%0A%20%20%20%20-%20%22%2Fconfig%22%0A%20%20%20%20-%20%22--out-dir%22%0A%20%20%20%20-%20%22%2Fetc%2Fcoredns%22%0A%20%20%20%20-%20%22--resolvconf-path%22%0A%20%20%20%20-%20%22%2Fvar%2Frun%2FNetworkManager%2Fresolv.conf%22%0A%20%20%20%20resources%3A%20%7B%7D%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20kubeconfig%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20resource-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fconfig%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20conf-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fcoredns%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20nm-resolv%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Frun%2FNetworkManager%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20nodeip-configuration%0A%20%20%20%20%20%20mountPath%3A%20%22%2Frun%2Fnodeip-configuration%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20imagePullPolicy%3A%20IfNotPresent%0A%20%20containers%3A%0A%20%20-%20name%3A%20coredns%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A4f6294ed30ab476019aaaa77874157facc77413988f82ffc46f94d3a98d2e4f1%0A%20%20%20%20args%3A%0A%20%20%20%20-%20%22--conf%22%0A%20%20%20%20-%20%22%2Fetc%2Fcoredns%2FCorefile%22%0A%20%20%20%20resources%3A%0A%20%20%20%20%20%20requests%3A%0A%20%20%20%20%20%20%20%20cpu%3A%20100m%0A%20%20%20%20%20%20%20%20memory%3A%20200Mi%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20conf-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fcoredns%22%0A%20%20%20%20-%20name%3A%20nodeip-configuration%0A%20%20%20%20%20%20mountPath%3A%20%22%2Frun%2Fnodeip-configuration%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20livenessProbe%3A%0A%20%20%20%20%20%20httpGet%3A%0A%20%20%20%20%20%20%20%20path%3A%20%2Fhealth%0A%20%20%20%20%20%20%20%20port%3A%2018080%0A%20%20%20%20%20%20%20%20scheme%3A%20HTTP%0A%20%20%20%20%20%20initialDelaySeconds%3A%2060%0A%20%20%20%20%20%20timeoutSeconds%3A%205%0A%20%20%20%20%20%20successThreshold%3A%201%0A%20%20%20%20%20%20failureThreshold%3A%205%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20imagePullPolicy%3A%20IfNotPresent%0A%20%20-%20name%3A%20coredns-monitor%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A93e7b8c870261726d44bddc7ba0a702d3720d1838141dac837fb8c3be7c6e1a1%0A%20%20%20%20command%3A%0A%20%20%20%20-%20corednsmonitor%0A%20%20%20%20-%20%22%2Fvar%2Flib%2Fkubelet%2Fkubeconfig%22%0A%20%20%20%20-%20%22%2Fconfig%2FCorefile.tmpl%22%0A%20%20%20%20-%20%22%2Fetc%2Fcoredns%2FCorefile%22%0A%20%20%20%20-%20%22--api-vips%22%0A%20%20%20%20-%20%2210.100.0.50%22%0A%20%20%20%20-%20%22--ingress-vips%22%0A%20%20%20%20-%20%2210.100.0.51%22%0A%20%20%20%20resources%3A%0A%20%20%20%20%20%20requests%3A%0A%20%20%20%20%20%20%20%20cpu%3A%20100m%0A%20%20%20%20%20%20%20%20memory%3A%20200Mi%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20kubeconfig%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20resource-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fconfig%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20conf-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fcoredns%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20nm-resolv%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Frun%2FNetworkManager%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20nodeip-configuration%0A%20%20%20%20%20%20mountPath%3A%20%22%2Frun%2Fnodeip-configuration%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20imagePullPolicy%3A%20IfNotPresent%0A%20%20hostNetwork%3A%20true%0A%20%20tolerations%3A%0A%20%20-%20operator%3A%20Exists%0A%20%20priorityClassName%3A%20system-node-critical%0Astatus%3A%20%7B%7D%0A
          mode: 420
          overwrite: true
          path: /etc/kubernetes/manifests/coredns.yaml
        - contents:
            source: data:,Initial%20Creation%0A
          mode: 384
          overwrite: true
          path: /etc/docker/certs.d/.create
        - contents:
            source: data:,%23%20Proxy%20environment%20variables%20will%20be%20populated%20in%20this%20file.%20Properly%0A%23%20url%20encoded%20passwords%20with%20special%20characters%20will%20use%20'%25%3CHEX%3E%3CHEX%3E'.%0A%23%20Systemd%20requires%20that%20any%20%25%20used%20in%20a%20password%20be%20represented%20as%0A%23%20%25%25%20in%20a%20unit%20file%20since%20%25%20is%20a%20prefix%20for%20macros%3B%20this%20restriction%20does%20not%0A%23%20apply%20for%20environment%20files.%20Templates%20that%20need%20the%20proxy%20set%20should%20use%0A%23%20'EnvironmentFile%3D%2Fetc%2Fmco%2Fproxy.env'.%0A
          mode: 420
          overwrite: true
          path: /etc/mco/proxy.env
        - contents:
            source: data:,%5BManager%5D%0ADefaultEnvironment%3DGODEBUG%3Dx509ignoreCN%3D0%0A
          mode: 420
          overwrite: true
          path: /etc/systemd/system.conf.d/10-default-env-godebug.conf
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%23%20Workaround%3A%0A%23%20https%3A%2F%2Fissues.redhat.com%2Fbrowse%2FOCPBUGS-38779%0A%0Adriver%3D%24(nmcli%20-t%20-m%20tabular%20-f%20general.driver%20dev%20show%20%22%24%7BDEVICE_IFACE%7D%22)%0A%0Aif%20%5B%5B%20%22%242%22%20%3D%3D%20%22up%22%20%26%26%20%22%24%7Bdriver%7D%22%20%3D%3D%20%22idpf%22%20%5D%5D%3B%20then%0A%20%20ethtool%20-K%20%24%7BDEVICE_IFACE%7D%20tx-checksumming%20off%0Afi
          mode: 484
          overwrite: true
          path: /etc/NetworkManager/dispatcher.d/99-gcp-disable-idpf-tx-checksum-off
        - contents:
            source: data:,global%0A%20%20stats%20socket%20%2Fvar%2Flib%2Fhaproxy%2Frun%2Fhaproxy.sock%20%20mode%20600%20level%20admin%20expose-fd%20listeners%0Adefaults%0A%20%20maxconn%2040000%0A%20%20mode%20%20%20%20tcp%0A%20%20log%20%20%20%20%20%2Fvar%2Frun%2Fhaproxy%2Fhaproxy-log.sock%20local0%20notice%20alert%0A%20%20log-format%20%22%25ci%3A%25cp%20-%3E%20%25fi%3A%25fp%20%5B%25t%5D%20%25ft%20%25b%2F%25s%20%25Tw%2F%25Tc%2F%25Tt%20%25B%20%25ts%20%25ac%2F%25fc%2F%25bc%2F%25sc%2F%25rc%20%25sq%2F%25bq%22%0A%20%20option%20%20dontlognull%0A%20%20retries%203%0A%20%20timeout%20http-request%2030s%0A%20%20timeout%20queue%20%20%20%20%20%20%20%201m%0A%20%20timeout%20connect%20%20%20%20%20%2010s%0A%20%20timeout%20client%20%20%20%20%20%20%2086400s%0A%20%20timeout%20server%20%20%20%20%20%20%2086400s%0A%20%20timeout%20tunnel%20%20%20%20%20%20%2086400s%0A%7B%7B-%20if%20gt%20(len%20.LBConfig.Backends)%200%20%7D%7D%0Afrontend%20%20main%0A%20%20bind%20%3A%3A%3A%7B%7B%20.LBConfig.LbPort%20%7D%7D%20v4v6%0A%20%20default_backend%20masters%0Alisten%20health_check_http_url%0A%20%20bind%20%3A%3A%3A9444%20v4v6%0A%20%20mode%20http%0A%20%20monitor-uri%20%2Fhaproxy_ready%0A%20%20option%20dontlognull%0A%7B%7B-%20end%20%7D%7D%0Alisten%20stats%0A%20%20bind%20localhost%3A%7B%7B%20.LBConfig.StatPort%20%7D%7D%0A%20%20mode%20http%0A%20%20stats%20enable%0A%20%20stats%20hide-version%0A%20%20stats%20uri%20%2Fhaproxy_stats%0A%20%20stats%20refresh%2030s%0A%20%20stats%20auth%20Username%3APassword%0Abackend%20masters%0A%20%20%20timeout%20check%2010s%0A%20%20%20option%20%20httpchk%20GET%20%2Freadyz%20HTTP%2F1.0%0A%20%20%20balance%20roundrobin%0A%7B%7B-%20range%20.LBConfig.Backends%20%7D%7D%0A%20%20%20server%20%7B%7B%20.Host%20%7D%7D%20%7B%7B%20.Address%20%7D%7D%3A%7B%7B%20.Port%20%7D%7D%20weight%201%20verify%20none%20check%20check-ssl%20inter%205s%20fall%203%20rise%201%0A%7B%7B-%20end%20%7D%7D%0A
          mode: 420
          overwrite: true
          path: /etc/kubernetes/static-pod-resources/haproxy/haproxy.cfg.tmpl
        - contents:
            source: data:,kind%3A%20Pod%0AapiVersion%3A%20v1%0Ametadata%3A%0A%20%20name%3A%20haproxy%0A%20%20namespace%3A%20openshift-kni-infra%0A%20%20creationTimestamp%3A%0A%20%20deletionGracePeriodSeconds%3A%2065%0A%20%20labels%3A%0A%20%20%20%20app%3A%20kni-infra-api-lb%0A%20%20annotations%3A%0A%20%20%20%20target.workload.openshift.io%2Fmanagement%3A%20'%7B%22effect%22%3A%20%22PreferredDuringScheduling%22%7D'%0A%20%20%20%20openshift.io%2Frequired-scc%3A%20privileged%0Aspec%3A%0A%20%20volumes%3A%0A%20%20-%20name%3A%20resource-dir%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fetc%2Fkubernetes%2Fstatic-pod-resources%2Fhaproxy%22%0A%20%20-%20name%3A%20kubeconfigvarlib%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20-%20name%3A%20run-dir%0A%20%20%20%20empty-dir%3A%20%7B%7D%0A%20%20-%20name%3A%20conf-dir%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fetc%2Fhaproxy%22%0A%20%20-%20name%3A%20chroot-host%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2F%22%0A%20%20initContainers%3A%0A%20%20-%20name%3A%20verify-api-int-resolvable%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A93e7b8c870261726d44bddc7ba0a702d3720d1838141dac837fb8c3be7c6e1a1%0A%20%20%20%20command%3A%0A%20%20%20%20-%20%22%2Fbin%2Fbash%22%0A%20%20%20%20-%20%22-c%22%0A%20%20%20%20-%20%7C%0A%20%20%20%20%20%20%2Fusr%2Fbin%2Fcurl%20-o%20%2Fdev%2Fnull%20-kLfs%20https%3A%2F%2Fapi-int.comp-poc-rh01.rhpoc.int%3A6443%2Fhealthz%0A%20%20%20%20resources%3A%20%7B%7D%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20chroot-host%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fhost%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20kubeconfigvarlib%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20imagePullPolicy%3A%20IfNotPresent%0A%20%20containers%3A%0A%20%20-%20name%3A%20haproxy%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3Ae1eb49c0c126c193cd035f844746edd98c6c674fdfa6b822d078d4a491b4834d%0A%20%20%20%20env%3A%0A%20%20%20%20%20%20-%20name%3A%20OLD_HAPROXY_PS_FORCE_DEL_TIMEOUT%0A%20%20%20%20%20%20%20%20value%3A%20%22120%22%0A%20%20%20%20command%3A%0A%20%20%20%20-%20%22%2Fbin%2Fbash%22%0A%20%20%20%20-%20%22-c%22%0A%20%20%20%20-%20%7C%0A%20%20%20%20%20%20%23%2Fbin%2Fbash%0A%20%20%20%20%20%20verify_old_haproxy_ps_being_deleted()%0A%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20local%20prev_pids%0A%0A%20%20%20%20%20%20%20%20prev_pids%3D%22%241%22%0A%20%20%20%20%20%20%20%20sleep%20%24OLD_HAPROXY_PS_FORCE_DEL_TIMEOUT%0A%20%20%20%20%20%20%20%20cur_pids%3D%24(pidof%20haproxy)%0A%0A%20%20%20%20%20%20%20%20for%20val%20in%20%24prev_pids%3B%20do%0A%20%20%20%20%20%20%20%20%20%20%20%20if%20%5B%5B%20%24cur_pids%20%3D~%20(%5E%7C%5B%5B%3Aspace%3A%5D%5D)%22%24val%22(%24%7C%5B%5B%3Aspace%3A%5D%5D)%20%5D%5D%20%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20kill%20%24val%0A%20%20%20%20%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20done%0A%20%20%20%20%20%20%7D%0A%0A%20%20%20%20%20%20reload_haproxy()%0A%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20old_pids%3D%24(pidof%20haproxy)%0A%20%20%20%20%20%20%20%20if%20%5B%20-n%20%22%24old_pids%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%2Fusr%2Fsbin%2Fhaproxy%20-W%20-db%20-f%20%2Fetc%2Fhaproxy%2Fhaproxy.cfg%20%20-p%20%2Fvar%2Flib%2Fhaproxy%2Frun%2Fhaproxy.pid%20-x%20%2Fvar%2Flib%2Fhaproxy%2Frun%2Fhaproxy.sock%20-sf%20%24old_pids%20%26%0A%20%20%20%20%20%20%20%20%20%20%20%20%23There%20seems%20to%20be%20some%20cases%20where%20HAProxy%20doesn't%20drain%20properly.%0A%20%20%20%20%20%20%20%20%20%20%20%20%23To%20handle%20that%20case%2C%20SIGTERM%20signal%20being%20sent%20to%20old%20HAProxy%20processes%20which%20haven't%20terminated.%0A%20%20%20%20%20%20%20%20%20%20%20%20verify_old_haproxy_ps_being_deleted%20%22%24old_pids%22%20%20%26%0A%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20%2Fusr%2Fsbin%2Fhaproxy%20-W%20-db%20-f%20%2Fetc%2Fhaproxy%2Fhaproxy.cfg%20%20-p%20%2Fvar%2Flib%2Fhaproxy%2Frun%2Fhaproxy.pid%20%26%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%7D%0A%0A%20%20%20%20%20%20msg_handler()%0A%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20while%20read%20-r%20line%3B%20do%0A%20%20%20%20%20%20%20%20%20%20echo%20%22The%20client%20send%3A%20%24line%22%20%20%3E%262%0A%20%20%20%20%20%20%20%20%20%20%23%20currently%20only%20'reload'%20msg%20is%20supported%0A%20%20%20%20%20%20%20%20%20%20if%20%5B%20%22%24line%22%20%3D%20reload%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20reload_haproxy%0A%20%20%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20done%0A%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20set%20-ex%0A%20%20%20%20%20%20declare%20-r%20haproxy_sock%3D%22%2Fvar%2Frun%2Fhaproxy%2Fhaproxy-master.sock%22%0A%20%20%20%20%20%20declare%20-r%20haproxy_log_sock%3D%22%2Fvar%2Frun%2Fhaproxy%2Fhaproxy-log.sock%22%0A%20%20%20%20%20%20export%20-f%20msg_handler%0A%20%20%20%20%20%20export%20-f%20reload_haproxy%0A%20%20%20%20%20%20export%20-f%20verify_old_haproxy_ps_being_deleted%0A%20%20%20%20%20%20rm%20-f%20%22%24haproxy_sock%22%20%22%24haproxy_log_sock%22%0A%20%20%20%20%20%20socat%20UNIX-RECV%3A%24%7Bhaproxy_log_sock%7D%20STDOUT%20%26%0A%20%20%20%20%20%20if%20%5B%20-s%20%22%2Fetc%2Fhaproxy%2Fhaproxy.cfg%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%2Fusr%2Fsbin%2Fhaproxy%20-W%20-db%20-f%20%2Fetc%2Fhaproxy%2Fhaproxy.cfg%20%20-p%20%2Fvar%2Flib%2Fhaproxy%2Frun%2Fhaproxy.pid%20%26%0A%20%20%20%20%20%20fi%0A%20%20%20%20%20%20socat%20UNIX-LISTEN%3A%24%7Bhaproxy_sock%7D%2Cfork%20system%3A'bash%20-c%20msg_handler'%0A%20%20%20%20resources%3A%0A%20%20%20%20%20%20requests%3A%0A%20%20%20%20%20%20%20%20cpu%3A%20100m%0A%20%20%20%20%20%20%20%20memory%3A%20200Mi%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20conf-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fhaproxy%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20run-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Frun%2Fhaproxy%22%0A%20%20%20%20livenessProbe%3A%0A%20%20%20%20%20%20initialDelaySeconds%3A%2050%0A%20%20%20%20%20%20httpGet%3A%0A%20%20%20%20%20%20%20%20path%3A%20%2Fhaproxy_ready%0A%20%20%20%20%20%20%20%20port%3A%209444%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20imagePullPolicy%3A%20IfNotPresent%0A%20%20-%20name%3A%20haproxy-monitor%0A%20%20%20%20securityContext%3A%0A%20%20%20%20%20%20capabilities%3A%0A%20%20%20%20%20%20%20%20add%3A%20%5B%22NET_ADMIN%22%2C%20%22SYS_CHROOT%22%5D%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A93e7b8c870261726d44bddc7ba0a702d3720d1838141dac837fb8c3be7c6e1a1%0A%20%20%20%20command%3A%0A%20%20%20%20-%20monitor%0A%20%20%20%20-%20%22%2Fvar%2Flib%2Fkubelet%2Fkubeconfig%22%0A%20%20%20%20-%20%22%2Fconfig%2Fhaproxy.cfg.tmpl%22%0A%20%20%20%20-%20%22%2Fetc%2Fhaproxy%2Fhaproxy.cfg%22%0A%20%20%20%20-%20%22--api-vips%22%0A%20%20%20%20-%20%2210.100.0.50%22%0A%20%20%20%20resources%3A%0A%20%20%20%20%20%20requests%3A%0A%20%20%20%20%20%20%20%20cpu%3A%20100m%0A%20%20%20%20%20%20%20%20memory%3A%20200Mi%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20conf-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fhaproxy%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20run-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Frun%2Fhaproxy%22%0A%20%20%20%20-%20name%3A%20resource-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fconfig%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20chroot-host%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fhost%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20kubeconfigvarlib%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20imagePullPolicy%3A%20IfNotPresent%0A%20%20hostNetwork%3A%20true%0A%20%20tolerations%3A%0A%20%20-%20operator%3A%20Exists%0A%20%20priorityClassName%3A%20system-node-critical%0Astatus%3A%20%7B%7D%0A
          mode: 420
          overwrite: true
          path: /etc/kubernetes/manifests/haproxy.yaml
        - contents:
            source: data:,%23%20Force-load%20legacy%20iptables%20so%20it%20is%20usable%20from%20pod%20network%20namespaces%0Aip_tables%0A
          mode: 420
          overwrite: true
          path: /etc/modules-load.d/iptables.conf
        - contents:
            source: data:,global_defs%20%7B%0A%20%20%20%20enable_script_security%0A%20%20%20%20script_user%20root%0A%20%20%20%20max_auto_priority%20-1%0A%20%20%20%20vrrp_garp_master_refresh%2060%0A%7D%0A%0A%23%20These%20are%20separate%20checks%20to%20provide%20the%20following%20behavior%3A%0A%23%20If%20the%20loadbalancer%20is%20healthy%20then%20all%20is%20well%20regardless%0A%23%20of%20what%20the%20local%20API%20status%20is.%20Both%20checks%20will%20return%20success%20and%0A%23%20we'll%20have%20the%20maximum%20priority.%20This%20means%20as%20long%20as%20there%20is%20a%20node%0A%23%20with%20a%20functional%20loadbalancer%20it%20will%20get%20the%20VIP.%0A%23%20If%20all%20of%20the%20loadbalancers%20go%20down%20but%20the%20local%20API%20is%20still%20running%2C%0A%23%20the%20_both%20check%20will%20still%20succeed%20and%20allow%20any%20node%20with%20a%20functional%0A%23%20API%20to%20take%20the%20VIP.%20This%20isn't%20preferred%20because%20it%20means%20all%20API%0A%23%20traffic%20will%20go%20through%20one%20node%2C%20but%20at%20least%20it%20keeps%20the%20API%20available.%0Avrrp_script%20chk_ocp_lb%20%7B%0A%20%20%20%20script%20%22%2Fusr%2Fbin%2Ftimeout%201.9%20%2Fetc%2Fkeepalived%2Fchk_ocp_script.sh%22%0A%20%20%20%20interval%202%0A%20%20%20%20weight%2020%0A%20%20%20%20rise%203%0A%20%20%20%20fall%203%0A%7D%0A%0Avrrp_script%20chk_ocp_both%20%7B%0A%20%20%20%20script%20%22%2Fusr%2Fbin%2Ftimeout%201.9%20%2Fetc%2Fkeepalived%2Fchk_ocp_script_both.sh%22%0A%20%20%20%20interval%202%0A%20%20%20%20%23%20Use%20a%20smaller%20weight%20for%20this%20check%20so%20it%20won't%20trigger%20the%20move%20from%0A%20%20%20%20%23%20bootstrap%20to%20master%20by%20itself.%0A%20%20%20%20weight%205%0A%20%20%20%20rise%203%0A%20%20%20%20fall%203%0A%7D%0A%0Avrrp_script%20chk_mcs%20%7B%0A%20%20%20%20script%20%22%2Fusr%2Fbin%2Ftimeout%201.9%20%2Fetc%2Fkeepalived%2Fchk_mcs_script.sh%22%0A%20%20%20%20interval%202%0A%20%20%20%20weight%203%0A%20%20%20%20rise%203%0A%20%20%20%20fall%203%0A%7D%0A%0A%23%20TODO%3A%20Improve%20this%20check.%20The%20port%20is%20assumed%20to%20be%20alive.%0A%23%20Need%20to%20assess%20what%20is%20the%20ramification%20if%20the%20port%20is%20not%20there.%0Avrrp_script%20chk_ingress_ready%20%7B%0A%20%20%20%20script%20%22%2Fusr%2Fbin%2Ftimeout%200.9%20%2Fusr%2Fbin%2Fcurl%20-o%20%2Fdev%2Fnull%20-Lfs%20http%3A%2F%2Flocalhost%3A1936%2Fhealthz%2Fready%22%0A%20%20%20%20interval%201%0A%20%20%20%20weight%2010%0A%20%20%20%20rise%203%0A%20%20%20%20fall%202%0A%7D%0A%0Avrrp_script%20chk_ingress%20%7B%0A%20%20%20%20script%20%22%2Fusr%2Fbin%2Ftimeout%200.9%20%2Fusr%2Fbin%2Fcurl%20-o%20%2Fdev%2Fnull%20-Lfs%20http%3A%2F%2Flocalhost%3A1936%2Fhealthz%22%0A%20%20%20%20interval%201%0A%20%20%20%20rise%203%0A%20%20%20%20fall%202%0A%7D%0A%0Avrrp_script%20chk_default_ingress%20%7B%0A%20%20%20%20script%20%22%2Fusr%2Fbin%2Ftimeout%204.9%20%2Fetc%2Fkeepalived%2Fchk_default_ingress.sh%22%0A%20%20%20%20interval%205%0A%20%20%20%20weight%2050%0A%20%20%20%20rise%203%0A%20%20%20%20fall%202%0A%7D%0A%0A%7B%7B%20range%20%24i%2C%20%24config%20%3A%3D%20.Configs%20%7D%7D%0A%7B%7B%24nonVirtualIP%20%3A%3D%20.NonVirtualIP%7D%7D%0A%0A%7B%7B%24participateInAPIVRPP%20%3A%3D%20not%20.EnableUnicast%7D%7D%0A%7B%7B-%20if%20.EnableUnicast%7D%7D%0A%7B%7B-%20range%20.LBConfig.Backends%7D%7D%0A%7B%7B-%20if%20eq%20%24nonVirtualIP%20.Address%7D%7D%0A%7B%7B%24participateInAPIVRPP%20%3D%20true%7D%7D%0A%7B%7B-%20end%7D%7D%0A%7B%7B-%20end%7D%7D%0A%7B%7B-%20end%7D%7D%0A%0A%7B%7Bif%20%24participateInAPIVRPP%7D%7D%0Avrrp_instance%20%7B%7B%20.Cluster.Name%20%7D%7D_API_%7B%7B%24i%7D%7D%20%7B%0A%20%20%20%20state%20BACKUP%0A%20%20%20%20interface%20%7B%7B%20.VRRPInterface%20%7D%7D%0A%20%20%20%20virtual_router_id%20%7B%7B%20.Cluster.APIVirtualRouterID%20%7D%7D%0A%20%20%20%20priority%2040%0A%20%20%20%20advert_int%201%0A%20%20%20%20%7B%7Bif%20.EnableUnicast%7D%7D%0A%20%20%20%20unicast_src_ip%20%7B%7B.NonVirtualIP%7D%7D%0A%20%20%20%20unicast_peer%20%7B%0A%20%20%20%20%20%20%20%20%7B%7B-%20range%20.LBConfig.Backends%20-%7D%7D%0A%20%20%20%20%20%20%20%20%7B%7B-%20if%20ne%20%24nonVirtualIP%20.Address%7D%7D%0A%20%20%20%20%20%20%20%20%7B%7B.Address%7D%7D%0A%20%20%20%20%20%20%20%20%7B%7B-%20end%7D%7D%0A%20%20%20%20%20%20%20%20%7B%7B-%20end%7D%7D%0A%20%20%20%20%7D%0A%20%20%20%20%7B%7Bend%7D%7D%0A%20%20%20%20authentication%20%7B%0A%20%20%20%20%20%20%20%20auth_type%20PASS%0A%20%20%20%20%20%20%20%20auth_pass%20%7B%7B%20.Cluster.Name%20%7D%7D_api_vip%0A%20%20%20%20%7D%0A%20%20%20%20virtual_ipaddress%20%7B%0A%20%20%20%20%20%20%20%20%7B%7B%20.Cluster.APIVIP%20%7D%7D%2F%7B%7B%20.Cluster.VIPNetmask%20%7D%7D%20label%20vip%0A%20%20%20%20%7D%0A%20%20%20%20track_script%20%7B%0A%20%20%20%20%20%20%20%20chk_ocp_lb%0A%20%20%20%20%20%20%20%20chk_ocp_both%0A%20%20%20%20%20%20%20%20chk_mcs%0A%20%20%20%20%7D%0A%7D%0A%7B%7Bend%7D%7D%0A%0A%7B%7B%24participateInIngressVRPP%20%3A%3D%20not%20.EnableUnicast%7D%7D%0A%7B%7B-%20if%20.EnableUnicast%7D%7D%0A%7B%7B-%20range%20.IngressConfig.Peers%7D%7D%0A%7B%7B-%20if%20eq%20%24nonVirtualIP%20.%7D%7D%0A%7B%7B%24participateInIngressVRPP%20%3D%20true%7D%7D%0A%7B%7B-%20end%7D%7D%0A%7B%7B-%20end%7D%7D%0A%7B%7B-%20end%7D%7D%0A%0A%7B%7Bif%20%24participateInIngressVRPP%7D%7D%0Avrrp_instance%20%7B%7B%20.Cluster.Name%20%7D%7D_INGRESS_%7B%7B%24i%7D%7D%20%7B%0A%20%20%20%20state%20BACKUP%0A%20%20%20%20interface%20%7B%7B%20.VRRPInterface%20%7D%7D%0A%20%20%20%20virtual_router_id%20%7B%7B%20.Cluster.IngressVirtualRouterID%20%7D%7D%0A%20%20%20%20priority%2020%0A%20%20%20%20advert_int%201%0A%20%20%20%20%7B%7Bif%20.EnableUnicast%7D%7D%0A%20%20%20%20unicast_src_ip%20%7B%7B.NonVirtualIP%7D%7D%0A%20%20%20%20unicast_peer%20%7B%0A%20%20%20%20%20%20%20%20%7B%7B-%20range%20.IngressConfig.Peers%7D%7D%0A%20%20%20%20%20%20%20%20%7B%7B-%20if%20ne%20%24nonVirtualIP%20.%7D%7D%0A%20%20%20%20%20%20%20%20%7B%7B.%7D%7D%0A%20%20%20%20%20%20%20%20%7B%7B-%20end%7D%7D%0A%20%20%20%20%20%20%20%20%7B%7B-%20end%7D%7D%0A%20%20%20%20%7D%0A%20%20%20%20%7B%7Bend%7D%7D%0A%20%20%20%20authentication%20%7B%0A%20%20%20%20%20%20%20%20auth_type%20PASS%0A%20%20%20%20%20%20%20%20auth_pass%20%7B%7B%20.Cluster.Name%20%7D%7D_ingress_vip%0A%20%20%20%20%7D%0A%20%20%20%20virtual_ipaddress%20%7B%0A%20%20%20%20%20%20%20%20%7B%7B%20.Cluster.IngressVIP%20%7D%7D%2F%7B%7B%20.Cluster.VIPNetmask%20%7D%7D%20label%20vip%0A%20%20%20%20%7D%0A%20%20%20%20track_script%20%7B%0A%20%20%20%20%20%20%20%20chk_ingress%0A%20%20%20%20%20%20%20%20chk_ingress_ready%0A%20%20%20%20%20%20%20%20chk_default_ingress%0A%20%20%20%20%7D%0A%7D%0A%7B%7B%20end%20%7D%7D%0A%7B%7B%20end%20%7D%7D%0A
          mode: 420
          overwrite: true
          path: /etc/kubernetes/static-pod-resources/keepalived/keepalived.conf.tmpl
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Achroot%20%2Fhost%20%2Fbin%2Fcrictl%20ps%20--state%20running%20%7C%20grep%20-qE%20'%5Csmachine-config-server%5Cs'%0A
          mode: 493
          overwrite: true
          path: /etc/kubernetes/static-pod-resources/keepalived/scripts/chk_mcs_script.sh.tmpl
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%2Fusr%2Fbin%2Fcurl%20-o%20%2Fdev%2Fnull%20-kLfs%20http%3A%2F%2Flocalhost%3A9444%2Fhaproxy_ready%20%26%26%20%5B%20-e%20%2Fvar%2Frun%2Fkeepalived%2Fiptables-rule-exists%20%5D%20%7C%7C%20%2Fusr%2Fbin%2Fcurl%20-kLfs%20https%3A%2F%2Flocalhost%3A%7B%7B%20.LBConfig.ApiPort%20%7D%7D%2Freadyz%0A
          mode: 493
          overwrite: true
          path: /etc/kubernetes/static-pod-resources/keepalived/scripts/chk_ocp_script_both.sh.tmpl
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Achroot%20%2Fhost%20%2Fbin%2Fcrictl%20pods%20--namespace%20openshift-ingress%20--state%20Ready%20%7C%20grep%20-qE%20'router-default-%5B%5B%3Aalnum%3A%5D%5D%7B5%2C%7D-%5B%5B%3Aalnum%3A%5D%5D%7B5%2C%7D'%0A
          mode: 493
          overwrite: true
          path: /etc/kubernetes/static-pod-resources/keepalived/scripts/chk_default_ingress.sh.tmpl
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%2Fusr%2Fbin%2Fcurl%20-o%20%2Fdev%2Fnull%20-kLfs%20http%3A%2F%2Flocalhost%3A9444%2Fhaproxy_ready%20%26%26%20%5B%20-e%20%2Fvar%2Frun%2Fkeepalived%2Fiptables-rule-exists%20%5D%0A
          mode: 493
          overwrite: true
          path: /etc/kubernetes/static-pod-resources/keepalived/scripts/chk_ocp_script.sh.tmpl
        - contents:
            source: data:,kind%3A%20Pod%0AapiVersion%3A%20v1%0Ametadata%3A%0A%20%20name%3A%20keepalived%0A%20%20namespace%3A%20openshift-kni-infra%0A%20%20creationTimestamp%3A%0A%20%20deletionGracePeriodSeconds%3A%2065%0A%20%20labels%3A%0A%20%20%20%20app%3A%20kni-infra-vrrp%0A%20%20annotations%3A%0A%20%20%20%20target.workload.openshift.io%2Fmanagement%3A%20'%7B%22effect%22%3A%20%22PreferredDuringScheduling%22%7D'%0A%20%20%20%20openshift.io%2Frequired-scc%3A%20privileged%0Aspec%3A%0A%20%20volumes%3A%0A%20%20-%20name%3A%20resource-dir%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fetc%2Fkubernetes%2Fstatic-pod-resources%2Fkeepalived%22%0A%20%20-%20name%3A%20script-dir%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fetc%2Fkubernetes%2Fstatic-pod-resources%2Fkeepalived%2Fscripts%22%0A%20%20-%20name%3A%20kubeconfig%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fetc%2Fkubernetes%22%0A%20%20-%20name%3A%20kubeconfigvarlib%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20-%20name%3A%20conf-dir%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fetc%2Fkeepalived%22%0A%20%20-%20name%3A%20run-dir%0A%20%20%20%20empty-dir%3A%20%7B%7D%0A%20%20-%20name%3A%20chroot-host%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2F%22%0A%20%20-%20name%3A%20nodeip-configuration%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Frun%2Fnodeip-configuration%22%0A%20%20initContainers%3A%0A%20%20-%20name%3A%20render-config-keepalived%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A93e7b8c870261726d44bddc7ba0a702d3720d1838141dac837fb8c3be7c6e1a1%0A%20%20%20%20command%3A%0A%20%20%20%20-%20runtimecfg%0A%20%20%20%20-%20render%0A%20%20%20%20-%20%22%2Fetc%2Fkubernetes%2Fkubeconfig%22%0A%20%20%20%20-%20%22--api-vips%22%0A%20%20%20%20-%20%2210.100.0.50%22%0A%20%20%20%20-%20%22--ingress-vips%22%0A%20%20%20%20-%20%2210.100.0.51%22%0A%20%20%20%20-%20%22%2Fconfig%22%0A%20%20%20%20-%20%22--out-dir%22%0A%20%20%20%20-%20%22%2Fetc%2Fkeepalived%22%0A%20%20%20%20resources%3A%20%7B%7D%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20kubeconfig%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fkubernetes%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20script-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fconfig%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20conf-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fkeepalived%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20nodeip-configuration%0A%20%20%20%20%20%20mountPath%3A%20%22%2Frun%2Fnodeip-configuration%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20imagePullPolicy%3A%20IfNotPresent%0A%20%20containers%3A%0A%20%20-%20name%3A%20keepalived%0A%20%20%20%20securityContext%3A%0A%20%20%20%20%20%20capabilities%3A%0A%20%20%20%20%20%20%20%20add%3A%20%5B%22NET_ADMIN%22%2C%20%22NET_RAW%22%2C%20%22SYS_CHROOT%22%5D%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A3b0561a80561d95854d5f364f8cd6c3458d27cfb798bf93e09ffcfab97609216%0A%20%20%20%20env%3A%0A%20%20%20%20%20%20-%20name%3A%20NSS_SDB_USE_CACHE%0A%20%20%20%20%20%20%20%20value%3A%20%22no%22%0A%20%20%20%20command%3A%0A%20%20%20%20-%20%2Fbin%2Fbash%0A%20%20%20%20-%20-c%0A%20%20%20%20-%20%7C%0A%20%20%20%20%20%20%23%2Fbin%2Fbash%0A%20%20%20%20%20%20sigterm_handler()%0A%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20if%20pid%3D%24(pgrep%20-o%20keepalived)%3B%20then%0A%20%20%20%20%20%20%20%20%20%20kill%20-s%20SIGTERM%20%22%24pid%22%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%7D%0A%0A%20%20%20%20%20%20reload_keepalived()%0A%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20if%20pid%3D%24(pgrep%20-o%20keepalived)%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20kill%20-s%20SIGHUP%20%22%24pid%22%0A%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20%2Fusr%2Fsbin%2Fkeepalived%20-f%20%2Fetc%2Fkeepalived%2Fkeepalived.conf%20--dont-fork%20--vrrp%20--log-detail%20--log-console%20%26%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%7D%0A%0A%20%20%20%20%20%20msg_handler()%0A%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20while%20read%20-r%20line%3B%20do%0A%20%20%20%20%20%20%20%20%20%20echo%20%22The%20client%20sent%3A%20%24line%22%20%3E%262%0A%20%20%20%20%20%20%20%20%20%20%23%20currently%20only%20'reload'%20msg%20is%20supported%0A%20%20%20%20%20%20%20%20%20%20if%20%5B%20%22%24line%22%20%3D%20reload%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20reload_keepalived%0A%20%20%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20done%0A%20%20%20%20%20%20%7D%0A%0A%20%20%20%20%20%20remove_vip()%0A%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20address%3D%241%0A%20%20%20%20%20%20%20%20interface%3D%24(ip%20-o%20a%20%7C%20awk%20%22%2F%5Cs%24%7Baddress%7D%5C%2F%2F%20%7Bprint%20%5C%242%7D%22)%0A%20%20%20%20%20%20%20%20cidr%3D%24(ip%20-o%20a%20%7C%20awk%20%22%2F%5Cs%24%7Baddress%7D%5C%2F%2F%20%7Bprint%20%5C%244%7D%22)%0A%20%20%20%20%20%20%20%20if%20%5B%20-n%20%22%24interface%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20ip%20a%20del%20%24cidr%20dev%20%24interface%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%7D%0A%0A%20%20%20%20%20%20set%20-ex%0A%20%20%20%20%20%20%23%20Ensure%20that%20we%20don't%20have%20stale%20VIPs%20configured%0A%20%20%20%20%20%20%23%20See%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1931505%0A%20%20%20%20%20%20remove_vip%20%2210.100.0.50%22%0A%20%20%20%20%20%20remove_vip%20%2210.100.0.51%22%0A%20%20%20%20%20%20declare%20-r%20keepalived_sock%3D%22%2Fvar%2Frun%2Fkeepalived%2Fkeepalived.sock%22%0A%20%20%20%20%20%20export%20-f%20msg_handler%0A%20%20%20%20%20%20export%20-f%20reload_keepalived%0A%20%20%20%20%20%20export%20-f%20sigterm_handler%0A%0A%20%20%20%20%20%20%23%20in%20remote%20worker%20case%20sleep%20forever%0A%20%20%20%20%20%20if%20%5B%20-f%20%22%2Frun%2Fnodeip-configuration%2Fremote-worker%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20sleep%20infinity%0A%20%20%20%20%20%20%20%20%20exit%200%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20trap%20sigterm_handler%20SIGTERM%0A%20%20%20%20%20%20if%20%5B%20-s%20%22%2Fetc%2Fkeepalived%2Fkeepalived.conf%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%2Fusr%2Fsbin%2Fkeepalived%20-f%20%2Fetc%2Fkeepalived%2Fkeepalived.conf%20--dont-fork%20--vrrp%20--log-detail%20--log-console%20%26%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20rm%20-f%20%22%24keepalived_sock%22%0A%20%20%20%20%20%20socat%20UNIX-LISTEN%3A%24%7Bkeepalived_sock%7D%2Cfork%20system%3A'bash%20-c%20msg_handler'%0A%20%20%20%20resources%3A%0A%20%20%20%20%20%20requests%3A%0A%20%20%20%20%20%20%20%20cpu%3A%20100m%0A%20%20%20%20%20%20%20%20memory%3A%20200Mi%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20conf-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fkeepalived%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20run-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Frun%2Fkeepalived%22%0A%20%20%20%20-%20name%3A%20chroot-host%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fhost%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20kubeconfigvarlib%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20nodeip-configuration%0A%20%20%20%20%20%20mountPath%3A%20%22%2Frun%2Fnodeip-configuration%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20livenessProbe%3A%0A%20%20%20%20%20%20exec%3A%0A%20%20%20%20%20%20%20%20command%3A%0A%20%20%20%20%20%20%20%20-%20%2Fbin%2Fbash%0A%20%20%20%20%20%20%20%20-%20-c%0A%20%20%20%20%20%20%20%20-%20%7C%0A%20%20%20%20%20%20%20%20%20%20%5B%20!%20-s%20%22%2Fetc%2Fkeepalived%2Fkeepalived.conf%22%20%5D%20%7C%7C%20(echo%20%22%22%20%3E%20%2Ftmp%2Fkeepalived.data%20%26%26%20kill%20-s%20SIGUSR1%20%22%24(pgrep%20-o%20keepalived)%22%20%26%26%20for%20i%20in%20%24(seq%205)%3B%20do%20grep%20-q%20%22VRRP%20Instance%22%20%2Ftmp%2Fkeepalived.data%20%26%26%20exit%200%20%7C%7C%20sleep%201%3B%20done%20%26%26%20exit%201)%0A%20%20%20%20%20%20initialDelaySeconds%3A%2020%0A%20%20%20%20%20%20timeoutSeconds%3A%205%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20imagePullPolicy%3A%20IfNotPresent%0A%20%20-%20name%3A%20keepalived-monitor%0A%20%20%20%20securityContext%3A%0A%20%20%20%20%20%20capabilities%3A%0A%20%20%20%20%20%20%20%20add%3A%20%5B%22NET_ADMIN%22%2C%20%22SYS_CHROOT%22%5D%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A93e7b8c870261726d44bddc7ba0a702d3720d1838141dac837fb8c3be7c6e1a1%0A%20%20%20%20env%3A%0A%20%20%20%20%20%20-%20name%3A%20ENABLE_UNICAST%0A%20%20%20%20%20%20%20%20value%3A%20%22yes%22%0A%20%20%20%20%20%20-%20name%3A%20IS_BOOTSTRAP%0A%20%20%20%20%20%20%20%20value%3A%20%22no%22%0A%20%20%20%20%20%20-%20name%3A%20POD_NAMESPACE%0A%20%20%20%20%20%20%20%20valueFrom%3A%0A%20%20%20%20%20%20%20%20%20%20fieldRef%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20fieldPath%3A%20metadata.namespace%0A%20%20%20%20command%3A%0A%20%20%20%20-%20%2Fbin%2Fbash%0A%20%20%20%20-%20-c%0A%20%20%20%20-%20%7C%0A%20%20%20%20%20%20%23%2Fbin%2Fbash%0A%20%20%20%20%20%20%23%20in%20remote%20worker%20case%20sleep%20forever%0A%20%20%20%20%20%20if%20%5B%20-f%20%22%2Frun%2Fnodeip-configuration%2Fremote-worker%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20sleep%20infinity%0A%20%20%20%20%20%20%20%20%20%20exit%200%0A%20%20%20%20%20%20fi%0A%20%20%20%20%20%20api_vips%3D10.100.0.50%0A%20%20%20%20%20%20ingress_vips%3D10.100.0.51%0A%20%20%20%20%20%20dynkeepalived%20%2Fvar%2Flib%2Fkubelet%2Fkubeconfig%20%2Fconfig%2Fkeepalived.conf.tmpl%20%2Fetc%2Fkeepalived%2Fkeepalived.conf%20--api-vips%20%22%24%7Bapi_vips%7D%22%20--ingress-vips%20%22%24%7Bingress_vips%7D%22%0A%20%20%20%20resources%3A%0A%20%20%20%20%20%20requests%3A%0A%20%20%20%20%20%20%20%20cpu%3A%20100m%0A%20%20%20%20%20%20%20%20memory%3A%20200Mi%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20resource-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fconfig%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20kubeconfigvarlib%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20conf-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fkeepalived%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20run-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Frun%2Fkeepalived%22%0A%20%20%20%20-%20name%3A%20chroot-host%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fhost%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20nodeip-configuration%0A%20%20%20%20%20%20mountPath%3A%20%22%2Frun%2Fnodeip-configuration%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20imagePullPolicy%3A%20IfNotPresent%0A%20%20hostNetwork%3A%20true%0A%20%20tolerations%3A%0A%20%20-%20operator%3A%20Exists%0A%20%20priorityClassName%3A%20system-node-critical%0Astatus%3A%20%7B%7D%0A
          mode: 420
          overwrite: true
          path: /etc/kubernetes/manifests/keepalived.yaml
        - contents:
            source: data:,NODE_SIZING_ENABLED%3Dfalse%0ASYSTEM_RESERVED_MEMORY%3D1Gi%0ASYSTEM_RESERVED_CPU%3D500m%0ASYSTEM_RESERVED_ES%3D1Gi
          mode: 420
          overwrite: true
          path: /etc/node-sizing-enabled.env
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-e%0ANODE_SIZES_ENV%3D%24%7BNODE_SIZES_ENV%3A-%2Fetc%2Fnode-sizing.env%7D%0AVERSION_1%3D1%0AVERSION_2%3D2%0ANODE_AUTO_SIZING_VERSION%3D%24%7BNODE_AUTO_SIZING_VERSION%3A-%24VERSION_2%7D%0ANODE_AUTO_SIZING_VERSION_FILE%3D%24%7BNODE_AUTO_SIZING_VERSION_FILE%3A-%2Fetc%2Fnode-sizing-version.json%7D%0Afunction%20dynamic_memory_sizing%20%7B%0A%20%20%20%20total_memory%3D%24(free%20-g%7Cawk%20'%2F%5EMem%3A%2F%7Bprint%20%242%7D')%0A%20%20%20%20%23%20total_memory%3D8%20test%20the%20recommended%20values%20by%20modifying%20this%20value%0A%20%20%20%20recommended_systemreserved_memory%3D0%0A%20%20%20%20if%20((%24total_memory%20%3C%3D%204))%3B%20then%20%23%2025%25%20of%20the%20first%204GB%20of%20memory%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24total_memory%200.25%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D0%0A%20%20%20%20else%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D1%0A%20%20%20%20%20%20%20%20total_memory%3D%24((total_memory-4))%0A%20%20%20%20fi%0A%20%20%20%20if%20((%24total_memory%20%3C%3D%204))%3B%20then%20%23%2020%25%20of%20the%20next%204GB%20of%20memory%20(up%20to%208GB)%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%20%24(echo%20%24total_memory%200.20%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D0%0A%20%20%20%20else%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%200.80%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D%24((total_memory-4))%0A%20%20%20%20fi%0A%20%20%20%20if%20((%24total_memory%20%3C%3D%208))%3B%20then%20%23%2010%25%20of%20the%20next%208GB%20of%20memory%20(up%20to%2016GB)%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%20%24(echo%20%24total_memory%200.10%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D0%0A%20%20%20%20else%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%200.80%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D%24((total_memory-8))%0A%20%20%20%20fi%0A%20%20%20%20if%20((%24total_memory%20%3C%3D%20112))%3B%20then%20%23%206%25%20of%20the%20next%20112GB%20of%20memory%20(up%20to%20128GB)%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%20%24(echo%20%24total_memory%200.06%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D0%0A%20%20%20%20else%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%206.72%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D%24((total_memory-112))%0A%20%20%20%20fi%0A%20%20%20%20if%20((%24total_memory%20%3E%3D%200))%3B%20then%20%23%202%25%20of%20any%20memory%20above%20128GB%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%20%24(echo%20%24total_memory%200.02%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20fi%0A%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%20%7C%20awk%20'%7Bprintf(%22%25d%5Cn%22%2C%241%20%2B%200.5)%7D')%20%23%20Round%20off%20so%20we%20avoid%20float%20conversions%0A%20%20%20%20echo%20%22SYSTEM_RESERVED_MEMORY%3D%24%7Brecommended_systemreserved_memory%7DGi%22%3E%3E%20%24%7BNODE_SIZES_ENV%7D%0A%7D%0Afunction%20dynamic_cpu_sizing%20%7B%0A%20%20%20%20total_cpu%3D%24(getconf%20_NPROCESSORS_ONLN)%0A%20%20%20%20if%20%5B%20%22%241%22%20-eq%20%22%24VERSION_1%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D0%0A%20%20%20%20%20%20%20%20if%20((%24total_cpu%20%3C%3D%201))%3B%20then%20%23%206%25%20of%20the%20first%20core%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24total_cpu%200.06%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D0%0A%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D0.06%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D%24((total_cpu-1))%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20if%20((%24total_cpu%20%3C%3D%201))%3B%20then%20%23%201%25%20of%20the%20next%20core%20(up%20to%202%20cores)%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24recommended_systemreserved_cpu%20%24(echo%20%24total_cpu%200.01%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D0%0A%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24recommended_systemreserved_cpu%200.01%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D%24((total_cpu-1))%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20if%20((%24total_cpu%20%3C%3D%202))%3B%20then%20%23%200.5%25%20of%20the%20next%202%20cores%20(up%20to%204%20cores)%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24recommended_systemreserved_cpu%20%24(echo%20%24total_cpu%200.005%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D0%0A%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24recommended_systemreserved_cpu%200.01%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D%24((total_cpu-2))%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20if%20((%24total_cpu%20%3E%3D%200))%3B%20then%20%23%200.25%25%20of%20any%20cores%20above%204%20cores%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24recommended_systemreserved_cpu%20%24(echo%20%24total_cpu%200.0025%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20else%0A%20%20%20%20%20%20%20%20%23%20Base%20allocation%20for%201%20CPU%20in%20fractions%20of%20a%20core%20(60%20millicores%20%3D%200.06%20CPU%20core)%0A%20%20%20%20%20%20%20%20base_allocation_fraction%3D0.06%0A%20%20%20%20%20%20%20%20%23%20Increment%20per%20additional%20CPU%20in%20fractions%20of%20a%20core%20(12%20millicores%20%3D%200.012%20CPU%20core)%0A%20%20%20%20%20%20%20%20increment_per_cpu_fraction%3D0.012%0A%20%20%20%20%20%20%20%20if%20((total_cpu%20%3E%201))%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Calculate%20the%20total%20system-reserved%20CPU%20in%20fractions%2C%20starting%20with%20the%20base%20allocation%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20and%20adding%20the%20incremental%20fraction%20for%20each%20additional%20CPU%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(awk%20-v%20base%3D%22%24base_allocation_fraction%22%20-v%20increment%3D%22%24increment_per_cpu_fraction%22%20-v%20cpus%3D%22%24total_cpu%22%20'BEGIN%20%7Bprintf%20%22%25.2f%5Cn%22%2C%20base%20%2B%20increment%20*%20(cpus%20-%201)%7D')%0A%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20For%20a%20single%20CPU%2C%20use%20the%20base%20allocation%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24base_allocation_fraction%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Enforce%20minimum%20threshold%20of%200.5%20CPU%0A%20%20%20%20recommended_systemreserved_cpu%3D%24(awk%20-v%20val%3D%22%24recommended_systemreserved_cpu%22%20'BEGIN%20%7Bif%20(val%20%3C%200.5)%20print%200.5%3B%20else%20print%20val%7D')%0A%0A%20%20%20%20echo%20%22SYSTEM_RESERVED_CPU%3D%24%7Brecommended_systemreserved_cpu%7D%22%3E%3E%20%24%7BNODE_SIZES_ENV%7D%0A%7D%0Afunction%20dynamic_ephemeral_sizing%20%7B%0A%20%20%20%20echo%20%22Not%20implemented%20yet%22%0A%7D%0Afunction%20dynamic_pid_sizing%20%7B%0A%20%20%20%20echo%20%22Not%20implemented%20yet%22%0A%7D%0Afunction%20set_memory%20%7B%0A%20%20%20%20SYSTEM_RESERVED_MEMORY%3D%241%0A%20%20%20%20if%20%5B%20-z%20%22%24%7BSYSTEM_RESERVED_MEMORY%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20SYSTEM_RESERVED_MEMORY%3D%221Gi%22%0A%20%20%20%20fi%0A%20%20%20%20echo%20%22SYSTEM_RESERVED_MEMORY%3D%24%7BSYSTEM_RESERVED_MEMORY%7D%22%20%3E%3E%20%24%7BNODE_SIZES_ENV%7D%0A%7D%0Afunction%20set_cpu%20%7B%0A%20%20%20%20SYSTEM_RESERVED_CPU%3D%241%0A%20%20%20%20if%20%5B%20-z%20%22%24%7BSYSTEM_RESERVED_CPU%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20SYSTEM_RESERVED_CPU%3D%22500m%22%0A%20%20%20%20fi%0A%20%20%20%20echo%20%22SYSTEM_RESERVED_CPU%3D%24%7BSYSTEM_RESERVED_CPU%7D%22%20%3E%3E%20%24%7BNODE_SIZES_ENV%7D%0A%7D%0Afunction%20set_es%20%7B%0A%20%20%20%20SYSTEM_RESERVED_ES%3D%241%0A%20%20%20%20if%20%5B%20-z%20%22%24%7BSYSTEM_RESERVED_ES%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20SYSTEM_RESERVED_ES%3D%221Gi%22%0A%20%20%20%20fi%0A%20%20%20%20echo%20%22SYSTEM_RESERVED_ES%3D%24%7BSYSTEM_RESERVED_ES%7D%22%20%3E%3E%20%24%7BNODE_SIZES_ENV%7D%0A%7D%0Afunction%20dynamic_node_sizing%20%7B%0A%20%20%20%20rm%20-f%20%24%7BNODE_SIZES_ENV%7D%0A%20%20%20%20dynamic_memory_sizing%0A%20%20%20%20dynamic_cpu_sizing%20%241%0A%20%20%20%20set_es%20%242%0A%20%20%20%20%23dynamic_ephemeral_sizing%0A%20%20%20%20%23dynamic_pid_sizing%0A%7D%0Afunction%20static_node_sizing%20%7B%0A%20%20%20%20rm%20-f%20%24%7BNODE_SIZES_ENV%7D%0A%20%20%20%20set_memory%20%241%0A%20%20%20%20set_cpu%20%242%0A%20%20%20%20set_es%20%243%0A%7D%0Afunction%20create_version_file%20%7B%0A%20%20%20%20echo%20%22%7B%5C%22version%5C%22%3A%20%241%7D%22%20%3E%20%242%0A%7D%0Aif%20!%20%5B%20-f%20%24NODE_AUTO_SIZING_VERSION_FILE%20%5D%3B%20then%0A%20%20%20%20create_version_file%20%24NODE_AUTO_SIZING_VERSION%20%24NODE_AUTO_SIZING_VERSION_FILE%0Afi%0Anew_version%3D%24(jq%20.version%20%24NODE_AUTO_SIZING_VERSION_FILE)%0Aif%20%5B%20%241%20%3D%3D%20%22true%22%20%5D%3B%20then%0A%20%20%20%20dynamic_node_sizing%20%24new_version%20%244%0Aelif%20%5B%20%241%20%3D%3D%20%22false%22%20%5D%3B%20then%0A%20%20%20%20static_node_sizing%20%242%20%243%20%244%0Aelse%0A%20%20%20%20echo%20%22Unrecognized%20command%20line%20option.%20Valid%20options%20are%20%5C%22true%5C%22%20or%20%5C%22false%5C%22%22%0Afi%0A
          mode: 493
          overwrite: true
          path: /usr/local/sbin/dynamic-system-reserved-calc.sh
        - contents:
            source: data:,%23%20Turning%20on%20Accounting%20helps%20track%20down%20performance%20issues.%0A%5BManager%5D%0ADefaultCPUAccounting%3Dyes%0ADefaultMemoryAccounting%3Dyes%0ADefaultBlockIOAccounting%3Dyes%0A
          mode: 420
          overwrite: true
          path: /etc/systemd/system.conf.d/kubelet-cgroups.conf
        - contents:
            source: data:,%5BService%5D%0AEnvironment%3D%22KUBELET_LOG_LEVEL%3D2%22%0A
          mode: 420
          overwrite: true
          path: /etc/systemd/system/kubelet.service.d/20-logging.conf
        - contents:
            source: data:,%23%20ignore%20known%20SDN-managed%20devices%0A%5Bdevice%5D%0Amatch-device%3Dinterface-name%3Abr-int%3Binterface-name%3Abr-local%3Binterface-name%3Abr-nexthop%3Binterface-name%3Aovn-k8s-*%3Binterface-name%3Ak8s-*%3Binterface-name%3Atun0%3Binterface-name%3Abr0%3Binterface-name%3Apatch-br-*%3Binterface-name%3Abr-ext%3Binterface-name%3Aext-vxlan%3Binterface-name%3Aext%3Binterface-name%3Aint%3Binterface-name%3Avxlan_sys_*%3Binterface-name%3Agenev_sys_*%3Bdriver%3Aveth%0Amanaged%3D0%0A
          mode: 420
          overwrite: true
          path: /etc/NetworkManager/conf.d/sdn.conf
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-eux%0A%0A%23%20Clean%20up%20old%20config%20on%20behalf%20of%20mtu-migration%0Aif%20!%20systemctl%20-q%20is-enabled%20mtu-migration%3B%20then%0A%20%20echo%20%22Cleaning%20up%20left%20over%20mtu%20migration%20configuration%22%0A%20%20rm%20-rf%20%2Fetc%2Fcno%2Fmtu-migration%0Afi%0A%0Aif%20%5B%20-e%20%2Fetc%2Fnmstate%2Fopenshift%2Fapplied%20%5D%3B%20then%0A%20%20echo%20%22Configuration%20already%20applied%2C%20exiting%22%0A%20%20exit%200%0Afi%0A%0Asrc_path%3D%22%2Fetc%2Fnmstate%2Fopenshift%22%0Adst_path%3D%22%2Fetc%2Fnmstate%22%0Ahostname%3D%24(hostname%20-s)%0Ahost_file%3D%22%24%7Bhostname%7D.yml%22%0Acluster_file%3D%22cluster.yml%22%0Aconfig_file%3D%22%22%0Aif%20%5B%20-s%20%22%24src_path%2F%24host_file%22%20%5D%3B%20then%0A%20%20config_file%3D%24host_file%0Aelif%20%5B%20-s%20%22%24src_path%2F%24cluster_file%22%20%5D%3B%20then%0A%20%20config_file%3D%24cluster_file%0Aelse%0A%20%20echo%20%22No%20configuration%20found%20at%20%24src_path%2F%24host_file%20or%20%24src_path%2F%24cluster_file%22%0A%20%20exit%200%0Afi%0A%0Aif%20%5B%20-e%20%22%24dst_path%2F%24config_file%22%20%5D%3B%20then%0A%20%20echo%20%22ERROR%3A%20File%20%24dst_path%2F%24config_file%20exists.%20Refusing%20to%20overwrite.%22%0A%20%20exit%201%0Afi%0A%0A%23%20Handle%20the%20case%20where%20we're%20migrating%20from%20configure-ovs%0Aovs-vsctl%20--timeout%3D30%20--if-exists%20del-br%20br-ex%0A%0A%23%20Handle%20the%20case%20where%20we're%20migrating%20from%20OpenShift%20SDN%0Aovs-vsctl%20--timeout%3D30%20--if-exists%20del-br%20br0%0A%0Acp%20%22%24src_path%2F%24config_file%22%20%2Fetc%2Fnmstate%0Atouch%20%2Fetc%2Fnmstate%2Fopenshift%2Fapplied%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/nmstate-configuration.sh
        - contents:
            source: data:,%5Bservice%5D%0Akeep_state_file_after_apply%20%3D%20true%0A
          mode: 420
          overwrite: true
          path: /etc/nmstate/nmstate.conf
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%23%20Set%20interface%20ofport_request%20to%20guarantee%20stable%20ofport%20numbers.%20This%20is%20important%20for%20flow%20matches.%0A%23%20Otherwise%2C%20another%20ofport%20number%20is%20assigned%20to%20the%20interface%20on%20every%20restart%20of%20NetworkManager.%0A%23%20This%20script%20will%20build%20an%20associative%20array%20INTERFACE_NAME-%3Eofport_request%20and%20will%20save%20it%20to%20file%20CONFIGURATION_FILE.%0A%23%20When%20an%20interface%20is%20brought%20up%2C%20this%20will%20reuse%20the%20value%20from%20the%20associative%20array%20if%20such%20a%20value%20exists.%0A%23%20Otherwise%2C%20this%20will%20try%20to%20use%20the%20current%20ofport%20value.%20If%20the%20ofport%20value%20is%20already%20reserved%2C%20then%0A%23%20this%20uses%20the%20lowest%20available%20numerical%20value%2C%20instead.%0Aset%20-eux%20-o%20pipefail%0Aif%20%5B%5B%20%22OVNKubernetes%22%20!%3D%20%22OVNKubernetes%22%20%5D%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0AINTERFACE_NAME%3D%241%0AOPERATION%3D%242%0A%0A%23%20Only%20execute%20this%20on%20pre-up%0Aif%20%5B%20%22%24%7BOPERATION%7D%22%20!%3D%20%22pre-up%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20interface's%20NM%20uuid%0AINTERFACE_CONNECTION_UUID%3D%24(nmcli%20-t%20-f%20device%2Ctype%2Cuuid%20conn%20%7C%20awk%20-F%20'%3A'%20'%7Bif(%241%3D%3D%22'%24%7BINTERFACE_NAME%7D'%22%20%26%26%20%242!~%2F%5Eovs*%2F)%20print%20%24NF%7D')%0Aif%20%5B%20%22%24%7BINTERFACE_CONNECTION_UUID%7D%22%20%3D%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20interface's%20slave-type.%20If%20this%20is%20not%20an%20ovs-port%2C%20then%20exit%0AINTERFACE_OVS_SLAVE_TYPE%3D%24(nmcli%20-t%20-f%20connection.slave-type%20conn%20show%20%22%24%7BINTERFACE_CONNECTION_UUID%7D%22%20%7C%20awk%20-F%20'%3A'%20'%7Bprint%20%24NF%7D')%0Aif%20%5B%20%22%24%7BINTERFACE_OVS_SLAVE_TYPE%7D%22%20!%3D%20%22ovs-port%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20This%20is%20not%20necessarily%20a%20UUID%20(can%20be%20a%20name%20in%20case%20of%20bonds)%20but%20this%20should%20be%20unique%0APORT%3D%24(nmcli%20-t%20-f%20connection.master%20conn%20show%20%22%24%7BINTERFACE_CONNECTION_UUID%7D%22%20%7C%20awk%20-F%20'%3A'%20'%7Bprint%20%24NF%7D')%0Aif%20%5B%20%22%24%7BPORT%7D%22%20%3D%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20interface's%20NM%20uuid%0APORT_CONNECTION_UUID%3D%24(nmcli%20-t%20-f%20device%2Ctype%2Cuuid%20conn%20%7C%20awk%20-F%20'%3A'%20'%7Bif(%20(%241%3D%3D%22'%24%7BPORT%7D'%22%20%7C%7C%20%243%3D%3D%22'%24%7BPORT%7D'%22)%20%26%26%20%242~%2F%5Eovs*%2F)%20print%20%24NF%7D')%0Aif%20%5B%20%22%24%7BPORT_CONNECTION_UUID%7D%22%20%3D%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20port's%20slave-type.%20If%20this%20is%20not%20an%20ovs-bridge%2C%20then%20exit%0APORT_OVS_SLAVE_TYPE%3D%24(nmcli%20-t%20-f%20connection.slave-type%20conn%20show%20%22%24%7BPORT_CONNECTION_UUID%7D%22%20%7C%20awk%20-F%20'%3A'%20'%7Bprint%20%24NF%7D')%0Aif%20%5B%20%22%24%7BPORT_OVS_SLAVE_TYPE%7D%22%20!%3D%20%22ovs-bridge%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20port's%20master.%20If%20it%20doesn't%20have%20any%2C%20assume%20it's%20not%20our%20bridge%0ABRIDGE_ID%3D%24(nmcli%20-t%20-f%20connection.master%20conn%20show%20%22%24%7BPORT_CONNECTION_UUID%7D%22%20%7C%20awk%20-F%20'%3A'%20'%7Bprint%20%24NF%7D')%0Aif%20%5B%20%22%24%7BBRIDGE_ID%7D%22%20%3D%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20bridge%20name%0ABRIDGE_NAME%3D%24(nmcli%20-t%20-f%20connection.interface-name%20conn%20show%20%22%24%7BBRIDGE_ID%7D%22%20%7C%20awk%20-F%20'%3A'%20'%7Bprint%20%24NF%7D')%0A%23%20Limit%20this%20to%20br-ex%20and%20br-ex1%20only.%20If%20one%20wanted%20to%20enable%20this%20for%20all%20OVS%20bridges%2C%0A%23%20the%20condition%20would%20be%3A%20if%20%5B%20%22%24BRIDGE_NAME%22%20%3D%3D%20%22%22%20%5D%3B%20then%0Aif%20%5B%20%22%24%7BBRIDGE_NAME%7D%22%20!%3D%20%22br-ex%22%20%5D%20%26%26%20%5B%20%22%24%7BBRIDGE_NAME%7D%22%20!%3D%20%22br-ex1%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Make%20sure%20that%20the%20interface%20is%20plugged%20into%20OVS%0A%23%20This%20should%20always%20be%20the%20case%20given%20that%20we%20are%20in%20pre-up%2C%20but%20exit%20gracefully%20in%20the%20odd%20case%20that%20it's%20not%0Aif%20!%20ovs-vsctl%20list%20interface%20%22%24%7BINTERFACE_NAME%7D%22%20%3E%2Fdev%2Fnull%202%3E%261%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0ACONFIGURATION_FILE%3D%22%2Frun%2Fofport_requests.%24%7BBRIDGE_NAME%7D%22%0A%0A%23%20Declare%20a%20new%20associative%20array.%20If%20CONFIGURATION_FILE%20exists%2C%20source%20entries%20from%20there%0Adeclare%20-A%20INTERFACES%0Aif%20%5B%20-f%20%22%24%7BCONFIGURATION_FILE%7D%22%20%5D%3B%20then%0A%20%20%20%20echo%20%22Sourcing%20configuration%20file%20'%24%7BCONFIGURATION_FILE%7D'%20with%20contents%3A%22%0A%20%20%20%20cat%20%22%24%7BCONFIGURATION_FILE%7D%22%0A%20%20%20%20source%20%22%24%7BCONFIGURATION_FILE%7D%22%0Afi%0A%0A%23%20get_interface_ofport_request%20will%20return%0A%23%20*%20either%3A%20the%20current%20ofport%20assignment%20for%20the%20port%20if%20no%20interface%20has%20claimed%20this%20ofport%20number%2C%20yet%0A%23%20*%20or%3A%20%20%20%20%20the%20lowest%20available%20free%20ofport%20number%0Afunction%20get_interface_ofport_request()%20%7B%0A%20%20%20%20%23%20Build%20an%20array%20that%20only%20contains%20the%20currently%20reserved%20ofport_requests%0A%20%20%20%20declare%20-A%20ofport_requests%0A%20%20%20%20for%20interface_name%20in%20%22%24%7B!INTERFACES%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20%20%20%20%20ofport_requests%5B%24%7BINTERFACES%5B%24interface_name%5D%7D%5D%3D%24%7BINTERFACES%5B%24interface_name%5D%7D%0A%20%20%20%20done%0A%0A%20%20%20%20%23%20Get%20the%20current%20ofport%20number%20assignment%0A%20%20%20%20local%20current_ofport%3D%24(ovs-vsctl%20get%20Interface%20%22%24%7BINTERFACE_NAME%7D%22%20ofport)%0A%0A%20%20%20%20%23%20If%20the%20current%20ofport%20number%20is%20still%20free%2C%20use%20it%0A%20%20%20%20if%20!%20%5B%20%22%24%7Bofport_requests%5B%24current_ofport%5D%2Ba%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%24current_ofport%0A%20%20%20%20%20%20%20%20return%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20If%20the%20current%20ofport%20number%20is%20not%20free%2C%20return%20the%20lowest%20free%20entry%0A%20%20%20%20i%3D0%0A%20%20%20%20for%20i%20in%20%7B1..65000%7D%3B%20do%0A%20%20%20%20%20%20%20%20if%20!%20%5B%20%22%24%7Bofport_requests%5B%24i%5D%2Ba%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20echo%20%24i%0A%20%20%20%20%20%20%20%20%20%20%20%20return%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20done%0A%0A%20%20%20%20%23%20if%20we%20still%20cannot%20find%20an%20ID%2C%20exit%20with%20an%20error%0A%20%20%20%20echo%20%22Impossible%20to%20find%20an%20ofport%20ID%20for%20interface%20%24%7BINTERFACE_NAME%7D%22%20%3E%262%0A%20%20%20%20exit%201%0A%7D%0A%0A%23%20If%20INTERFACES%5BINTERFACE_NAME%5D%20exists%2C%20use%20that%20value%0A%23%20If%20INTERFACES%5BINTERFACE_NAME%5D%20does%20not%20exists%2C%20use%20the%20value%20from%20get_interface_ofport_request%0Aif%20!%20%5B%20%22%24%7BINTERFACES%5B%24INTERFACE_NAME%5D%2Ba%7D%22%20%5D%3B%20then%0A%20%20%20%20INTERFACES%5B%24INTERFACE_NAME%5D%3D%24(get_interface_ofport_request)%0Afi%0A%23%20Set%20ofport_request%20according%20to%20INTERFACES%5BINTERFACE_NAME%5D%0Aovs-vsctl%20set%20Interface%20%22%24%7BINTERFACE_NAME%7D%22%20ofport_request%3D%24%7BINTERFACES%5B%24INTERFACE_NAME%5D%7D%0A%0A%23%20Save%20current%20state%20of%20INTERFACES%20to%20CONFIGURATION_FILE%0Adeclare%20-p%20INTERFACES%20%3E%7C%20%22%24%7BCONFIGURATION_FILE%7D%22%0A
          mode: 493
          overwrite: true
          path: /etc/NetworkManager/dispatcher.d/pre-up.d/10-ofport-request.sh
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%0A%23%20Extract%20Podman%20version%20and%20determine%20the%20signature%20policy%0A%2Fusr%2Fbin%2Fpodman%20-v%20%7C%20%2Fbin%2Fawk%20'%7B%0A%20%20%20%20split(%243%2C%20version%2C%20%22-%22)%3B%0A%20%20%20%20clean_version%20%3D%20version%5B1%5D%3B%0A%0A%20%20%20%20split(clean_version%2C%20current%2C%20%2F%5C.%2F)%3B%0A%20%20%20%20split(%224.4.1%22%2C%20target%2C%20%2F%5C.%2F)%3B%0A%0A%20%20%20%20for%20(i%20%3D%201%3B%20i%20%3C%3D%203%3B%20i%2B%2B)%20%7B%0A%20%20%20%20%20%20%20%20if%20((current%5Bi%5D%20%2B%200)%20%3C%20(target%5Bi%5D%20%2B%200))%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20print%20%22--signature-policy%20%2Fetc%2Fmachine-config-daemon%2Fpolicy-for-old-podman.json%22%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20exit%3B%0A%20%20%20%20%20%20%20%20%7D%20else%20if%20((current%5Bi%5D%20%2B%200)%20%3E%20(target%5Bi%5D%20%2B%200))%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20exit%3B%0A%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%7D%0A%7D'%20%3E%20%2Ftmp%2Fpodman_policy_args%0A
          mode: 493
          overwrite: true
          path: /etc/machine-config-daemon/generate_podman_policy_args.sh
        - contents:
            source: data:,%7B%22auths%22%3A%7B%22cloud.openshift.com%22%3A%7B%22auth%22%3A%22b3BlbnNoaWZ0LXJlbGVhc2UtZGV2K29jbV9hY2Nlc3NfOTRmZDViZTMwOTM3NGU5NDlkM2Q5NzhmOTQzZGFlYTI6TDc0UlozWjNEUUM1U0RFMjBUUUU3UDRZR1RNSDRIRUdMUkMySzk3MjJMSE1PMlBPVUNaUDJFVVo0UDc1N1RLQw%3D%3D%22%2C%22email%22%3A%22jgoldberg%40allcovered.com%22%7D%2C%22quay.io%22%3A%7B%22auth%22%3A%22b3BlbnNoaWZ0LXJlbGVhc2UtZGV2K29jbV9hY2Nlc3NfOTRmZDViZTMwOTM3NGU5NDlkM2Q5NzhmOTQzZGFlYTI6TDc0UlozWjNEUUM1U0RFMjBUUUU3UDRZR1RNSDRIRUdMUkMySzk3MjJMSE1PMlBPVUNaUDJFVVo0UDc1N1RLQw%3D%3D%22%2C%22email%22%3A%22jgoldberg%40allcovered.com%22%7D%2C%22registry.connect.redhat.com%22%3A%7B%22auth%22%3A%22fHVoYy1wb29sLTljZTJiZWU4LTUwYWQtNDVlNC04NDExLTNkNjQ1NWNkODI1NjpleUpoYkdjaU9pSlNVelV4TWlKOS5leUp6ZFdJaU9pSTNaakppTldOallXWXhZVEEwWXpZMVlUSTFaRGN6TjJSa05UVXlNbVJqWWlKOS5NZHFkUUgzenYyMHFzQ0dfR2hGYy1WSzFRNGRsOW05TFhqcmhQNjNjUDh0dDVGX25Wc1U5NGxlcmVVSEQ4R1FXRUxDZlIzeE5HQ2dOSXFPNWUyNC02U3NGOFNTQV9RSnZIODVzLTBBWXlWMHY2QnJxV21CRHNLSWdnSzE2SFhWUzd4cTlSZ05hN200RFRMdUF2RUdtVkRSQ05VUVNFN1FMTWMxaUVhSVI4RVdrT0pPUklQd3hQM3YyUDlsTHpSRWtKYl82WVRjUWRjQUR3T0d1OWkzUHIwMWRHX1d4QU90NkFxcFZBX0JSaHRhNFRjWTFwSHk1bXBlWWVIVnE3Q3hzZWFRV3FzR01Oc0lObkFFNGdjV0MyekVXVl9NZHpIQXVad203WWsxMjg5VVhfYnhVMWhDUkVzdG5zdGdCSERheFRpSTFjalZSZkJ4X05hb0RMU01GVXBzNmlDVXhTTUxzVmc3Mi04LVJHal9nVmMxRDZPNjJkODJoakdaaW5HekJsendzMkZLYlFnNDRjb1VWcWpDdUMwdktCdVJRbDhkX0taVGZTWFVSTS0wOE91YjBNdDRIMjVjZmx6bjNERWdDcUtlSVlUYVdMS3ZranRKVy1MaGdLRjlDUHFqWmozUjhwN2xja2ZkR0lPbHRvY0hZY0xXVlM3QURjdmRNaWVLa3p5STRHb2RPamp2NU5OVF9UWDdjRHBRRVdWUnlENkxkOElXODA4SHVoSmtfa2R0MWVDSkxSTTVUdFBSRHVxZ3UwODlqcWM4WXRVWFhfcm9KcFhoSE5iMUlnekZTdFJqZktTSVJ6YTdlV2g4VWxvRmNwNXJZOV9VeDFTaFVnZ3JlQXFmQ1Y4NXF5Wjlya2RibVNZUE5PRVdzTmtUeGJoY0Q4YWpkYlJrWkFCRQ%3D%3D%22%2C%22email%22%3A%22jgoldberg%40allcovered.com%22%7D%2C%22registry.redhat.io%22%3A%7B%22auth%22%3A%22fHVoYy1wb29sLTljZTJiZWU4LTUwYWQtNDVlNC04NDExLTNkNjQ1NWNkODI1NjpleUpoYkdjaU9pSlNVelV4TWlKOS5leUp6ZFdJaU9pSTNaakppTldOallXWXhZVEEwWXpZMVlUSTFaRGN6TjJSa05UVXlNbVJqWWlKOS5NZHFkUUgzenYyMHFzQ0dfR2hGYy1WSzFRNGRsOW05TFhqcmhQNjNjUDh0dDVGX25Wc1U5NGxlcmVVSEQ4R1FXRUxDZlIzeE5HQ2dOSXFPNWUyNC02U3NGOFNTQV9RSnZIODVzLTBBWXlWMHY2QnJxV21CRHNLSWdnSzE2SFhWUzd4cTlSZ05hN200RFRMdUF2RUdtVkRSQ05VUVNFN1FMTWMxaUVhSVI4RVdrT0pPUklQd3hQM3YyUDlsTHpSRWtKYl82WVRjUWRjQUR3T0d1OWkzUHIwMWRHX1d4QU90NkFxcFZBX0JSaHRhNFRjWTFwSHk1bXBlWWVIVnE3Q3hzZWFRV3FzR01Oc0lObkFFNGdjV0MyekVXVl9NZHpIQXVad203WWsxMjg5VVhfYnhVMWhDUkVzdG5zdGdCSERheFRpSTFjalZSZkJ4X05hb0RMU01GVXBzNmlDVXhTTUxzVmc3Mi04LVJHal9nVmMxRDZPNjJkODJoakdaaW5HekJsendzMkZLYlFnNDRjb1VWcWpDdUMwdktCdVJRbDhkX0taVGZTWFVSTS0wOE91YjBNdDRIMjVjZmx6bjNERWdDcUtlSVlUYVdMS3ZranRKVy1MaGdLRjlDUHFqWmozUjhwN2xja2ZkR0lPbHRvY0hZY0xXVlM3QURjdmRNaWVLa3p5STRHb2RPamp2NU5OVF9UWDdjRHBRRVdWUnlENkxkOElXODA4SHVoSmtfa2R0MWVDSkxSTTVUdFBSRHVxZ3UwODlqcWM4WXRVWFhfcm9KcFhoSE5iMUlnekZTdFJqZktTSVJ6YTdlV2g4VWxvRmNwNXJZOV9VeDFTaFVnZ3JlQXFmQ1Y4NXF5Wjlya2RibVNZUE5PRVdzTmtUeGJoY0Q4YWpkYlJrWkFCRQ%3D%3D%22%2C%22email%22%3A%22jgoldberg%40allcovered.com%22%7D%7D%7D%0A
          mode: 384
          overwrite: true
          path: /var/lib/kubelet/config.json
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-eo%20pipefail%0A%0Afunction%20pull_baremetal_runtime_cfg_image%20%7B%0A%20%20%20%20%23%20By%20default%20podman%20retries%20to%20pull%20an%20image%203%20times%20with%201%20second%20back-off.%20It%20is%20not%20configurable.%20For%20this%0A%20%20%20%20%23%20reason%20we%20are%20implementing%20our%20own%20logic%20of%20pulling%20image%20and%20retrying%20indefinitely.%0A%20%20%20%20%23%20Ref.%3A%20https%3A%2F%2Fgithub.com%2Fcontainers%2Fcommon%2Fblob%2Fe028741ef77fdfa3ae261b9d23cdd50253d586c4%2Flibimage%2Fcopier.go%23L27-L30%0A%0A%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Checking%20if%20baremetal%20runtime%20cfg%20image%20already%20exists%22%0A%20%20%20%20if%20!%20%2Fusr%2Fbin%2Fpodman%20image%20exists%20%22quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A93e7b8c870261726d44bddc7ba0a702d3720d1838141dac837fb8c3be7c6e1a1%22%3B%20then%0A%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Starting%20download%20of%20baremetal%20runtime%20cfg%20image%22%0A%20%20%20%20%20%20while%20!%20%2Fusr%2Fbin%2Fpodman%20pull%20--authfile%20%2Fvar%2Flib%2Fkubelet%2Fconfig.json%20%22quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A93e7b8c870261726d44bddc7ba0a702d3720d1838141dac837fb8c3be7c6e1a1%22%3B%20do%20sleep%201%3B%20done%0A%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Download%20of%20baremetal%20runtime%20cfg%20image%20completed%22%0A%20%20%20%20else%0A%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Image%20exists%2C%20no%20need%20to%20download%22%0A%20%20%20%20fi%0A%7D%0A%0Afunction%20resolv_prepender%20%7B%0A%20%20%20%20%20%20%20%20%23%20In%20DHCP%20connections%2C%20the%20resolv.conf%20content%20may%20be%20late%2C%20thus%20we%20wait%20for%20nameservers%0A%20%20%20%20%20%20%20%20while%20!%20grep%20nameserver%20%2Fvar%2Frun%2FNetworkManager%2Fresolv.conf%3B%20do%0A%20%20%20%20%20%20%20%20%20%20%20%20%3E%262%20echo%20%20%22NM%20resolv-prepender%3A%20NM%20resolv.conf%20still%20empty%20of%20nameserver%22%0A%20%20%20%20%20%20%20%20%20%20%20%20sleep%200.5%0A%20%20%20%20%20%20%20%20done%0A%0A%20%20%20%20%20%20%20%20%23%20Ensure%20resolv.conf%20exists%20and%20contains%20nameservers%20before%20we%20try%20to%20pull%20image%20or%20run%20podman%0A%20%20%20%20%20%20%20%20if%20%5B%5B%20!%20-e%20%2Fetc%2Fresolv.conf%20%5D%5D%20%7C%7C%20!%20grep%20-q%20nameserver%20%2Fetc%2Fresolv.conf%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20cp%20%2Fvar%2Frun%2FNetworkManager%2Fresolv.conf%20%2Fetc%2Fresolv.conf%0A%20%20%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20%20%20%23%20Ensure%20baremetalRuntimeCfgImage%20is%20pulled%20in%20a%20reliable%20way%20before%20trying%20to%20use%20it%0A%20%20%20%20%20%20%20%20%23%20in%20the%20subsequent%20code%0A%20%20%20%20%20%20%20%20pull_baremetal_runtime_cfg_image%0A%0A%20%20%20%20%20%20%20%20NAMESERVER_IP%3D%22%24(%2Fusr%2Fbin%2Fpodman%20run%20--rm%20%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20--authfile%20%2Fvar%2Flib%2Fkubelet%2Fconfig.json%20%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20--net%3Dhost%20%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A93e7b8c870261726d44bddc7ba0a702d3720d1838141dac837fb8c3be7c6e1a1%20%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20node-ip%20%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20show%20%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%2210.100.0.50%22%20%20%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%2210.100.0.51%22%20)%22%0A%20%20%20%20%20%20%20%20DOMAINS%3D%22%24%7BIP4_DOMAINS%3A-%7D%20%24%7BIP6_DOMAINS%3A-%7D%20comp-poc-rh01.rhpoc.int%22%0A%20%20%20%20%20%20%20%20if%20%5B%5B%20-n%20%22%24NAMESERVER_IP%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20KNICONFDONEPATH%3D%22%2Frun%2Fresolv-prepender-kni-conf-done%22%0A%20%20%20%20%20%20%20%20%20%20%20%20if%20systemctl%20-q%20is-enabled%20systemd-resolved%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Configure%20for%20OKD%20domain%20and%20local%20IP%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20mkdir%20-p%20%2Fetc%2Fsystemd%2Fresolved.conf.d%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20KNICONFTMPPATH%3D%22%24(mktemp)%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20KNICONFPATH%3D%22%2Fetc%2Fsystemd%2Fresolved.conf.d%2F60-kni.conf%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20echo%20%22%5BResolve%5D%22%20%3E%20%22%24%7BKNICONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20echo%20%22DNS%3D%24NAMESERVER_IP%22%20%3E%3E%20%22%24%7BKNICONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20echo%20%22Domains%3D%24%7BDOMAINS%7D%22%20%3E%3E%20%22%24%7BKNICONFTMPPATH%7D%22%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20If%20KNI%20conf%20is%20not%20created%20or%20doesn't%20match%20what%20is%20generated%20or%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20if%20we%20haven't%20completed%20a%20full%20update%20-%20create%20or%20update%20it%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20%5B%5B%20!%20-f%20%22%24%7BKNICONFPATH%7D%22%20%5D%5D%20%7C%7C%20%5B%5B%20!%20-f%20%22%24%7BKNICONFDONEPATH%7D%22%20%5D%5D%20%7C%7C%20!%20cmp%20--silent%20%22%24%7BKNICONFPATH%7D%22%20%22%24%7BKNICONFTMPPATH%7D%22%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Creating%2Fupdating%20%2Fetc%2Fsystemd%2Fresolved.conf.d%2F60-kni.conf%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Remove%20the%20done%20file%20flag%20before%20writing%20the%20config%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20This%20would%20guard%20against%20interruptions%20and%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20prevent%20double%20restart%20of%20systemd-resolved%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20rm%20-f%20%22%24%7BKNICONFDONEPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Copy%20tmp%20file%20contents%20to%20preserve%20permissions%20and%20SELinux%20label%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20cat%20%22%24%7BKNICONFTMPPATH%7D%22%20%3E%20%22%24%7BKNICONFPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20%5B%5B%20!%20-f%20%22%24%7BKNICONFDONEPATH%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20systemctl%20-q%20is-active%20systemd-resolved%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Restarting%20systemd-resolved%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20systemctl%20restart%20systemd-resolved%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20touch%20%22%24%7BKNICONFDONEPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20rm%20-rf%20%22%24%7BKNICONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Prepending%20'nameserver%20%24NAMESERVER_IP'%20to%20%2Fetc%2Fresolv.conf%20(other%20nameservers%20from%20%2Fvar%2Frun%2FNetworkManager%2Fresolv.conf)%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20RESOLVCONFTMPPATH%3D%22%24(mktemp)%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20sed%20-e%20%22%2FGenerated%20by%2Fc%23%20Generated%20by%20KNI%20resolv%20prepender%20NM%20dispatcher%20script%22%20%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%2Fvar%2Frun%2FNetworkManager%2Fresolv.conf%20%3E%20%22%24%7BRESOLVCONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20sed%20-i%20%220%2C%2F%5Enameserver.*%2Fs%2F%2Fnameserver%20%24NAMESERVER_IP%5Cn%5C0%2F%22%20%22%24%7BRESOLVCONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20!%20grep%20-q%20search%20%22%24%7BRESOLVCONFTMPPATH%7D%22%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Make%20sure%20we%20have%20a%20search%20entry%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20echo%20%22search%20comp-poc-rh01.rhpoc.int%22%20%3E%3E%20%22%24%7BRESOLVCONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Make%20sure%20cluster%20domain%20is%20first%20in%20the%20search%20list%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20sed%20-i%20%22s%2F%5Esearch%20%5C(.*%5C)%2Fsearch%20comp-poc-rh01.rhpoc.int%20%5C1%2F%22%20%22%24%7BRESOLVCONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Remove%20duplicate%20cluster%20domain%20entries%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20sed%20-i%20%22s%2F%5C(search%20comp-poc-rh01.rhpoc.int.*%5C)%20comp-poc-rh01.rhpoc.int%5C(%20.*%5C%7C%24%5C)%2F%5C1%5C2%2F%22%20%22%24%7BRESOLVCONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Only%20leave%20the%20first%203%20nameservers%20in%20%2Fetc%2Fresolv.conf%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20sed%20-i%20'%3Aa%20%24!%7BN%3B%20ba%7D%3B%20s%2F%5C(%5E%5C%7C%5Cn%5C)nameserver%2F%5Cn%23%20nameserver%2F4g'%20%22%24%7BRESOLVCONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Only%20touch%20existing%20resolv.conf%20if%20files%20actually%20differ%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20!%20cmp%20-s%20%22%24%7BRESOLVCONFTMPPATH%7D%22%20%2Fetc%2Fresolv.conf%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20chmod%20644%20%22%24%7BRESOLVCONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20mv%20-Zf%20%22%24%7BRESOLVCONFTMPPATH%7D%22%20%2Fetc%2Fresolv.conf%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Workaround%20for%20bz%201929160.%20Reload%20NetworkManager%20to%20force%20it%20to%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20re-run%20the%20lookup%20of%20the%20hostname%20now%20that%20we%20know%20we%20have%20DNS%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20servers%20configured%20correctly%20in%20resolv.conf.%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20nmcli%20general%20reload%20dns-rc%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20touch%20%22%24%7BKNICONFDONEPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20rm%20-rf%20%22%24%7BRESOLVCONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20fi%0A%7D%0A%0Aresolv_prepender%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/resolv-prepender.sh
        - contents:
            source: data:,%23%20Needed%20by%20the%20OpenShift%20SDN.%20See%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1758552%0Anet.ipv4.conf.all.arp_announce%20%3D%202%0A
          mode: 420
          overwrite: true
          path: /etc/sysctl.d/arp.conf
        - contents:
            source: data:,%23%20See%3A%20rhbz%231384746%2C%20OCPBUGS-24012%0Anet.ipv4.neigh.default.gc_thresh1%3D8192%0Anet.ipv4.neigh.default.gc_thresh2%3D32768%0Anet.ipv4.neigh.default.gc_thresh3%3D65536%0Anet.ipv6.neigh.default.gc_thresh1%3D8192%0Anet.ipv6.neigh.default.gc_thresh2%3D32768%0Anet.ipv6.neigh.default.gc_thresh3%3D65536%0A
          mode: 420
          overwrite: true
          path: /etc/sysctl.d/gc-thresh.conf
        - contents:
            source: data:,%0Afs.inotify.max_user_watches%20%3D%2065536%0Afs.inotify.max_user_instances%20%3D%208192%0A
          mode: 420
          overwrite: true
          path: /etc/sysctl.d/inotify.conf
        - contents:
            source: data:,vm.unprivileged_userfaultfd%20%3D%201
          mode: 420
          overwrite: true
          path: /etc/sysctl.d/enable-userfaultfd.conf
        - contents:
            source: data:,%23%20Needed%20for%20OpenShift%20Logging%20(ElasticSearch).%20See%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1793714%0Avm.max_map_count%20%3D%20262144%0A
          mode: 420
          overwrite: true
          path: /etc/sysctl.d/vm-max-map.conf
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-euo%20pipefail%0A%0A%23%20First%2C%20we%20need%20to%20wait%20until%20DHCP%20finishes%20and%20the%20node%20has%20a%20non-%60localhost%60%0A%23%20hostname%20before%20%60kubelet.service%60%20starts.%0A%23%20That's%20the%20%60--wait%60%20argument%20as%20used%20by%20%60node-valid-hostname.service%60.%0A%23%0A%23%20Second%2C%20on%20GCP%20specifically%20we%20truncate%20the%20hostname%20if%20it's%20%3E63%20characters.%0A%23%20That's%20%60gcp-hostname.service%60.%0A%0A%23%20Block%20indefinitely%20until%20the%20host%20gets%20a%20non-localhost%20name.%0A%23%20Note%20node-valid-hostname.service%20uses%20systemd%20to%20abort%20if%20this%20takes%20too%20long.%0Await_localhost()%20%7B%0A%20%20%20%20echo%20%22waiting%20for%20non-localhost%20hostname%20to%20be%20assigned%22%0A%20%20%20%20while%20%5B%5B%20%22%24(%3C%20%2Fproc%2Fsys%2Fkernel%2Fhostname)%22%20%3D~%20(localhost%7Clocalhost.localdomain)%20%5D%5D%3B%0A%20%20%20%20do%0A%20%20%20%20%20%20%20%20sleep%201%0A%20%20%20%20done%0A%20%20%20%20echo%20%22node%20identified%20as%20%24(%3C%2Fproc%2Fsys%2Fkernel%2Fhostname)%22%0A%20%20%20%20echo%20%22saving%20hostname%20to%20prevent%20NetworkManager%20from%20ever%20unsetting%20it%22%0A%20%20%20%20hostnamectl%20set-hostname%20--static%20--transient%20%24(%3C%2Fproc%2Fsys%2Fkernel%2Fhostname)%0A%20%20%20%20exit%200%0A%7D%0A%0Aset_gcp_hostname()%20%7B%0A%20%20%20%20%2Fusr%2Fbin%2Fafterburn%20--provider%20gcp%20--hostname%3D%2Frun%2Fafterburn.hostname%0A%0A%20%20%20%20local%20host_name%3D%24(cat%20%2Frun%2Fafterburn.hostname)%0A%20%20%20%20local%20type_arg%3D%22transient%22%0A%0A%20%20%20%20%23%20%2Fetc%2Fhostname%20is%20used%20for%20static%20hostnames%20and%20is%20authoritative.%0A%20%20%20%20%23%20This%20will%20check%20to%20make%20sure%20that%20the%20static%20hostname%20is%20the%0A%20%20%20%20%23%20less%20than%20or%20equal%20to%2063%20characters%20in%20length.%0A%20%20%20%20if%20%5B%20-f%20%2Fetc%2Fhostname%20%5D%20%26%26%20%5B%20%22%24(cat%20%2Fetc%2Fhostname%20%7C%20wc%20-m)%22%20-gt%200%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20etc_name%3D%22%24(%3C%20%2Fetc%2Fhostname)%22%0A%20%20%20%20%20%20%20%20type_arg%3D%22static%22%0A%20%20%20%20%20%20%20%20if%20%5B%20%22%24%7Betc_name%7D%22%20!%3D%20%22%24%7Bhost_name%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20echo%20%22%2Fetc%2Fhostname%20is%20set%20to%20%24%7Betc_name%7D%20but%20does%20not%20match%20%24%7Bhost_name%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20echo%20%22using%20%2Fetc%2Fhostname%20as%20the%20authoritative%20name%22%0A%20%20%20%20%20%20%20%20%20%20%20%20host_name%3D%22%24%7Betc_name%7D%22%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Only%20mutate%20the%20hostname%20if%20the%20length%20is%20longer%20than%2063%20characters.%20The%0A%20%20%20%20%23%20hostname%20will%20be%20the%20lesser%20of%2063%20characters%20after%20the%20first%20dot%20in%20the%0A%20%20%20%20%23%20FQDN.%20%20This%20algorithm%20is%20only%20known%20to%20work%20in%20GCP%2C%20and%20hence%20is%20only%0A%20%20%20%20%23%20executed%20in%20GCP.%0A%20%20%20%20if%20%5B%20%22%24%7B%23host_name%7D%22%20-gt%2063%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20alt_name%3D%24(printf%20%22%24%7Bhost_name%7D%22%20%7C%20cut%20-f1%20-d'.'%20%7C%20cut%20-c%20-63)%0A%20%20%20%20%20%20%20%20echo%20%22%24%7Bhost_name%7D%20is%20longer%20than%2063%20characters%2C%20using%20truncated%20hostname%22%0A%20%20%20%20%20%20%20%20host_name%3D%22%24%7Balt_name%7D%22%0A%20%20%20%20fi%0A%20%20%20%20echo%20%22setting%20%24%7Btype_arg%7D%20hostname%20to%20%24%7Bhost_name%7D%22%0A%20%20%20%20%2Fbin%2Fhostnamectl%20%22--%24%7Btype_arg%7D%22%20set-hostname%20%22%24%7Bhost_name%7D%22%0A%20%20%20%20exit%200%0A%7D%0A%0Aset_openstack_hostname()%20%7B%0A%20%20%20%20%23%20Read%20metadata%20written%20by%20afterburn%20service%0A%20%20%20%20.%20%2Frun%2Fmetadata%2Fafterburn%0A%0A%20%20%20%20%23%20node-valid-hostname%20sets%20persistent%20hostname%20from%20%2Fproc%2Fsys%2Fkernel%2Fhostname%0A%20%20%20%20echo%20%22%24AFTERBURN_OPENSTACK_HOSTNAME%22%20%3E%20%2Fproc%2Fsys%2Fkernel%2Fhostname%0A%7D%0A%0Aset_powervs_hostname()%20%7B%0A%20%20%20%20%23%20Read%20metadata%20written%20by%20afterburn%20service%0A%20%20%20%20.%20%2Frun%2Fmetadata%2Fafterburn%0A%0A%20%20%20%20%23%20node-valid-hostname%20sets%20persistent%20hostname%20from%20%2Fproc%2Fsys%2Fkernel%2Fhostname%0A%20%20%20%20echo%20%22%24AFTERBURN_POWERVS_LOCAL_HOSTNAME%22%20%3E%20%2Fproc%2Fsys%2Fkernel%2Fhostname%0A%7D%0A%0Aarg%3D%24%7B1%7D%3B%20shift%3B%0Acase%20%22%24%7Barg%7D%22%20in%0A%20%20%20%20--wait)%20wait_localhost%3B%3B%0A%20%20%20%20--gcp)%20set_gcp_hostname%3B%3B%0A%20%20%20%20--openstack)%20set_openstack_hostname%3B%3B%0A%20%20%20%20--powervs)%20set_powervs_hostname%3B%3B%0A%20%20%20%20*)%20echo%20%22Unhandled%20arg%20%24arg%22%3B%20exit%201%0Aesac%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/mco-hostname
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%0Aset%20-eou%20pipefail%0A%0A%23%20context%0Aintapi%3D%24(oc%20get%20infrastructures.config.openshift.io%20cluster%20-o%20%22jsonpath%3D%7B.status.apiServerInternalURI%7D%22)%0Acontext%3D%22%24(oc%20config%20current-context)%22%0A%23%20cluster%0Acluster%3D%22%24(oc%20config%20view%20-o%20%22jsonpath%3D%7B.contexts%5B%3F(%40.name%3D%3D%5C%22%24context%5C%22)%5D.context.cluster%7D%22)%22%0Aserver%3D%22%24(oc%20config%20view%20-o%20%22jsonpath%3D%7B.clusters%5B%3F(%40.name%3D%3D%5C%22%24cluster%5C%22)%5D.cluster.server%7D%22)%22%0A%23%20token%0Aca_crt_data%3D%22%24(oc%20get%20secret%20-n%20openshift-machine-config-operator%20node-bootstrapper-token%20-o%20%22jsonpath%3D%7B.data.ca%5C.crt%7D%22%20%7C%20base64%20--decode)%22%0Anamespace%3D%22%24(oc%20get%20secret%20-n%20openshift-machine-config-operator%20node-bootstrapper-token%20%20-o%20%22jsonpath%3D%7B.data.namespace%7D%22%20%7C%20base64%20--decode)%22%0Atoken%3D%22%24(oc%20get%20secret%20-n%20openshift-machine-config-operator%20node-bootstrapper-token%20-o%20%22jsonpath%3D%7B.data.token%7D%22%20%7C%20base64%20--decode)%22%0A%0Aexport%20KUBECONFIG%3D%22%24(mktemp)%22%0Akubectl%20config%20set-credentials%20%22kubelet%22%20--token%3D%22%24token%22%20%3E%2Fdev%2Fnull%0Aca_crt%3D%22%24(mktemp)%22%3B%20echo%20%22%24ca_crt_data%22%20%3E%20%24ca_crt%0Akubectl%20config%20set-cluster%20%24cluster%20--server%3D%22%24intapi%22%20--certificate-authority%3D%22%24ca_crt%22%20--embed-certs%20%3E%2Fdev%2Fnull%0Akubectl%20config%20set-context%20kubelet%20--cluster%3D%22%24cluster%22%20--user%3D%22kubelet%22%20%3E%2Fdev%2Fnull%0Akubectl%20config%20use-context%20kubelet%20%3E%2Fdev%2Fnull%0Acat%20%22%24KUBECONFIG%22%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/recover-kubeconfig.sh
        - contents:
            source: data:,
          mode: 493
          overwrite: true
          path: /etc/kubernetes/kubelet-plugins/volume/exec/.dummy
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%23%20Workaround%3A%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1941714%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1935539%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1987108%0A%0Adriver%3D%24(nmcli%20-t%20-m%20tabular%20-f%20general.driver%20dev%20show%20%22%24%7BDEVICE_IFACE%7D%22)%0A%0Aif%20%5B%5B%20%22%242%22%20%3D%3D%20%22up%22%20%26%26%20%22%24%7Bdriver%7D%22%20%3D%3D%20%22vmxnet3%22%20%5D%5D%3B%20then%0A%20%20logger%20-s%20%2299-vsphere-disable-tx-udp-tnl%20triggered%20by%20%24%7B2%7D%20on%20device%20%24%7BDEVICE_IFACE%7D.%22%0A%20%20ethtool%20-K%20%24%7BDEVICE_IFACE%7D%20tx-udp_tnl-segmentation%20off%0A%20%20ethtool%20-K%20%24%7BDEVICE_IFACE%7D%20tx-udp_tnl-csum-segmentation%20off%0A%20%20ethtool%20-K%20%24%7BDEVICE_IFACE%7D%20tx-checksum-ip-generic%20off%0Afi%0A
          mode: 484
          overwrite: true
          path: /etc/NetworkManager/dispatcher.d/99-vsphere-disable-tx-udp-tnl
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%0Auntil%20%5B%20-e%20%2Frun%2Fnodeip-configuration%2Fbr-ex-up%20%5D%0Ado%0A%20%20sleep%201%0Adone%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/wait-for-br-ex-up.sh
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-x%0A%0Aif%20%5B%20!%20-e%20%22%2Fetc%2Fipsec.d%2Fopenshift.conf%22%20%5D%3B%20then%0A%20%20exit%200%0Afi%0A%0A%23%20Modify%20existing%20IPsec%20connection%20entries%20with%20%22auto%3Dstart%22%0A%23%20option%20and%20restart%20ipsec%20systemd%20service.%20This%20helps%20to%0A%23%20establish%20IKE%20SAs%20for%20the%20existing%20IPsec%20connections%20with%0A%23%20peer%20nodes.%20This%20option%20will%20be%20deleted%20from%20connections%0A%23%20once%20ovs-monitor-ipsec%20process%20spinned%20up%20on%20the%20node%20by%0A%23%20ovn-ipsec-host%20pod%2C%20but%20still%20it%20won't%20reestablish%20IKE%20SAs%0A%23%20again%20with%20peer%20nodes%2C%20so%20it%20shouldn't%20be%20a%20problem.%0Aif%20!%20grep%20-q%20%22auto%3Dstart%22%20%2Fetc%2Fipsec.d%2Fopenshift.conf%3B%20then%0A%20%20sed%20-i%20'%2F%5E.*conn%20ovn.*%24%2Fa%5C%20%20%20%20auto%3Dstart'%20%2Fetc%2Fipsec.d%2Fopenshift.conf%0Afi%0Achroot%20%2Fproc%2F1%2Froot%20ipsec%20restart%0A%0A%23%20Wait%20for%20upto%2060s%20to%20get%20IPsec%20SAs%20to%20establish%20with%20peer%20nodes.%0Atimeout%3D60%0Aelapsed%3D0%0Adesiredconn%3D%22%22%0Aestablishedsa%3D%22%22%0Awhile%20%5B%5B%20%24elapsed%20-lt%20%24timeout%20%5D%5D%3B%20do%0A%20%20desiredconn%3D%24(grep%20-E%20'%5E%5Cs*conn%5Cs%2B'%20%2Fetc%2Fipsec.d%2Fopenshift.conf%20%7C%20grep%20-v%20'%25default'%20%7C%20awk%20'%7Bprint%20%242%7D'%20%7C%20tr%20'%20'%20'%5Cn'%20%7C%20sort%20%7C%20tr%20'%5Cn'%20'%20')%0A%20%20establishedsa%3D%24(ipsec%20showstates%20%7C%20grep%20STATE_V2_ESTABLISHED_CHILD_SA%20%7C%20grep%20-o%20'%22%5B%5E%22%5D*%22'%20%7C%20sed%20's%2F%22%2F%2Fg'%20%7C%20tr%20'%20'%20'%5Cn'%20%7C%20sort%20%7C%20uniq%20%7C%20tr%20'%5Cn'%20'%20')%0A%20%20if%20%5B%20%22%24desiredconn%22%20%3D%3D%20%22%24establishedsa%22%20%5D%3B%20then%0A%20%20%20%20echo%20%22IPsec%20SAs%20are%20established%20for%20desired%20connections%20after%20%24%7Belapsed%7Ds%22%0A%20%20%20%20break%0A%20%20else%0A%20%20%20%20echo%20%22IPsec%20SAs%20are%20not%20established%20yet%2C%20total%20waited%20time%20%24%7Belapsed%7Ds%22%0A%20%20%20%20sleep%202s%0A%20%20fi%0A%20%20elapsed%3D%24((elapsed%20%2B%202))%0Adone%0A%0Aif%20%5B%5B%20%24elapsed%20-ge%20%24timeout%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22Timed%20out%20waiting%2C%20some%20connections%20are%20not%20established%2C%20desired%20conns%20%24desiredconn%2C%20established%20conns%20%24establishedsa%22%0Afi%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/ipsec-connect-wait.sh
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-eux%0A%0Aif%20%5B%20!%20-e%20%2Fetc%2Fnmstate%2Fopenshift%2Fapplied%20%5D%3B%20then%0A%20%20%23%20No%20need%20to%20do%20this%20if%20no%20NMState%20configuration%20was%20applied%0A%20%20exit%200%0Afi%0A%0A%23%20This%20logic%20is%20borrowed%20from%20configure-ovs.sh%0A%23%20TODO%3A%20Find%20a%20platform-agnostic%20way%20to%20do%20this.%20It%20won't%20work%20on%20platforms%20where%0A%23%20nodeip-configuration%20is%20not%20used.%0Aip%3D%24(cat%20%2Frun%2Fnodeip-configuration%2Fprimary-ip)%0Aif%20%5B%5B%20%22%24%7Bip%7D%22%20%3D%3D%20%22%22%20%5D%5D%3B%20then%0A%20%20echo%20%22No%20ip%20to%20bind%20was%20found%22%0A%20%20exit%201%0Afi%0Awhile%20%3A%0Ado%0A%20%20random_port%3D%24(shuf%20-i%2050000-60000%20-n%201)%0A%20%20echo%20%22Trying%20to%20bind%20%24%7Bip%7D%20on%20port%20%24%7Brandom_port%7D%22%0A%20%20exit_code%3D%24(timeout%202s%20nc%20-l%20%22%24%7Bip%7D%22%20%24%7Brandom_port%7D%3B%20echo%20%24%3F)%0A%20%20if%20%5B%5B%20exit_code%20-eq%20124%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22Address%20bound%20successfully%22%0A%20%20%20%20exit%200%0A%20%20fi%0A%20%20sleep%2010%0Adone%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/wait-for-primary-ip.sh
        - contents:
            source: data:,unqualified-search-registries%20%3D%20%5B'registry.access.redhat.com'%2C%20'docker.io'%5D%0A
          mode: 420
          overwrite: true
          path: /etc/containers/registries.conf
        - contents:
            source: data:,%5Bcrio%5D%0Ainternal_wipe%20%3D%20true%0Ainternal_repair%20%3D%20true%0A%0A%5Bcrio.api%5D%0Astream_address%20%3D%20%22127.0.0.1%22%0Astream_port%20%3D%20%220%22%0A%0A%5Bcrio.runtime%5D%0Aselinux%20%3D%20true%0Aconmon%20%3D%20%22%22%0Aconmon_cgroup%20%3D%20%22pod%22%0Adefault_env%20%3D%20%5B%0A%20%20%20%20%22NSS_SDB_USE_CACHE%3Dno%22%2C%0A%5D%0Adefault_runtime%20%3D%20%22crun%22%0Alog_level%20%3D%20%22info%22%0Acgroup_manager%20%3D%20%22systemd%22%0Adefault_sysctls%20%3D%20%5B%0A%20%20%20%20%22net.ipv4.ping_group_range%3D0%202147483647%22%2C%0A%5D%0Ahooks_dir%20%3D%20%5B%0A%20%20%20%20%22%2Fetc%2Fcontainers%2Foci%2Fhooks.d%22%2C%0A%20%20%20%20%22%2Frun%2Fcontainers%2Foci%2Fhooks.d%22%2C%0A%20%20%20%20%22%2Fusr%2Fshare%2Fcontainers%2Foci%2Fhooks.d%22%2C%0A%5D%0Amanage_ns_lifecycle%20%3D%20true%0Aabsent_mount_sources_to_reject%20%3D%20%5B%0A%20%20%20%20%22%2Fetc%2Fhostname%22%2C%0A%5D%0Adrop_infra_ctr%20%3D%20true%0A%0A%5Bcrio.runtime.runtimes.runc%5D%0Aruntime_root%20%3D%20%22%2Frun%2Frunc%22%0Aallowed_annotations%20%3D%20%5B%0A%20%20%20%20%22io.containers.trace-syscall%22%2C%0A%20%20%20%20%22io.kubernetes.cri-o.Devices%22%2C%0A%20%20%20%20%22io.kubernetes.cri-o.LinkLogs%22%2C%0A%5D%0A%0A%5Bcrio.runtime.runtimes.crun%5D%0Aruntime_root%20%3D%20%22%2Frun%2Fcrun%22%0Aallowed_annotations%20%3D%20%5B%0A%20%20%20%20%22io.containers.trace-syscall%22%2C%0A%20%20%20%20%22io.kubernetes.cri-o.Devices%22%2C%0A%20%20%20%20%22io.kubernetes.cri-o.LinkLogs%22%2C%0A%5D%0A%23%20Based%20on%20https%3A%2F%2Fgithub.com%2Fcontainers%2Fcrun%2Fblob%2F27d7dd3a0%2FREADME.md%3Fplain%3D1%23L48%0Acontainer_min_memory%20%3D%20%22512KiB%22%0Adefault_annotations%20%3D%20%7B%22run.oci.systemd.subgroup%22%20%3D%20%22%22%7D%0A%0A%5Bcrio.runtime.workloads.openshift-builder%5D%0Aactivation_annotation%20%3D%20%22io.openshift.builder%22%0Aallowed_annotations%20%3D%20%5B%0A%20%20%22io.kubernetes.cri-o.userns-mode%22%2C%0A%20%20%22io.kubernetes.cri-o.Devices%22%0A%5D%0A%5Bcrio.runtime.workloads.openshift-builder.resources%5D%0A%0A%5Bcrio.image%5D%0Aglobal_auth_file%20%3D%20%22%2Fvar%2Flib%2Fkubelet%2Fconfig.json%22%0Apause_image%20%3D%20%22quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A2f61599219ee63c77391e05d2e02a8a5baae1c463d0ef965c49a5c470546db90%22%0Apause_image_auth_file%20%3D%20%22%2Fvar%2Flib%2Fkubelet%2Fconfig.json%22%0Apause_command%20%3D%20%22%2Fusr%2Fbin%2Fpod%22%0A%0A%5Bcrio.network%5D%0Anetwork_dir%20%3D%20%22%2Fetc%2Fkubernetes%2Fcni%2Fnet.d%2F%22%0Aplugin_dirs%20%3D%20%5B%0A%20%20%20%20%22%2Fvar%2Flib%2Fcni%2Fbin%22%2C%0A%20%20%20%20%22%2Fusr%2Flibexec%2Fcni%22%2C%0A%5D%0A%0A%5Bcrio.metrics%5D%0Aenable_metrics%20%3D%20true%0Ametrics_host%20%3D%20%22127.0.0.1%22%0Ametrics_port%20%3D%209537%0Ametrics_collectors%20%3D%20%5B%0A%20%20%22operations%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22operations_total%22%0A%20%20%22operations_latency_microseconds_total%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22operations_latency_seconds_total%22%0A%20%20%22operations_latency_microseconds%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22operations_latency_seconds%22%0A%20%20%22operations_errors%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22operations_errors_total%22%0A%20%20%22image_pulls_layer_size%22%2C%0A%20%20%22containers_oom_total%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22containers_oom_count_total%22%0A%20%20%22containers_oom%22%2C%0A%20%20%23%20Drop%20metrics%20with%20excessive%20label%20cardinality.%0A%20%20%23%20%22image_pulls_by_digest%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_pulls_bytes_total%22%0A%20%20%23%20%22image_pulls_by_name%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_pulls_bytes_total%22%0A%20%20%23%20%22image_pulls_by_name_skipped%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_pulls_skipped_bytes_total%22%0A%20%20%23%20%22image_pulls_failures%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_pulls_failure_total%22%0A%20%20%23%20%22image_pulls_successes%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_pulls_success_total%22%0A%20%20%23%20%22image_layer_reuse%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_layer_reuse_total%22%0A%20%20%22operations_total%22%2C%0A%20%20%22operations_latency_seconds_total%22%2C%0A%20%20%22operations_latency_seconds%22%2C%0A%20%20%22operations_errors_total%22%2C%0A%20%20%22image_pulls_bytes_total%22%2C%0A%20%20%22image_pulls_skipped_bytes_total%22%2C%0A%20%20%22image_pulls_success_total%22%2C%0A%20%20%22image_pulls_failure_total%22%2C%0A%20%20%22image_layer_reuse_total%22%2C%0A%20%20%22containers_oom_count_total%22%2C%0A%20%20%22processes_defunct%22%0A%5D%0A
          mode: 420
          overwrite: true
          path: /etc/crio/crio.conf.d/00-default
        - contents:
            source: data:,%7B%0A%20%20%20%20%22default%22%3A%20%5B%0A%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%22type%22%3A%20%22insecureAcceptAnything%22%0A%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%5D%2C%0A%20%20%20%20%22transports%22%3A%0A%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%22docker-daemon%22%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22%22%3A%20%5B%7B%22type%22%3A%22insecureAcceptAnything%22%7D%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20%20%20%7D%0A%7D%0A
          mode: 420
          overwrite: true
          path: /etc/machine-config-daemon/policy-for-old-podman.json
        - contents:
            source: data:,%7B%0A%20%20%20%20%22default%22%3A%20%5B%0A%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%22type%22%3A%20%22insecureAcceptAnything%22%0A%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%5D%2C%0A%20%20%20%20%22transports%22%3A%0A%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%22docker-daemon%22%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22%22%3A%20%5B%7B%22type%22%3A%22insecureAcceptAnything%22%7D%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20%20%20%7D%0A%7D
          mode: 420
          overwrite: true
          path: /etc/containers/policy.json
        - contents:
            source: data:,
          mode: 420
          overwrite: true
          path: /etc/kubernetes/cloud.conf
        - contents:
            source: data:,authorization%3A%0A%20%20static%3A%0A%20%20%20%20-%20resourceRequest%3A%20false%0A%20%20%20%20%20%20path%3A%20%2Fmetrics%0A%20%20%20%20%20%20verb%3A%20get%0A%20%20%20%20%20%20user%3A%0A%20%20%20%20%20%20%20%20name%3A%20system%3Aserviceaccount%3Aopenshift-monitoring%3Aprometheus-k8s
          mode: 420
          overwrite: true
          path: /etc/kubernetes/crio-metrics-proxy.cfg
        - contents:
            source: data:,apiVersion%3A%20v1%0Akind%3A%20Pod%0Ametadata%3A%0A%20%20name%3A%20kube-rbac-proxy-crio%0A%20%20namespace%3A%20openshift-machine-config-operator%0A%20%20annotations%3A%0A%20%20%20%20target.workload.openshift.io%2Fmanagement%3A%20'%7B%22effect%22%3A%20%22PreferredDuringScheduling%22%7D'%0A%20%20%20%20openshift.io%2Frequired-scc%3A%20privileged%0Aspec%3A%0A%20%20volumes%3A%0A%20%20-%20name%3A%20etc-kube%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fetc%2Fkubernetes%22%0A%20%20-%20name%3A%20var-lib-kubelet%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20hostNetwork%3A%20true%0A%20%20priorityClassName%3A%20system-cluster-critical%0A%20%20initContainers%3A%0A%20%20-%20name%3A%20setup%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3Ab6413e64e7d5885315b3cabc65c2af82135ee649b1664976b3d300884d302414%0A%20%20%20%20imagePullPolicy%3A%20IfNotPresent%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20var-lib-kubelet%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20command%3A%20%5B'%2Fbin%2Fbash'%2C%20'-ec'%5D%0A%20%20%20%20args%3A%0A%20%20%20%20-%20%7C%0A%20%20%20%20%20%20echo%20-n%20%22Waiting%20for%20kubelet%20key%20and%20certificate%20to%20be%20available%22%0A%20%20%20%20%20%20while%20%5B%20-n%20%22%24(test%20-e%20%2Fvar%2Flib%2Fkubelet%2Fpki%2Fkubelet-server-current.pem)%22%20%5D%20%3B%20do%0A%20%20%20%20%20%20%20%20echo%20-n%20%22.%22%0A%20%20%20%20%20%20%20%20sleep%201%0A%20%20%20%20%20%20%20%20((%20tries%20%2B%3D%201%20))%0A%20%20%20%20%20%20%20%20if%20%5B%5B%20%22%24%7Btries%7D%22%20-gt%2010%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20echo%20%22Timed%20out%20waiting%20for%20kubelet%20key%20and%20cert.%22%0A%20%20%20%20%20%20%20%20%20%20exit%201%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20done%0A%20%20%20%20securityContext%3A%0A%20%20%20%20%20%20privileged%3A%20true%0A%20%20%20%20resources%3A%0A%20%20%20%20%20%20requests%3A%0A%20%20%20%20%20%20%20%20memory%3A%2050Mi%0A%20%20%20%20%20%20%20%20cpu%3A%205m%0A%20%20containers%3A%0A%20%20-%20name%3A%20kube-rbac-proxy-crio%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3Ab6413e64e7d5885315b3cabc65c2af82135ee649b1664976b3d300884d302414%0A%20%20%20%20securityContext%3A%0A%20%20%20%20%20%20privileged%3A%20true%0A%20%20%20%20ports%3A%0A%20%20%20%20-%20containerPort%3A%209637%0A%20%20%20%20args%3A%0A%20%20%20%20-%20--secure-listen-address%3D%3A9637%0A%20%20%20%20-%20--config-file%3D%2Fetc%2Fkubernetes%2Fcrio-metrics-proxy.cfg%0A%20%20%20%20-%20--client-ca-file%3D%2Fetc%2Fkubernetes%2Fkubelet-ca.crt%0A%20%20%20%20-%20--logtostderr%3Dtrue%0A%20%20%20%20-%20--kubeconfig%3D%2Fvar%2Flib%2Fkubelet%2Fkubeconfig%0A%20%20%20%20-%20--tls-cipher-suites%3DTLS_AES_128_GCM_SHA256%2CTLS_AES_256_GCM_SHA384%2CTLS_CHACHA20_POLY1305_SHA256%2CTLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256%2CTLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256%2CTLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384%2CTLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384%2CTLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256%2CTLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256%20%0A%20%20%20%20-%20--tls-min-version%3DVersionTLS12%0A%20%20%20%20-%20--upstream%3Dhttp%3A%2F%2F127.0.0.1%3A9537%0A%20%20%20%20-%20--tls-cert-file%3D%2Fvar%2Flib%2Fkubelet%2Fpki%2Fkubelet-server-current.pem%0A%20%20%20%20-%20--tls-private-key-file%3D%2Fvar%2Flib%2Fkubelet%2Fpki%2Fkubelet-server-current.pem%0A%20%20%20%20resources%3A%0A%20%20%20%20%20%20requests%3A%0A%20%20%20%20%20%20%20%20cpu%3A%2020m%0A%20%20%20%20%20%20%20%20memory%3A%2050Mi%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20etc-kube%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fkubernetes%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20%20%20readOnly%3A%20true%0A%20%20%20%20-%20name%3A%20var-lib-kubelet%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20%20%20readOnly%3A%20true
          mode: 420
          overwrite: true
          path: /etc/kubernetes/manifests/criometricsproxy.yaml
        - contents:
            compression: ""
            source: data:text/plain;charset=utf-8;base64,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
          mode: 420
          overwrite: true
          path: /etc/kubernetes/kubelet.conf
        - contents:
            source: data:,%23!%2Fbin%2Fsh%0Aif%20%5B%20-x%20%2Fusr%2Fbin%2Fkubensenter%20%5D%3B%20then%0A%20%20exec%20%2Fusr%2Fbin%2Fkubensenter%20%22%24%40%22%0Aelse%0A%20%20exec%20%22%24%40%22%0Afi%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/kubenswrapper
        - contents:
            source: data:text/plain;charset=utf-8;base64,CnBvb2wgMC5yaGVsLnBvb2wubnRwLm9yZyBpYnVyc3QKZHJpZnRmaWxlIC92YXIvbGliL2Nocm9ueS9kcmlmdAptYWtlc3RlcCAxLjAgMwpydGNzeW5jCmxvZ2RpciAvdmFyL2xvZy9jaHJvbnkKc2VydmVyIDc0LjIwOC4yNS40NiBpYnVyc3QKc2VydmVyIHRpbWUubG10bGFicy5jb20gaWJ1cnN0CnNlcnZlciBsaXRoaXVtLmNvbnN0YW50LmNvbSBpYnVyc3QKc2VydmVyIDY5LjE3Ni44NC4zOCBpYnVyc3QKc2VydmVyIGFybTEubWF4aG9zdC5pbyBpYnVyc3QKc2VydmVyIG50cDEubGF4LnVzLmhvam1hcmsubmV0IGlidXJzdApzZXJ2ZXIgbnRwMTEua2VybmZ1c2lvbi5hdCBpYnVyc3QKc2VydmVyIHRyaWFuZ2xlLmthbnNhcy5uZXQgaWJ1cnN0
          mode: 420
          overwrite: true
          path: /etc/chrony.conf
      systemd:
        units:
        - contents: |
            [Unit]
            Description=Cleans NetworkManager state generated by dracut
            # Removal of this file signals firstboot completion
            ConditionPathExists=!/etc/ignition-machine-config-encapsulated.json
            # This is opt-in for some deployment types, and opt-out for others.
            ConditionPathExists=/var/lib/mco/nm-clean-initrd-state
            Wants=network-pre.target
            Before=network-pre.target

            [Service]
            Type=oneshot
            # Remove any existing state possibly generated NM run by dracut. We want NM to
            # consider all profiles autoconnect priority when it starts instead of
            # remembering which profile was a device activated with when NM is run by
            # dracut.
            ExecStart=/usr/local/bin/nm-clean-initrd-state.sh
            StandardOutput=journal+console
            StandardError=journal+console

            [Install]
            WantedBy=network-online.target
          enabled: true
          name: NetworkManager-clean-initrd-state.service
        - dropins:
          - contents: |
              # vim:set ft=systemd :
              #
              # This drop-in will enable any service built with this
              # github.com/containers/kubemntns library to properly join the mount namespace
              # managed by kubens.service
              #

              [Unit]
              After=kubens.service

              [Service]
              EnvironmentFile=-/run/kubens/env
            name: 01-kubens.conf
          - contents: ""
            name: 10-mco-default-env.conf
          - contents: |
              [Service]
              Environment="ENABLE_PROFILE_UNIX_SOCKET=true"
            name: 10-mco-profile-unix-socket.conf
          - contents: |
              [Unit]
              After=kubelet-dependencies.target
              Requires=kubelet-dependencies.target
            name: 05-mco-ordering.conf
          - contents: |
              [Service]
              Environment="GODEBUG=x509ignoreCN=0,madvdontneed=1"
            name: 10-mco-default-madv.conf
          name: crio.service
        - dropins:
          - contents: |
              [Unit]
              ConditionPathExists=/enoent
            name: mco-disabled.conf
          name: docker.socket
        - contents: |
            [Unit]
            Description=The firstboot OS update has completed
            Documentation=https://github.com/openshift/machine-config-operator/
            Requires=basic.target

            [Install]
            WantedBy=default.target
          enabled: true
          name: firstboot-osupdate.target
        - dropins:
          - contents: |
              [Unit]
              After=ovs-configuration.service
              Before=crio.service
            name: 01-after-configure-ovs.conf
          name: ipsec.service
        - contents: |
            [Unit]
            Description=Dynamically sets the system reserved for the kubelet
            Wants=network-online.target
            After=network-online.target firstboot-osupdate.target
            Before=kubelet-dependencies.target

            [Service]
            # Need oneshot to delay kubelet
            Type=oneshot
            RemainAfterExit=yes
            EnvironmentFile=/etc/node-sizing-enabled.env
            ExecStart=/bin/bash /usr/local/sbin/dynamic-system-reserved-calc.sh ${NODE_SIZING_ENABLED} ${SYSTEM_RESERVED_MEMORY} ${SYSTEM_RESERVED_CPU} ${SYSTEM_RESERVED_ES}
            [Install]
            RequiredBy=kubelet-dependencies.target
          enabled: true
          name: kubelet-auto-node-size.service
        - contents: |
            [Unit]
            Description=Dependencies necessary to run kubelet
            Documentation=https://github.com/openshift/machine-config-operator/
            Requires=basic.target network-online.target
            Wants=NetworkManager-wait-online.service crio-wipe.service
            Wants=rpc-statd.service chrony-wait.service
          name: kubelet-dependencies.target
        - contents: |
            [Unit]
            Description=Kubernetes Kubelet
            Requires=crio.service kubelet-dependencies.target
            After=kubelet-dependencies.target
            After=ostree-finalize-staged.service

            [Service]
            Type=notify
            ExecStartPre=/bin/mkdir --parents /etc/kubernetes/manifests
            ExecStartPre=-/usr/sbin/restorecon -ri /var/lib/kubelet/pod-resources /usr/local/bin/kubenswrapper /usr/bin/kubensenter
            Environment="KUBELET_NODE_IP=0.0.0.0"
            EnvironmentFile=/etc/os-release
            EnvironmentFile=-/etc/kubernetes/kubelet-workaround
            EnvironmentFile=-/etc/kubernetes/kubelet-env
            EnvironmentFile=/etc/node-sizing.env

            ExecStart=/usr/local/bin/kubenswrapper \
                /usr/bin/kubelet \
                  --config=/etc/kubernetes/kubelet.conf \
                  --bootstrap-kubeconfig=/etc/kubernetes/kubeconfig \
                  --kubeconfig=/var/lib/kubelet/kubeconfig \
                  --container-runtime-endpoint=/var/run/crio/crio.sock \
                  --runtime-cgroups=/system.slice/crio.service \
                  --node-labels=node-role.kubernetes.io/control-plane,node-role.kubernetes.io/master,node.openshift.io/os_id=${ID} \
                  --node-ip=${KUBELET_NODE_IP} \
                  --address=${KUBELET_NODE_IP} \
                  --minimum-container-ttl-duration=6m0s \
                  --cloud-provider= \
                  --volume-plugin-dir=/etc/kubernetes/kubelet-plugins/volume/exec \
                  --hostname-override=${KUBELET_NODE_NAME} \
                  --register-with-taints=node-role.kubernetes.io/master=:NoSchedule \
                  --pod-infra-container-image=quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:2f61599219ee63c77391e05d2e02a8a5baae1c463d0ef965c49a5c470546db90 \
                  --system-reserved=cpu=${SYSTEM_RESERVED_CPU},memory=${SYSTEM_RESERVED_MEMORY},ephemeral-storage=${SYSTEM_RESERVED_ES} \
                  --v=${KUBELET_LOG_LEVEL}

            Restart=always
            RestartSec=10

            [Install]
            WantedBy=multi-user.target
          dropins:
          - contents: |
              # vim:set ft=systemd :
              #
              # This drop-in will enable any service built with this
              # github.com/containers/kubemntns library to properly join the mount namespace
              # managed by kubens.service
              #

              [Unit]
              After=kubens.service

              [Service]
              EnvironmentFile=-/run/kubens/env
            name: 01-kubens.conf
          - contents: ""
            name: 10-mco-default-env.conf
          - contents: |
              [Service]
              # Wait for resolv-prepender to configure nameservers, exit 255 otherwise
              # to mark the unit as failed and retry later
              ExecCondition=/bin/bash -c '[ -f /run/resolv-prepender-kni-conf-done ] || { echo "NM resolv-prepender failed"; exit 255; }'
            name: 10-mco-on-prem-wait-resolv.conf
          - contents: |
              [Service]
              Environment="GODEBUG=x509ignoreCN=0,madvdontneed=1"
            name: 10-mco-default-madv.conf
          enabled: true
          name: kubelet.service
        - contents: |
            [Unit]
            Description=Manages a mount namespace for kubernetes-specific mounts

            [Service]
            Type=oneshot
            RemainAfterExit=yes
            RuntimeDirectory=kubens
            Environment=RUNTIME_DIRECTORY=%t/kubens
            Environment=BIND_POINT=%t/kubens/mnt
            Environment=ENVFILE=%t/kubens/env

            # Set up the runtime directory as an unbindable mountpoint
            ExecStartPre=bash -c "findmnt ${RUNTIME_DIRECTORY} || mount --make-unbindable --bind ${RUNTIME_DIRECTORY} ${RUNTIME_DIRECTORY}"
            # Ensure the bind point exists
            ExecStartPre=touch ${BIND_POINT}
            # Use 'unshare' to create the new mountpoint, then 'mount --make-rshared' so it cascades internally
            ExecStart=unshare --mount=${BIND_POINT} --propagation slave mount --make-rshared /
            # Finally, set an env pointer for ease-of-use
            ExecStartPost=bash -c 'echo "KUBENSMNT=${BIND_POINT}" > "${ENVFILE}"'

            # On stop, a recursive unmount cleans up the namespace and bind-mounted unbindable parent directory
            ExecStop=umount -R ${RUNTIME_DIRECTORY}

            [Install]
            WantedBy=multi-user.target
          enabled: false
          name: kubens.service
        - contents: |
            [Unit]
            Description=Machine Config Daemon Firstboot
            # Make sure it runs only on OSTree booted system
            ConditionPathExists=/run/ostree-booted
            # Removal of this file signals firstboot completion
            ConditionPathExists=/etc/ignition-machine-config-encapsulated.json
            After=machine-config-daemon-pull.service
            Before=kubelet-dependencies.target

            [Service]
            Type=oneshot
            RemainAfterExit=yes
            # Disable existing repos (if any) so that OS extensions would use embedded RPMs only
            ExecStartPre=-/usr/bin/sh -c "sed -i 's/enabled=1/enabled=0/' /etc/yum.repos.d/*.repo"
            # Run this via podman because we want to use the nmstatectl binary in our container
            ExecStart=/usr/bin/podman run --rm --privileged --net=host -v /:/rootfs  --entrypoint machine-config-daemon 'quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:94bac6c3782cf6579032c7c9dabca74146753d9a44591125acd30d606d7d340c' firstboot-complete-machineconfig --persist-nics
            ExecStart=/usr/bin/podman run --rm --privileged --pid=host --net=host -v /:/rootfs  --entrypoint machine-config-daemon 'quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:94bac6c3782cf6579032c7c9dabca74146753d9a44591125acd30d606d7d340c' firstboot-complete-machineconfig
            [Install]
            RequiredBy=firstboot-osupdate.target
          enabled: true
          name: machine-config-daemon-firstboot.service
        - contents: |
            [Unit]
            Description=Machine Config Daemon Pull
            # Make sure it runs only on OSTree booted system
            ConditionPathExists=/run/ostree-booted
            # This "stamp file" is unlinked when we complete
            # machine-config-daemon-firstboot.service
            ConditionPathExists=/etc/ignition-machine-config-encapsulated.json
            # Run after crio-wipe so the pulled MCD image is protected against a corrupted storage from a forced shutdown
            Wants=crio-wipe.service NetworkManager-wait-online.service
            After=crio-wipe.service NetworkManager-wait-online.service network.service

            [Service]
            Type=oneshot
            RemainAfterExit=yes
            ExecStartPre=/etc/machine-config-daemon/generate_podman_policy_args.sh
            ExecStart=/bin/sh -c "while ! /usr/bin/podman pull $(cat /tmp/podman_policy_args) --authfile=/var/lib/kubelet/config.json 'quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:94bac6c3782cf6579032c7c9dabca74146753d9a44591125acd30d606d7d340c'; do sleep 1; done"

            [Install]
            RequiredBy=machine-config-daemon-firstboot.service
          enabled: true
          name: machine-config-daemon-pull.service
        - contents: |
            [Unit]
            Description=Applies per-node NMState network configuration
            Requires=openvswitch.service
            Wants=NetworkManager-wait-online.service
            After=NetworkManager-wait-online.service openvswitch.service network.service nodeip-configuration.service
            Before=nmstate.service kubelet-dependencies.target ovs-configuration.service node-valid-hostname.service

            [Service]
            Type=oneshot
            # Would prefer to do Restart=on-failure instead of this bash retry loop, but
            # the version of systemd we have right now doesn't support it. It should be
            # available in systemd v244 and higher.
            ExecStart=/usr/local/bin/nmstate-configuration.sh
            StandardOutput=journal+console
            StandardError=journal+console

            [Install]
            WantedBy=network-online.target
          enabled: true
          name: nmstate-configuration.service
        - contents: |
            [Unit]
            Description=Apply nmstate on-disk state
            Documentation=man:nmstate.service(8) https://www.nmstate.io
            After=NetworkManager-wait-online.service
            Before=network-online.target
            Wants=NetworkManager-wait-online.service
            Requires=NetworkManager.service

            [Service]
            Type=oneshot
            ExecStart=/usr/bin/nmstatectl service
            RemainAfterExit=yes

            [Install]
            WantedBy=NetworkManager.service
          enabled: true
          name: nmstate.service
        - contents: |
            [Unit]
            Description=Wait for a non-localhost hostname
            Before=kubelet-dependencies.target

            [Service]
            Type=oneshot
            RemainAfterExit=yes
            User=root
            ExecStart=/usr/local/bin/mco-hostname --wait

            # Wait up to 5min for the node to get a non-localhost name
            TimeoutSec=300

            [Install]
            # TODO: Change this to RequiredBy after we fix https://github.com/openshift/machine-config-operator/pull/3865#issuecomment-1746963115
            WantedBy=kubelet-dependencies.target
          enabled: true
          name: node-valid-hostname.service
        - contents: |
            [Unit]
            Description=Writes IP address configuration so that kubelet and crio services select a valid node IP
            # This only applies to VIP managing environments where the kubelet and crio IP
            # address picking logic is flawed and may end up selecting an address from a
            # different subnet or a deprecated address
            Wants=NetworkManager-wait-online.service
            After=NetworkManager-wait-online.service firstboot-osupdate.target
            Before=kubelet-dependencies.target ovs-configuration.service

            [Service]
            # Need oneshot to delay kubelet
            Type=oneshot
            # Would prefer to do Restart=on-failure instead of this bash retry loop, but
            # the version of systemd we have right now doesn't support it. It should be
            # available in systemd v244 and higher.
            ExecStart=/bin/bash -c " \
              until \
              /usr/bin/podman run --rm \
              --authfile /var/lib/kubelet/config.json \
              --net=host \
              --security-opt label=disable \
              --volume /etc/systemd/system:/etc/systemd/system \
              --volume /run/nodeip-configuration:/run/nodeip-configuration \
              quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:93e7b8c870261726d44bddc7ba0a702d3720d1838141dac837fb8c3be7c6e1a1 \
              node-ip \
              set \
              --platform BareMetal \
              --retry-on-failure \
              ${NODEIP_HINT:-} \
              10.100.0.50  \
              10.100.0.51 ; \
              do \
              sleep 5; \
              done"
            ExecStart=/bin/systemctl daemon-reload
            ExecStartPre=/bin/mkdir -p /run/nodeip-configuration
            ExecStartPost=+/usr/local/bin/configure-ip-forwarding.sh
            StandardOutput=journal+console
            StandardError=journal+console
            EnvironmentFile=-/etc/default/nodeip-configuration

            [Install]
            RequiredBy=kubelet-dependencies.target
          enabled: true
          name: nodeip-configuration.service
        - contents: |
            [Unit]
            Description=Watches for changes in /var/run/NetworkManager/resolv.conf according to on-prem IPI needs
            [Path]
            PathModified=/var/run/NetworkManager/resolv.conf
            PathModified=/run/resolv-prepender/env
            Unit=on-prem-resolv-prepender.service
            [Install]
            WantedBy=multi-user.target
          enabled: true
          name: on-prem-resolv-prepender.path
        - contents: |
            [Unit]
            Description=Populates resolv.conf according to on-prem IPI needs
            # Per https://issues.redhat.com/browse/OCPBUGS-27162 there is a problem if this is started before crio-wipe
            After=crio-wipe.service
            StartLimitIntervalSec=0
            [Service]
            Type=oneshot
            # Would prefer to do Restart=on-failure instead of this bash retry loop, but
            # the version of systemd we have right now doesn't support it. It should be
            # available in systemd v244 and higher.
            ExecStart=/bin/bash -c " \
              until \
              /usr/local/bin/resolv-prepender.sh; \
              do \
              sleep 10; \
              done"
            EnvironmentFile=-/run/resolv-prepender/env
          enabled: false
          name: on-prem-resolv-prepender.service
        - enabled: true
          name: openvswitch.service
        - contents: |
            [Unit]
            # Kdump will generate it's initramfs based on the running state when kdump.service run
            # If OVS has already run, the kdump fails to gather a working network config,
            # which prevent network log exports, sush as SSH.
            # See https://issues.redhat.com/browse/OCPBUGS-28239
            After=kdump.service
            Description=Configures OVS with proper host networking configuration
            # This service is used to move a physical NIC into OVS and reconfigure OVS to use the host IP
            Requires=openvswitch.service
            Wants=NetworkManager-wait-online.service
            After=firstboot-osupdate.target
            After=NetworkManager-wait-online.service openvswitch.service network.service nodeip-configuration.service nmstate.service
            Before=kubelet-dependencies.target node-valid-hostname.service

            [Service]
            # Need oneshot to delay kubelet
            Type=oneshot
            ExecStart=/usr/local/bin/configure-ovs.sh OVNKubernetes
            StandardOutput=journal+console
            StandardError=journal+console

            [Install]
            RequiredBy=kubelet-dependencies.target
          enabled: true
          name: ovs-configuration.service
        - dropins:
          - contents: |
              [Service]
              Restart=always
              ExecStartPre=-/bin/sh -c '/usr/bin/chown -R :$${OVS_USER_ID##*:} /var/lib/openvswitch'
              ExecStartPre=-/bin/sh -c '/usr/bin/chown -R :$${OVS_USER_ID##*:} /etc/openvswitch'
              ExecStartPre=-/bin/sh -c '/usr/bin/chown -R :$${OVS_USER_ID##*:} /run/openvswitch'
              ExecStartPost=-/usr/bin/ovs-appctl vlog/set syslog:info
              ExecReload=-/usr/bin/ovs-appctl vlog/set syslog:info
            name: 10-ovs-vswitchd-restart.conf
          name: ovs-vswitchd.service
        - dropins:
          - contents: |
              [Service]
              Restart=always
            name: 10-ovsdb-restart.conf
          enabled: true
          name: ovsdb-server.service
        - dropins:
          - contents: ""
            name: 10-mco-default-env.conf
          - contents: |
              # See https://github.com/openshift/machine-config-operator/issues/1897
              [Service]
              Nice=10
              IOSchedulingClass=best-effort
              IOSchedulingPriority=6
            name: mco-controlplane-nice.conf
          name: rpm-ostreed.service
        - contents: |
            [Unit]
            Description=Wait for br-ex up event from NetworkManager
            Wants=ovs-configuration.service
            After=ovs-configuration.service
            Before=node-valid-hostname.service

            [Service]
            Type=oneshot
            ExecStart=/usr/local/bin/wait-for-br-ex-up.sh

            [Install]
            RequiredBy=node-valid-hostname.service
          enabled: true
          name: wait-for-br-ex-up.service
        - contents: |
            [Unit]
            Description=Ensure IKE SA established for existing IPsec connections.
            After=ipsec.service
            Before=kubelet-dependencies.target node-valid-hostname.service

            [Service]
            Type=oneshot
            ExecStart=/usr/local/bin/ipsec-connect-wait.sh
            StandardOutput=journal+console
            StandardError=journal+console

            [Install]
            WantedBy=ipsec.service
          enabled: true
          name: wait-for-ipsec-connect.service
        - contents: |
            [Unit]
            Description=Ensure primary IP is assigned and usable
            Requires=nmstate.service
            After=nmstate.service
            Before=kubelet-dependencies.target

            [Service]
            Type=oneshot
            # Would prefer to do Restart=on-failure instead of this bash retry loop, but
            # the version of systemd we have right now doesn't support it. It should be
            # available in systemd v244 and higher.
            ExecStart=/bin/bash -c " \
              until \
              /usr/local/bin/wait-for-primary-ip.sh; \
              do \
              sleep 10; \
              done"
            StandardOutput=journal+console
            StandardError=journal+console

            [Install]
            WantedBy=network-online.target
          enabled: true
          name: wait-for-primary-ip.service
        - dropins:
          - contents: |
              [Unit]
              ConditionPathExists=/enoent
            name: mco-disabled.conf
          name: zincati.service
        - contents: |
            [Unit]
            Description=Kubernetes Kubelet After Reboot Cleanup
            Before=kubelet.service

            [Service]
            Type=oneshot
            ExecStart=/bin/rm -f /var/lib/kubelet/cpu_manager_state
            ExecStart=/bin/rm -f /var/lib/kubelet/memory_manager_state
            ExecStart=-/bin/rm -f /var/lib/kubelet/dra_manager_state

            [Install]
            WantedBy=multi-user.target
          enabled: true
          name: kubelet-cleanup.service
    extensions: []
    fips: false
    kernelArguments:
    - schedstats=enable
    - systemd.unified_cgroup_hierarchy=1
    - cgroup_no_v1="all"
    - psi=0
    - psi=1
    kernelType: default
    osImageURL: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4e309dd906392e783a404b92dfd4fa4c32d74e2804ee37d1fb8a00c9355d5978
- apiVersion: machineconfiguration.openshift.io/v1
  kind: MachineConfig
  metadata:
    annotations:
      machineconfiguration.openshift.io/generated-by-controller-version: fcf8f254943cbcba1400ba55f3978cc292b6460b
      machineconfiguration.openshift.io/release-image-version: 4.18.26
    creationTimestamp: "2025-12-18T20:53:45Z"
    generation: 1
    name: rendered-master-75b612782c9b85e89669001a76df78c0
    ownerReferences:
    - apiVersion: machineconfiguration.openshift.io/v1
      blockOwnerDeletion: true
      controller: true
      kind: MachineConfigPool
      name: master
      uid: 94ee58c6-d020-4644-985a-6daad3eb3116
    resourceVersion: "54724210"
    uid: ff01dc22-6af6-4621-b2c2-04dea617668e
  spec:
    baseOSExtensionsContainerImage: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:7033f46996eddcbad8c8b8aeb18e601bdeef3d04bd7f79cd194db5e6346a7fc4
    config:
      ignition:
        version: 3.4.0
      passwd:
        users:
        - name: core
          sshAuthorizedKeys:
          - ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQD7F2mFgxGcyTmG/KTR+D0wnMAM1rlaaaqGMz5ueugnUjlWxtssJLq1TIQSwOdllxWgzJt9LXHQZNVqxpLk/imx7UqnRYohX+10WNtxRQ8O/HqMpdngMgYlBVHwmgsQeDle441kUv/NFAwLGpRK4zvNwxcUMu2z4sajxqxc0sGqvqpVYsOq7jnFbWELgRX+JyZmWGhGfdHwySraydgV0NtSEANksJO1H0220vnrpMnGtyyOkiqDi4LnT1iAs+VvqZl0EaPxOzCMPTVQqqeH19bBKKnbmQABRZxlI7o4vvRH8p/YXG301cCgfVXfdbFuU7OLiHDA73nd9zk+AyEm/8ssq9rSAzleFaP3I9RqNvK/YWLoC/DHwZeCGrvva/JpPdw3TY3eE9mVVlonz59SjSi3V8Go8bveYSUHm/2oGfCn9ziCH40htpYLllQZfSBqH0IF1BrsQ62o9LWwKyp1vrmlEiijQy5mClTOHbeC2EHSP04u8+v5EC8UA1Jh2f1kers=
            root@localhost.localdomain
          - ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQDaG45aoa4HpJ+V029gSYKSv5IenhVmZcJvicGrs+D0PgzzwNIGG52iK4r3YOoEYJn4nX80OHf4ob23avJ1ruDPR9inD1c+oiAk5BLRE7CNdU1mllWE0l6pYRHfpIuCOXC6iWpX1kXbVPJZk3ytVZOgff7LkaIIzbAjDjJ+N1MQSUmKvnioh8c6WtFfQNAZ2gFBCRWPLxcjHdyTYvy+oB0qR10WpQYHrGVB0LawtudQrO/8zHcfZJpI0uFwSAvYqspgiO3hPfuT0Fx8xzAb66AK/2vF/WrMOH3AbBu5S954B+xZI4apPJN/Yy5ENRVIoL7w9V5pV5FENtsSvQ+fpFat9yoVewvy5CMo8qJHrvAqlBJ9JriVX2mnigJRkshG0F+Z7BLZUjMcueSIIzasQ2igc8nbpfElSnTmoyweiMbFIXNJJwaV/tKbFkF3J7A3fz1qbfSQ7AIHAigoUf/CnCr+j+BQs1ZZMoWGQOPwFo00OBDICnP0Pc6wBr4iN6gnDFs=
            jnakamura@JNakamura-22
      storage:
        files:
        - contents:
            source: data:,%23%20This%20file%20signals%20NetworkManager-clean-initrd-state%20service%20to%20run%20on%0A%23%20boot.%20This%20service%20is%20used%20to%20clean%20up%20the%20network%20activation%20state%0A%23%20generated%20by%20dracut%20so%20that%20other%20network%20configuration%20deployed%20by%20the%0A%23%20user%20can%20be%20activated.%20This%20only%20happens%20if%20dracut%20activated%20a%20default%0A%23%20network%20configuration%20and%20there%20is%20an%20alternate%20configuration%20available%20in%0A%23%20the%20root%20filesystem.%20Otherwise%2C%20it%20is%20assumed%20that%20the%20network%0A%23%20configuration%20activated%20by%20dracut%20is%20the%20one%20that%20is%20intended%20to%20be%20used%0A%23%20throughout%20the%20life%20of%20the%20system.%0A%23%20Opt-out%20for%20baremetal%20IPI%20deplyments%2C%20opt-in%20otherwise.%0A
          mode: 493
          overwrite: true
          path: /var/lib/mco/nm-clean-initrd-state
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-ex%20-o%20pipefail%0A%0ANM_DEVICES_DIR%3D%2Frun%2FNetworkManager%2Fdevices%0ANM_RUN_CONN_DIR%3D%2Frun%2FNetworkManager%2Fsystem-connections%0ANM_ETC_CONN_DIR%3D%2Fetc%2FNetworkManager%2Fsystem-connections%0A%0Alogger%20-t%20nm-clean-initrd-state%20%22Cleaning%20network%20activation%20state%20generated%20by%20dracut...%22%0Alogger%20-t%20nm-clean-initrd-state%20%22To%20disable%2C%20remove%20%2Fvar%2Flib%2Fmco%2Fnm-clean-initrd-state%22%0A%0Aif%20%5B%20!%20-e%20%22%24NM_DEVICES_DIR%22%20%5D%20%7C%7C%20%5B%20!%20-e%20%22%24NM_RUN_CONN_DIR%22%20%5D%20%7C%7C%20%5B%20!%20-e%20%22%24NM_ETC_CONN_DIR%22%20%5D%3B%20then%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22There%20is%20no%20network%20activation%20state%20to%20clean%22%0A%20%20exit%0Afi%0A%0A%23%20Some%20deployments%20require%20an%20active%20network%20early%20in%20the%20boot%20process.%20To%0A%23%20achieve%20this%2C%20dracut%20runs%20specific%20NetworkManager%20modules.%20This%20results%20in%0A%23%20NetworkManager%20keyfiles%20being%20generated%20(either%20default%20or%20from%20ip%20kernel%0A%23%20arguments)%20and%20activated.%20This%20activation%20generates%20state%20that%20makes%20those%0A%23%20profiles%20to%20be%20re-activated%20by%20the%20NetworkManager%20service%20later%20in%20the%0A%23%20boot%20process.%20And%20this%20has%20the%20effect%20that%20other%20profiles%20deployed%20by%20the%0A%23%20user%20for%20the%20same%20set%20of%20devices%20are%20ignored.%0A%0A%23%20Most%20of%20the%20time%20this%20is%20the%20desired%20behavior.%20The%20exception%20to%20this%20rule%0A%23%20is%20when%20the%20user%20wants%20to%20run%20the%20boot%20process%20with%20a%20different%20network%0A%23%20setup%20than%20the%20real%20root%20which%20is%20usually%20related%20to%20the%20fact%20that%0A%23%20generating%20images%20with%20customized%20kernel%20arguments%20is%20a%20complication%20in%0A%23%20the%20deployment%20pipeline.%0A%0A%23%20This%20need%20has%20been%20exacerbated%20by%20past%20NetworkManager%20bugs%20that%20activated%0A%23%20the%20network%20on%20boot%20when%20it%20was%20not%20really%20needed.%20Most%20notably%20when%20ip%0A%23%20kernel%20argument%20is%20present%2C%20something%20that%20the%20baremetal%20installer%20adds%20by%0A%23%20default.%0A%0A%23%20The%20intention%20here%20is%20to%20remove%20the%20state%20that%20was%20generated%20with%20the%0A%23%20activation%20of%20those%20profiles%20during%20dracut%20execution.%20Then%20when%0A%23%20NetworkManager%20service%20runs%2C%20the%20profiles%20generated%20by%20dracut%2C%20along%20with%0A%23%20other%20profiles%20configured%20by%20the%20user%2C%20are%20evaluated%20towards%20finding%20the%0A%23%20most%20appropriate%20profile%20to%20connect%20a%20device%20with.%20As%20a%20precaution%2C%20clean%0A%23%20state%20only%20for%20devices%20that%3A%0A%23%20-%20have%20been%20activated%20with%20a%20default%20profile%20(assume%20that%20a%20non-default%0A%23%20%20%20configuration%20expresses%20intention%20by%20user%20to%20run%20with%20it%20permanently)%0A%23%20-%20have%20a%20specific%20configured%20profile%20set%20to%20auto-connect%20(if%20there%20is%20no%0A%23%20%20%20alternate%20configured%20profile%20for%20a%20device%20it%20makes%20no%20sense%20to%0A%23%20%20%20de-activate%20anything)%0A%23%0A%23%20Although%20this%20can%20theoretically%20happen%20on%20any%20deployment%20type%2C%20need%20has%0A%23%20mostly%20come%20from%20IPI%20bare%20metal%20deployments.%20For%20the%20time%20being%2C%20this%0A%23%20should%20be%20opt-in%20in%20any%20other%20deploment%20type.%0A%23%0A%23%20There%20is%20an%20RFE%20filed%20against%20NM%20that%20once%20implemented%20would%20make%20this%0A%23%20script%20unnecessary%3A%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D2089707%0A%0Afor%20device%20in%20%22%24%7BNM_DEVICES_DIR%7D%22%2F*%3B%20do%0A%20%20if%20%5B%20!%20-e%20%22%24device%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20the%20device%20file%20name%20is%20the%20ifindex%0A%20%20ifindex%3D%24(basename%20%22%24device%22)%0A%20%20%0A%20%20%23%20get%20the%20interface%20name%20by%20ifindex%0A%20%20ifname%3D%24(ip%20-j%20link%20show%20%7C%20jq%20-r%20%22.%5B%5D%20%7C%20select(.ifindex%20%3D%3D%20%24%7Bifindex%7D)%20%7C%20.ifname%20%2F%2F%20empty%22)%0A%0A%20%20%23%20no%20interface%20name%20found%2C%20ignore%0A%20%20if%20%5B%20-z%20%22%24ifname%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20get%20the%20uuid%20of%20the%20profile%20the%20device%20has%20been%20activated%20with%0A%20%20active_profile_uuid%3D%24(sed%20-nr%20'%2F%5E%5C%5Bdevice%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Econnection-uuid%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24device%22)%0A%0A%20%20%23%20the%20device%20was%20not%20activated%20with%20any%20profile%2C%20ignore%0A%20%20if%20%5B%20-z%20%22%24active_profile_uuid%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20find%20the%20generated%20profile%20by%20uuid%0A%20%20for%20profile%20in%20%22%24%7BNM_RUN_CONN_DIR%7D%22%2F*%3B%20do%0A%20%20%20%20generated_profile_uuid%3D%24(sed%20-nr%20'%2F%5E%5C%5Bconnection%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Euuid%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20%20%20if%20%5B%20%22%24active_profile_uuid%22%20%3D%20%22%24generated_profile_uuid%22%20%5D%3B%20then%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20done%0A%0A%20%20%23%20generated%20profile%20not%20found%2C%20ignore%0A%20%20if%20%5B%20%22%24active_profile_uuid%22%20!%3D%20%22%24generated_profile_uuid%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20check%20that%20it%20is%20not%20specific%20for%20the%20device%2C%20otherwise%20ignore%0A%20%20profile_ifname%3D%24(sed%20-nr%20'%2F%5E%5C%5Bconnection%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Einterface-name%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20if%20%5B%20-n%20%22%24profile_ifname%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20profile%20not%20generated%20by%20nm-initrd-generator%2C%20ignore%0A%20%20%23%20only%20check%20it%20if%20the%20key%20is%20set%20(from%20NM%201.32.4)%0A%20%20origin%3D%24(sed%20-nr%20'%2F%5E%5C%5Buser%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Eorg.freedesktop.NetworkManager.origin%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20if%20%5B%20-n%20%22%24origin%22%20%5D%20%26%26%20%5B%20%22%24origin%22%20!%3D%20%22nm-initrd-generator%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20find%20the%20configured%20profile%20by%20name%20with%20auto-connect%20set%0A%20%20for%20profile%20in%20%22%24%7BNM_ETC_CONN_DIR%7D%22%2F*%3B%20do%0A%20%20%20%20profile_ifname%3D%24(sed%20-nr%20'%2F%5E%5C%5Bconnection%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Einterface-name%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20%20%20autoconnect%3D%24(sed%20-nr%20'%2F%5E%5C%5Bconnection%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Eautoconnect%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20%20%20if%20%5B%20%22%24profile_ifname%22%20%3D%20%22%24ifname%22%20%5D%20%26%26%20%5B%20%22%24autoconnect%22%20!%3D%20%22false%22%20%5D%3B%20then%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20done%0A%0A%20%20%23%20configured%20profile%20not%20found%2C%20ignore%0A%20%20if%20%5B%20%22%24profile_ifname%22%20!%3D%20%22%24ifname%22%20%5D%20%7C%7C%20%5B%20%22%24autoconnect%22%20%3D%20%22false%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20configured_profile_uuid%3D%24(sed%20-nr%20'%2F%5E%5C%5Bconnection%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Euuid%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22%24ifname%20activated%20with%20default%20generated%20profile%20%24generated_profile_uuid%22%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22%24ifname%20has%20different%20configured%20specific%20profile%20%24configured_profile_uuid%22%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22%24ifname%3A%20removing%20state...%22%0A%20%20%0A%20%20%23%20NM%20can%20still%20generate%20internal%20profiles%20from%20the%20IP%20address%0A%20%20%23%20configuration%20of%20devices%2C%20so%20flush%20addresses%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22Flushing%20IP%20addresses%20from%20%24ifname%22%0A%20%20ip%20addr%20flush%20%22%24ifname%22%0A%20%20ip%20-6%20addr%20flush%20%22%24ifname%22%0A%0A%20%20%23%20remove%20device%20state%20file%20to%20prevent%20NM%20to%20unilaterally%20connect%20with%20the%0A%20%20%23%20latest%20activated%20profile%20without%20evaluating%20other%20profiles%20%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22Removing%20%24device%22%0A%20%20rm%20-f%20--%20%22%24device%22%0A%0Adone%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/nm-clean-initrd-state.sh
        - contents:
            source: data:,%5Bconnection%5D%0Aipv6.dhcp-duid%3Dll%0Aipv6.dhcp-iaid%3Dmac%0A
          mode: 420
          overwrite: true
          path: /etc/NetworkManager/conf.d/01-ipv6.conf
        - contents:
            source: data:,%5Bmain%5D%0Aplugins%3Dkeyfile%2Cifcfg-rh%0A%5Bkeyfile%5D%0Apath%3D%2Fetc%2FNetworkManager%2Fsystem-connections%0A
          mode: 420
          overwrite: true
          path: /etc/NetworkManager/conf.d/20-keyfiles.conf
        - contents:
            source: data:,%5Bmain%5D%0Arc-manager%3Dunmanaged%0A
          mode: 420
          overwrite: true
          path: /etc/NetworkManager/conf.d/99-kni.conf
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-eo%20pipefail%0AIFACE%3D%241%0ASTATUS%3D%242%0A%0Afunction%20resolv_prepender%20%7B%0A%20%20mkdir%20-p%20%2Frun%2Fresolv-prepender%0A%20%20echo%20%22IP4_DOMAINS%3D%24IP4_DOMAINS%22%20%3E%20%2Frun%2Fresolv-prepender%2Fenv.new%0A%20%20echo%20%22IP6_DOMAINS%3D%24IP6_DOMAINS%22%20%3E%3E%20%2Frun%2Fresolv-prepender%2Fenv.new%0A%0A%20%20if%20!%20diff%20-q%20%2Frun%2Fresolv-prepender%2Fenv%20%2Frun%2Fresolv-prepender%2Fenv.new%3B%20then%0A%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Environment%20variable(s)%20changed.%20Systemd%20path%20unit%20will%20pick%20the%20change.%22%0A%20%20%20%20mv%20-f%20%2Frun%2Fresolv-prepender%2Fenv.new%20%2Frun%2Fresolv-prepender%2Fenv%0A%20%20fi%0A%7D%0A%0Aexport%20IP4_DOMAINS%20IP6_DOMAINS%0Aexport%20-f%20resolv_prepender%0A%0A%23%20For%20RHEL8%20with%20NetworkManager%20%3E%3D%201.36%20and%20RHEL9%20with%20NetworkManager%20%3E%3D1.42%20we%20can%20use%20simplified%20logic%0A%23%20of%20observing%20only%20a%20single%20%22dns-change%22%20event.%20Older%20version%20of%20NetworkManager%20require%20however%20that%20we%0A%23%20react%20on%20a%20set%20of%20multiple%20events.%20Once%20dns-change%20event%20is%20detected%20we%20create%20a%20flag%20file%20to%20ignore%0A%23%20subsequent%20up%26co.%20events%20as%20undesired.%0A%23%0A%23%20Given%20an%20overall%20Network%20Manager%20dispatcher%20timeout%20of%2090%20seconds%2C%20we%20are%20enforcing%20a%20slightly%20shorter%0A%23%20timeout%20for%20the%20observed%20events.%20It%20is%20not%20really%20required%20because%20all%20we%20do%20in%20this%20function%20is%20to%20write%20a%20file.%0A%23%20We%20could%20get%20rid%20of%20this%20timeout%20completely%2C%20but%20it%20also%20does%20not%20cost%20much%20to%20keep%20it.%0Acase%20%22%24STATUS%22%20in%0A%20%20dns-change)%0A%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%20triggered%20by%20%24%7BIFACE%7D%20%24%7BSTATUS%7D.%22%0A%20%20%20%20if%20%5B%20!%20-f%20%22%2Frun%2Fnetworkmanager-dns-event-detected%22%20%5D%3B%20then%0A%20%20%20%20%20%20touch%20%2Frun%2Fnetworkmanager-dns-event-detected%0A%20%20%20%20fi%0A%20%20%20%20if%20!%20timeout%2060s%20bash%20-c%20resolv_prepender%3B%20then%0A%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Timeout%20occurred%22%0A%20%20%20%20%20%20exit%201%0A%20%20%20%20fi%0A%20%20%3B%3B%0A%0A%20%20up%7Cdhcp4-change%7Cdhcp6-change%7Creapply)%0A%20%20%20%20if%20%5B%20!%20-f%20%22%2Frun%2Fnetworkmanager-dns-event-detected%22%20%5D%3B%20then%0A%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%20triggered%20by%20%24%7BIFACE%7D%20%24%7BSTATUS%7D.%22%0A%20%20%20%20%20%20if%20!%20timeout%2030s%20bash%20-c%20resolv_prepender%3B%20then%0A%20%20%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Timeout%20occurred%22%0A%20%20%20%20%20%20%20%20exit%201%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20If%20%24DHCP6_FQDN_FQDN%20is%20not%20empty%20and%20is%20not%20localhost.localdomain%20and%20static%20hostname%20was%20not%20already%20set%0A%20%20%20%20if%20%5B%5B%20-n%20%22%24DHCP6_FQDN_FQDN%22%20%26%26%20%22%24DHCP6_FQDN_FQDN%22%20!%3D%20%22localhost.localdomain%22%20%26%26%20%22%24DHCP6_FQDN_FQDN%22%20%3D~%20%22.%22%20%5D%5D%20%3B%20then%0A%20%20%20%20%20%20%20STATIC_HOSTNAME%3D%22%24(test%20!%20-e%20%2Fetc%2Fhostname%20%26%26%20echo%20-n%20%7C%7C%20cat%20%2Fetc%2Fhostname%20%7C%20xargs)%22%0A%0A%20%20%20%20%20%20%20if%20%5B%5B%20-z%20%22%24STATIC_HOSTNAME%22%20%7C%7C%20%22%24STATIC_HOSTNAME%22%20%3D%3D%20%22localhost.localdomain%22%20%5D%5D%20%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%23%20run%20with%20systemd-run%20to%20avoid%20selinux%20problems%0A%20%20%20%20%20%20%20%20%20%20systemd-run%20--property%3DType%3Doneshot%20--unit%20resolve-prepender-hostnamectl%20-Pq%20%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20hostnamectl%20set-hostname%20--static%20--transient%20%24DHCP6_FQDN_FQDN%0A%20%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20if%20%5B%5B%20%22%24STATUS%22%20%3D%3D%20%22up%22%20%5D%5D%20%26%26%20%5B%5B%20%24IFACE%20%3D%3D%20%22br-ex%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20%2Fbin%2Fmkdir%20-p%20%2Frun%2Fnodeip-configuration%0A%20%20%20%20%20%20%20%20touch%20%2Frun%2Fnodeip-configuration%2Fbr-ex-up%0A%20%20%20%20fi%0A%20%20%3B%3B%0A%20%20*)%0A%20%20%3B%3B%0Aesac%0A
          mode: 493
          overwrite: true
          path: /etc/NetworkManager/dispatcher.d/30-resolv-prepender
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-ex%20-o%20pipefail%0A%0Aif%20%5B%5B%20%22OVNKubernetes%22%20%3D%3D%20%22OVNKubernetes%22%20%26%26%20%22%24CONNECTION_ID%22%20%3D%3D%20%22Wired%20Connection%22%20%5D%5D%0Athen%0A%20%20%20%20%3E%262%20echo%20%22Refusing%20to%20modify%20default%20connection.%22%0A%20%20%20%20exit%200%0Afi%0A%0Aif%20%5B%20-z%20%24%7BDHCP4_IP_ADDRESS%3A-%7D%20%5D%0Athen%0A%20%20%20%20%3E%262%20echo%20%22Not%20a%20DHCP4%20address.%20Ignoring.%22%0A%20%20%20%20exit%200%0Afi%0A%0Aif%20%5B%20%24%7BDHCP4_DHCP_LEASE_TIME%3A-0%7D%20-lt%204294967295%20%5D%0Athen%0A%20%20%20%20%3E%262%20echo%20%22Not%20an%20infinite%20DHCP4%20lease.%20Ignoring.%22%0A%20%20%20%20exit%200%0Afi%0A%0AIPS%3D(%24IP4_ADDRESS_0)%0ACIDR%3D%24%7BIPS%5B0%5D%7D%0AGATEWAY%3D%24%7BIPS%5B1%5D%7D%0A%0ATYPE%3D%24(nmcli%20--get-values%20connection.type%20connection%20show%20%22%24CONNECTION_ID%22)%0A%0A%23%20Modifying%20the%20default%20connection%20id%20directly%20doesn't%20do%20what%20we%20want.%0A%23%20If%20we%20see%20that%2C%20then%20we%20need%20to%20create%20a%20new%20connection.%0Aif%20%5B%20%22%24CONNECTION_ID%22%20%3D%3D%20%22Wired%20Connection%22%20%5D%0Athen%0A%20%20%20%20if%20!%20nmcli%20con%20show%20inf-lease-to-static%0A%20%20%20%20then%0A%20%20%20%20%20%20%20%20nmcli%20con%20add%20type%20%22%24TYPE%22%20con-name%20inf-lease-to-static%0A%20%20%20%20fi%0A%20%20%20%20STATIC_INT_NAME%3Dinf-lease-to-static%0Aelse%0A%20%20%20%20STATIC_INT_NAME%3D%22%24CONNECTION_ID%22%0Afi%0Anmcli%20con%20mod%20%22%24STATIC_INT_NAME%22%20%5C%0A%20%20conn.interface%20%22%241%22%20%5C%0A%20%20connection.autoconnect%20yes%20%5C%0A%20%20ipv4.addresses%20%22%24CIDR%22%20%5C%0A%20%20ipv4.method%20manual%20%5C%0A%20%20ipv4.gateway%20%22%24GATEWAY%22%20%5C%0A%20%20ipv4.dns%20%22%24IP4_NAMESERVERS%22%0A%0Aif%20%5B%20-n%20%22%24IP4_DOMAINS%22%20%5D%3B%20then%0A%20%20%20%20nmcli%20con%20mod%20%22%24STATIC_INT_NAME%22%20ipv4.dns-search%20%22%24IP4_DOMAINS%22%0Afi%0Aplus%3D''%0Afor%20i%20in%20%24(seq%200%20%24((%24IP4_NUM_ROUTES-1))%20)%0Ado%0A%20%20%20%20varname%3D%22IP4_ROUTE_%24i%22%0A%20%20%20%20nmcli%20con%20mod%20%22%24STATIC_INT_NAME%22%20%24%7Bplus%7Dipv4.routes%20%22%24%7B!varname%7D%22%0A%20%20%20%20plus%3D'%2B'%0Adone%0A%0Anmcli%20con%20up%20%22%24STATIC_INT_NAME%22%0A%0Aif%20%5B%20-n%20%22%24%7BDHCP4_HOST_NAME%3A-%7D%22%20%5D%0Athen%0A%20%20%20%20systemd-run%20--property%3DType%3Doneshot%20--unit%20static-dhcp-hostnamectl%20-Pq%20%5C%0A%20%20%20%20%20%20hostnamectl%20set-hostname%20--static%20--transient%20%22%24DHCP4_HOST_NAME%22%0Afi%0A
          mode: 493
          overwrite: true
          path: /etc/NetworkManager/dispatcher.d/30-static-dhcp
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-ex%20-o%20pipefail%0A%0Aif%20%5B%20-z%20%22%24DHCP6_IP6_ADDRESS%22%20%5D%0Athen%0A%20%20%20%20%3E%262%20echo%20%22Not%20a%20DHCP6%20address.%20Ignoring.%22%0A%20%20%20%20exit%200%0Afi%0A%0ALEASE_TIME%3D%24(ip%20-j%20-6%20a%20show%20%22%24DEVICE_IFACE%22%20%7C%20jq%20-r%20%22.%5B%5D.addr_info%5B%5D%20%7C%20select(.scope%3D%3D%5C%22global%5C%22)%20%7C%20select(.deprecated!%3Dtrue)%20%7C%20select(.local%3D%3D%5C%22%24DHCP6_IP6_ADDRESS%5C%22)%20%7C%20.preferred_life_time%22)%0APREFIX_LEN%3D%24(ip%20-j%20-6%20a%20show%20%22%24DEVICE_IFACE%22%20%7C%20jq%20-r%20%22.%5B%5D.addr_info%5B%5D%20%7C%20select(.scope%3D%3D%5C%22global%5C%22)%20%7C%20select(.deprecated!%3Dtrue)%20%7C%20select(.local%3D%3D%5C%22%24DHCP6_IP6_ADDRESS%5C%22)%20%7C%20.prefixlen%22)%0A%0Aif%20%5B%20%24%7BLEASE_TIME%3A-0%7D%20-lt%204294967295%20%5D%0Athen%0A%20%20%20%20%3E%262%20echo%20%22Not%20an%20infinite%20DHCP6%20lease.%20Ignoring.%22%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20We%20don't%20want%20this%20to%20run%20before%20OVNKubernetes%20creates%20its%20bridge.%20If%20we%0A%23%20see%20the%20default%20CONNECTION_ID%20we%20know%20to%20wait.%0Aif%20%5B%20%22%24CONNECTION_ID%22%20%3D%3D%20%22Wired%20Connection%22%20%5D%0Athen%0A%20%20%20%20%3E%262%20echo%20%22Refusing%20to%20modify%20default%20connection.%22%0A%20%20%20%20exit%200%0Afi%0A%0ACIDR%3D%22%24DHCP6_IP6_ADDRESS%2F%24PREFIX_LEN%22%0Anmcli%20con%20mod%20%22%24CONNECTION_ID%22%20ipv6.addresses%20%22%24CIDR%22%0Anmcli%20con%20mod%20%22%24CONNECTION_ID%22%20connection.autoconnect%20%22yes%22%0Anmcli%20con%20mod%20%22%24CONNECTION_ID%22%20ipv6.method%20%22manual%22%0Anmcli%20con%20mod%20%22%24CONNECTION_ID%22%20ipv6.gateway%20%22%24IP6_GATEWAY%22%0Anmcli%20con%20mod%20%22%24CONNECTION_ID%22%20ipv6.dns%20%22%24IP6_NAMESERVERS%22%0ASEARCH_DOMAIN%3D%22%24%7BDHCP6_FQDN_FQDN%23*.%7D%22%0Aif%20%5B%20-n%20%22%24SEARCH_DOMAIN%22%20%5D%3B%20then%0A%20%20%20%20nmcli%20con%20mod%20%22%24CONNECTION_ID%22%20ipv6.dns-search%20%22%24SEARCH_DOMAIN%22%0Afi%0Aplus%3D''%0Afor%20i%20in%20%24(seq%200%20%24((%24IP6_NUM_ROUTES-1))%20)%0Ado%0A%20%20%20%20varname%3D%22IP6_ROUTE_%24i%22%0A%20%20%20%20nmcli%20con%20mod%20%22%24CONNECTION_ID%22%20%24%7Bplus%7Dipv6.routes%20%22%24%7B!varname%7D%22%0A%20%20%20%20plus%3D'%2B'%0Adone%0A%0A%23%20Copy%20it%20from%20the%20OverlayFS%20mount%20to%20the%20persistent%20lowerdir%0Acp%20%22%24CONNECTION_FILENAME%22%20%2Fetc%2FNetworkManager%2Fsystem-connections%0A
          mode: 493
          overwrite: true
          path: /etc/NetworkManager/dispatcher.d/30-static-dhcpv6
        - contents:
            source: data:,
          mode: 384
          overwrite: true
          path: /etc/pki/ca-trust/source/anchors/openshift-config-user-ca-bundle.crt
        - contents:
            source: data:,KUBERNETES_SERVICE_HOST%3D'api-int.comp-poc-rh01.rhpoc.int'%0AKUBERNETES_SERVICE_PORT%3D'6443'%0A
          mode: 420
          overwrite: true
          path: /etc/kubernetes/apiserver-url.env
        - contents:
            source: data:,%23%20This%20file%20is%20managed%20by%20machine-config-operator.%0A%23%20Suppress%20audit%20rules%20which%20always%20trigger%20for%20container%0A%23%20workloads%2C%20as%20they%20spam%20the%20audit%20log.%20%20Workloads%20are%20expected%0A%23%20to%20be%20dynamic%2C%20and%20the%20networking%20stack%20uses%20iptables.%0A-a%20exclude%2Calways%20-F%20msgtype%3DNETFILTER_CFG%0A%23%20The%20default%20bridged%20networking%20enables%20promiscuous%20on%20the%20veth%0A%23%20device.%20%20Ideally%2C%20we'd%20teach%20audit%20to%20ignore%20only%20veth%20devices%2C%0A%23%20since%20one%20might%20legitimately%20care%20about%20promiscuous%20on%20real%20physical%0A%23%20devices.%20%20But%20we%20can't%20currently%20differentiate.%0A-a%20exclude%2Calways%20-F%20msgtype%3DANOM_PROMISCUOUS%0A
          mode: 420
          overwrite: true
          path: /etc/audit/rules.d/mco-audit-quiet-containers.rules
        - contents:
            source: data:,mode%3A%20unicast%0A
          mode: 420
          overwrite: true
          path: /etc/keepalived/monitor.conf
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%0A%23%20ESP%20offload%2C%20either%20in%20actual%20hardware%20or%20as%20part%20as%20GRO%20(generic%0A%23%20recieve%20offload)%20does%20not%20work%20for%20interfaces%20attached%20to%20an%20OVS%20bridge%0A%23%20so%20turn%20it%20off%20for%20the%20time%20being.%0A%23%20https%3A%2F%2Fissues.redhat.com%2Fbrowse%2FRHEL-58811%0A%0A%23%20Depends%20on%20ipsec%20service%20drop-in%20to%20start%20it%20after%20configure-ovs%20to%20make%0A%23%20sure%20offloads%20are%20disabled%20before%20ipsec%20starts.%0A%0Aif%20%5B%5B%20%22%242%22%20!%3D%20%22up%22%20%5D%5D%3B%20then%0A%20%20exit%0Afi%0A%0Adevice%3D%24DEVICE_IFACE%0Akind_slave%3D%24(ip%20-j%20-d%20link%20show%20%22%24device%22%20%7C%20jq%20-r%20'.%5B0%5D%20%7C%20.linkinfo.info_slave_kind%20%2F%2F%20empty')%0A%0Aif%20%5B%20%22%24kind_slave%22%20%3D%20%22openvswitch%22%20%5D%3B%20then%0A%20%20for%20feature%20in%20tx-esp-segmentation%20esp-hw-offload%20esp-tx-csum-hw-offload%3B%20do%0A%20%20%20%20if%20ethtool%20-k%20%22%24device%22%20%7C%20grep%20-qE%20%22%5E%24%7Bfeature%7D%3A%20off%22%3B%20then%0A%20%20%20%20%20%20%23%20already%20disabled%2C%20nothing%20to%20do%0A%20%20%20%20%20%20continue%0A%20%20%20%20fi%0A%20%20%20%20%0A%20%20%20%20logger%20-t%2099-esp-offload%20-s%20%22Setting%20%24feature%20off%20for%20%24device%3A%20unsupported%20when%20attached%20to%20Open%20vSwitch%20bridge%22%0A%20%20%20%20ethtool%20-K%20%22%24device%22%20%22%24feature%22%20off%0A%20%20done%0Afi%0A
          mode: 484
          overwrite: true
          path: /etc/NetworkManager/dispatcher.d/99-esp-offload
        - contents:
            source: data:,r%20%2Fetc%2Fkubernetes%2Fcni%2Fnet.d%2F80-openshift-network.conf%0Ar%20%2Fetc%2Fkubernetes%2Fcni%2Fnet.d%2F10-ovn-kubernetes.conf%0Ad%20%2Frun%2Fmultus%2Fcni%2Fnet.d%2F%200755%20root%20root%20-%20-%0AD%20%2Fvar%2Flib%2Fcni%2Fnetworks%2Fopenshift-sdn%2F%200755%20root%20root%20-%20-%0A
          mode: 420
          overwrite: true
          path: /etc/tmpfiles.d/cleanup-cni.conf
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-ex%0A%0A%23%20Used%20for%20on-prem%20deployments%20to%20enable%20ip%20forwarding%20as%20part%20of%20nodeip-configuration%20service.%0A%23%20IP%20forwarding%20is%20required%20on%20the%20node%20IP%20(k8s%20API)%20interface%20in%20order%20for%20keepalived%20to%20function.%0A%0Aecho%20%22Configuring%20IP%20Forwarding...%22%0Aovnk_config_dir%3D'%2Fetc%2Fovnk'%0Aip_hint_file%3D%22%2Frun%2Fnodeip-configuration%2Fprimary-ip%22%0A%0Aget_ip_from_ip_hint_file()%20%7B%0A%20%20local%20ip_hint_file%3D%22%241%22%0A%20%20if%20%5B%5B%20!%20-f%20%22%24%7Bip_hint_file%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22error%3A%20unable%20to%20enable%20IP%20forwarding.%20IP%20hint%20file%3A%20%24%7Bip_hint_file%7D%20does%20not%20exist!%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%20%20ip_hint%3D%24(cat%20%22%24%7Bip_hint_file%7D%22)%0A%20%20echo%20%22%24%7Bip_hint%7D%22%0A%7D%0A%0Aget_nodeip_hint_interface()%20%7B%0A%20%20local%20ip_hint%3D%22%22%0A%20%20local%20ip_hint_file%3D%22%241%22%0A%20%20local%20iface%3D%22%22%0A%0A%20%20ip_hint%3D%24(get_ip_from_ip_hint_file%20%22%24%7Bip_hint_file%7D%22)%0A%20%20if%20%5B%5B%20-z%20%22%24%7Bip_hint%7D%22%20%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22error%3A%20unable%20to%20enable%20IP%20forwarding.%20IP%20hint%20file%3A%20%24%7Bip_hint_file%7D%20is%20empty!%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%0A%20%20iface%3D%24(ip%20-j%20addr%20%7C%20jq%20-r%20%22first(.%5B%5D%20%7C%20select(any(.addr_info%5B%5D%3B%20.local%3D%3D%5C%22%24%7Bip_hint%7D%5C%22)))%20%7C%20.ifname%22)%0A%20%20if%20%5B%5B%20-z%20%22%24%7Biface%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22error%3A%20unable%20to%20enable%20IP%20forwarding.%20Cannot%20detect%20valid%20interface%20within%20file%3A%20%24%7Bip_hint_file%7D%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%20%20echo%20%22%24%7Biface%7D%22%0A%7D%0A%0Aiface%3D%24(get_nodeip_hint_interface%20%22%24%7Bip_hint_file%7D%22)%0A%0Aecho%20%22Node%20IP%20interface%20determined%20as%3A%20%24%7Biface%7D.%20Enabling%20IP%20forwarding...%22%0Afile_paths%3D(%22%2Fproc%2Fsys%2Fnet%2Fipv4%2Fconf%2F%24%7Biface%7D%2Fforwarding%22%20%22%2Fproc%2Fsys%2Fnet%2Fipv6%2Fconf%2F%24%7Biface%7D%2Fforwarding%22)%0Afor%20file_path%20in%20%22%24%7Bfile_paths%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20if%20%5B%20-f%20%22%24%7Bfile_path%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%221%22%20%3E%20%22%24%7Bfile_path%7D%22%0A%20%20%20%20fi%0Adone%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/configure-ip-forwarding.sh
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-x%0A%0Aif%20%5B%20-e%20%2Fetc%2Fnmstate%2Fopenshift%2Fapplied%20%5D%3B%20then%0A%20%20echo%20%22Skipping%20configure-ovs%20due%20to%20manual%20network%20configuration%22%0A%20%20exit%200%0Afi%0A%0A%23%20This%20file%20is%20not%20needed%20anymore%20in%204.7%2B%2C%20but%20when%20rolling%20back%20to%204.6%0A%23%20the%20ovs%20pod%20needs%20it%20to%20know%20ovs%20is%20running%20on%20the%20host.%0Atouch%20%2Fvar%2Frun%2Fovs-config-executed%0A%0A%23%20These%20are%20well%20knwon%20NM%20default%20paths%0ANM_CONN_ETC_PATH%3D%22%2Fetc%2FNetworkManager%2Fsystem-connections%22%0ANM_CONN_RUN_PATH%3D%22%2Frun%2FNetworkManager%2Fsystem-connections%22%0A%0A%23%20This%20is%20the%20path%20where%20NM%20is%20known%20to%20be%20configured%20to%20store%20user%20keyfiles%20%0ANM_CONN_CONF_PATH%3D%22%24NM_CONN_ETC_PATH%22%0A%0A%23%20This%20is%20where%20we%20want%20our%20keyfiles%20to%20finally%20reside.%20configure-ovs%0A%23%20operates%20with%20temporary%20keyfiles%20in%20NM_CONN_RUN_PATH%20and%20then%20as%20a%20last%0A%23%20step%20moves%20those%20keyfiles%20to%20NM_CONN_SET_PATH%20if%20it%20is%20a%20different%20path%0A%23%20(not%20by%20default).%20This%20mitigates%20hard%20interruptions%20(SIGKILL%2C%20hard%20reboot)%0A%23%20of%20configure-ovs%20leaving%20the%20machine%20with%20a%20half-baked%20set%20of%20keyfiles%0A%23%20that%20might%20prevent%20machine%20networking%20from%20working%20correctly.%0ANM_CONN_SET_PATH%3D%22%24%7BNM_CONN_SET_PATH%3A-%24NM_CONN_RUN_PATH%7D%22%0A%0AMANAGED_NM_CONN_SUFFIX%3D%22-slave-ovs-clone%22%0A%23%20Workaround%20to%20ensure%20OVS%20is%20installed%20due%20to%20bug%20in%20systemd%20Requires%3A%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1888017%0Acopy_nm_conn_files()%20%7B%0A%20%20local%20dst_path%3D%22%241%22%0A%20%20for%20src%20in%20%22%24%7BMANAGED_NM_CONN_FILES%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20src_path%3D%24(dirname%20%22%24src%22)%0A%20%20%20%20file%3D%24(basename%20%22%24src%22)%0A%20%20%20%20if%20%5B%20-f%20%22%24src_path%2F%24file%22%20%5D%3B%20then%0A%20%20%20%20%20%20if%20%5B%20!%20-f%20%22%24dst_path%2F%24file%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22Copying%20configuration%20%24file%22%0A%20%20%20%20%20%20%20%20cp%20%22%24src_path%2F%24file%22%20%22%24dst_path%2F%24file%22%0A%20%20%20%20%20%20elif%20!%20cmp%20--silent%20%22%24src_path%2F%24file%22%20%22%24dst_path%2F%24file%22%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22Copying%20updated%20configuration%20%24file%22%0A%20%20%20%20%20%20%20%20cp%20-f%20%22%24src_path%2F%24file%22%20%22%24dst_path%2F%24file%22%0A%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20echo%20%22Skipping%20%24file%20since%20it's%20equal%20at%20destination%22%0A%20%20%20%20%20%20fi%0A%20%20%20%20else%0A%20%20%20%20%20%20echo%20%22Skipping%20%24file%20since%20it%20does%20not%20exist%20at%20source%22%0A%20%20%20%20fi%0A%20%20done%0A%7D%0A%0Aupdate_nm_conn_files_base()%20%7B%0A%20%20base_path%3D%24%7B1%7D%0A%20%20bridge_name%3D%24%7B2%7D%0A%20%20port_name%3D%24%7B3%7D%0A%20%20ovs_port%3D%22ovs-port-%24%7Bbridge_name%7D%22%0A%20%20ovs_interface%3D%22ovs-if-%24%7Bbridge_name%7D%22%0A%20%20default_port_name%3D%22ovs-port-%24%7Bport_name%7D%22%20%23%20ovs-port-phys0%0A%20%20bridge_interface_name%3D%22ovs-if-%24%7Bport_name%7D%22%20%23%20ovs-if-phys0%0A%20%20%23%20In%20RHEL7%20files%20in%20%2F%7Betc%2Crun%7D%2FNetworkManager%2Fsystem-connections%20end%20without%20the%20suffix%20'.nmconnection'%2C%20whereas%20in%20RHCOS%20they%20end%20with%20the%20suffix.%0A%20%20MANAGED_NM_CONN_FILES%3D(%24(echo%20%22%24%7Bbase_path%7D%22%2F%7B%22%24bridge_name%22%2C%22%24ovs_interface%22%2C%22%24ovs_port%22%2C%22%24bridge_interface_name%22%2C%22%24default_port_name%22%7D%7B%2C.nmconnection%7D))%0A%20%20shopt%20-s%20nullglob%0A%20%20MANAGED_NM_CONN_FILES%2B%3D(%24%7Bbase_path%7D%2F*%24%7BMANAGED_NM_CONN_SUFFIX%7D.nmconnection%20%24%7Bbase_path%7D%2F*%24%7BMANAGED_NM_CONN_SUFFIX%7D)%0A%20%20shopt%20-u%20nullglob%0A%7D%0A%0Aupdate_nm_conn_run_files()%20%7B%0A%20%20update_nm_conn_files_base%20%22%24%7BNM_CONN_RUN_PATH%7D%22%20%22%24%7B1%7D%22%20%22%24%7B2%7D%22%0A%7D%0A%0Aupdate_nm_conn_set_files()%20%7B%0A%20%20update_nm_conn_files_base%20%22%24%7BNM_CONN_SET_PATH%7D%22%20%22%24%7B1%7D%22%20%22%24%7B2%7D%22%0A%7D%0A%0Aupdate_nm_conn_etc_files()%20%7B%0A%20%20update_nm_conn_files_base%20%22%24%7BNM_CONN_ETC_PATH%7D%22%20%22%24%7B1%7D%22%20%22%24%7B2%7D%22%0A%7D%0A%0A%23%20Move%20and%20reload%20keyfiles%20at%20their%20final%20destination%0Aset_nm_conn_files()%20%7B%0A%20%20if%20%5B%20%22%24NM_CONN_RUN_PATH%22%20!%3D%20%22%24NM_CONN_SET_PATH%22%20%5D%3B%20then%0A%20%20%20%20update_nm_conn_run_files%20br-ex%20phys0%0A%20%20%20%20copy_nm_conn_files%20%22%24NM_CONN_SET_PATH%22%0A%20%20%20%20rm_nm_conn_files%0A%20%20%20%20update_nm_conn_run_files%20br-ex1%20phys1%0A%20%20%20%20copy_nm_conn_files%20%22%24NM_CONN_SET_PATH%22%0A%20%20%20%20rm_nm_conn_files%0A%0A%20%20%20%20%23%20reload%20keyfiles%0A%20%20%20%20nmcli%20connection%20reload%0A%20%20fi%0A%7D%0A%0A%23%20Used%20to%20remove%20files%20managed%20by%20configure-ovs%20and%20temporary%20leftover%20files%20from%20network%20manager%0Arm_nm_conn_files()%20%7B%0A%20%20for%20file%20in%20%22%24%7BMANAGED_NM_CONN_FILES%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20if%20%5B%20-f%20%22%24file%22%20%5D%3B%20then%0A%20%20%20%20%20%20rm%20-f%20%22%24file%22%0A%20%20%20%20%20%20echo%20%22Removed%20nmconnection%20file%20%24file%22%0A%20%20%20%20%20%20nm_config_changed%3D1%0A%20%20%20%20fi%0A%20%20done%0A%20%20for%20file%20in%20%22%24%7BMANAGED_NM_CONN_FILES%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20for%20temp%20in%20%24(compgen%20-G%20%22%24%7Bfile%7D.*%22)%3B%20do%0A%20%20%20%20%20%20rm%20-f%20%22%24temp%22%0A%20%20%20%20%20%20echo%20%22Removed%20nmconnection%20temporary%20file%20%24temp%22%0A%20%20%20%20%20%20nm_config_changed%3D1%0A%20%20%20%20done%0A%20%20done%0A%7D%0A%0A%23%20Used%20to%20clone%20a%20slave%20connection%20by%20uuid%2C%20returns%20new%20name%0Aclone_slave_connection()%20%7B%0A%20%20local%20uuid%3D%22%241%22%0A%20%20local%20old_name%0A%20%20old_name%3D%22%24(nmcli%20-g%20connection.id%20connection%20show%20uuid%20%22%24uuid%22)%22%0A%20%20local%20new_name%3D%22%24%7Bold_name%7D%24%7BMANAGED_NM_CONN_SUFFIX%7D%22%0A%20%20if%20nmcli%20connection%20show%20id%20%22%24%7Bnew_name%7D%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20echo%20%22WARNING%3A%20existing%20ovs%20slave%20%24%7Bnew_name%7D%20connection%20profile%20file%20found%2C%20overwriting...%22%20%3E%262%0A%20%20%20%20nmcli%20connection%20delete%20id%20%22%24%7Bnew_name%7D%22%20%26%3E%20%2Fdev%2Fnull%0A%20%20fi%0A%20%20clone_nm_conn%20%24uuid%20%22%24%7Bnew_name%7D%22%0A%20%20echo%20%22%24%7Bnew_name%7D%22%0A%7D%0A%0A%23%20Used%20to%20replace%20an%20old%20master%20connection%20uuid%20with%20a%20new%20one%20on%20all%20connections%0Areplace_connection_master()%20%7B%0A%20%20local%20old%3D%22%241%22%0A%20%20local%20new%3D%22%242%22%0A%20%20for%20conn_uuid%20in%20%24(nmcli%20-g%20UUID%20connection%20show)%20%3B%20do%0A%20%20%20%20if%20%5B%20%22%24(nmcli%20-g%20connection.master%20connection%20show%20uuid%20%22%24conn_uuid%22)%22%20!%3D%20%22%24old%22%20%5D%3B%20then%0A%20%20%20%20%20%20continue%0A%20%20%20%20fi%0A%0A%20%20%20%20local%20active_state%3D%24(nmcli%20-g%20GENERAL.STATE%20connection%20show%20%22%24conn_uuid%22)%0A%20%20%20%20local%20autoconnect%3D%24(nmcli%20-g%20connection.autoconnect%20connection%20show%20%22%24conn_uuid%22)%0A%20%20%20%20if%20%5B%20%22%24active_state%22%20!%3D%20%22activated%22%20%5D%20%26%26%20%5B%20%22%24autoconnect%22%20!%3D%20%22yes%22%20%5D%3B%20then%0A%20%20%20%20%20%20%23%20Assume%20that%20slave%20profiles%20intended%20to%20be%20used%20are%20those%20that%20are%3A%0A%20%20%20%20%20%20%23%20-%20active%0A%20%20%20%20%20%20%23%20-%20or%20inactive%20(which%20might%20be%20due%20to%20link%20being%20down)%20but%20to%20be%20autoconnected.%0A%20%20%20%20%20%20%23%20Otherwise%2C%20ignore%20them.%0A%20%20%20%20%20%20continue%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20make%20changes%20for%20slave%20profiles%20in%20a%20new%20clone%0A%20%20%20%20local%20new_name%0A%20%20%20%20new_name%3D%24(clone_slave_connection%20%24conn_uuid)%0A%0A%20%20%20%20mod_nm_conn%20%22%24new_name%22%20connection.master%20%22%24new%22%20connection.autoconnect-priority%20100%20connection.autoconnect%20no%20%0A%20%20%20%20echo%20%22Replaced%20master%20%24old%20with%20%24new%20for%20slave%20profile%20%24new_name%22%0A%20%20done%0A%7D%0A%0A%23%20when%20creating%20the%20bridge%2C%20we%20use%20a%20value%20lower%20than%20NM's%20ethernet%20device%20default%20route%20metric%0A%23%20(we%20pick%2048%20and%2049%20to%20be%20lower%20than%20anything%20that%20NM%20chooses%20by%20default)%0ABRIDGE_METRIC%3D%2248%22%0ABRIDGE1_METRIC%3D%2249%22%0A%23%20Given%20an%20interface%2C%20generates%20NM%20configuration%20to%20add%20to%20an%20OVS%20bridge%0Aconvert_to_bridge()%20%7B%0A%20%20local%20iface%3D%24%7B1%7D%0A%20%20local%20bridge_name%3D%24%7B2%7D%0A%20%20local%20port_name%3D%24%7B3%7D%0A%20%20local%20bridge_metric%3D%24%7B4%7D%0A%20%20local%20ovs_port%3D%22ovs-port-%24%7Bbridge_name%7D%22%0A%20%20local%20ovs_interface%3D%22ovs-if-%24%7Bbridge_name%7D%22%0A%20%20local%20default_port_name%3D%22ovs-port-%24%7Bport_name%7D%22%20%23%20ovs-port-phys0%0A%20%20local%20bridge_interface_name%3D%22ovs-if-%24%7Bport_name%7D%22%20%23%20ovs-if-phys0%0A%0A%20%20if%20%5B%20%22%24iface%22%20%3D%20%22%24bridge_name%22%20%5D%3B%20then%0A%20%20%20%20%23%20handle%20vlans%20and%20bonds%20etc%20if%20they%20have%20already%20been%0A%20%20%20%20%23%20configured%20via%20nm%20key%20files%20and%20br-ex%20is%20already%20up%0A%20%20%20%20ifaces%3D%24(ovs-vsctl%20list-ifaces%20%24%7Biface%7D)%0A%20%20%20%20for%20intf%20in%20%24ifaces%3B%20do%20configure_driver_options%20%24intf%3B%20done%0A%20%20%20%20echo%20%22Networking%20already%20configured%20and%20up%20for%20%24%7Bbridge-name%7D!%22%0A%20%20%20%20return%0A%20%20fi%0A%0A%20%20%23%20flag%20to%20reload%20NM%20to%20account%20for%20all%20the%20configuration%20changes%0A%20%20%23%20going%20forward%0A%20%20nm_config_changed%3D1%0A%0A%20%20if%20%5B%20-z%20%22%24iface%22%20%5D%3B%20then%0A%20%20%20%20echo%20%22ERROR%3A%20Unable%20to%20find%20default%20gateway%20interface%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%20%20%23%20find%20the%20MAC%20from%20OVS%20config%20or%20the%20default%20interface%20to%20use%20for%20OVS%20internal%20port%0A%20%20%23%20this%20prevents%20us%20from%20getting%20a%20different%20DHCP%20lease%20and%20dropping%20connection%0A%20%20if%20!%20iface_mac%3D%24(%3C%22%2Fsys%2Fclass%2Fnet%2F%24%7Biface%7D%2Faddress%22)%3B%20then%0A%20%20%20%20echo%20%22Unable%20to%20determine%20default%20interface%20MAC%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%0A%20%20echo%20%22MAC%20address%20found%20for%20iface%3A%20%24%7Biface%7D%3A%20%24%7Biface_mac%7D%22%0A%0A%20%20%23%20find%20MTU%20from%20original%20iface%0A%20%20iface_mtu%3D%24(ip%20link%20show%20%22%24iface%22%20%7C%20awk%20'%7Bprint%20%245%3B%20exit%7D')%0A%20%20if%20%5B%5B%20-z%20%22%24iface_mtu%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22Unable%20to%20determine%20default%20interface%20MTU%2C%20defaulting%20to%201500%22%0A%20%20%20%20iface_mtu%3D1500%0A%20%20else%0A%20%20%20%20echo%20%22MTU%20found%20for%20iface%3A%20%24%7Biface%7D%3A%20%24%7Biface_mtu%7D%22%0A%20%20fi%0A%0A%20%20%23%20store%20old%20conn%20for%20later%0A%20%20old_conn%3D%24(nmcli%20--fields%20UUID%2CDEVICE%20conn%20show%20--active%20%7C%20awk%20%22%2F%5Cs%24%7Biface%7D%5Cs*%5C%24%2F%20%7Bprint%20%5C%241%7D%22)%0A%0A%20%20if%20%5B%5B%20-z%20%22%24old_conn%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22ERROR%3A%20cannot%20find%20connection%20for%20interface%3A%20%24%7Biface%7D%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%0A%20%20%23%20create%20bridge%0A%20%20if%20!%20nmcli%20connection%20show%20%22%24bridge_name%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-br%20%22%24bridge_name%22%0A%20%20%20%20add_nm_conn%20%22%24bridge_name%22%20type%20ovs-bridge%20conn.interface%20%22%24bridge_name%22%20802-3-ethernet.mtu%20%24%7Biface_mtu%7D%20%5C%0A%20%20%20%20connection.autoconnect-slaves%201%0A%20%20fi%0A%0A%20%20%23%20find%20default%20port%20to%20add%20to%20bridge%0A%20%20if%20!%20nmcli%20connection%20show%20%22%24default_port_name%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-port%20%22%24bridge_name%22%20%24%7Biface%7D%0A%20%20%20%20add_nm_conn%20%22%24default_port_name%22%20type%20ovs-port%20conn.interface%20%24%7Biface%7D%20slave-type%20ovs-bridge%20master%20%22%24bridge_name%22%20%5C%0A%20%20%20%20connection.autoconnect-slaves%201%0A%20%20fi%0A%0A%20%20if%20!%20nmcli%20connection%20show%20%22%24ovs_port%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-port%20%22%24bridge_name%22%20%22%24bridge_name%22%0A%20%20%20%20add_nm_conn%20%22%24ovs_port%22%20type%20ovs-port%20conn.interface%20%22%24bridge_name%22%20slave-type%20ovs-bridge%20master%20%22%24bridge_name%22%0A%20%20fi%0A%0A%20%20extra_phys_args%3D()%0A%20%20%23%20check%20if%20this%20interface%20is%20a%20vlan%2C%20bond%2C%20team%2C%20or%20ethernet%20type%0A%20%20if%20%5B%20%22%24(nmcli%20--get-values%20connection.type%20conn%20show%20%24%7Bold_conn%7D)%22%20%3D%3D%20%22vlan%22%20%5D%3B%20then%0A%20%20%20%20iface_type%3Dvlan%0A%20%20%20%20vlan_id%3D%24(nmcli%20--get-values%20vlan.id%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20if%20%5B%20-z%20%22%24vlan_id%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22ERROR%3A%20unable%20to%20determine%20vlan_id%20for%20vlan%20connection%3A%20%24%7Bold_conn%7D%22%0A%20%20%20%20%20%20exit%201%0A%20%20%20%20fi%0A%20%20%20%20vlan_parent%3D%24(nmcli%20--get-values%20vlan.parent%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20if%20%5B%20-z%20%22%24vlan_parent%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22ERROR%3A%20unable%20to%20determine%20vlan_parent%20for%20vlan%20connection%3A%20%24%7Bold_conn%7D%22%0A%20%20%20%20%20%20exit%201%0A%20%20%20%20fi%0A%0A%20%20%20%20if%20nmcli%20connection%20show%20uuid%20%22%24vlan_parent%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20%20%20%23%20if%20the%20VLAN%20connection%20is%20configured%20with%20a%20connection%20UUID%20as%20parent%2C%20we%20need%20to%20find%20the%20underlying%20device%0A%20%20%20%20%20%20%23%20and%20create%20the%20bridge%20against%20it%2C%20as%20the%20parent%20connection%20can%20be%20replaced%20by%20another%20bridge.%0A%20%20%20%20%20%20vlan_parent%3D%24(nmcli%20--get-values%20GENERAL.DEVICES%20conn%20show%20uuid%20%24%7Bvlan_parent%7D)%0A%20%20%20%20fi%0A%0A%20%20%20%20extra_phys_args%3D(%20dev%20%22%24%7Bvlan_parent%7D%22%20id%20%22%24%7Bvlan_id%7D%22%20)%0A%20%20elif%20%5B%20%22%24(nmcli%20--get-values%20connection.type%20conn%20show%20%24%7Bold_conn%7D)%22%20%3D%3D%20%22bond%22%20%5D%3B%20then%0A%20%20%20%20iface_type%3Dbond%0A%20%20%20%20%23%20check%20bond%20options%0A%20%20%20%20bond_opts%3D%24(nmcli%20--get-values%20bond.options%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20if%20%5B%20-n%20%22%24bond_opts%22%20%5D%3B%20then%0A%20%20%20%20%20%20extra_phys_args%2B%3D(%20bond.options%20%22%24%7Bbond_opts%7D%22%20)%0A%20%20%20%20%20%20MODE_REGEX%3D%22(%5E%7C%2C)mode%3Dactive-backup(%2C%7C%24)%22%0A%20%20%20%20%20%20MAC_REGEX%3D%22(%5E%7C%2C)fail_over_mac%3D(1%7Cactive%7C2%7Cfollow)(%2C%7C%24)%22%0A%20%20%20%20%20%20if%20%5B%5B%20%24bond_opts%20%3D~%20%24MODE_REGEX%20%5D%5D%20%26%26%20%5B%5B%20%24bond_opts%20%3D~%20%24MAC_REGEX%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20clone_mac%3D0%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%20%20elif%20%5B%20%22%24(nmcli%20--get-values%20connection.type%20conn%20show%20%24%7Bold_conn%7D)%22%20%3D%3D%20%22team%22%20%5D%3B%20then%0A%20%20%20%20iface_type%3Dteam%0A%20%20%20%20%23%20check%20team%20config%20options%0A%20%20%20%20team_config_opts%3D%24(nmcli%20--get-values%20team.config%20-e%20no%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20if%20%5B%20-n%20%22%24team_config_opts%22%20%5D%3B%20then%0A%20%20%20%20%20%20%23%20team.config%20is%20json%2C%20remove%20spaces%20to%20avoid%20problems%20later%20on%0A%20%20%20%20%20%20extra_phys_args%2B%3D(%20team.config%20%22%24%7Bteam_config_opts%2F%2F%5B%5B%3Aspace%3A%5D%5D%2F%7D%22%20)%0A%20%20%20%20%20%20team_mode%3D%24(echo%20%22%24%7Bteam_config_opts%7D%22%20%7C%20jq%20-r%20%22.runner.name%20%2F%2F%20empty%22)%0A%20%20%20%20%20%20team_mac_policy%3D%24(echo%20%22%24%7Bteam_config_opts%7D%22%20%7C%20jq%20-r%20%22.runner.hwaddr_policy%20%2F%2F%20empty%22)%0A%20%20%20%20%20%20MAC_REGEX%3D%22(by_active%7Conly_active)%22%0A%20%20%20%20%20%20if%20%5B%20%22%24team_mode%22%20%3D%20%22activebackup%22%20%5D%20%26%26%20%5B%5B%20%22%24team_mac_policy%22%20%3D~%20%24MAC_REGEX%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20clone_mac%3D0%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%20%20elif%20%5B%20%22%24(nmcli%20--get-values%20connection.type%20conn%20show%20%24%7Bold_conn%7D)%22%20%3D%3D%20%22tun%22%20%5D%3B%20then%0A%20%20%20%20iface_type%3Dtun%0A%20%20%20%20tun_mode%3D%24(nmcli%20--get-values%20tun.mode%20-e%20no%20connection%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20extra_phys_args%2B%3D(%20tun.mode%20%22%24%7Btun_mode%7D%22%20)%0A%20%20elif%20%5B%20%22%24(nmcli%20--get-values%20connection.type%20conn%20show%20%24%7Bold_conn%7D)%22%20%3D%3D%20%22bridge%22%20%5D%3B%20then%0A%20%20%20%20iface_type%3Dbridge%0A%20%20else%0A%20%20%20%20iface_type%3D802-3-ethernet%0A%20%20fi%0A%0A%20%20if%20%5B%20!%20%22%24%7Bclone_mac%3A-%7D%22%20%3D%20%220%22%20%5D%3B%20then%0A%20%20%20%20%23%20In%20active-backup%20link%20aggregation%2C%20with%20fail_over_mac%20mode%20enabled%2C%0A%20%20%20%20%23%20cloning%20the%20mac%20address%20is%20not%20supported.%20It%20is%20possible%20then%20that%0A%20%20%20%20%23%20br-ex%20has%20a%20different%20mac%20address%20than%20the%20bond%20which%20might%20be%0A%20%20%20%20%23%20troublesome%20on%20some%20platforms%20where%20the%20nic%20won't%20accept%20packets%20with%0A%20%20%20%20%23%20a%20different%20destination%20mac.%20But%20nobody%20has%20complained%20so%20far%20so%20go%20on%0A%20%20%20%20%23%20with%20what%20we%20got.%20%0A%20%20%20%20%0A%20%20%20%20%23%20Do%20set%20it%20though%20for%20other%20link%20aggregation%20configurations%20where%20the%0A%20%20%20%20%23%20mac%20address%20would%20otherwise%20depend%20on%20enslave%20order%20for%20which%20we%20have%0A%20%20%20%20%23%20no%20control%20going%20forward.%0A%20%20%20%20extra_phys_args%2B%3D(%20802-3-ethernet.cloned-mac-address%20%22%24%7Biface_mac%7D%22%20)%0A%20%20fi%0A%0A%20%20%23%20use%20%24%7Bextra_phys_args%5B%40%5D%2B%22%24%7Bextra_phys_args%5B%40%5D%7D%22%7D%20instead%20of%20%24%7Bextra_phys_args%5B%40%5D%7D%20to%20be%20compatible%20with%20bash%204.2%20in%20RHEL7.9%0A%20%20if%20!%20nmcli%20connection%20show%20%22%24bridge_interface_name%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20destroy%20interface%20%24%7Biface%7D%0A%20%20%20%20ovs_default_port_conn%3D%24(nmcli%20-g%20connection.uuid%20conn%20show%20%22%24default_port_name%22)%0A%20%20%20%20add_nm_conn%20%22%24bridge_interface_name%22%20type%20%24%7Biface_type%7D%20conn.interface%20%24%7Biface%7D%20master%20%22%24ovs_default_port_conn%22%20%5C%0A%20%20%20%20%20%20slave-type%20ovs-port%20connection.autoconnect-priority%20100%20connection.autoconnect-slaves%201%20802-3-ethernet.mtu%20%24%7Biface_mtu%7D%20%5C%0A%20%20%20%20%20%20%24%7Bextra_phys_args%5B%40%5D%2B%22%24%7Bextra_phys_args%5B%40%5D%7D%22%7D%0A%20%20fi%0A%0A%20%20%23%20Get%20the%20new%20connection%20uuids%0A%20%20new_conn%3D%24(nmcli%20-g%20connection.uuid%20conn%20show%20%22%24bridge_interface_name%22)%0A%20%20ovs_port_conn%3D%24(nmcli%20-g%20connection.uuid%20conn%20show%20%22%24ovs_port%22)%0A%0A%20%20%23%20Update%20connections%20with%20master%20property%20set%20to%20use%20the%20new%20connection%0A%20%20replace_connection_master%20%24old_conn%20%24new_conn%0A%20%20replace_connection_master%20%24iface%20%24new_conn%0A%0A%20%20ipv4_method%3D%24(nmcli%20-g%20ipv4.method%20conn%20show%20%22%24old_conn%22)%0A%20%20ipv6_method%3D%24(nmcli%20-g%20ipv6.method%20conn%20show%20%22%24old_conn%22)%0A%0A%20%20ipv4_addresses%3D%24(nmcli%20-g%20ipv4.addresses%20conn%20show%20%22%24old_conn%22)%0A%20%20ipv6_addresses%3D%24(nmcli%20-g%20ipv6.addresses%20conn%20show%20%22%24old_conn%22)%0A%0A%20%20%23%20Warn%20about%20an%20invalid%20MTU%20that%20will%20most%20likely%20fail%20in%20one%20way%20or%0A%20%20%23%20another%0A%20%20if%20%5B%20%24%7Biface_mtu%7D%20-lt%201280%20%5D%20%26%26%20%5B%20%22%24%7Bipv6_method%7D%22%20!%3D%20%22disabled%22%20%5D%3B%20then%0A%20%20%20%20echo%20%22WARNING%3A%20MTU%20%24%7Biface_mtu%7D%20is%20lower%20than%20the%20minimum%20required%20of%201280%20for%20IPv6%22%0A%20%20fi%0A%0A%20%20if%20!%20nmcli%20connection%20show%20%22%24ovs_interface%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20destroy%20interface%20%22%24bridge_name%22%0A%20%20%20%20%23%20Clone%20the%20connection%20in%20case%20the%20method%20is%20manual%20or%20in%20case%20the%20an%20address%20is%20set%20(DHCP%20%2B%20static%20IP)%0A%20%20%20%20if%20%5B%20%22%24%7Bipv4_method%7D%22%20%3D%20%22manual%22%20%5D%20%7C%7C%20%5B%20%22%24%7Bipv4_addresses%7D%22%20!%3D%20%22%22%20%5D%20%7C%7C%20%5B%20%22%24%7Bipv6_method%7D%22%20%3D%20%22manual%22%20%5D%20%7C%7C%20%5B%20%22%24%7Bipv6_addresses%7D%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22Static%20IP%20addressing%20detected%20on%20default%20gateway%20connection%3A%20%24%7Bold_conn%7D%22%0A%20%20%20%20%20%20%23%20clone%20the%20old%20connection%20to%20get%20the%20address%20settings%0A%20%20%20%20%20%20%23%20prefer%20cloning%20vs%20copying%20the%20connection%20file%20to%20avoid%20problems%20with%20selinux%0A%20%20%20%20%20%20clone_nm_conn%20%22%24%7Bold_conn%7D%22%20%22%24%7Bovs_interface%7D%22%0A%20%20%20%20%20%20shopt%20-s%20nullglob%0A%20%20%20%20%20%20new_conn_files%3D(%24%7BNM_CONN_RUN_PATH%7D%2F%22%24%7Bovs_interface%7D%22*)%0A%20%20%20%20%20%20shopt%20-u%20nullglob%0A%20%20%20%20%20%20if%20%5B%20%24%7B%23new_conn_files%5B%40%5D%7D%20-ne%201%20%5D%20%7C%7C%20%5B%20!%20-f%20%22%24%7Bnew_conn_files%5B0%5D%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22ERROR%3A%20could%20not%20find%20%24%7Bovs_interface%7D%20conn%20file%20after%20cloning%20from%20%24%7Bold_conn%7D%22%0A%20%20%20%20%20%20%20%20exit%201%0A%20%20%20%20%20%20fi%0A%20%20%20%20%20%20new_conn_file%3D%22%24%7Bnew_conn_files%5B0%5D%7D%22%0A%0A%20%20%20%20%20%20%23%20modify%20the%20connection%20type%20directly%20because%20it%20can't%20be%20modified%0A%20%20%20%20%20%20%23%20through%20nmcli%0A%20%20%20%20%20%20sed%20-i%20'%2F%5E%5C%5Bconnection%5C%5D%24%2F%2C%2F%5E%5C%5B%2F%20s%2F%5Etype%3D.*%24%2Ftype%3Dovs-interface%2F'%20%24%7Bnew_conn_file%7D%0A%0A%20%20%20%20%20%20%23%20modify%20some%20more%20settings%20through%20nmcli%0A%20%20%20%20%20%20mod_nm_conn%20%22%24%7Bovs_interface%7D%22%20conn.interface%20%22%24bridge_name%22%20%5C%0A%20%20%20%20%20%20%20%20connection.multi-connect%20%22%22%20connection.autoconnect%20no%20%5C%0A%20%20%20%20%20%20%20%20connection.master%20%22%24ovs_port_conn%22%20connection.slave-type%20ovs-port%20%5C%0A%20%20%20%20%20%20%20%20ovs-interface.type%20internal%20%5C%0A%20%20%20%20%20%20%20%20802-3-ethernet.mtu%20%24%7Biface_mtu%7D%20802-3-ethernet.cloned-mac-address%20%24%7Biface_mac%7D%20%5C%0A%20%20%20%20%20%20%20%20ipv4.route-metric%20%22%24%7Bbridge_metric%7D%22%20ipv6.route-metric%20%22%24%7Bbridge_metric%7D%22%0A%0A%20%20%20%20%20%20echo%20%22Loaded%20new%20%24ovs_interface%20connection%20file%3A%20%24%7Bnew_conn_file%7D%22%0A%20%20%20%20else%0A%20%20%20%20%20%20extra_if_brex_args%3D%22%22%0A%20%20%20%20%20%20%23%20check%20if%20interface%20had%20ipv4%2Fipv6%20addresses%20assigned%0A%20%20%20%20%20%20num_ipv4_addrs%3D%24(ip%20-j%20a%20show%20dev%20%24%7Biface%7D%20%7C%20jq%20%22.%5B0%5D.addr_info%20%7C%20map(.%20%7C%20select(.family%20%3D%3D%20%5C%22inet%5C%22))%20%7C%20length%22)%0A%20%20%20%20%20%20if%20%5B%20%22%24num_ipv4_addrs%22%20-gt%200%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20extra_if_brex_args%2B%3D%22ipv4.may-fail%20no%20%22%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20%23%20IPV6%20should%20have%20at%20least%20a%20link%20local%20address.%20Check%20for%20more%20than%201%20to%20see%20if%20there%20is%20an%0A%20%20%20%20%20%20%23%20assigned%20address.%0A%20%20%20%20%20%20num_ip6_addrs%3D%24(ip%20-j%20a%20show%20dev%20%24%7Biface%7D%20%7C%20jq%20%22.%5B0%5D.addr_info%20%7C%20map(.%20%7C%20select(.family%20%3D%3D%20%5C%22inet6%5C%22%20and%20.scope%20!%3D%20%5C%22link%5C%22))%20%7C%20length%22)%0A%20%20%20%20%20%20if%20%5B%20%22%24num_ip6_addrs%22%20-gt%200%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20extra_if_brex_args%2B%3D%22ipv6.may-fail%20no%20%22%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20%23%20check%20for%20dhcp%20client%20ids%0A%20%20%20%20%20%20dhcp_client_id%3D%24(nmcli%20--get-values%20ipv4.dhcp-client-id%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20%20%20if%20%5B%20-n%20%22%24dhcp_client_id%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20extra_if_brex_args%2B%3D%22ipv4.dhcp-client-id%20%24%7Bdhcp_client_id%7D%20%22%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20dhcp6_client_id%3D%24(nmcli%20--get-values%20ipv6.dhcp-duid%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20%20%20if%20%5B%20-n%20%22%24dhcp6_client_id%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20extra_if_brex_args%2B%3D%22ipv6.dhcp-duid%20%24%7Bdhcp6_client_id%7D%20%22%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20ipv6_addr_gen_mode%3D%24(nmcli%20--get-values%20ipv6.addr-gen-mode%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20%20%20if%20%5B%20-n%20%22%24ipv6_addr_gen_mode%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20extra_if_brex_args%2B%3D%22ipv6.addr-gen-mode%20%24%7Bipv6_addr_gen_mode%7D%20%22%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20add_nm_conn%20%22%24ovs_interface%22%20type%20ovs-interface%20slave-type%20ovs-port%20conn.interface%20%22%24bridge_name%22%20master%20%22%24ovs_port_conn%22%20%5C%0A%20%20%20%20%20%20%20%20802-3-ethernet.mtu%20%24%7Biface_mtu%7D%20802-3-ethernet.cloned-mac-address%20%24%7Biface_mac%7D%20%5C%0A%20%20%20%20%20%20%20%20ipv4.method%20%22%24%7Bipv4_method%7D%22%20ipv4.route-metric%20%22%24%7Bbridge_metric%7D%22%20%5C%0A%20%20%20%20%20%20%20%20ipv6.method%20%22%24%7Bipv6_method%7D%22%20ipv6.route-metric%20%22%24%7Bbridge_metric%7D%22%20%5C%0A%20%20%20%20%20%20%20%20%24%7Bextra_if_brex_args%7D%0A%20%20%20%20fi%0A%20%20fi%0A%0A%20%20configure_driver_options%20%22%24%7Biface%7D%22%0A%7D%0A%0A%23%20Used%20to%20remove%20a%20bridge%0Aremove_ovn_bridges()%20%7B%0A%20%20bridge_name%3D%24%7B1%7D%0A%20%20port_name%3D%24%7B2%7D%0A%0A%20%20%23%20Remove%20the%20keyfiles%20from%20known%20configuration%20paths%0A%20%20update_nm_conn_run_files%20%24%7Bbridge_name%7D%20%24%7Bport_name%7D%0A%20%20rm_nm_conn_files%0A%20%20update_nm_conn_set_files%20%24%7Bbridge_name%7D%20%24%7Bport_name%7D%0A%20%20rm_nm_conn_files%0A%20%20%23%20Shouldn't%20be%20necessary%2C%20workaround%20for%20https%3A%2F%2Fissues.redhat.com%2Fbrowse%2FOCPBUGS-41489%0A%20%20update_nm_conn_etc_files%20%24%7Bbridge_name%7D%20%24%7Bport_name%7D%0A%20%20rm_nm_conn_files%0A%0A%20%20%23%20NetworkManager%20will%20not%20remove%20%24%7Bbridge_name%7D%20if%20it%20has%20the%20patch%20port%20created%20by%20ovn-kubernetes%0A%20%20%23%20so%20remove%20explicitly%0A%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-br%20%24%7Bbridge_name%7D%0A%7D%0A%0A%23%20Removes%20any%20previous%20ovs%20configuration%0Aremove_all_ovn_bridges()%20%7B%0A%20%20echo%20%22Reverting%20any%20previous%20OVS%20configuration%22%0A%20%20%0A%20%20remove_ovn_bridges%20br-ex%20phys0%0A%20%20remove_ovn_bridges%20br-ex1%20phys1%0A%20%20%0A%20%20echo%20%22OVS%20configuration%20successfully%20reverted%22%0A%7D%0A%0A%23%20Reloads%20NM%20NetworkManager%20profiles%20if%20any%20configuration%20change%20was%20done.%0A%23%20Accepts%20a%20list%20of%20devices%20that%20should%20be%20re-connect%20after%20reload.%0Areload_profiles_nm()%20%7B%0A%20%20if%20%5B%20%24%7Bnm_config_changed%3A-0%7D%20-eq%200%20%5D%3B%20then%0A%20%20%20%20%23%20no%20config%20was%20changed%2C%20no%20need%20to%20reload%0A%20%20%20%20return%0A%20%20fi%0A%0A%20%20%23%20reload%20profiles%0A%20%20nmcli%20connection%20reload%0A%0A%20%20%23%20precautionary%20sleep%20of%2010s%20(default%20timeout%20of%20NM%20to%20bring%20down%20devices)%0A%20%20sleep%2010%0A%0A%20%20%23%20After%20reload%2C%20devices%20that%20were%20already%20connected%20should%20connect%20again%0A%20%20%23%20if%20any%20profile%20is%20available.%20If%20no%20profile%20is%20available%2C%20a%20device%20can%0A%20%20%23%20remain%20disconnected%20and%20we%20have%20to%20explicitly%20connect%20it%20so%20that%20a%0A%20%20%23%20profile%20is%20generated.%20This%20can%20happen%20for%20physical%20devices%20but%20should%0A%20%20%23%20not%20happen%20for%20software%20devices%20as%20those%20always%20require%20a%20profile.%0A%20%20for%20dev%20in%20%24%40%3B%20do%0A%20%20%20%20%23%20Only%20attempt%20to%20connect%20a%20disconnected%20device%0A%20%20%20%20local%20connected_state%3D%24(nmcli%20-g%20GENERAL.STATE%20device%20show%20%22%24dev%22%20%7C%7C%20echo%20%22%22)%0A%20%20%20%20if%20%5B%5B%20%22%24connected_state%22%20%3D~%20%22disconnected%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%23%20keep%20track%20if%20a%20profile%20by%20the%20same%20name%20as%20the%20device%20existed%20%0A%20%20%20%20%20%20%23%20before%20we%20attempt%20activation%0A%20%20%20%20%20%20local%20named_profile_existed%3D%24(%5B%20-f%20%22%24%7BNM_CONN_CONF_PATH%7D%2F%24%7Bdev%7D%22%20%5D%20%7C%7C%20%5B%20-f%20%22%24%7BNM_CONN_CONF_PATH%7D%2F%24%7Bdev%7D.nmconnection%22%20%5D%20%26%26%20echo%20%22yes%22)%0A%20%20%20%20%20%20%0A%20%20%20%20%20%20for%20i%20in%20%7B1..10%7D%3B%20do%0A%20%20%20%20%20%20%20%20%20%20echo%20%22Attempt%20%24i%20to%20connect%20device%20%24dev%22%0A%20%20%20%20%20%20%20%20%20%20nmcli%20device%20connect%20%22%24dev%22%20%26%26%20break%0A%20%20%20%20%20%20%20%20%20%20sleep%205%0A%20%20%20%20%20%20done%0A%0A%20%20%20%20%20%20%23%20if%20a%20profile%20did%20not%20exist%20before%20but%20does%20now%2C%20it%20was%20generated%0A%20%20%20%20%20%20%23%20but%20we%20want%20it%20to%20be%20ephemeral%2C%20so%20move%20it%20back%20to%20%2Frun%0A%20%20%20%20%20%20if%20%5B%20!%20%22%24named_profile_existed%22%20%3D%20%22yes%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20MANAGED_NM_CONN_FILES%3D(%22%24%7BNM_CONN_CONF_PATH%7D%2F%24%7Bdev%7D%22%20%22%24%7BNM_CONN_CONF_PATH%7D%2F%24%7Bdev%7D.nmconnection%22)%0A%20%20%20%20%20%20%20%20copy_nm_conn_files%20%22%24%7BNM_CONN_RUN_PATH%7D%22%0A%20%20%20%20%20%20%20%20rm_nm_conn_files%0A%20%20%20%20%20%20%20%20%23%20reload%20profiles%20so%20that%20NM%20notices%20that%20some%20might%20have%20been%20moved%0A%20%20%20%20%20%20%20%20nmcli%20connection%20reload%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20echo%20%22Waiting%20for%20interface%20%24dev%20to%20activate...%22%0A%20%20%20%20if%20!%20timeout%2060%20bash%20-c%20%22while%20!%20nmcli%20-g%20DEVICE%2CSTATE%20c%20%7C%20grep%20%22'%22'%22%24dev%22%3Aactivated'%22'%22%3B%20do%20sleep%205%3B%20done%22%3B%20then%0A%20%20%20%20%20%20echo%20%22WARNING%3A%20%24dev%20did%20not%20activate%22%0A%20%20%20%20fi%0A%20%20done%0A%0A%20%20nm_config_changed%3D0%0A%7D%0A%0A%23%20Removes%20all%20configuration%20and%20reloads%20NM%20if%20necessary%0Arollback_nm()%20%7B%0A%20%20phys0%3D%24(get_bridge_physical_interface%20ovs-if-phys0)%0A%20%20phys1%3D%24(get_bridge_physical_interface%20ovs-if-phys1)%0A%20%20%0A%20%20%23%20Revert%20changes%20made%20by%20%2Fusr%2Flocal%2Fbin%2Fconfigure-ovs.sh%20during%20SDN%20migration.%0A%20%20remove_all_ovn_bridges%0A%20%20%0A%20%20%23%20reload%20profiles%20so%20that%20NM%20notices%20that%20some%20were%20removed%0A%20%20reload_profiles_nm%20%22%24phys0%22%20%22%24phys1%22%0A%7D%0A%0A%23%20Add%20a%20temporary%20deactivated%20connection%20profile%20%0A%23%20First%20argument%20is%20the%20connection%20name%20folowed%20by%20arguments%20passed%20to%0A%23%20%60nmcli%20connection%20add%60%0Aadd_nm_conn()%20%7B%0A%20%20%23%20Use%20%60save%20no%60%20to%20add%20a%20temporary%20profile%0A%20%20nmcli%20c%20add%20save%20no%20con-name%20%22%24%40%22%20connection.autoconnect%20no%0A%7D%0A%0A%23%20Modify%20a%20temporary%20connection%20profile%20%0A%23%20First%20argument%20is%20the%20connection%20name%20followed%20by%20arguments%20passed%20to%0A%23%20%60nmcli%20connection%20modify%60%0Amod_nm_conn()%20%7B%0A%20%20%23%20the%20easiest%20thing%20to%20do%20here%20would%20be%20to%20use%20%60nmcli%20c%20mod%20--temporary%60%0A%20%20%23%20but%20there%20is%20a%20bug%20in%20selinux%20profiles%20that%20denies%20NM%20from%20performing%0A%20%20%23%20the%20operation%0A%20%20local%20dst_path%3D%24%7BNM_CONN_RUN_PATH%7D%2F%241.nmconnection%0A%20%20local%20src_path%0A%20%20src_path%3D%24(mktemp)%0A%20%20shift%0A%20%20cat%20%22%24dst_path%22%20%3E%20%22%24src_path%22%0A%20%20rm%20-f%20%22%24dst_path%22%0A%20%20nmcli%20--offline%20c%20mod%20%22%24%40%22%20%3C%20%22%24src_path%22%20%3E%20%22%24dst_path%22%0A%20%20rm%20-f%20%22%24src_path%22%0A%20%20chmod%20600%20%22%24dst_path%22%0A%20%20nmcli%20c%20load%20%22%24dst_path%22%0A%7D%0A%0A%23%20Clone%20to%20a%20temporary%20connection%20profile%20%0A%23%20First%20argument%20is%20the%20connection%20to%20clone%2C%20second%20argument%20is%20the%20clone%20name%0Aclone_nm_conn()%20%7B%0A%20%20%23%20clone%20as%20temporary%20so%20that%20it%20is%20generated%20in%20NM_CONN_RUN_PATH%0A%20%20nmcli%20connection%20clone%20--temporary%20%22%241%22%20%22%242%22%20%26%3E%20%2Fdev%2Fnull%0A%7D%0A%0A%23%20Activates%20an%20ordered%20set%20of%20NM%20connection%20profiles%0Aactivate_nm_connections()%20%7B%0A%20%20local%20connections%3D(%22%24%40%22)%0A%0A%20%20%23%20We%20want%20autoconnect%20set%20for%20our%20cloned%20slave%20profiles%20so%20that%20they%20are%0A%20%20%23%20used%20over%20the%20original%20profiles%20if%20implicitly%20re-activated%20with%20other%0A%20%20%23%20dependant%20profiles.%20Otherwise%20if%20a%20slave%20activates%20with%20an%20old%20profile%2C%0A%20%20%23%20the%20old%20master%20profile%20might%20activate%20as%20well%2C%20interfering%20and%20causing%0A%20%20%23%20further%20activations%20to%20fail.%0A%20%20%23%20Slave%20interfaces%20should%20already%20be%20active%20so%20setting%20autoconnect%20here%0A%20%20%23%20won't%20implicitly%20activate%20them%20but%20there%20is%20an%20edge%20case%20where%20a%20slave%0A%20%20%23%20might%20be%20inactive%20(link%20down%20for%20example)%20and%20in%20that%20case%20setting%0A%20%20%23%20autoconnect%20will%20cause%20an%20implicit%20activation.%20This%20is%20not%20necessarily%20a%0A%20%20%23%20problem%20and%20hopefully%20we%20can%20make%20sure%20everything%20is%20activated%20as%20we%0A%20%20%23%20want%20next.%0A%20%20for%20conn%20in%20%22%24%7Bconnections%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20local%20slave_type%3D%24(nmcli%20-g%20connection.slave-type%20connection%20show%20%22%24conn%22)%0A%20%20%20%20if%20%5B%20%22%24slave_type%22%20%3D%20%22team%22%20%5D%20%7C%7C%20%5B%20%22%24slave_type%22%20%3D%20%22bond%22%20%5D%3B%20then%0A%20%20%20%20%20%20mod_nm_conn%20%22%24conn%22%20connection.autoconnect%20yes%0A%20%20%20%20fi%0A%20%20done%0A%0A%20%20%23%20Activate%20all%20connections%20and%20fail%20if%20activation%20fails%0A%20%20%23%20For%20slave%20connections%20-%20for%20as%20long%20as%20at%20least%20one%20slave%20that%20belongs%20to%20a%20bond%2Fteam%0A%20%20%23%20comes%20up%2C%20we%20should%20not%20fail%0A%20%20declare%20-A%20master_interfaces%0A%20%20for%20conn%20in%20%22%24%7Bconnections%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20%23%20Get%20the%20slave%20type%0A%20%20%20%20local%20slave_type%3D%24(nmcli%20-g%20connection.slave-type%20connection%20show%20%22%24conn%22)%0A%20%20%20%20local%20is_slave%3Dfalse%0A%20%20%20%20if%20%5B%20%22%24slave_type%22%20%3D%20%22team%22%20%5D%20%7C%7C%20%5B%20%22%24slave_type%22%20%3D%20%22bond%22%20%5D%3B%20then%0A%20%20%20%20%20%20is_slave%3Dtrue%0A%20%20%20%20fi%20%0A%0A%20%20%20%20%23%20For%20slave%20interfaces%2C%20initialize%20the%20master%20interface%20to%20false%20if%20the%20key%20is%20not%20yet%20in%20the%20array%0A%20%20%20%20local%20master_interface%0A%20%20%20%20if%20%24is_slave%3B%20then%0A%20%20%20%20%20%20master_interface%3D%24(nmcli%20-g%20connection.master%20connection%20show%20%22%24conn%22)%0A%20%20%20%20%20%20if%20!%20%5B%5B%20-v%20%22master_interfaces%5B%24master_interface%5D%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20master_interfaces%5B%22%24master_interface%22%5D%3Dfalse%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20slaves%20should%20implicitly%20activate%2C%20give%20them%20a%20chance%20to%20do%20so%0A%20%20%20%20if%20%24is_slave%3B%20then%0A%20%20%20%20%20%20if%20!%20timeout%205%20bash%20-c%20%22while%20!%20nmcli%20-g%20GENERAL.STATE%20conn%20show%20%22%24conn%22%20%7C%20grep%20activated%3B%20do%20sleep%201%3B%20done%22%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22WARNING%3A%20slave%20%24conn%20did%20not%20implicitly%20activate%20in%205s%2C%20activating%20explicitly.%22%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Do%20not%20activate%20interfaces%20that%20are%20already%20active%0A%20%20%20%20%23%20But%20set%20the%20entry%20in%20master_interfaces%20to%20true%20if%20this%20is%20a%20slave%0A%20%20%20%20%23%20Also%20set%20autoconnect%20to%20yes%0A%20%20%20%20local%20active_state%3D%24(nmcli%20-g%20GENERAL.STATE%20conn%20show%20%22%24conn%22)%0A%20%20%20%20if%20%5B%20%22%24active_state%22%20%3D%3D%20%22activated%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22Connection%20%24conn%20already%20activated%22%0A%20%20%20%20%20%20if%20%24is_slave%3B%20then%0A%20%20%20%20%20%20%20%20master_interfaces%5B%24master_interface%5D%3Dtrue%0A%20%20%20%20%20%20fi%0A%20%20%20%20%20%20mod_nm_conn%20%22%24conn%22%20connection.autoconnect%20yes%0A%20%20%20%20%20%20continue%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Activate%20all%20interfaces%20that%20are%20not%20yet%20active%0A%20%20%20%20for%20i%20in%20%7B1..10%7D%3B%20do%0A%20%20%20%20%20%20echo%20%22Attempt%20%24i%20to%20bring%20up%20connection%20%24conn%22%0A%20%20%20%20%20%20nmcli%20conn%20up%20%22%24conn%22%20%26%26%20s%3D0%20%26%26%20break%20%7C%7C%20s%3D%24%3F%0A%20%20%20%20%20%20sleep%205%0A%20%20%20%20done%0A%20%20%20%20if%20%5B%20%24s%20-eq%200%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22Brought%20up%20connection%20%24conn%20successfully%22%0A%20%20%20%20%20%20if%20%24is_slave%3B%20then%0A%20%20%20%20%20%20%20%20master_interfaces%5B%22%24master_interface%22%5D%3Dtrue%0A%20%20%20%20%20%20fi%0A%20%20%20%20elif%20!%20%24is_slave%3B%20then%0A%20%20%20%20%20%20echo%20%22ERROR%3A%20Cannot%20bring%20up%20connection%20%24conn%20after%20%24i%20attempts%22%0A%20%20%20%20%20%20return%20%24s%0A%20%20%20%20fi%0A%20%20%20%20mod_nm_conn%20%22%24conn%22%20connection.autoconnect%20yes%0A%20%20done%0A%20%20%23%20Check%20that%20all%20master%20interfaces%20report%20at%20least%20a%20single%20active%20slave%0A%20%20%23%20Note%3A%20associative%20arrays%20require%20an%20exclamation%20mark%20when%20looping%0A%20%20for%20i%20in%20%22%24%7B!master_interfaces%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20if%20!%20%24%7Bmaster_interfaces%5B%22%24i%22%5D%7D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22ERROR%3A%20Cannot%20bring%20up%20any%20slave%20interface%20for%20master%20interface%3A%20%24i%22%0A%20%20%20%20%20%20%20%20return%201%0A%20%20%20%20fi%0A%20%20done%0A%7D%0A%0A%23%20Accepts%20parameters%20%24iface_default_hint_file%2C%20%24iface%0A%23%20Writes%20content%20of%20%24iface%20into%20%24iface_default_hint_file%0Awrite_iface_default_hint()%20%7B%0A%20%20local%20iface_default_hint_file%3D%22%241%22%0A%20%20local%20iface%3D%22%242%22%0A%0A%20%20echo%20%22%24%7Biface%7D%22%20%3E%7C%20%22%24%7Biface_default_hint_file%7D%22%0A%7D%0A%0A%23%20Accepts%20parameters%20%24iface_default_hint_file%0A%23%20Returns%20the%20stored%20interface%20default%20hint%20if%20the%20hint%20is%20non-empty%2C%0A%23%20not%20br-ex%2C%20not%20br-ex1%20and%20if%20the%20interface%20can%20be%20found%20in%20%2Fsys%2Fclass%2Fnet%0Aget_iface_default_hint()%20%7B%0A%20%20local%20iface_default_hint_file%3D%241%0A%20%20if%20%5B%20-f%20%22%24%7Biface_default_hint_file%7D%22%20%5D%3B%20then%0A%20%20%20%20local%20iface_default_hint%3D%24(cat%20%22%24%7Biface_default_hint_file%7D%22)%0A%20%20%20%20if%20%5B%20%22%24%7Biface_default_hint%7D%22%20!%3D%20%22%22%20%5D%20%26%26%0A%20%20%20%20%20%20%20%20%5B%20%22%24%7Biface_default_hint%7D%22%20!%3D%20%22br-ex%22%20%5D%20%26%26%0A%20%20%20%20%20%20%20%20%5B%20%22%24%7Biface_default_hint%7D%22%20!%3D%20%22br-ex1%22%20%5D%20%26%26%0A%20%20%20%20%20%20%20%20%5B%20-d%20%22%2Fsys%2Fclass%2Fnet%2F%24%7Biface_default_hint%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22%24%7Biface_default_hint%7D%22%0A%20%20%20%20%20%20%20%20return%0A%20%20%20%20fi%0A%20%20fi%0A%20%20echo%20%22%22%0A%7D%0A%0Aget_ip_from_ip_hint_file()%20%7B%0A%20%20local%20ip_hint_file%3D%22%241%22%0A%20%20if%20%5B%5B%20!%20-f%20%22%24%7Bip_hint_file%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20return%0A%20%20fi%0A%20%20ip_hint%3D%24(cat%20%22%24%7Bip_hint_file%7D%22)%0A%20%20echo%20%22%24%7Bip_hint%7D%22%0A%7D%0A%0A%23%20This%20function%20waits%20for%20ip%20address%20of%20br-ex%20to%20be%20bindable%20only%20in%20case%20of%20ipv6%0A%23%20This%20is%20workaround%20for%20OCPBUGS-673%20as%20it%20will%20not%20allow%20starting%20crio%0A%23%20before%20address%20is%20bindable%0Atry_to_bind_ipv6_address()%20%7B%0A%20%20%23%20Retry%20for%201%20minute%0A%20%20retries%3D60%0A%20%20until%20%5B%5B%20%24%7Bretries%7D%20-eq%200%20%5D%5D%3B%20do%0A%20%20%20%20ip%3D%24(ip%20-6%20-j%20addr%20%7C%20jq%20-r%20%22first(.%5B%5D%20%7C%20select(.ifname%3D%3D%5C%22br-ex%5C%22)%20%7C%20.addr_info%5B%5D%20%7C%20select(.scope%3D%3D%5C%22global%5C%22)%20%7C%20.local)%22)%0A%20%20%20%20if%20%5B%5B%20%22%24%7Bip%7D%22%20%3D%3D%20%22%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22No%20ipv6%20ip%20to%20bind%20was%20found%22%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20%20%20random_port%3D%24(shuf%20-i%2050000-60000%20-n%201)%0A%20%20%20%20echo%20%22Trying%20to%20bind%20%24%7Bip%7D%20on%20port%20%24%7Brandom_port%7D%22%0A%20%20%20%20exit_code%3D%24(timeout%202s%20nc%20-l%20%22%24%7Bip%7D%22%20%24%7Brandom_port%7D%3B%20echo%20%24%3F)%0A%20%20%20%20if%20%5B%5B%20exit_code%20-eq%20124%20%5D%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22Address%20bound%20successfully%22%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20%20%20sleep%201%0A%20%20%20%20((%20retries--%20))%0A%20%20done%0A%20%20if%20%5B%5B%20%24%7Bretries%7D%20-eq%200%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22Failed%20to%20bind%20ip%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%7D%0A%0A%23%20Get%20interface%20that%20matches%20ip%20from%20node%20ip%20hint%20file%0A%23%20in%20case%20file%20not%20exists%20return%20nothing%20and%0A%23%20fallback%20to%20default%20interface%20search%20flow%0Aget_nodeip_hint_interface()%20%7B%0A%20%20local%20ip_hint%3D%22%22%0A%20%20local%20ip_hint_file%3D%22%241%22%0A%20%20local%20extra_bridge%3D%22%242%22%0A%20%20local%20iface%3D%22%22%0A%0A%20%20ip_hint%3D%24(get_ip_from_ip_hint_file%20%22%24%7Bip_hint_file%7D%22)%0A%20%20if%20%5B%5B%20-z%20%22%24%7Bip_hint%7D%22%20%20%5D%5D%3B%20then%0A%20%20%20%20return%0A%20%20fi%0A%0A%20%20iface%3D%24(ip%20-j%20addr%20%7C%20jq%20-r%20%22first(.%5B%5D%20%7C%20select(any(.addr_info%5B%5D%3B%20.local%3D%3D%5C%22%24%7Bip_hint%7D%5C%22)%20and%20.ifname!%3D%5C%22br-ex1%5C%22%20and%20.ifname!%3D%5C%22%24%7Bextra_bridge%7D%5C%22))%20%7C%20.ifname%22)%0A%20%20if%20%5B%5B%20-n%20%22%24%7Biface%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22%24%7Biface%7D%22%0A%20%20fi%0A%7D%0A%0A%23%20Accepts%20parameters%20%24bridge_interface%20(e.g.%20ovs-port-phys0)%0A%23%20Returns%20the%20physical%20interface%20name%20if%20%24bridge_interface%20exists%2C%20%22%22%20otherwise%0Aget_bridge_physical_interface()%20%7B%0A%20%20local%20bridge_interface%3D%22%241%22%0A%20%20local%20physical_interface%3D%22%22%0A%20%20physical_interface%3D%24(nmcli%20-g%20connection.interface-name%20conn%20show%20%22%24%7Bbridge_interface%7D%22%202%3E%2Fdev%2Fnull%20%7C%7C%20echo%20%22%22)%0A%20%20echo%20%22%24%7Bphysical_interface%7D%22%0A%7D%0A%0A%23%20Accepts%20parameters%20%24iface_default_hint_file%2C%20%24extra_bridge_file%2C%20%24ip_hint_file%2C%20%24default_bridge_file%0A%23%20Determines%20the%20interface%20to%20be%20used%20for%20br-ex.%20Order%20of%20priority%20is%3A%0A%23%201.%20Use%20the%20user%20specified%20interface%20if%20provided%20in%20the%20default%20bridge%20file%0A%23%202.%20Use%20the%20node%20IP%20hint%20interface%0A%23%203.%20Use%20the%20previously%20selected%20interface%0A%23%204.%20Use%20the%20interface%20detected%20as%20default%20gateway%0A%23%0A%23%20Read%20%24default_bridge_file%20and%20return%20the%20contained%20interface.%20Otherwise%2C%0A%23%20read%20%24ip_hint_file%20and%20return%20the%20interface%20that%20matches%20this%20ip.%20Otherwise%2C%0A%23%20if%20the%20default%20interface%20is%20br-ex%2C%20use%20that%20and%20return.%0A%23%20If%20the%20default%20interface%20is%20not%20br-ex%3A%0A%23%20Check%20if%20there%20is%20a%20valid%20hint%20inside%20%24iface_default_hint_file.%20If%20so%2C%20use%20that%20hint.%0A%23%20If%20there%20is%20no%20valid%20hint%2C%20use%20the%20default%20interface%20that%20we%20found%20during%20the%20step%0A%23%20earlier.%0A%23%20Never%20use%20the%20interface%20that%20is%20provided%20inside%20%24extra_bridge_file%20for%20br-ex1.%0A%23%20Never%20use%20br-ex1.%0A%23%20Write%20the%20default%20interface%20to%20%24iface_default_hint_file%0Aget_default_bridge_interface()%20%7B%0A%20%20local%20iface%3D%22%22%0A%20%20local%20counter%3D0%0A%20%20local%20iface_default_hint_file%3D%22%241%22%0A%20%20local%20extra_bridge_file%3D%22%242%22%0A%20%20local%20ip_hint_file%3D%22%243%22%0A%20%20local%20default_bridge_file%3D%22%244%22%0A%20%20local%20extra_bridge%3D%22%22%0A%0A%20%20if%20%5B%20-f%20%22%24%7Bextra_bridge_file%7D%22%20%5D%3B%20then%0A%20%20%20%20extra_bridge%3D%24(cat%20%24%7Bextra_bridge_file%7D)%0A%20%20fi%0A%0A%20%20%23%20try%20to%20use%20user%20specified%20file%20first%0A%20%20if%20%5B%20-f%20%22%24default_bridge_file%22%20%5D%3B%20then%0A%20%20%20%20iface%3D%24(cat%20%22%24%7Bdefault_bridge_file%7D%22)%0A%20%20%20%20if%20%5B%20-z%20%22%24iface%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22ERROR%3A%20User%20specified%20bridge%20file%20detected%20without%20any%20data%22%0A%20%20%20%20%20%20exit%201%0A%20%20%20%20fi%0A%20%20%20%20echo%20%22%24%7Biface%7D%22%0A%20%20%20%20return%0A%20%20fi%0A%0A%20%20%23%20if%20node%20ip%20was%20set%2C%20we%20should%20search%20for%20interface%20that%20matches%20it%0A%20%20iface%3D%24(get_nodeip_hint_interface%20%22%24%7Bip_hint_file%7D%22%20%22%24%7Bextra_bridge%7D%22)%0A%20%20if%20%5B%5B%20-n%20%22%24%7Biface%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22%24%7Biface%7D%22%0A%20%20%20%20return%0A%20%20fi%0A%0A%20%20%23%20find%20default%20interface%0A%20%20%23%20the%20default%20interface%20might%20be%20br-ex%2C%20so%20check%20this%20before%20looking%20at%20the%20hint%0A%20%20while%20%5B%20%24%7Bcounter%7D%20-lt%2012%20%5D%3B%20do%0A%20%20%20%20%23%20check%20ipv4%0A%20%20%20%20%23%20never%20use%20the%20interface%20that's%20specified%20in%20extra_bridge_file%0A%20%20%20%20%23%20never%20use%20br-ex1%0A%20%20%20%20if%20%5B%20%22%24%7Bextra_bridge%7D%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20iface%3D%24(ip%20route%20show%20default%20%7C%20grep%20-v%20%22br-ex1%22%20%7C%20grep%20-v%20%22%24%7Bextra_bridge%7D%22%20%7C%20awk%20'%7B%20if%20(%244%20%3D%3D%20%22dev%22)%20%7B%20print%20%245%3B%20exit%20%7D%20%7D')%0A%20%20%20%20else%0A%20%20%20%20%20%20iface%3D%24(ip%20route%20show%20default%20%7C%20grep%20-v%20%22br-ex1%22%20%7C%20awk%20'%7B%20if%20(%244%20%3D%3D%20%22dev%22)%20%7B%20print%20%245%3B%20exit%20%7D%20%7D')%0A%20%20%20%20fi%0A%20%20%20%20if%20%5B%5B%20-n%20%22%24%7Biface%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20%20%20%23%20check%20ipv6%0A%20%20%20%20%23%20never%20use%20the%20interface%20that's%20specified%20in%20extra_bridge_file%0A%20%20%20%20%23%20never%20use%20br-ex1%0A%20%20%20%20if%20%5B%20%22%24%7Bextra_bridge%7D%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20iface%3D%24(ip%20-6%20route%20show%20default%20%7C%20grep%20-v%20%22br-ex1%22%20%7C%20grep%20-v%20%22%24%7Bextra_bridge%7D%22%20%7C%20awk%20'%7B%20if%20(%244%20%3D%3D%20%22dev%22)%20%7B%20print%20%245%3B%20exit%20%7D%20%7D')%0A%20%20%20%20else%0A%20%20%20%20%20%20iface%3D%24(ip%20-6%20route%20show%20default%20%7C%20grep%20-v%20%22br-ex1%22%20%7C%20awk%20'%7B%20if%20(%244%20%3D%3D%20%22dev%22)%20%7B%20print%20%245%3B%20exit%20%7D%20%7D')%0A%20%20%20%20fi%0A%20%20%20%20if%20%5B%5B%20-n%20%22%24%7Biface%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20%20%20counter%3D%24((counter%2B1))%0A%20%20%20%20sleep%205%0A%20%20done%0A%0A%20%20%23%20if%20the%20default%20interface%20does%20not%20point%20out%20of%20br-ex%20or%20br-ex1%0A%20%20if%20%5B%20%22%24%7Biface%7D%22%20!%3D%20%22br-ex%22%20%5D%20%26%26%20%5B%20%22%24%7Biface%7D%22%20!%3D%20%22br-ex1%22%20%5D%3B%20then%0A%20%20%20%20%23%20determine%20if%20an%20interface%20default%20hint%20exists%20from%20a%20previous%20run%0A%20%20%20%20%23%20and%20if%20the%20interface%20has%20a%20valid%20default%20route%0A%20%20%20%20iface_default_hint%3D%24(get_iface_default_hint%20%22%24%7Biface_default_hint_file%7D%22)%0A%20%20%20%20if%20%5B%20%22%24%7Biface_default_hint%7D%22%20!%3D%20%22%22%20%5D%20%26%26%0A%20%20%20%20%20%20%20%20%5B%20%22%24%7Biface_default_hint%7D%22%20!%3D%20%22%24%7Biface%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%23%20start%20wherever%20count%20left%20off%20in%20the%20previous%20loop%0A%20%20%20%20%20%20%23%20allow%20this%20for%20one%20more%20iteration%20than%20the%20previous%20loop%0A%20%20%20%20%20%20while%20%5B%20%24%7Bcounter%7D%20-le%2012%20%5D%3B%20do%0A%20%20%20%20%20%20%20%20%23%20check%20ipv4%0A%20%20%20%20%20%20%20%20if%20%5B%20%22%24(ip%20route%20show%20default%20dev%20%22%24%7Biface_default_hint%7D%22)%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20iface%3D%22%24%7Biface_default_hint%7D%22%0A%20%20%20%20%20%20%20%20%20%20break%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20%23%20check%20ipv6%0A%20%20%20%20%20%20%20%20if%20%5B%20%22%24(ip%20-6%20route%20show%20default%20dev%20%22%24%7Biface_default_hint%7D%22)%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20iface%3D%22%24%7Biface_default_hint%7D%22%0A%20%20%20%20%20%20%20%20%20%20break%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20counter%3D%24((counter%2B1))%0A%20%20%20%20%20%20%20%20sleep%205%0A%20%20%20%20%20%20done%0A%20%20%20%20fi%0A%20%20%20%20%23%20store%20what%20was%20determined%20was%20the%20(new)%20default%20interface%20inside%0A%20%20%20%20%23%20the%20default%20hint%20file%20for%20future%20reference%0A%20%20%20%20if%20%5B%20%22%24%7Biface%7D%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20write_iface_default_hint%20%22%24%7Biface_default_hint_file%7D%22%20%22%24%7Biface%7D%22%0A%20%20%20%20fi%0A%20%20fi%0A%20%20echo%20%22%24%7Biface%7D%22%0A%7D%0A%0A%23%20Used%20to%20print%20network%20state%0Aprint_state()%20%7B%0A%20%20echo%20%22Current%20device%2C%20connection%2C%20interface%20and%20routing%20state%3A%22%0A%20%20nmcli%20-g%20all%20device%20%7C%20grep%20-v%20unmanaged%0A%20%20nmcli%20-g%20all%20connection%0A%20%20ip%20-d%20address%20show%0A%20%20ip%20route%20show%0A%20%20ip%20-6%20route%20show%0A%7D%0A%0A%23%20Setup%20an%20exit%20trap%20to%20rollback%20on%20error%0Ahandle_exit()%20%7B%0A%20%20e%3D%24%3F%0A%20%20tdir%3D%24(mktemp%20-u%20-d%20-t%20%22configure-ovs-%24(date%20%2B%25Y-%25m-%25d-%25H-%25M-%25S)-XXXXXXXXXX%22)%0A%20%20%0A%20%20if%20%5B%20%24e%20-eq%200%20%5D%3B%20then%0A%20%20%20%20print_state%0A%20%20%20%20%23%20remove%20previous%20troubleshooting%20information%0A%20%20%20%20rm%20-rf%20%22%24(dirname%20%22%24tdir%22)%2Fconfigure-ovs-*%22%0A%20%20%20%20exit%200%0A%20%20fi%0A%0A%20%20echo%20%22ERROR%3A%20configure-ovs%20exited%20with%20error%3A%20%24e%22%0A%20%20print_state%0A%0A%20%20%23%20remove%20previous%20troubleshooting%20information%20except%20the%20oldest%20one%0A%20%20mapfile%20-t%20tdirs%20%3C%20%3C(compgen%20-G%20%22%24(dirname%20%22%24tdir%22)%2Fconfigure-ovs-*%22)%0A%20%20unset%20-v%20%22tdirs%5B0%5D%22%0A%20%20for%20dir%20in%20%22%24%7Btdirs%5B%40%5D%7D%22%3B%20do%20rm%20-rf%20%22%24dir%22%3B%20done%0A%0A%20%20%23%20copy%20configuration%20to%20tmp%20for%20troubleshooting%0A%20%20mkdir%20-p%20%22%24tdir%22%0A%20%20update_nm_conn_run_files%20br-ex%20phys0%0A%20%20copy_nm_conn_files%20%22%24tdir%22%0A%20%20update_nm_conn_run_files%20br-ex1%20phys1%0A%20%20copy_nm_conn_files%20%22%24tdir%22%0A%20%20echo%20%22Copied%20OVS%20configuration%20to%20%24tdir%20for%20troubleshooting%22%0A%0A%20%20%23%20attempt%20to%20restore%20the%20previous%20network%20state%0A%20%20echo%20%22Attempting%20to%20restore%20previous%20configuration...%22%0A%20%20rollback_nm%0A%20%20print_state%0A%0A%20%20exit%20%24e%0A%7D%0A%0A%23%20Setup%20a%20signal%20trap%20to%20rollback%0Ahandle_termination()%20%7B%0A%20%20echo%20%22WARNING%3A%20configure-ovs%20has%20been%20requested%20to%20terminate%2C%20quitting...%22%0A%20%20%0A%20%20%23%20by%20exiting%20with%20an%20error%20we%20will%20cleanup%20after%20ourselves%20in%20a%0A%20%20%23%20subsequent%20call%20to%20handle_exit%0A%20%20exit%201%0A%7D%0A%0A%23%20main%20function%0Aconfigure_ovs()%20%7B%0A%20%20set%20-eu%0A%0A%20%20%23%20setup%20traps%20to%20handle%20signals%20and%20other%20abnormal%20exits%0A%20%20trap%20'handle_termination'%20TERM%20INT%0A%20%20trap%20'handle_exit'%20EXIT%0A%0A%20%20%23%20this%20flag%20tracks%20if%20any%20config%20change%20was%20made%0A%20%20nm_config_changed%3D0%0A%0A%20%20%23%20Check%20that%20we%20are%20provided%20a%20valid%20NM%20connection%20path%0A%20%20if%20%5B%20%22%24NM_CONN_SET_PATH%22%20!%3D%20%22%24NM_CONN_CONF_PATH%22%20%5D%20%26%26%20%5B%20%22%24NM_CONN_SET_PATH%22%20!%3D%20%22%24NM_CONN_RUN_PATH%22%20%5D%3B%20then%0A%20%20%20%20echo%20%22Error%3A%20Incorrect%20NM%20connection%20path%3A%20%24NM_CONN_SET_PATH%20is%20not%20%24NM_CONN_CONF_PATH%20nor%20%24NM_CONN_RUN_PATH%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%0A%20%20%23%20Clean%20up%20old%20config%20on%20behalf%20of%20mtu-migration%0A%20%20if%20!%20systemctl%20-q%20is-enabled%20mtu-migration%3B%20then%0A%20%20%20%20echo%20%22Cleaning%20up%20left%20over%20mtu%20migration%20configuration%22%0A%20%20%20%20rm%20-rf%20%2Fetc%2Fcno%2Fmtu-migration%0A%20%20fi%0A%0A%20%20if%20!%20rpm%20-qa%20%7C%20grep%20-q%20openvswitch%3B%20then%0A%20%20%20%20echo%20%22WARNING%3A%20Openvswitch%20package%20is%20not%20installed!%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%0A%20%20%23%20print%20initial%20state%0A%20%20print_state%0A%0A%20%20if%20%5B%20%22%241%22%20%3D%3D%20%22OVNKubernetes%22%20%5D%3B%20then%0A%20%20%20%20%23%20Configures%20NICs%20onto%20OVS%20bridge%20%22br-ex%22%0A%20%20%20%20%23%20Configuration%20is%20either%20auto-detected%20or%20provided%20through%20a%20config%20file%20written%20already%20in%20Network%20Manager%0A%20%20%20%20%23%20key%20files%20under%20%2Fetc%2FNetworkManager%2Fsystem-connections%2F%0A%20%20%20%20%23%20Managing%20key%20files%20is%20outside%20of%20the%20scope%20of%20this%20script%0A%0A%20%20%20%20%23%20if%20the%20interface%20is%20of%20type%20vmxnet3%20add%20multicast%20capability%20for%20that%20driver%0A%20%20%20%20%23%20History%3A%20BZ%3A1854355%0A%20%20%20%20function%20configure_driver_options%20%7B%0A%20%20%20%20%20%20intf%3D%241%0A%20%20%20%20%20%20if%20%5B%20!%20-f%20%22%2Fsys%2Fclass%2Fnet%2F%24%7Bintf%7D%2Fdevice%2Fuevent%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22Device%20file%20doesn't%20exist%2C%20skipping%20setting%20multicast%20mode%22%0A%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20driver%3D%24(cat%20%22%2Fsys%2Fclass%2Fnet%2F%24%7Bintf%7D%2Fdevice%2Fuevent%22%20%7C%20grep%20DRIVER%20%7C%20awk%20-F%20%22%3D%22%20'%7Bprint%20%242%7D')%0A%20%20%20%20%20%20%20%20echo%20%22Driver%20name%20is%22%20%24driver%0A%20%20%20%20%20%20%20%20if%20%5B%20%22%24driver%22%20%3D%20%22vmxnet3%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20ip%20link%20set%20dev%20%22%24%7Bintf%7D%22%20allmulticast%20on%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20fi%0A%20%20%20%20%7D%0A%0A%20%20%20%20ovnk_config_dir%3D'%2Fetc%2Fovnk'%0A%20%20%20%20ovnk_var_dir%3D'%2Fvar%2Flib%2Fovnk'%0A%20%20%20%20extra_bridge_file%3D%22%24%7Bovnk_config_dir%7D%2Fextra_bridge%22%0A%20%20%20%20iface_default_hint_file%3D%22%24%7Bovnk_var_dir%7D%2Fiface_default_hint%22%0A%20%20%20%20ip_hint_file%3D%22%2Frun%2Fnodeip-configuration%2Fprimary-ip%22%0A%20%20%20%20%23%20explicitly%20specify%20which%20interface%20should%20be%20used%20with%20the%20default%20bridge%0A%20%20%20%20default_bridge_file%3D%22%24%7Bovnk_config_dir%7D%2Fdefault_bridge%22%0A%0A%20%20%20%20%23%20make%20sure%20to%20create%20ovnk_config_dir%20if%20it%20does%20not%20exist%2C%20yet%0A%20%20%20%20mkdir%20-p%20%22%24%7Bovnk_config_dir%7D%22%0A%20%20%20%20%23%20make%20sure%20to%20create%20ovnk_var_dir%20if%20it%20does%20not%20exist%2C%20yet%0A%20%20%20%20mkdir%20-p%20%22%24%7Bovnk_var_dir%7D%22%0A%0A%20%20%20%20%23%20For%20upgrade%20scenarios%2C%20make%20sure%20that%20we%20stabilize%20what%20we%20already%20configured%0A%20%20%20%20%23%20before.%20If%20we%20do%20not%20have%20a%20valid%20interface%20hint%2C%20find%20the%20physical%20interface%0A%20%20%20%20%23%20that's%20attached%20to%20ovs-if-phys0.%0A%20%20%20%20%23%20If%20we%20find%20such%20an%20interface%2C%20write%20it%20to%20the%20hint%20file.%0A%20%20%20%20iface_default_hint%3D%24(get_iface_default_hint%20%22%24%7Biface_default_hint_file%7D%22)%0A%20%20%20%20if%20%5B%20%22%24%7Biface_default_hint%7D%22%20%3D%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20current_interface%3D%24(get_bridge_physical_interface%20ovs-if-phys0)%0A%20%20%20%20%20%20if%20%5B%20%22%24%7Bcurrent_interface%7D%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20write_iface_default_hint%20%22%24%7Biface_default_hint_file%7D%22%20%22%24%7Bcurrent_interface%7D%22%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20delete%20iface_default_hint_file%20if%20it%20has%20the%20same%20content%20as%20extra_bridge_file%0A%20%20%20%20%23%20in%20that%20case%2C%20we%20must%20also%20force%20a%20reconfiguration%20of%20our%20network%20interfaces%0A%20%20%20%20%23%20to%20make%20sure%20that%20we%20reconcile%20this%20conflict%0A%20%20%20%20if%20%5B%20-f%20%22%24%7Biface_default_hint_file%7D%22%20%5D%20%26%26%0A%20%20%20%20%20%20%5B%20-f%20%22%24%7Bextra_bridge_file%7D%22%20%5D%20%26%26%0A%20%20%20%20%20%20%5B%20%22%24(cat%20%22%24%7Biface_default_hint_file%7D%22)%22%20%3D%3D%20%22%24(cat%20%22%24%7Bextra_bridge_file%7D%22)%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22%24%7Biface_default_hint_file%7D%20and%20%24%7Bextra_bridge_file%7D%20share%20the%20same%20content%22%0A%20%20%20%20%20%20echo%20%22Deleting%20file%20%24%7Biface_default_hint_file%7D%20to%20choose%20a%20different%20interface%22%0A%20%20%20%20%20%20rm%20-f%20%22%24%7Biface_default_hint_file%7D%22%0A%20%20%20%20%20%20rm%20-f%20%2Frun%2Fconfigure-ovs-boot-done%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20on%20every%20boot%20we%20rollback%20and%20generate%20the%20configuration%20again%2C%20to%20take%0A%20%20%20%20%23%20in%20any%20changes%20that%20have%20possibly%20been%20applied%20in%20the%20standard%0A%20%20%20%20%23%20configuration%20sources%0A%20%20%20%20if%20%5B%20!%20-f%20%2Frun%2Fconfigure-ovs-boot-done%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22Running%20on%20boot%2C%20restoring%20previous%20configuration%20before%20proceeding...%22%0A%20%20%20%20%20%20rollback_nm%0A%20%20%20%20%20%20print_state%0A%20%20%20%20fi%0A%20%20%20%20touch%20%2Frun%2Fconfigure-ovs-boot-done%0A%0A%20%20%20%20iface%3D%24(get_default_bridge_interface%20%22%24%7Biface_default_hint_file%7D%22%20%22%24%7Bextra_bridge_file%7D%22%20%22%24%7Bip_hint_file%7D%22%20%22%24%7Bdefault_bridge_file%7D%22)%0A%0A%20%20%20%20if%20%5B%20%22%24iface%22%20!%3D%20%22br-ex%22%20%5D%3B%20then%0A%20%20%20%20%20%20%23%20Specified%20interface%20is%20not%20br-ex.%0A%20%20%20%20%20%20%23%20Some%20deployments%20use%20a%20temporary%20solution%20where%20br-ex%20is%20moved%20out%20from%20the%20default%20gateway%20interface%0A%20%20%20%20%20%20%23%20and%20bound%20to%20a%20different%20nic%20(https%3A%2F%2Fgithub.com%2Ftrozet%2Fopenshift-ovn-migration).%0A%20%20%20%20%20%20%23%20This%20is%20now%20supported%20through%20an%20extra%20bridge%20if%20requested.%20If%20that%20is%20the%20case%2C%20we%20rollback.%0A%20%20%20%20%20%20%23%20We%20also%20rollback%20if%20it%20looks%20like%20we%20need%20to%20configure%20things%2C%20just%20in%20case%20there%20are%20any%20leftovers%0A%20%20%20%20%20%20%23%20from%20previous%20attempts.%0A%20%20%20%20%20%20if%20%5B%20-f%20%22%24extra_bridge_file%22%20%5D%20%7C%7C%20%5B%20-z%20%22%24(nmcli%20connection%20show%20--active%20br-ex%202%3E%20%2Fdev%2Fnull)%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22Bridge%20br-ex%20is%20not%20active%2C%20restoring%20previous%20configuration%20before%20proceeding...%22%0A%20%20%20%20%20%20%20%20rollback_nm%0A%20%20%20%20%20%20%20%20print_state%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20convert_to_bridge%20%22%24iface%22%20%22br-ex%22%20%22phys0%22%20%22%24%7BBRIDGE_METRIC%7D%22%0A%0A%20%20%20%20%23%20Check%20if%20we%20need%20to%20configure%20the%20second%20bridge%0A%20%20%20%20if%20%5B%20-f%20%22%24extra_bridge_file%22%20%5D%20%26%26%20(!%20nmcli%20connection%20show%20br-ex1%20%26%3E%20%2Fdev%2Fnull%20%7C%7C%20!%20nmcli%20connection%20show%20ovs-if-phys1%20%26%3E%20%2Fdev%2Fnull)%3B%20then%0A%20%20%20%20%20%20interface%3D%24(head%20-n%201%20%24extra_bridge_file)%0A%20%20%20%20%20%20convert_to_bridge%20%22%24interface%22%20%22br-ex1%22%20%22phys1%22%20%22%24%7BBRIDGE1_METRIC%7D%22%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Check%20if%20we%20need%20to%20remove%20the%20second%20bridge%0A%20%20%20%20if%20%5B%20!%20-f%20%22%24extra_bridge_file%22%20%5D%20%26%26%20(nmcli%20connection%20show%20br-ex1%20%26%3E%20%2Fdev%2Fnull%20%7C%7C%20nmcli%20connection%20show%20ovs-if-phys1%20%26%3E%20%2Fdev%2Fnull)%3B%20then%0A%20%20%20%20%20%20remove_ovn_bridges%20br-ex1%20phys1%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Remove%20bridges%20created%20by%20openshift-sdn%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-br%20br0%0A%0A%20%20%20%20%23%20Make%20sure%20everything%20is%20activated.%20Do%20it%20in%20a%20specific%20order%3A%0A%20%20%20%20%23%20-%20activate%20br-ex%20first%2C%20due%20to%20autoconnect-slaves%20this%20will%20also%0A%20%20%20%20%23%20%20%20activate%20ovs-port-br-ex%2C%20ovs-port-phys0%20and%20ovs-if-phys0.%20It%20is%0A%20%20%20%20%23%20%20%20important%20that%20ovs-if-phys0%20activates%20with%20br-ex%20to%20avoid%20the%0A%20%20%20%20%23%20%20%20ovs-if-phys0%20profile%20being%20overridden%20with%20a%20profile%20generated%20from%0A%20%20%20%20%23%20%20%20kargs.%20The%20activation%20of%20ovs-if-phys0%2C%20if%20a%20bond%2C%20might%20cause%20the%0A%20%20%20%20%23%20%20%20slaves%20to%20re-activate%2C%20but%20it%20should%20be%20with%20our%20profiles%20since%20they%0A%20%20%20%20%23%20%20%20have%20higher%20priority%0A%20%20%20%20%23%20-%20make%20sure%20that%20ovs-if-phys0%20and%20its%20slaves%2C%20if%20any%2C%20are%20activated.%0A%20%20%20%20%23%20-%20finally%20activate%20ovs-if-br-ex%20which%20holds%20the%20IP%20configuration.%0A%20%20%20%20connections%3D(br-ex%20ovs-if-phys0)%0A%20%20%20%20if%20%5B%20-f%20%22%24extra_bridge_file%22%20%5D%3B%20then%0A%20%20%20%20%20%20connections%2B%3D(br-ex1%20ovs-if-phys1)%0A%20%20%20%20fi%0A%20%20%20%20while%20IFS%3D%20read%20-r%20connection%3B%20do%0A%20%20%20%20%20%20if%20%5B%5B%20%24connection%20%3D%3D%20*%22%24MANAGED_NM_CONN_SUFFIX%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20connections%2B%3D(%22%24connection%22)%0A%20%20%20%20%20%20fi%0A%20%20%20%20done%20%3C%20%3C(nmcli%20-g%20NAME%20c)%0A%20%20%20%20connections%2B%3D(ovs-if-br-ex)%0A%20%20%20%20if%20%5B%20-f%20%22%24extra_bridge_file%22%20%5D%3B%20then%0A%20%20%20%20%20%20connections%2B%3D(ovs-if-br-ex1)%0A%20%20%20%20fi%0A%20%20%20%20activate_nm_connections%20%22%24%7Bconnections%5B%40%5D%7D%22%0A%20%20%20%20try_to_bind_ipv6_address%0A%20%20%20%20set_nm_conn_files%0A%20%20elif%20%5B%20%22%241%22%20%3D%3D%20%22OpenShiftSDN%22%20%5D%3B%20then%0A%20%20%20%20%23%20Revert%20changes%20made%20by%20%2Fusr%2Flocal%2Fbin%2Fconfigure-ovs.sh%20during%20SDN%20migration.%0A%20%20%20%20rollback_nm%0A%20%20%20%20%0A%20%20%20%20%23%20Remove%20bridges%20created%20by%20ovn-kubernetes%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-br%20br-int%20--%20--if-exists%20del-br%20br-local%0A%20%20fi%0A%7D%0A%0A%23%20Retry%20configure_ovs%20until%20it%20succeeds.%0A%23%20By%20default%2C%20retry%20every%2015%20minutes%20to%20give%20enough%20time%20to%20gather%0A%23%20troubleshooting%20information%20in%20between.%20Note%20that%20configure_ovs%20has%20other%0A%23%20internal%20retry%20mechanisms.%20This%20retry%20is%20intended%20to%20give%20some%0A%23%20self-healing%20capabilities%20to%20temporary%20but%20not%20necessarily%20short-lived%0A%23%20infrastructure%20problems.%0ARETRY%3D%22%24%7BRETRY-15m%7D%22%0Awhile%20true%3B%20do%0A%0A%20%20%23%20Disable%20retries%20if%20termination%20signal%20is%20received.%20Note%20that%20systemd%0A%20%20%23%20sends%20the%20signals%20to%20all%20processes%20in%20the%20group%20by%20default%20so%20we%20expect%0A%20%20%23%20configure_ovs%20to%20get%20its%20own%20signals.%0A%20%20trap%20'echo%20%22WARNING%3A%20termination%20requested%2C%20disabling%20retries%22%3B%20RETRY%3D%22%22'%20INT%20TERM%0A%20%20%0A%20%20%23%20Run%20configure_ovs%20in%20a%20sub-shell.%20%0A%20%20(%20configure_ovs%20%22%24%40%22%20)%0A%20%20e%3D%24%3F%0A%0A%20%20%23%20Handle%20signals%20while%20we%20sleep%0A%20%20trap%20'handle_termination'%20INT%20TERM%0A%20%20%0A%20%20%23%20Exit%20if%20succesful%20and%20not%20configured%20to%20retry%0A%20%20%5B%20%22%24e%22%20-eq%200%20%5D%20%7C%7C%20%5B%20-z%20%22%24RETRY%22%20%5D%20%26%26%20exit%20%22%24e%22%0A%20%20%0A%20%20echo%20%22configure-ovs%20failed%2C%20will%20retry%20after%20%24RETRY%22%0A%20%20%23%20flag%20that%20a%20retry%20has%20happened%0A%20%20touch%20%2Ftmp%2Fconfigure-ovs-retry%0A%20%20sleep%20%22%24RETRY%22%0A%0Adone%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/configure-ovs.sh
        - contents:
            source: data:,%23%20This%20file%20is%20generated%20by%20the%20Machine%20Config%20Operator's%20containerruntimeconfig%20controller.%0A%23%0A%23%20storage.conf%20is%20the%20configuration%20file%20for%20all%20tools%0A%23%20that%20share%20the%20containers%2Fstorage%20libraries%0A%23%20See%20man%205%20containers-storage.conf%20for%20more%20information%0A%23%20The%20%22container%20storage%22%20table%20contains%20all%20of%20the%20server%20options.%0A%5Bstorage%5D%0A%0A%23%20Default%20storage%20driver%2C%20must%20be%20set%20for%20proper%20operation.%0Adriver%20%3D%20%22overlay%22%0A%0A%23%20Temporary%20storage%20location%0Arunroot%20%3D%20%22%2Frun%2Fcontainers%2Fstorage%22%0A%0A%23%20Primary%20Read%2FWrite%20location%20of%20container%20storage%0Agraphroot%20%3D%20%22%2Fvar%2Flib%2Fcontainers%2Fstorage%22%0A%0A%5Bstorage.options%5D%0A%23%20Storage%20options%20to%20be%20passed%20to%20underlying%20storage%20drivers%0A%0A%23%20AdditionalImageStores%20is%20used%20to%20pass%20paths%20to%20additional%20Read%2FOnly%20image%20stores%0A%23%20Must%20be%20comma%20separated%20list.%0Aadditionalimagestores%20%3D%20%5B%0A%5D%0A%0A%23%20Remap-UIDs%2FGIDs%20is%20the%20mapping%20from%20UIDs%2FGIDs%20as%20they%20should%20appear%20inside%20of%0A%23%20a%20container%2C%20to%20UIDs%2FGIDs%20as%20they%20should%20appear%20outside%20of%20the%20container%2C%20and%0A%23%20the%20length%20of%20the%20range%20of%20UIDs%2FGIDs.%20%20Additional%20mapped%20sets%20can%20be%20listed%0A%23%20and%20will%20be%20heeded%20by%20libraries%2C%20but%20there%20are%20limits%20to%20the%20number%20of%0A%23%20mappings%20which%20the%20kernel%20will%20allow%20when%20you%20later%20attempt%20to%20run%20a%0A%23%20container.%0A%23%0A%23%20remap-uids%20%3D%200%3A1668442479%3A65536%0A%23%20remap-gids%20%3D%200%3A1668442479%3A65536%0A%0A%23%20Remap-User%2FGroup%20is%20a%20name%20which%20can%20be%20used%20to%20look%20up%20one%20or%20more%20UID%2FGID%0A%23%20ranges%20in%20the%20%2Fetc%2Fsubuid%20or%20%2Fetc%2Fsubgid%20file.%20%20Mappings%20are%20set%20up%20starting%0A%23%20with%20an%20in-container%20ID%20of%200%20and%20the%20a%20host-level%20ID%20taken%20from%20the%20lowest%0A%23%20range%20that%20matches%20the%20specified%20name%2C%20and%20using%20the%20length%20of%20that%20range.%0A%23%20Additional%20ranges%20are%20then%20assigned%2C%20using%20the%20ranges%20which%20specify%20the%0A%23%20lowest%20host-level%20IDs%20first%2C%20to%20the%20lowest%20not-yet-mapped%20container-level%20ID%2C%0A%23%20until%20all%20of%20the%20entries%20have%20been%20used%20for%20maps.%20This%20setting%20overrides%20the%0A%23%20Remap-UIDs%2FGIDs%20setting.%0A%23%0A%23%20remap-user%20%3D%20%22storage%22%0A%23%20remap-group%20%3D%20%22storage%22%0A%0A%5Bstorage.options.pull_options%5D%0A%23%20Options%20controlling%20how%20storage%20is%20populated%20when%20pulling%20images.%0A%0A%23%20Enable%20the%20%22zstd%3Achunked%22%20feature%2C%20which%20allows%20partial%20pulls%2C%20reusing%0A%23%20content%20that%20already%20exists%20on%20the%20system.%20This%20is%20disabled%20by%20default%2C%0A%23%20and%20must%20be%20explicitly%20enabled%20to%20be%20used.%20For%20more%20on%20zstd%3Achunked%2C%20see%0A%23%20https%3A%2F%2Fgithub.com%2Fcontainers%2Fstorage%2Fblob%2Fmain%2Fdocs%2Fcontainers-storage-zstd-chunked.md%0Aenable_partial_images%20%3D%20%22false%22%0A%0A%23%20Tells%20containers%2Fstorage%20to%20use%20hard%20links%20rather%20then%20create%20new%20files%20in%0A%23%20the%20image%2C%20if%20an%20identical%20file%20already%20existed%20in%20storage.%0Ause_hard_links%20%3D%20%22false%22%0A%0A%23%20Path%20to%20an%20ostree%20repository%20that%20might%20have%0A%23%20previously%20pulled%20content%20which%20can%20be%20used%20when%20attempting%20to%20avoid%0A%23%20pulling%20content%20from%20the%20container%20registry.%0Aostree_repos%20%3D%20%22%22%0A%0A%5Bstorage.options.overlay%5D%0A%23%20Storage%20Options%20for%20overlay%0A%0A%23%20Do%20not%20create%20a%20PRIVATE%20bind%20mount%20on%20the%20home%20directory.%0Askip_mount_home%20%3D%20%22true%22%0A%0A%23%20Size%20is%20used%20to%20set%20a%20maximum%20size%20of%20the%20container%20image.%20%20Only%20supported%20by%0A%23%20certain%20container%20storage%20drivers.%0Asize%20%3D%20%22%22%0A
          mode: 420
          overwrite: true
          path: /etc/containers/storage.conf
        - contents:
            source: data:,.%20%7B%0A%20%20%20%20errors%0A%20%20%20%20bufsize%20512%0A%20%20%20%20health%20%3A18080%0A%20%20%20%20forward%20.%20%7B%7B-%20range%20%24upstream%20%3A%3D%20.DNSUpstreams%7D%7D%20%7B%7B%24upstream%7D%7D%7B%7B-%20end%7D%7D%20%7B%0A%20%20%20%20%20%20%20%20policy%20sequential%0A%20%20%20%20%7D%0A%20%20%20%20cache%2030%0A%20%20%20%20reload%0A%20%20%20%20template%20IN%20%7B%7B%20.Cluster.IngressVIPRecordType%20%7D%7D%20comp-poc-rh01.rhpoc.int%20%7B%0A%20%20%20%20%20%20%20%20match%20.*%5B.%5Dapps.comp-poc-rh01.rhpoc.int%0A%20%20%20%20%20%20%20%20answer%20%22%7B%7B%22%7B%7B%20.Name%20%7D%7D%22%7D%7D%2060%20in%20%7B%7B%22%7B%7B%20.Type%20%7D%7D%22%7D%7D%2010.100.0.51%22%0A%20%20%20%20%20%20%20%20fallthrough%0A%20%20%20%20%7D%0A%20%20%20%20template%20IN%20%7B%7B%20.Cluster.IngressVIPEmptyType%20%7D%7D%20comp-poc-rh01.rhpoc.int%20%7B%0A%20%20%20%20%20%20%20%20match%20.*%5B.%5Dapps.comp-poc-rh01.rhpoc.int%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20fallthrough%0A%20%20%20%20%7D%0A%20%20%20%20template%20IN%20%7B%7B%20.Cluster.APIVIPRecordType%20%7D%7D%20comp-poc-rh01.rhpoc.int%20%7B%0A%20%20%20%20%20%20%20%20match%20%5Eapi.comp-poc-rh01.rhpoc.int%0A%20%20%20%20%20%20%20%20answer%20%22%7B%7B%22%7B%7B%20.Name%20%7D%7D%22%7D%7D%2060%20in%20%7B%7B%22%7B%7B%20.Type%20%7D%7D%22%7D%7D%2010.100.0.50%22%0A%20%20%20%20%20%20%20%20fallthrough%0A%20%20%20%20%7D%0A%20%20%20%20template%20IN%20%7B%7B%20.Cluster.APIVIPEmptyType%20%7D%7D%20comp-poc-rh01.rhpoc.int%20%7B%0A%20%20%20%20%20%20%20%20match%20%5Eapi.comp-poc-rh01.rhpoc.int%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20fallthrough%0A%20%20%20%20%7D%0A%20%20%20%20template%20IN%20%7B%7B%20.Cluster.APIVIPRecordType%20%7D%7D%20comp-poc-rh01.rhpoc.int%20%7B%0A%20%20%20%20%20%20%20%20match%20%5Eapi-int.comp-poc-rh01.rhpoc.int%0A%20%20%20%20%20%20%20%20answer%20%22%7B%7B%22%7B%7B%20.Name%20%7D%7D%22%7D%7D%2060%20in%20%7B%7B%22%7B%7B%20.Type%20%7D%7D%22%7D%7D%2010.100.0.50%22%0A%20%20%20%20%20%20%20%20fallthrough%0A%20%20%20%20%7D%0A%20%20%20%20template%20IN%20%7B%7B%20.Cluster.APIVIPEmptyType%20%7D%7D%20comp-poc-rh01.rhpoc.int%20%7B%0A%20%20%20%20%20%20%20%20match%20%5Eapi-int.comp-poc-rh01.rhpoc.int%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20fallthrough%0A%20%20%20%20%7D%0A%20%20%20%20hosts%20%7B%0A%20%20%20%20%20%20%20%20%7B%7B-%20range%20.Cluster.NodeAddresses%20%7D%7D%0A%20%20%20%20%20%20%20%20%7B%7B%20.Address%20%7D%7D%20%7B%7B%20.Name%20%7D%7D%20%7B%7B%20.Name%20%7D%7D.%7B%7B%20%24.Cluster.Name%20%7D%7D.%7B%7B%20%24.Cluster.Domain%20%7D%7D%0A%20%20%20%20%20%20%20%20%7B%7B-%20end%20%7D%7D%0A%20%20%20%20%20%20%20%20fallthrough%0A%20%20%20%20%7D%0A%7D%0A
          mode: 420
          overwrite: true
          path: /etc/kubernetes/static-pod-resources/coredns/Corefile.tmpl
        - contents:
            source: data:,kind%3A%20Pod%0AapiVersion%3A%20v1%0Ametadata%3A%0A%20%20name%3A%20coredns%0A%20%20namespace%3A%20openshift-kni-infra%0A%20%20creationTimestamp%3A%0A%20%20deletionGracePeriodSeconds%3A%2065%0A%20%20labels%3A%0A%20%20%20%20app%3A%20kni-infra-coredns%0A%20%20annotations%3A%0A%20%20%20%20target.workload.openshift.io%2Fmanagement%3A%20'%7B%22effect%22%3A%20%22PreferredDuringScheduling%22%7D'%0A%20%20%20%20openshift.io%2Frequired-scc%3A%20privileged%0Aspec%3A%0A%20%20volumes%3A%0A%20%20-%20name%3A%20resource-dir%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fetc%2Fkubernetes%2Fstatic-pod-resources%2Fcoredns%22%0A%20%20-%20name%3A%20kubeconfig%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20-%20name%3A%20conf-dir%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fetc%2Fcoredns%22%0A%20%20-%20name%3A%20nm-resolv%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fvar%2Frun%2FNetworkManager%22%0A%20%20-%20name%3A%20nodeip-configuration%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Frun%2Fnodeip-configuration%22%0A%20%20initContainers%3A%0A%20%20-%20name%3A%20render-config-coredns%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A93e7b8c870261726d44bddc7ba0a702d3720d1838141dac837fb8c3be7c6e1a1%0A%20%20%20%20command%3A%0A%20%20%20%20-%20runtimecfg%0A%20%20%20%20-%20render%0A%20%20%20%20-%20%22%2Fvar%2Flib%2Fkubelet%2Fkubeconfig%22%0A%20%20%20%20-%20%22--api-vips%22%0A%20%20%20%20-%20%2210.100.0.50%22%0A%20%20%20%20-%20%22--ingress-vips%22%0A%20%20%20%20-%20%2210.100.0.51%22%0A%20%20%20%20-%20%22%2Fconfig%22%0A%20%20%20%20-%20%22--out-dir%22%0A%20%20%20%20-%20%22%2Fetc%2Fcoredns%22%0A%20%20%20%20-%20%22--resolvconf-path%22%0A%20%20%20%20-%20%22%2Fvar%2Frun%2FNetworkManager%2Fresolv.conf%22%0A%20%20%20%20resources%3A%20%7B%7D%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20kubeconfig%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20resource-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fconfig%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20conf-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fcoredns%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20nm-resolv%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Frun%2FNetworkManager%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20nodeip-configuration%0A%20%20%20%20%20%20mountPath%3A%20%22%2Frun%2Fnodeip-configuration%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20imagePullPolicy%3A%20IfNotPresent%0A%20%20containers%3A%0A%20%20-%20name%3A%20coredns%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A4f6294ed30ab476019aaaa77874157facc77413988f82ffc46f94d3a98d2e4f1%0A%20%20%20%20args%3A%0A%20%20%20%20-%20%22--conf%22%0A%20%20%20%20-%20%22%2Fetc%2Fcoredns%2FCorefile%22%0A%20%20%20%20resources%3A%0A%20%20%20%20%20%20requests%3A%0A%20%20%20%20%20%20%20%20cpu%3A%20100m%0A%20%20%20%20%20%20%20%20memory%3A%20200Mi%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20conf-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fcoredns%22%0A%20%20%20%20-%20name%3A%20nodeip-configuration%0A%20%20%20%20%20%20mountPath%3A%20%22%2Frun%2Fnodeip-configuration%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20livenessProbe%3A%0A%20%20%20%20%20%20httpGet%3A%0A%20%20%20%20%20%20%20%20path%3A%20%2Fhealth%0A%20%20%20%20%20%20%20%20port%3A%2018080%0A%20%20%20%20%20%20%20%20scheme%3A%20HTTP%0A%20%20%20%20%20%20initialDelaySeconds%3A%2060%0A%20%20%20%20%20%20timeoutSeconds%3A%205%0A%20%20%20%20%20%20successThreshold%3A%201%0A%20%20%20%20%20%20failureThreshold%3A%205%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20imagePullPolicy%3A%20IfNotPresent%0A%20%20-%20name%3A%20coredns-monitor%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A93e7b8c870261726d44bddc7ba0a702d3720d1838141dac837fb8c3be7c6e1a1%0A%20%20%20%20command%3A%0A%20%20%20%20-%20corednsmonitor%0A%20%20%20%20-%20%22%2Fvar%2Flib%2Fkubelet%2Fkubeconfig%22%0A%20%20%20%20-%20%22%2Fconfig%2FCorefile.tmpl%22%0A%20%20%20%20-%20%22%2Fetc%2Fcoredns%2FCorefile%22%0A%20%20%20%20-%20%22--api-vips%22%0A%20%20%20%20-%20%2210.100.0.50%22%0A%20%20%20%20-%20%22--ingress-vips%22%0A%20%20%20%20-%20%2210.100.0.51%22%0A%20%20%20%20resources%3A%0A%20%20%20%20%20%20requests%3A%0A%20%20%20%20%20%20%20%20cpu%3A%20100m%0A%20%20%20%20%20%20%20%20memory%3A%20200Mi%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20kubeconfig%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20resource-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fconfig%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20conf-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fcoredns%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20nm-resolv%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Frun%2FNetworkManager%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20nodeip-configuration%0A%20%20%20%20%20%20mountPath%3A%20%22%2Frun%2Fnodeip-configuration%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20imagePullPolicy%3A%20IfNotPresent%0A%20%20hostNetwork%3A%20true%0A%20%20tolerations%3A%0A%20%20-%20operator%3A%20Exists%0A%20%20priorityClassName%3A%20system-node-critical%0Astatus%3A%20%7B%7D%0A
          mode: 420
          overwrite: true
          path: /etc/kubernetes/manifests/coredns.yaml
        - contents:
            source: data:,Initial%20Creation%0A
          mode: 384
          overwrite: true
          path: /etc/docker/certs.d/.create
        - contents:
            source: data:,%23%20Proxy%20environment%20variables%20will%20be%20populated%20in%20this%20file.%20Properly%0A%23%20url%20encoded%20passwords%20with%20special%20characters%20will%20use%20'%25%3CHEX%3E%3CHEX%3E'.%0A%23%20Systemd%20requires%20that%20any%20%25%20used%20in%20a%20password%20be%20represented%20as%0A%23%20%25%25%20in%20a%20unit%20file%20since%20%25%20is%20a%20prefix%20for%20macros%3B%20this%20restriction%20does%20not%0A%23%20apply%20for%20environment%20files.%20Templates%20that%20need%20the%20proxy%20set%20should%20use%0A%23%20'EnvironmentFile%3D%2Fetc%2Fmco%2Fproxy.env'.%0A
          mode: 420
          overwrite: true
          path: /etc/mco/proxy.env
        - contents:
            source: data:,%5BManager%5D%0ADefaultEnvironment%3DGODEBUG%3Dx509ignoreCN%3D0%0A
          mode: 420
          overwrite: true
          path: /etc/systemd/system.conf.d/10-default-env-godebug.conf
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%23%20Workaround%3A%0A%23%20https%3A%2F%2Fissues.redhat.com%2Fbrowse%2FOCPBUGS-38779%0A%0Adriver%3D%24(nmcli%20-t%20-m%20tabular%20-f%20general.driver%20dev%20show%20%22%24%7BDEVICE_IFACE%7D%22)%0A%0Aif%20%5B%5B%20%22%242%22%20%3D%3D%20%22up%22%20%26%26%20%22%24%7Bdriver%7D%22%20%3D%3D%20%22idpf%22%20%5D%5D%3B%20then%0A%20%20ethtool%20-K%20%24%7BDEVICE_IFACE%7D%20tx-checksumming%20off%0Afi
          mode: 484
          overwrite: true
          path: /etc/NetworkManager/dispatcher.d/99-gcp-disable-idpf-tx-checksum-off
        - contents:
            source: data:,global%0A%20%20stats%20socket%20%2Fvar%2Flib%2Fhaproxy%2Frun%2Fhaproxy.sock%20%20mode%20600%20level%20admin%20expose-fd%20listeners%0Adefaults%0A%20%20maxconn%2040000%0A%20%20mode%20%20%20%20tcp%0A%20%20log%20%20%20%20%20%2Fvar%2Frun%2Fhaproxy%2Fhaproxy-log.sock%20local0%20notice%20alert%0A%20%20log-format%20%22%25ci%3A%25cp%20-%3E%20%25fi%3A%25fp%20%5B%25t%5D%20%25ft%20%25b%2F%25s%20%25Tw%2F%25Tc%2F%25Tt%20%25B%20%25ts%20%25ac%2F%25fc%2F%25bc%2F%25sc%2F%25rc%20%25sq%2F%25bq%22%0A%20%20option%20%20dontlognull%0A%20%20retries%203%0A%20%20timeout%20http-request%2030s%0A%20%20timeout%20queue%20%20%20%20%20%20%20%201m%0A%20%20timeout%20connect%20%20%20%20%20%2010s%0A%20%20timeout%20client%20%20%20%20%20%20%2086400s%0A%20%20timeout%20server%20%20%20%20%20%20%2086400s%0A%20%20timeout%20tunnel%20%20%20%20%20%20%2086400s%0A%7B%7B-%20if%20gt%20(len%20.LBConfig.Backends)%200%20%7D%7D%0Afrontend%20%20main%0A%20%20bind%20%3A%3A%3A%7B%7B%20.LBConfig.LbPort%20%7D%7D%20v4v6%0A%20%20default_backend%20masters%0Alisten%20health_check_http_url%0A%20%20bind%20%3A%3A%3A9444%20v4v6%0A%20%20mode%20http%0A%20%20monitor-uri%20%2Fhaproxy_ready%0A%20%20option%20dontlognull%0A%7B%7B-%20end%20%7D%7D%0Alisten%20stats%0A%20%20bind%20localhost%3A%7B%7B%20.LBConfig.StatPort%20%7D%7D%0A%20%20mode%20http%0A%20%20stats%20enable%0A%20%20stats%20hide-version%0A%20%20stats%20uri%20%2Fhaproxy_stats%0A%20%20stats%20refresh%2030s%0A%20%20stats%20auth%20Username%3APassword%0Abackend%20masters%0A%20%20%20timeout%20check%2010s%0A%20%20%20option%20%20httpchk%20GET%20%2Freadyz%20HTTP%2F1.0%0A%20%20%20balance%20roundrobin%0A%7B%7B-%20range%20.LBConfig.Backends%20%7D%7D%0A%20%20%20server%20%7B%7B%20.Host%20%7D%7D%20%7B%7B%20.Address%20%7D%7D%3A%7B%7B%20.Port%20%7D%7D%20weight%201%20verify%20none%20check%20check-ssl%20inter%205s%20fall%203%20rise%201%0A%7B%7B-%20end%20%7D%7D%0A
          mode: 420
          overwrite: true
          path: /etc/kubernetes/static-pod-resources/haproxy/haproxy.cfg.tmpl
        - contents:
            source: data:,kind%3A%20Pod%0AapiVersion%3A%20v1%0Ametadata%3A%0A%20%20name%3A%20haproxy%0A%20%20namespace%3A%20openshift-kni-infra%0A%20%20creationTimestamp%3A%0A%20%20deletionGracePeriodSeconds%3A%2065%0A%20%20labels%3A%0A%20%20%20%20app%3A%20kni-infra-api-lb%0A%20%20annotations%3A%0A%20%20%20%20target.workload.openshift.io%2Fmanagement%3A%20'%7B%22effect%22%3A%20%22PreferredDuringScheduling%22%7D'%0A%20%20%20%20openshift.io%2Frequired-scc%3A%20privileged%0Aspec%3A%0A%20%20volumes%3A%0A%20%20-%20name%3A%20resource-dir%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fetc%2Fkubernetes%2Fstatic-pod-resources%2Fhaproxy%22%0A%20%20-%20name%3A%20kubeconfigvarlib%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20-%20name%3A%20run-dir%0A%20%20%20%20empty-dir%3A%20%7B%7D%0A%20%20-%20name%3A%20conf-dir%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fetc%2Fhaproxy%22%0A%20%20-%20name%3A%20chroot-host%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2F%22%0A%20%20initContainers%3A%0A%20%20-%20name%3A%20verify-api-int-resolvable%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A93e7b8c870261726d44bddc7ba0a702d3720d1838141dac837fb8c3be7c6e1a1%0A%20%20%20%20command%3A%0A%20%20%20%20-%20%22%2Fbin%2Fbash%22%0A%20%20%20%20-%20%22-c%22%0A%20%20%20%20-%20%7C%0A%20%20%20%20%20%20%2Fusr%2Fbin%2Fcurl%20-o%20%2Fdev%2Fnull%20-kLfs%20https%3A%2F%2Fapi-int.comp-poc-rh01.rhpoc.int%3A6443%2Fhealthz%0A%20%20%20%20resources%3A%20%7B%7D%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20chroot-host%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fhost%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20kubeconfigvarlib%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20imagePullPolicy%3A%20IfNotPresent%0A%20%20containers%3A%0A%20%20-%20name%3A%20haproxy%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3Ae1eb49c0c126c193cd035f844746edd98c6c674fdfa6b822d078d4a491b4834d%0A%20%20%20%20env%3A%0A%20%20%20%20%20%20-%20name%3A%20OLD_HAPROXY_PS_FORCE_DEL_TIMEOUT%0A%20%20%20%20%20%20%20%20value%3A%20%22120%22%0A%20%20%20%20command%3A%0A%20%20%20%20-%20%22%2Fbin%2Fbash%22%0A%20%20%20%20-%20%22-c%22%0A%20%20%20%20-%20%7C%0A%20%20%20%20%20%20%23%2Fbin%2Fbash%0A%20%20%20%20%20%20verify_old_haproxy_ps_being_deleted()%0A%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20local%20prev_pids%0A%0A%20%20%20%20%20%20%20%20prev_pids%3D%22%241%22%0A%20%20%20%20%20%20%20%20sleep%20%24OLD_HAPROXY_PS_FORCE_DEL_TIMEOUT%0A%20%20%20%20%20%20%20%20cur_pids%3D%24(pidof%20haproxy)%0A%0A%20%20%20%20%20%20%20%20for%20val%20in%20%24prev_pids%3B%20do%0A%20%20%20%20%20%20%20%20%20%20%20%20if%20%5B%5B%20%24cur_pids%20%3D~%20(%5E%7C%5B%5B%3Aspace%3A%5D%5D)%22%24val%22(%24%7C%5B%5B%3Aspace%3A%5D%5D)%20%5D%5D%20%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20kill%20%24val%0A%20%20%20%20%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20done%0A%20%20%20%20%20%20%7D%0A%0A%20%20%20%20%20%20reload_haproxy()%0A%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20old_pids%3D%24(pidof%20haproxy)%0A%20%20%20%20%20%20%20%20if%20%5B%20-n%20%22%24old_pids%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%2Fusr%2Fsbin%2Fhaproxy%20-W%20-db%20-f%20%2Fetc%2Fhaproxy%2Fhaproxy.cfg%20%20-p%20%2Fvar%2Flib%2Fhaproxy%2Frun%2Fhaproxy.pid%20-x%20%2Fvar%2Flib%2Fhaproxy%2Frun%2Fhaproxy.sock%20-sf%20%24old_pids%20%26%0A%20%20%20%20%20%20%20%20%20%20%20%20%23There%20seems%20to%20be%20some%20cases%20where%20HAProxy%20doesn't%20drain%20properly.%0A%20%20%20%20%20%20%20%20%20%20%20%20%23To%20handle%20that%20case%2C%20SIGTERM%20signal%20being%20sent%20to%20old%20HAProxy%20processes%20which%20haven't%20terminated.%0A%20%20%20%20%20%20%20%20%20%20%20%20verify_old_haproxy_ps_being_deleted%20%22%24old_pids%22%20%20%26%0A%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20%2Fusr%2Fsbin%2Fhaproxy%20-W%20-db%20-f%20%2Fetc%2Fhaproxy%2Fhaproxy.cfg%20%20-p%20%2Fvar%2Flib%2Fhaproxy%2Frun%2Fhaproxy.pid%20%26%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%7D%0A%0A%20%20%20%20%20%20msg_handler()%0A%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20while%20read%20-r%20line%3B%20do%0A%20%20%20%20%20%20%20%20%20%20echo%20%22The%20client%20send%3A%20%24line%22%20%20%3E%262%0A%20%20%20%20%20%20%20%20%20%20%23%20currently%20only%20'reload'%20msg%20is%20supported%0A%20%20%20%20%20%20%20%20%20%20if%20%5B%20%22%24line%22%20%3D%20reload%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20reload_haproxy%0A%20%20%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20done%0A%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20set%20-ex%0A%20%20%20%20%20%20declare%20-r%20haproxy_sock%3D%22%2Fvar%2Frun%2Fhaproxy%2Fhaproxy-master.sock%22%0A%20%20%20%20%20%20declare%20-r%20haproxy_log_sock%3D%22%2Fvar%2Frun%2Fhaproxy%2Fhaproxy-log.sock%22%0A%20%20%20%20%20%20export%20-f%20msg_handler%0A%20%20%20%20%20%20export%20-f%20reload_haproxy%0A%20%20%20%20%20%20export%20-f%20verify_old_haproxy_ps_being_deleted%0A%20%20%20%20%20%20rm%20-f%20%22%24haproxy_sock%22%20%22%24haproxy_log_sock%22%0A%20%20%20%20%20%20socat%20UNIX-RECV%3A%24%7Bhaproxy_log_sock%7D%20STDOUT%20%26%0A%20%20%20%20%20%20if%20%5B%20-s%20%22%2Fetc%2Fhaproxy%2Fhaproxy.cfg%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%2Fusr%2Fsbin%2Fhaproxy%20-W%20-db%20-f%20%2Fetc%2Fhaproxy%2Fhaproxy.cfg%20%20-p%20%2Fvar%2Flib%2Fhaproxy%2Frun%2Fhaproxy.pid%20%26%0A%20%20%20%20%20%20fi%0A%20%20%20%20%20%20socat%20UNIX-LISTEN%3A%24%7Bhaproxy_sock%7D%2Cfork%20system%3A'bash%20-c%20msg_handler'%0A%20%20%20%20resources%3A%0A%20%20%20%20%20%20requests%3A%0A%20%20%20%20%20%20%20%20cpu%3A%20100m%0A%20%20%20%20%20%20%20%20memory%3A%20200Mi%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20conf-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fhaproxy%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20run-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Frun%2Fhaproxy%22%0A%20%20%20%20livenessProbe%3A%0A%20%20%20%20%20%20initialDelaySeconds%3A%2050%0A%20%20%20%20%20%20httpGet%3A%0A%20%20%20%20%20%20%20%20path%3A%20%2Fhaproxy_ready%0A%20%20%20%20%20%20%20%20port%3A%209444%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20imagePullPolicy%3A%20IfNotPresent%0A%20%20-%20name%3A%20haproxy-monitor%0A%20%20%20%20securityContext%3A%0A%20%20%20%20%20%20capabilities%3A%0A%20%20%20%20%20%20%20%20add%3A%20%5B%22NET_ADMIN%22%2C%20%22SYS_CHROOT%22%5D%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A93e7b8c870261726d44bddc7ba0a702d3720d1838141dac837fb8c3be7c6e1a1%0A%20%20%20%20command%3A%0A%20%20%20%20-%20monitor%0A%20%20%20%20-%20%22%2Fvar%2Flib%2Fkubelet%2Fkubeconfig%22%0A%20%20%20%20-%20%22%2Fconfig%2Fhaproxy.cfg.tmpl%22%0A%20%20%20%20-%20%22%2Fetc%2Fhaproxy%2Fhaproxy.cfg%22%0A%20%20%20%20-%20%22--api-vips%22%0A%20%20%20%20-%20%2210.100.0.50%22%0A%20%20%20%20resources%3A%0A%20%20%20%20%20%20requests%3A%0A%20%20%20%20%20%20%20%20cpu%3A%20100m%0A%20%20%20%20%20%20%20%20memory%3A%20200Mi%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20conf-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fhaproxy%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20run-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Frun%2Fhaproxy%22%0A%20%20%20%20-%20name%3A%20resource-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fconfig%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20chroot-host%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fhost%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20kubeconfigvarlib%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20imagePullPolicy%3A%20IfNotPresent%0A%20%20hostNetwork%3A%20true%0A%20%20tolerations%3A%0A%20%20-%20operator%3A%20Exists%0A%20%20priorityClassName%3A%20system-node-critical%0Astatus%3A%20%7B%7D%0A
          mode: 420
          overwrite: true
          path: /etc/kubernetes/manifests/haproxy.yaml
        - contents:
            source: data:,%23%20Force-load%20legacy%20iptables%20so%20it%20is%20usable%20from%20pod%20network%20namespaces%0Aip_tables%0A
          mode: 420
          overwrite: true
          path: /etc/modules-load.d/iptables.conf
        - contents:
            source: data:,global_defs%20%7B%0A%20%20%20%20enable_script_security%0A%20%20%20%20script_user%20root%0A%20%20%20%20max_auto_priority%20-1%0A%20%20%20%20vrrp_garp_master_refresh%2060%0A%7D%0A%0A%23%20These%20are%20separate%20checks%20to%20provide%20the%20following%20behavior%3A%0A%23%20If%20the%20loadbalancer%20is%20healthy%20then%20all%20is%20well%20regardless%0A%23%20of%20what%20the%20local%20API%20status%20is.%20Both%20checks%20will%20return%20success%20and%0A%23%20we'll%20have%20the%20maximum%20priority.%20This%20means%20as%20long%20as%20there%20is%20a%20node%0A%23%20with%20a%20functional%20loadbalancer%20it%20will%20get%20the%20VIP.%0A%23%20If%20all%20of%20the%20loadbalancers%20go%20down%20but%20the%20local%20API%20is%20still%20running%2C%0A%23%20the%20_both%20check%20will%20still%20succeed%20and%20allow%20any%20node%20with%20a%20functional%0A%23%20API%20to%20take%20the%20VIP.%20This%20isn't%20preferred%20because%20it%20means%20all%20API%0A%23%20traffic%20will%20go%20through%20one%20node%2C%20but%20at%20least%20it%20keeps%20the%20API%20available.%0Avrrp_script%20chk_ocp_lb%20%7B%0A%20%20%20%20script%20%22%2Fusr%2Fbin%2Ftimeout%201.9%20%2Fetc%2Fkeepalived%2Fchk_ocp_script.sh%22%0A%20%20%20%20interval%202%0A%20%20%20%20weight%2020%0A%20%20%20%20rise%203%0A%20%20%20%20fall%203%0A%7D%0A%0Avrrp_script%20chk_ocp_both%20%7B%0A%20%20%20%20script%20%22%2Fusr%2Fbin%2Ftimeout%201.9%20%2Fetc%2Fkeepalived%2Fchk_ocp_script_both.sh%22%0A%20%20%20%20interval%202%0A%20%20%20%20%23%20Use%20a%20smaller%20weight%20for%20this%20check%20so%20it%20won't%20trigger%20the%20move%20from%0A%20%20%20%20%23%20bootstrap%20to%20master%20by%20itself.%0A%20%20%20%20weight%205%0A%20%20%20%20rise%203%0A%20%20%20%20fall%203%0A%7D%0A%0Avrrp_script%20chk_mcs%20%7B%0A%20%20%20%20script%20%22%2Fusr%2Fbin%2Ftimeout%201.9%20%2Fetc%2Fkeepalived%2Fchk_mcs_script.sh%22%0A%20%20%20%20interval%202%0A%20%20%20%20weight%203%0A%20%20%20%20rise%203%0A%20%20%20%20fall%203%0A%7D%0A%0A%23%20TODO%3A%20Improve%20this%20check.%20The%20port%20is%20assumed%20to%20be%20alive.%0A%23%20Need%20to%20assess%20what%20is%20the%20ramification%20if%20the%20port%20is%20not%20there.%0Avrrp_script%20chk_ingress_ready%20%7B%0A%20%20%20%20script%20%22%2Fusr%2Fbin%2Ftimeout%200.9%20%2Fusr%2Fbin%2Fcurl%20-o%20%2Fdev%2Fnull%20-Lfs%20http%3A%2F%2Flocalhost%3A1936%2Fhealthz%2Fready%22%0A%20%20%20%20interval%201%0A%20%20%20%20weight%2010%0A%20%20%20%20rise%203%0A%20%20%20%20fall%202%0A%7D%0A%0Avrrp_script%20chk_ingress%20%7B%0A%20%20%20%20script%20%22%2Fusr%2Fbin%2Ftimeout%200.9%20%2Fusr%2Fbin%2Fcurl%20-o%20%2Fdev%2Fnull%20-Lfs%20http%3A%2F%2Flocalhost%3A1936%2Fhealthz%22%0A%20%20%20%20interval%201%0A%20%20%20%20rise%203%0A%20%20%20%20fall%202%0A%7D%0A%0Avrrp_script%20chk_default_ingress%20%7B%0A%20%20%20%20script%20%22%2Fusr%2Fbin%2Ftimeout%204.9%20%2Fetc%2Fkeepalived%2Fchk_default_ingress.sh%22%0A%20%20%20%20interval%205%0A%20%20%20%20weight%2050%0A%20%20%20%20rise%203%0A%20%20%20%20fall%202%0A%7D%0A%0A%7B%7B%20range%20%24i%2C%20%24config%20%3A%3D%20.Configs%20%7D%7D%0A%7B%7B%24nonVirtualIP%20%3A%3D%20.NonVirtualIP%7D%7D%0A%0A%7B%7B%24participateInAPIVRPP%20%3A%3D%20not%20.EnableUnicast%7D%7D%0A%7B%7B-%20if%20.EnableUnicast%7D%7D%0A%7B%7B-%20range%20.LBConfig.Backends%7D%7D%0A%7B%7B-%20if%20eq%20%24nonVirtualIP%20.Address%7D%7D%0A%7B%7B%24participateInAPIVRPP%20%3D%20true%7D%7D%0A%7B%7B-%20end%7D%7D%0A%7B%7B-%20end%7D%7D%0A%7B%7B-%20end%7D%7D%0A%0A%7B%7Bif%20%24participateInAPIVRPP%7D%7D%0Avrrp_instance%20%7B%7B%20.Cluster.Name%20%7D%7D_API_%7B%7B%24i%7D%7D%20%7B%0A%20%20%20%20state%20BACKUP%0A%20%20%20%20interface%20%7B%7B%20.VRRPInterface%20%7D%7D%0A%20%20%20%20virtual_router_id%20%7B%7B%20.Cluster.APIVirtualRouterID%20%7D%7D%0A%20%20%20%20priority%2040%0A%20%20%20%20advert_int%201%0A%20%20%20%20%7B%7Bif%20.EnableUnicast%7D%7D%0A%20%20%20%20unicast_src_ip%20%7B%7B.NonVirtualIP%7D%7D%0A%20%20%20%20unicast_peer%20%7B%0A%20%20%20%20%20%20%20%20%7B%7B-%20range%20.LBConfig.Backends%20-%7D%7D%0A%20%20%20%20%20%20%20%20%7B%7B-%20if%20ne%20%24nonVirtualIP%20.Address%7D%7D%0A%20%20%20%20%20%20%20%20%7B%7B.Address%7D%7D%0A%20%20%20%20%20%20%20%20%7B%7B-%20end%7D%7D%0A%20%20%20%20%20%20%20%20%7B%7B-%20end%7D%7D%0A%20%20%20%20%7D%0A%20%20%20%20%7B%7Bend%7D%7D%0A%20%20%20%20authentication%20%7B%0A%20%20%20%20%20%20%20%20auth_type%20PASS%0A%20%20%20%20%20%20%20%20auth_pass%20%7B%7B%20.Cluster.Name%20%7D%7D_api_vip%0A%20%20%20%20%7D%0A%20%20%20%20virtual_ipaddress%20%7B%0A%20%20%20%20%20%20%20%20%7B%7B%20.Cluster.APIVIP%20%7D%7D%2F%7B%7B%20.Cluster.VIPNetmask%20%7D%7D%20label%20vip%0A%20%20%20%20%7D%0A%20%20%20%20track_script%20%7B%0A%20%20%20%20%20%20%20%20chk_ocp_lb%0A%20%20%20%20%20%20%20%20chk_ocp_both%0A%20%20%20%20%20%20%20%20chk_mcs%0A%20%20%20%20%7D%0A%7D%0A%7B%7Bend%7D%7D%0A%0A%7B%7B%24participateInIngressVRPP%20%3A%3D%20not%20.EnableUnicast%7D%7D%0A%7B%7B-%20if%20.EnableUnicast%7D%7D%0A%7B%7B-%20range%20.IngressConfig.Peers%7D%7D%0A%7B%7B-%20if%20eq%20%24nonVirtualIP%20.%7D%7D%0A%7B%7B%24participateInIngressVRPP%20%3D%20true%7D%7D%0A%7B%7B-%20end%7D%7D%0A%7B%7B-%20end%7D%7D%0A%7B%7B-%20end%7D%7D%0A%0A%7B%7Bif%20%24participateInIngressVRPP%7D%7D%0Avrrp_instance%20%7B%7B%20.Cluster.Name%20%7D%7D_INGRESS_%7B%7B%24i%7D%7D%20%7B%0A%20%20%20%20state%20BACKUP%0A%20%20%20%20interface%20%7B%7B%20.VRRPInterface%20%7D%7D%0A%20%20%20%20virtual_router_id%20%7B%7B%20.Cluster.IngressVirtualRouterID%20%7D%7D%0A%20%20%20%20priority%2020%0A%20%20%20%20advert_int%201%0A%20%20%20%20%7B%7Bif%20.EnableUnicast%7D%7D%0A%20%20%20%20unicast_src_ip%20%7B%7B.NonVirtualIP%7D%7D%0A%20%20%20%20unicast_peer%20%7B%0A%20%20%20%20%20%20%20%20%7B%7B-%20range%20.IngressConfig.Peers%7D%7D%0A%20%20%20%20%20%20%20%20%7B%7B-%20if%20ne%20%24nonVirtualIP%20.%7D%7D%0A%20%20%20%20%20%20%20%20%7B%7B.%7D%7D%0A%20%20%20%20%20%20%20%20%7B%7B-%20end%7D%7D%0A%20%20%20%20%20%20%20%20%7B%7B-%20end%7D%7D%0A%20%20%20%20%7D%0A%20%20%20%20%7B%7Bend%7D%7D%0A%20%20%20%20authentication%20%7B%0A%20%20%20%20%20%20%20%20auth_type%20PASS%0A%20%20%20%20%20%20%20%20auth_pass%20%7B%7B%20.Cluster.Name%20%7D%7D_ingress_vip%0A%20%20%20%20%7D%0A%20%20%20%20virtual_ipaddress%20%7B%0A%20%20%20%20%20%20%20%20%7B%7B%20.Cluster.IngressVIP%20%7D%7D%2F%7B%7B%20.Cluster.VIPNetmask%20%7D%7D%20label%20vip%0A%20%20%20%20%7D%0A%20%20%20%20track_script%20%7B%0A%20%20%20%20%20%20%20%20chk_ingress%0A%20%20%20%20%20%20%20%20chk_ingress_ready%0A%20%20%20%20%20%20%20%20chk_default_ingress%0A%20%20%20%20%7D%0A%7D%0A%7B%7B%20end%20%7D%7D%0A%7B%7B%20end%20%7D%7D%0A
          mode: 420
          overwrite: true
          path: /etc/kubernetes/static-pod-resources/keepalived/keepalived.conf.tmpl
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Achroot%20%2Fhost%20%2Fbin%2Fcrictl%20ps%20--state%20running%20%7C%20grep%20-qE%20'%5Csmachine-config-server%5Cs'%0A
          mode: 493
          overwrite: true
          path: /etc/kubernetes/static-pod-resources/keepalived/scripts/chk_mcs_script.sh.tmpl
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%2Fusr%2Fbin%2Fcurl%20-o%20%2Fdev%2Fnull%20-kLfs%20http%3A%2F%2Flocalhost%3A9444%2Fhaproxy_ready%20%26%26%20%5B%20-e%20%2Fvar%2Frun%2Fkeepalived%2Fiptables-rule-exists%20%5D%20%7C%7C%20%2Fusr%2Fbin%2Fcurl%20-kLfs%20https%3A%2F%2Flocalhost%3A%7B%7B%20.LBConfig.ApiPort%20%7D%7D%2Freadyz%0A
          mode: 493
          overwrite: true
          path: /etc/kubernetes/static-pod-resources/keepalived/scripts/chk_ocp_script_both.sh.tmpl
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Achroot%20%2Fhost%20%2Fbin%2Fcrictl%20pods%20--namespace%20openshift-ingress%20--state%20Ready%20%7C%20grep%20-qE%20'router-default-%5B%5B%3Aalnum%3A%5D%5D%7B5%2C%7D-%5B%5B%3Aalnum%3A%5D%5D%7B5%2C%7D'%0A
          mode: 493
          overwrite: true
          path: /etc/kubernetes/static-pod-resources/keepalived/scripts/chk_default_ingress.sh.tmpl
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%2Fusr%2Fbin%2Fcurl%20-o%20%2Fdev%2Fnull%20-kLfs%20http%3A%2F%2Flocalhost%3A9444%2Fhaproxy_ready%20%26%26%20%5B%20-e%20%2Fvar%2Frun%2Fkeepalived%2Fiptables-rule-exists%20%5D%0A
          mode: 493
          overwrite: true
          path: /etc/kubernetes/static-pod-resources/keepalived/scripts/chk_ocp_script.sh.tmpl
        - contents:
            source: data:,kind%3A%20Pod%0AapiVersion%3A%20v1%0Ametadata%3A%0A%20%20name%3A%20keepalived%0A%20%20namespace%3A%20openshift-kni-infra%0A%20%20creationTimestamp%3A%0A%20%20deletionGracePeriodSeconds%3A%2065%0A%20%20labels%3A%0A%20%20%20%20app%3A%20kni-infra-vrrp%0A%20%20annotations%3A%0A%20%20%20%20target.workload.openshift.io%2Fmanagement%3A%20'%7B%22effect%22%3A%20%22PreferredDuringScheduling%22%7D'%0A%20%20%20%20openshift.io%2Frequired-scc%3A%20privileged%0Aspec%3A%0A%20%20volumes%3A%0A%20%20-%20name%3A%20resource-dir%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fetc%2Fkubernetes%2Fstatic-pod-resources%2Fkeepalived%22%0A%20%20-%20name%3A%20script-dir%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fetc%2Fkubernetes%2Fstatic-pod-resources%2Fkeepalived%2Fscripts%22%0A%20%20-%20name%3A%20kubeconfig%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fetc%2Fkubernetes%22%0A%20%20-%20name%3A%20kubeconfigvarlib%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20-%20name%3A%20conf-dir%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fetc%2Fkeepalived%22%0A%20%20-%20name%3A%20run-dir%0A%20%20%20%20empty-dir%3A%20%7B%7D%0A%20%20-%20name%3A%20chroot-host%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2F%22%0A%20%20-%20name%3A%20nodeip-configuration%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Frun%2Fnodeip-configuration%22%0A%20%20initContainers%3A%0A%20%20-%20name%3A%20render-config-keepalived%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A93e7b8c870261726d44bddc7ba0a702d3720d1838141dac837fb8c3be7c6e1a1%0A%20%20%20%20command%3A%0A%20%20%20%20-%20runtimecfg%0A%20%20%20%20-%20render%0A%20%20%20%20-%20%22%2Fetc%2Fkubernetes%2Fkubeconfig%22%0A%20%20%20%20-%20%22--api-vips%22%0A%20%20%20%20-%20%2210.100.0.50%22%0A%20%20%20%20-%20%22--ingress-vips%22%0A%20%20%20%20-%20%2210.100.0.51%22%0A%20%20%20%20-%20%22%2Fconfig%22%0A%20%20%20%20-%20%22--out-dir%22%0A%20%20%20%20-%20%22%2Fetc%2Fkeepalived%22%0A%20%20%20%20resources%3A%20%7B%7D%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20kubeconfig%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fkubernetes%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20script-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fconfig%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20conf-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fkeepalived%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20nodeip-configuration%0A%20%20%20%20%20%20mountPath%3A%20%22%2Frun%2Fnodeip-configuration%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20imagePullPolicy%3A%20IfNotPresent%0A%20%20containers%3A%0A%20%20-%20name%3A%20keepalived%0A%20%20%20%20securityContext%3A%0A%20%20%20%20%20%20capabilities%3A%0A%20%20%20%20%20%20%20%20add%3A%20%5B%22NET_ADMIN%22%2C%20%22NET_RAW%22%2C%20%22SYS_CHROOT%22%5D%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A3b0561a80561d95854d5f364f8cd6c3458d27cfb798bf93e09ffcfab97609216%0A%20%20%20%20env%3A%0A%20%20%20%20%20%20-%20name%3A%20NSS_SDB_USE_CACHE%0A%20%20%20%20%20%20%20%20value%3A%20%22no%22%0A%20%20%20%20command%3A%0A%20%20%20%20-%20%2Fbin%2Fbash%0A%20%20%20%20-%20-c%0A%20%20%20%20-%20%7C%0A%20%20%20%20%20%20%23%2Fbin%2Fbash%0A%20%20%20%20%20%20sigterm_handler()%0A%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20if%20pid%3D%24(pgrep%20-o%20keepalived)%3B%20then%0A%20%20%20%20%20%20%20%20%20%20kill%20-s%20SIGTERM%20%22%24pid%22%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%7D%0A%0A%20%20%20%20%20%20reload_keepalived()%0A%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20if%20pid%3D%24(pgrep%20-o%20keepalived)%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20kill%20-s%20SIGHUP%20%22%24pid%22%0A%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20%2Fusr%2Fsbin%2Fkeepalived%20-f%20%2Fetc%2Fkeepalived%2Fkeepalived.conf%20--dont-fork%20--vrrp%20--log-detail%20--log-console%20%26%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%7D%0A%0A%20%20%20%20%20%20msg_handler()%0A%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20while%20read%20-r%20line%3B%20do%0A%20%20%20%20%20%20%20%20%20%20echo%20%22The%20client%20sent%3A%20%24line%22%20%3E%262%0A%20%20%20%20%20%20%20%20%20%20%23%20currently%20only%20'reload'%20msg%20is%20supported%0A%20%20%20%20%20%20%20%20%20%20if%20%5B%20%22%24line%22%20%3D%20reload%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20reload_keepalived%0A%20%20%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20done%0A%20%20%20%20%20%20%7D%0A%0A%20%20%20%20%20%20remove_vip()%0A%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20address%3D%241%0A%20%20%20%20%20%20%20%20interface%3D%24(ip%20-o%20a%20%7C%20awk%20%22%2F%5Cs%24%7Baddress%7D%5C%2F%2F%20%7Bprint%20%5C%242%7D%22)%0A%20%20%20%20%20%20%20%20cidr%3D%24(ip%20-o%20a%20%7C%20awk%20%22%2F%5Cs%24%7Baddress%7D%5C%2F%2F%20%7Bprint%20%5C%244%7D%22)%0A%20%20%20%20%20%20%20%20if%20%5B%20-n%20%22%24interface%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20ip%20a%20del%20%24cidr%20dev%20%24interface%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%7D%0A%0A%20%20%20%20%20%20set%20-ex%0A%20%20%20%20%20%20%23%20Ensure%20that%20we%20don't%20have%20stale%20VIPs%20configured%0A%20%20%20%20%20%20%23%20See%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1931505%0A%20%20%20%20%20%20remove_vip%20%2210.100.0.50%22%0A%20%20%20%20%20%20remove_vip%20%2210.100.0.51%22%0A%20%20%20%20%20%20declare%20-r%20keepalived_sock%3D%22%2Fvar%2Frun%2Fkeepalived%2Fkeepalived.sock%22%0A%20%20%20%20%20%20export%20-f%20msg_handler%0A%20%20%20%20%20%20export%20-f%20reload_keepalived%0A%20%20%20%20%20%20export%20-f%20sigterm_handler%0A%0A%20%20%20%20%20%20%23%20in%20remote%20worker%20case%20sleep%20forever%0A%20%20%20%20%20%20if%20%5B%20-f%20%22%2Frun%2Fnodeip-configuration%2Fremote-worker%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20sleep%20infinity%0A%20%20%20%20%20%20%20%20%20exit%200%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20trap%20sigterm_handler%20SIGTERM%0A%20%20%20%20%20%20if%20%5B%20-s%20%22%2Fetc%2Fkeepalived%2Fkeepalived.conf%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%2Fusr%2Fsbin%2Fkeepalived%20-f%20%2Fetc%2Fkeepalived%2Fkeepalived.conf%20--dont-fork%20--vrrp%20--log-detail%20--log-console%20%26%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20rm%20-f%20%22%24keepalived_sock%22%0A%20%20%20%20%20%20socat%20UNIX-LISTEN%3A%24%7Bkeepalived_sock%7D%2Cfork%20system%3A'bash%20-c%20msg_handler'%0A%20%20%20%20resources%3A%0A%20%20%20%20%20%20requests%3A%0A%20%20%20%20%20%20%20%20cpu%3A%20100m%0A%20%20%20%20%20%20%20%20memory%3A%20200Mi%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20conf-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fkeepalived%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20run-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Frun%2Fkeepalived%22%0A%20%20%20%20-%20name%3A%20chroot-host%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fhost%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20kubeconfigvarlib%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20nodeip-configuration%0A%20%20%20%20%20%20mountPath%3A%20%22%2Frun%2Fnodeip-configuration%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20livenessProbe%3A%0A%20%20%20%20%20%20exec%3A%0A%20%20%20%20%20%20%20%20command%3A%0A%20%20%20%20%20%20%20%20-%20%2Fbin%2Fbash%0A%20%20%20%20%20%20%20%20-%20-c%0A%20%20%20%20%20%20%20%20-%20%7C%0A%20%20%20%20%20%20%20%20%20%20%5B%20!%20-s%20%22%2Fetc%2Fkeepalived%2Fkeepalived.conf%22%20%5D%20%7C%7C%20(echo%20%22%22%20%3E%20%2Ftmp%2Fkeepalived.data%20%26%26%20kill%20-s%20SIGUSR1%20%22%24(pgrep%20-o%20keepalived)%22%20%26%26%20for%20i%20in%20%24(seq%205)%3B%20do%20grep%20-q%20%22VRRP%20Instance%22%20%2Ftmp%2Fkeepalived.data%20%26%26%20exit%200%20%7C%7C%20sleep%201%3B%20done%20%26%26%20exit%201)%0A%20%20%20%20%20%20initialDelaySeconds%3A%2020%0A%20%20%20%20%20%20timeoutSeconds%3A%205%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20imagePullPolicy%3A%20IfNotPresent%0A%20%20-%20name%3A%20keepalived-monitor%0A%20%20%20%20securityContext%3A%0A%20%20%20%20%20%20capabilities%3A%0A%20%20%20%20%20%20%20%20add%3A%20%5B%22NET_ADMIN%22%2C%20%22SYS_CHROOT%22%5D%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A93e7b8c870261726d44bddc7ba0a702d3720d1838141dac837fb8c3be7c6e1a1%0A%20%20%20%20env%3A%0A%20%20%20%20%20%20-%20name%3A%20ENABLE_UNICAST%0A%20%20%20%20%20%20%20%20value%3A%20%22yes%22%0A%20%20%20%20%20%20-%20name%3A%20IS_BOOTSTRAP%0A%20%20%20%20%20%20%20%20value%3A%20%22no%22%0A%20%20%20%20%20%20-%20name%3A%20POD_NAMESPACE%0A%20%20%20%20%20%20%20%20valueFrom%3A%0A%20%20%20%20%20%20%20%20%20%20fieldRef%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20fieldPath%3A%20metadata.namespace%0A%20%20%20%20command%3A%0A%20%20%20%20-%20%2Fbin%2Fbash%0A%20%20%20%20-%20-c%0A%20%20%20%20-%20%7C%0A%20%20%20%20%20%20%23%2Fbin%2Fbash%0A%20%20%20%20%20%20%23%20in%20remote%20worker%20case%20sleep%20forever%0A%20%20%20%20%20%20if%20%5B%20-f%20%22%2Frun%2Fnodeip-configuration%2Fremote-worker%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20sleep%20infinity%0A%20%20%20%20%20%20%20%20%20%20exit%200%0A%20%20%20%20%20%20fi%0A%20%20%20%20%20%20api_vips%3D10.100.0.50%0A%20%20%20%20%20%20ingress_vips%3D10.100.0.51%0A%20%20%20%20%20%20dynkeepalived%20%2Fvar%2Flib%2Fkubelet%2Fkubeconfig%20%2Fconfig%2Fkeepalived.conf.tmpl%20%2Fetc%2Fkeepalived%2Fkeepalived.conf%20--api-vips%20%22%24%7Bapi_vips%7D%22%20--ingress-vips%20%22%24%7Bingress_vips%7D%22%0A%20%20%20%20resources%3A%0A%20%20%20%20%20%20requests%3A%0A%20%20%20%20%20%20%20%20cpu%3A%20100m%0A%20%20%20%20%20%20%20%20memory%3A%20200Mi%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20resource-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fconfig%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20kubeconfigvarlib%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20conf-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fkeepalived%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20run-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Frun%2Fkeepalived%22%0A%20%20%20%20-%20name%3A%20chroot-host%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fhost%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20nodeip-configuration%0A%20%20%20%20%20%20mountPath%3A%20%22%2Frun%2Fnodeip-configuration%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20imagePullPolicy%3A%20IfNotPresent%0A%20%20hostNetwork%3A%20true%0A%20%20tolerations%3A%0A%20%20-%20operator%3A%20Exists%0A%20%20priorityClassName%3A%20system-node-critical%0Astatus%3A%20%7B%7D%0A
          mode: 420
          overwrite: true
          path: /etc/kubernetes/manifests/keepalived.yaml
        - contents:
            source: data:,NODE_SIZING_ENABLED%3Dfalse%0ASYSTEM_RESERVED_MEMORY%3D1Gi%0ASYSTEM_RESERVED_CPU%3D500m%0ASYSTEM_RESERVED_ES%3D1Gi
          mode: 420
          overwrite: true
          path: /etc/node-sizing-enabled.env
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-e%0ANODE_SIZES_ENV%3D%24%7BNODE_SIZES_ENV%3A-%2Fetc%2Fnode-sizing.env%7D%0AVERSION_1%3D1%0AVERSION_2%3D2%0ANODE_AUTO_SIZING_VERSION%3D%24%7BNODE_AUTO_SIZING_VERSION%3A-%24VERSION_2%7D%0ANODE_AUTO_SIZING_VERSION_FILE%3D%24%7BNODE_AUTO_SIZING_VERSION_FILE%3A-%2Fetc%2Fnode-sizing-version.json%7D%0Afunction%20dynamic_memory_sizing%20%7B%0A%20%20%20%20total_memory%3D%24(free%20-g%7Cawk%20'%2F%5EMem%3A%2F%7Bprint%20%242%7D')%0A%20%20%20%20%23%20total_memory%3D8%20test%20the%20recommended%20values%20by%20modifying%20this%20value%0A%20%20%20%20recommended_systemreserved_memory%3D0%0A%20%20%20%20if%20((%24total_memory%20%3C%3D%204))%3B%20then%20%23%2025%25%20of%20the%20first%204GB%20of%20memory%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24total_memory%200.25%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D0%0A%20%20%20%20else%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D1%0A%20%20%20%20%20%20%20%20total_memory%3D%24((total_memory-4))%0A%20%20%20%20fi%0A%20%20%20%20if%20((%24total_memory%20%3C%3D%204))%3B%20then%20%23%2020%25%20of%20the%20next%204GB%20of%20memory%20(up%20to%208GB)%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%20%24(echo%20%24total_memory%200.20%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D0%0A%20%20%20%20else%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%200.80%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D%24((total_memory-4))%0A%20%20%20%20fi%0A%20%20%20%20if%20((%24total_memory%20%3C%3D%208))%3B%20then%20%23%2010%25%20of%20the%20next%208GB%20of%20memory%20(up%20to%2016GB)%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%20%24(echo%20%24total_memory%200.10%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D0%0A%20%20%20%20else%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%200.80%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D%24((total_memory-8))%0A%20%20%20%20fi%0A%20%20%20%20if%20((%24total_memory%20%3C%3D%20112))%3B%20then%20%23%206%25%20of%20the%20next%20112GB%20of%20memory%20(up%20to%20128GB)%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%20%24(echo%20%24total_memory%200.06%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D0%0A%20%20%20%20else%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%206.72%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D%24((total_memory-112))%0A%20%20%20%20fi%0A%20%20%20%20if%20((%24total_memory%20%3E%3D%200))%3B%20then%20%23%202%25%20of%20any%20memory%20above%20128GB%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%20%24(echo%20%24total_memory%200.02%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20fi%0A%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%20%7C%20awk%20'%7Bprintf(%22%25d%5Cn%22%2C%241%20%2B%200.5)%7D')%20%23%20Round%20off%20so%20we%20avoid%20float%20conversions%0A%20%20%20%20echo%20%22SYSTEM_RESERVED_MEMORY%3D%24%7Brecommended_systemreserved_memory%7DGi%22%3E%3E%20%24%7BNODE_SIZES_ENV%7D%0A%7D%0Afunction%20dynamic_cpu_sizing%20%7B%0A%20%20%20%20total_cpu%3D%24(getconf%20_NPROCESSORS_ONLN)%0A%20%20%20%20if%20%5B%20%22%241%22%20-eq%20%22%24VERSION_1%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D0%0A%20%20%20%20%20%20%20%20if%20((%24total_cpu%20%3C%3D%201))%3B%20then%20%23%206%25%20of%20the%20first%20core%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24total_cpu%200.06%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D0%0A%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D0.06%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D%24((total_cpu-1))%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20if%20((%24total_cpu%20%3C%3D%201))%3B%20then%20%23%201%25%20of%20the%20next%20core%20(up%20to%202%20cores)%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24recommended_systemreserved_cpu%20%24(echo%20%24total_cpu%200.01%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D0%0A%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24recommended_systemreserved_cpu%200.01%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D%24((total_cpu-1))%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20if%20((%24total_cpu%20%3C%3D%202))%3B%20then%20%23%200.5%25%20of%20the%20next%202%20cores%20(up%20to%204%20cores)%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24recommended_systemreserved_cpu%20%24(echo%20%24total_cpu%200.005%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D0%0A%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24recommended_systemreserved_cpu%200.01%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D%24((total_cpu-2))%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20if%20((%24total_cpu%20%3E%3D%200))%3B%20then%20%23%200.25%25%20of%20any%20cores%20above%204%20cores%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24recommended_systemreserved_cpu%20%24(echo%20%24total_cpu%200.0025%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20else%0A%20%20%20%20%20%20%20%20%23%20Base%20allocation%20for%201%20CPU%20in%20fractions%20of%20a%20core%20(60%20millicores%20%3D%200.06%20CPU%20core)%0A%20%20%20%20%20%20%20%20base_allocation_fraction%3D0.06%0A%20%20%20%20%20%20%20%20%23%20Increment%20per%20additional%20CPU%20in%20fractions%20of%20a%20core%20(12%20millicores%20%3D%200.012%20CPU%20core)%0A%20%20%20%20%20%20%20%20increment_per_cpu_fraction%3D0.012%0A%20%20%20%20%20%20%20%20if%20((total_cpu%20%3E%201))%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Calculate%20the%20total%20system-reserved%20CPU%20in%20fractions%2C%20starting%20with%20the%20base%20allocation%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20and%20adding%20the%20incremental%20fraction%20for%20each%20additional%20CPU%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(awk%20-v%20base%3D%22%24base_allocation_fraction%22%20-v%20increment%3D%22%24increment_per_cpu_fraction%22%20-v%20cpus%3D%22%24total_cpu%22%20'BEGIN%20%7Bprintf%20%22%25.2f%5Cn%22%2C%20base%20%2B%20increment%20*%20(cpus%20-%201)%7D')%0A%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20For%20a%20single%20CPU%2C%20use%20the%20base%20allocation%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24base_allocation_fraction%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Enforce%20minimum%20threshold%20of%200.5%20CPU%0A%20%20%20%20recommended_systemreserved_cpu%3D%24(awk%20-v%20val%3D%22%24recommended_systemreserved_cpu%22%20'BEGIN%20%7Bif%20(val%20%3C%200.5)%20print%200.5%3B%20else%20print%20val%7D')%0A%0A%20%20%20%20echo%20%22SYSTEM_RESERVED_CPU%3D%24%7Brecommended_systemreserved_cpu%7D%22%3E%3E%20%24%7BNODE_SIZES_ENV%7D%0A%7D%0Afunction%20dynamic_ephemeral_sizing%20%7B%0A%20%20%20%20echo%20%22Not%20implemented%20yet%22%0A%7D%0Afunction%20dynamic_pid_sizing%20%7B%0A%20%20%20%20echo%20%22Not%20implemented%20yet%22%0A%7D%0Afunction%20set_memory%20%7B%0A%20%20%20%20SYSTEM_RESERVED_MEMORY%3D%241%0A%20%20%20%20if%20%5B%20-z%20%22%24%7BSYSTEM_RESERVED_MEMORY%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20SYSTEM_RESERVED_MEMORY%3D%221Gi%22%0A%20%20%20%20fi%0A%20%20%20%20echo%20%22SYSTEM_RESERVED_MEMORY%3D%24%7BSYSTEM_RESERVED_MEMORY%7D%22%20%3E%3E%20%24%7BNODE_SIZES_ENV%7D%0A%7D%0Afunction%20set_cpu%20%7B%0A%20%20%20%20SYSTEM_RESERVED_CPU%3D%241%0A%20%20%20%20if%20%5B%20-z%20%22%24%7BSYSTEM_RESERVED_CPU%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20SYSTEM_RESERVED_CPU%3D%22500m%22%0A%20%20%20%20fi%0A%20%20%20%20echo%20%22SYSTEM_RESERVED_CPU%3D%24%7BSYSTEM_RESERVED_CPU%7D%22%20%3E%3E%20%24%7BNODE_SIZES_ENV%7D%0A%7D%0Afunction%20set_es%20%7B%0A%20%20%20%20SYSTEM_RESERVED_ES%3D%241%0A%20%20%20%20if%20%5B%20-z%20%22%24%7BSYSTEM_RESERVED_ES%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20SYSTEM_RESERVED_ES%3D%221Gi%22%0A%20%20%20%20fi%0A%20%20%20%20echo%20%22SYSTEM_RESERVED_ES%3D%24%7BSYSTEM_RESERVED_ES%7D%22%20%3E%3E%20%24%7BNODE_SIZES_ENV%7D%0A%7D%0Afunction%20dynamic_node_sizing%20%7B%0A%20%20%20%20rm%20-f%20%24%7BNODE_SIZES_ENV%7D%0A%20%20%20%20dynamic_memory_sizing%0A%20%20%20%20dynamic_cpu_sizing%20%241%0A%20%20%20%20set_es%20%242%0A%20%20%20%20%23dynamic_ephemeral_sizing%0A%20%20%20%20%23dynamic_pid_sizing%0A%7D%0Afunction%20static_node_sizing%20%7B%0A%20%20%20%20rm%20-f%20%24%7BNODE_SIZES_ENV%7D%0A%20%20%20%20set_memory%20%241%0A%20%20%20%20set_cpu%20%242%0A%20%20%20%20set_es%20%243%0A%7D%0Afunction%20create_version_file%20%7B%0A%20%20%20%20echo%20%22%7B%5C%22version%5C%22%3A%20%241%7D%22%20%3E%20%242%0A%7D%0Aif%20!%20%5B%20-f%20%24NODE_AUTO_SIZING_VERSION_FILE%20%5D%3B%20then%0A%20%20%20%20create_version_file%20%24NODE_AUTO_SIZING_VERSION%20%24NODE_AUTO_SIZING_VERSION_FILE%0Afi%0Anew_version%3D%24(jq%20.version%20%24NODE_AUTO_SIZING_VERSION_FILE)%0Aif%20%5B%20%241%20%3D%3D%20%22true%22%20%5D%3B%20then%0A%20%20%20%20dynamic_node_sizing%20%24new_version%20%244%0Aelif%20%5B%20%241%20%3D%3D%20%22false%22%20%5D%3B%20then%0A%20%20%20%20static_node_sizing%20%242%20%243%20%244%0Aelse%0A%20%20%20%20echo%20%22Unrecognized%20command%20line%20option.%20Valid%20options%20are%20%5C%22true%5C%22%20or%20%5C%22false%5C%22%22%0Afi%0A
          mode: 493
          overwrite: true
          path: /usr/local/sbin/dynamic-system-reserved-calc.sh
        - contents:
            source: data:,%23%20Turning%20on%20Accounting%20helps%20track%20down%20performance%20issues.%0A%5BManager%5D%0ADefaultCPUAccounting%3Dyes%0ADefaultMemoryAccounting%3Dyes%0ADefaultBlockIOAccounting%3Dyes%0A
          mode: 420
          overwrite: true
          path: /etc/systemd/system.conf.d/kubelet-cgroups.conf
        - contents:
            source: data:,%5BService%5D%0AEnvironment%3D%22KUBELET_LOG_LEVEL%3D2%22%0A
          mode: 420
          overwrite: true
          path: /etc/systemd/system/kubelet.service.d/20-logging.conf
        - contents:
            source: data:,%23%20ignore%20known%20SDN-managed%20devices%0A%5Bdevice%5D%0Amatch-device%3Dinterface-name%3Abr-int%3Binterface-name%3Abr-local%3Binterface-name%3Abr-nexthop%3Binterface-name%3Aovn-k8s-*%3Binterface-name%3Ak8s-*%3Binterface-name%3Atun0%3Binterface-name%3Abr0%3Binterface-name%3Apatch-br-*%3Binterface-name%3Abr-ext%3Binterface-name%3Aext-vxlan%3Binterface-name%3Aext%3Binterface-name%3Aint%3Binterface-name%3Avxlan_sys_*%3Binterface-name%3Agenev_sys_*%3Bdriver%3Aveth%0Amanaged%3D0%0A
          mode: 420
          overwrite: true
          path: /etc/NetworkManager/conf.d/sdn.conf
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-eux%0A%0A%23%20Clean%20up%20old%20config%20on%20behalf%20of%20mtu-migration%0Aif%20!%20systemctl%20-q%20is-enabled%20mtu-migration%3B%20then%0A%20%20echo%20%22Cleaning%20up%20left%20over%20mtu%20migration%20configuration%22%0A%20%20rm%20-rf%20%2Fetc%2Fcno%2Fmtu-migration%0Afi%0A%0Aif%20%5B%20-e%20%2Fetc%2Fnmstate%2Fopenshift%2Fapplied%20%5D%3B%20then%0A%20%20echo%20%22Configuration%20already%20applied%2C%20exiting%22%0A%20%20exit%200%0Afi%0A%0Asrc_path%3D%22%2Fetc%2Fnmstate%2Fopenshift%22%0Adst_path%3D%22%2Fetc%2Fnmstate%22%0Ahostname%3D%24(hostname%20-s)%0Ahost_file%3D%22%24%7Bhostname%7D.yml%22%0Acluster_file%3D%22cluster.yml%22%0Aconfig_file%3D%22%22%0Aif%20%5B%20-s%20%22%24src_path%2F%24host_file%22%20%5D%3B%20then%0A%20%20config_file%3D%24host_file%0Aelif%20%5B%20-s%20%22%24src_path%2F%24cluster_file%22%20%5D%3B%20then%0A%20%20config_file%3D%24cluster_file%0Aelse%0A%20%20echo%20%22No%20configuration%20found%20at%20%24src_path%2F%24host_file%20or%20%24src_path%2F%24cluster_file%22%0A%20%20exit%200%0Afi%0A%0Aif%20%5B%20-e%20%22%24dst_path%2F%24config_file%22%20%5D%3B%20then%0A%20%20echo%20%22ERROR%3A%20File%20%24dst_path%2F%24config_file%20exists.%20Refusing%20to%20overwrite.%22%0A%20%20exit%201%0Afi%0A%0A%23%20Handle%20the%20case%20where%20we're%20migrating%20from%20configure-ovs%0Aovs-vsctl%20--timeout%3D30%20--if-exists%20del-br%20br-ex%0A%0A%23%20Handle%20the%20case%20where%20we're%20migrating%20from%20OpenShift%20SDN%0Aovs-vsctl%20--timeout%3D30%20--if-exists%20del-br%20br0%0A%0Acp%20%22%24src_path%2F%24config_file%22%20%2Fetc%2Fnmstate%0Atouch%20%2Fetc%2Fnmstate%2Fopenshift%2Fapplied%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/nmstate-configuration.sh
        - contents:
            source: data:,%5Bservice%5D%0Akeep_state_file_after_apply%20%3D%20true%0A
          mode: 420
          overwrite: true
          path: /etc/nmstate/nmstate.conf
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%23%20Set%20interface%20ofport_request%20to%20guarantee%20stable%20ofport%20numbers.%20This%20is%20important%20for%20flow%20matches.%0A%23%20Otherwise%2C%20another%20ofport%20number%20is%20assigned%20to%20the%20interface%20on%20every%20restart%20of%20NetworkManager.%0A%23%20This%20script%20will%20build%20an%20associative%20array%20INTERFACE_NAME-%3Eofport_request%20and%20will%20save%20it%20to%20file%20CONFIGURATION_FILE.%0A%23%20When%20an%20interface%20is%20brought%20up%2C%20this%20will%20reuse%20the%20value%20from%20the%20associative%20array%20if%20such%20a%20value%20exists.%0A%23%20Otherwise%2C%20this%20will%20try%20to%20use%20the%20current%20ofport%20value.%20If%20the%20ofport%20value%20is%20already%20reserved%2C%20then%0A%23%20this%20uses%20the%20lowest%20available%20numerical%20value%2C%20instead.%0Aset%20-eux%20-o%20pipefail%0Aif%20%5B%5B%20%22OVNKubernetes%22%20!%3D%20%22OVNKubernetes%22%20%5D%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0AINTERFACE_NAME%3D%241%0AOPERATION%3D%242%0A%0A%23%20Only%20execute%20this%20on%20pre-up%0Aif%20%5B%20%22%24%7BOPERATION%7D%22%20!%3D%20%22pre-up%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20interface's%20NM%20uuid%0AINTERFACE_CONNECTION_UUID%3D%24(nmcli%20-t%20-f%20device%2Ctype%2Cuuid%20conn%20%7C%20awk%20-F%20'%3A'%20'%7Bif(%241%3D%3D%22'%24%7BINTERFACE_NAME%7D'%22%20%26%26%20%242!~%2F%5Eovs*%2F)%20print%20%24NF%7D')%0Aif%20%5B%20%22%24%7BINTERFACE_CONNECTION_UUID%7D%22%20%3D%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20interface's%20slave-type.%20If%20this%20is%20not%20an%20ovs-port%2C%20then%20exit%0AINTERFACE_OVS_SLAVE_TYPE%3D%24(nmcli%20-t%20-f%20connection.slave-type%20conn%20show%20%22%24%7BINTERFACE_CONNECTION_UUID%7D%22%20%7C%20awk%20-F%20'%3A'%20'%7Bprint%20%24NF%7D')%0Aif%20%5B%20%22%24%7BINTERFACE_OVS_SLAVE_TYPE%7D%22%20!%3D%20%22ovs-port%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20This%20is%20not%20necessarily%20a%20UUID%20(can%20be%20a%20name%20in%20case%20of%20bonds)%20but%20this%20should%20be%20unique%0APORT%3D%24(nmcli%20-t%20-f%20connection.master%20conn%20show%20%22%24%7BINTERFACE_CONNECTION_UUID%7D%22%20%7C%20awk%20-F%20'%3A'%20'%7Bprint%20%24NF%7D')%0Aif%20%5B%20%22%24%7BPORT%7D%22%20%3D%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20interface's%20NM%20uuid%0APORT_CONNECTION_UUID%3D%24(nmcli%20-t%20-f%20device%2Ctype%2Cuuid%20conn%20%7C%20awk%20-F%20'%3A'%20'%7Bif(%20(%241%3D%3D%22'%24%7BPORT%7D'%22%20%7C%7C%20%243%3D%3D%22'%24%7BPORT%7D'%22)%20%26%26%20%242~%2F%5Eovs*%2F)%20print%20%24NF%7D')%0Aif%20%5B%20%22%24%7BPORT_CONNECTION_UUID%7D%22%20%3D%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20port's%20slave-type.%20If%20this%20is%20not%20an%20ovs-bridge%2C%20then%20exit%0APORT_OVS_SLAVE_TYPE%3D%24(nmcli%20-t%20-f%20connection.slave-type%20conn%20show%20%22%24%7BPORT_CONNECTION_UUID%7D%22%20%7C%20awk%20-F%20'%3A'%20'%7Bprint%20%24NF%7D')%0Aif%20%5B%20%22%24%7BPORT_OVS_SLAVE_TYPE%7D%22%20!%3D%20%22ovs-bridge%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20port's%20master.%20If%20it%20doesn't%20have%20any%2C%20assume%20it's%20not%20our%20bridge%0ABRIDGE_ID%3D%24(nmcli%20-t%20-f%20connection.master%20conn%20show%20%22%24%7BPORT_CONNECTION_UUID%7D%22%20%7C%20awk%20-F%20'%3A'%20'%7Bprint%20%24NF%7D')%0Aif%20%5B%20%22%24%7BBRIDGE_ID%7D%22%20%3D%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20bridge%20name%0ABRIDGE_NAME%3D%24(nmcli%20-t%20-f%20connection.interface-name%20conn%20show%20%22%24%7BBRIDGE_ID%7D%22%20%7C%20awk%20-F%20'%3A'%20'%7Bprint%20%24NF%7D')%0A%23%20Limit%20this%20to%20br-ex%20and%20br-ex1%20only.%20If%20one%20wanted%20to%20enable%20this%20for%20all%20OVS%20bridges%2C%0A%23%20the%20condition%20would%20be%3A%20if%20%5B%20%22%24BRIDGE_NAME%22%20%3D%3D%20%22%22%20%5D%3B%20then%0Aif%20%5B%20%22%24%7BBRIDGE_NAME%7D%22%20!%3D%20%22br-ex%22%20%5D%20%26%26%20%5B%20%22%24%7BBRIDGE_NAME%7D%22%20!%3D%20%22br-ex1%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Make%20sure%20that%20the%20interface%20is%20plugged%20into%20OVS%0A%23%20This%20should%20always%20be%20the%20case%20given%20that%20we%20are%20in%20pre-up%2C%20but%20exit%20gracefully%20in%20the%20odd%20case%20that%20it's%20not%0Aif%20!%20ovs-vsctl%20list%20interface%20%22%24%7BINTERFACE_NAME%7D%22%20%3E%2Fdev%2Fnull%202%3E%261%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0ACONFIGURATION_FILE%3D%22%2Frun%2Fofport_requests.%24%7BBRIDGE_NAME%7D%22%0A%0A%23%20Declare%20a%20new%20associative%20array.%20If%20CONFIGURATION_FILE%20exists%2C%20source%20entries%20from%20there%0Adeclare%20-A%20INTERFACES%0Aif%20%5B%20-f%20%22%24%7BCONFIGURATION_FILE%7D%22%20%5D%3B%20then%0A%20%20%20%20echo%20%22Sourcing%20configuration%20file%20'%24%7BCONFIGURATION_FILE%7D'%20with%20contents%3A%22%0A%20%20%20%20cat%20%22%24%7BCONFIGURATION_FILE%7D%22%0A%20%20%20%20source%20%22%24%7BCONFIGURATION_FILE%7D%22%0Afi%0A%0A%23%20get_interface_ofport_request%20will%20return%0A%23%20*%20either%3A%20the%20current%20ofport%20assignment%20for%20the%20port%20if%20no%20interface%20has%20claimed%20this%20ofport%20number%2C%20yet%0A%23%20*%20or%3A%20%20%20%20%20the%20lowest%20available%20free%20ofport%20number%0Afunction%20get_interface_ofport_request()%20%7B%0A%20%20%20%20%23%20Build%20an%20array%20that%20only%20contains%20the%20currently%20reserved%20ofport_requests%0A%20%20%20%20declare%20-A%20ofport_requests%0A%20%20%20%20for%20interface_name%20in%20%22%24%7B!INTERFACES%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20%20%20%20%20ofport_requests%5B%24%7BINTERFACES%5B%24interface_name%5D%7D%5D%3D%24%7BINTERFACES%5B%24interface_name%5D%7D%0A%20%20%20%20done%0A%0A%20%20%20%20%23%20Get%20the%20current%20ofport%20number%20assignment%0A%20%20%20%20local%20current_ofport%3D%24(ovs-vsctl%20get%20Interface%20%22%24%7BINTERFACE_NAME%7D%22%20ofport)%0A%0A%20%20%20%20%23%20If%20the%20current%20ofport%20number%20is%20still%20free%2C%20use%20it%0A%20%20%20%20if%20!%20%5B%20%22%24%7Bofport_requests%5B%24current_ofport%5D%2Ba%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%24current_ofport%0A%20%20%20%20%20%20%20%20return%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20If%20the%20current%20ofport%20number%20is%20not%20free%2C%20return%20the%20lowest%20free%20entry%0A%20%20%20%20i%3D0%0A%20%20%20%20for%20i%20in%20%7B1..65000%7D%3B%20do%0A%20%20%20%20%20%20%20%20if%20!%20%5B%20%22%24%7Bofport_requests%5B%24i%5D%2Ba%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20echo%20%24i%0A%20%20%20%20%20%20%20%20%20%20%20%20return%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20done%0A%0A%20%20%20%20%23%20if%20we%20still%20cannot%20find%20an%20ID%2C%20exit%20with%20an%20error%0A%20%20%20%20echo%20%22Impossible%20to%20find%20an%20ofport%20ID%20for%20interface%20%24%7BINTERFACE_NAME%7D%22%20%3E%262%0A%20%20%20%20exit%201%0A%7D%0A%0A%23%20If%20INTERFACES%5BINTERFACE_NAME%5D%20exists%2C%20use%20that%20value%0A%23%20If%20INTERFACES%5BINTERFACE_NAME%5D%20does%20not%20exists%2C%20use%20the%20value%20from%20get_interface_ofport_request%0Aif%20!%20%5B%20%22%24%7BINTERFACES%5B%24INTERFACE_NAME%5D%2Ba%7D%22%20%5D%3B%20then%0A%20%20%20%20INTERFACES%5B%24INTERFACE_NAME%5D%3D%24(get_interface_ofport_request)%0Afi%0A%23%20Set%20ofport_request%20according%20to%20INTERFACES%5BINTERFACE_NAME%5D%0Aovs-vsctl%20set%20Interface%20%22%24%7BINTERFACE_NAME%7D%22%20ofport_request%3D%24%7BINTERFACES%5B%24INTERFACE_NAME%5D%7D%0A%0A%23%20Save%20current%20state%20of%20INTERFACES%20to%20CONFIGURATION_FILE%0Adeclare%20-p%20INTERFACES%20%3E%7C%20%22%24%7BCONFIGURATION_FILE%7D%22%0A
          mode: 493
          overwrite: true
          path: /etc/NetworkManager/dispatcher.d/pre-up.d/10-ofport-request.sh
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%0A%23%20Extract%20Podman%20version%20and%20determine%20the%20signature%20policy%0A%2Fusr%2Fbin%2Fpodman%20-v%20%7C%20%2Fbin%2Fawk%20'%7B%0A%20%20%20%20split(%243%2C%20version%2C%20%22-%22)%3B%0A%20%20%20%20clean_version%20%3D%20version%5B1%5D%3B%0A%0A%20%20%20%20split(clean_version%2C%20current%2C%20%2F%5C.%2F)%3B%0A%20%20%20%20split(%224.4.1%22%2C%20target%2C%20%2F%5C.%2F)%3B%0A%0A%20%20%20%20for%20(i%20%3D%201%3B%20i%20%3C%3D%203%3B%20i%2B%2B)%20%7B%0A%20%20%20%20%20%20%20%20if%20((current%5Bi%5D%20%2B%200)%20%3C%20(target%5Bi%5D%20%2B%200))%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20print%20%22--signature-policy%20%2Fetc%2Fmachine-config-daemon%2Fpolicy-for-old-podman.json%22%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20exit%3B%0A%20%20%20%20%20%20%20%20%7D%20else%20if%20((current%5Bi%5D%20%2B%200)%20%3E%20(target%5Bi%5D%20%2B%200))%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20exit%3B%0A%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%7D%0A%7D'%20%3E%20%2Ftmp%2Fpodman_policy_args%0A
          mode: 493
          overwrite: true
          path: /etc/machine-config-daemon/generate_podman_policy_args.sh
        - contents:
            source: data:,%7B%22auths%22%3A%7B%22cloud.openshift.com%22%3A%7B%22auth%22%3A%22b3BlbnNoaWZ0LXJlbGVhc2UtZGV2K29jbV9hY2Nlc3NfOTRmZDViZTMwOTM3NGU5NDlkM2Q5NzhmOTQzZGFlYTI6TDc0UlozWjNEUUM1U0RFMjBUUUU3UDRZR1RNSDRIRUdMUkMySzk3MjJMSE1PMlBPVUNaUDJFVVo0UDc1N1RLQw%3D%3D%22%2C%22email%22%3A%22jgoldberg%40allcovered.com%22%7D%2C%22quay.io%22%3A%7B%22auth%22%3A%22b3BlbnNoaWZ0LXJlbGVhc2UtZGV2K29jbV9hY2Nlc3NfOTRmZDViZTMwOTM3NGU5NDlkM2Q5NzhmOTQzZGFlYTI6TDc0UlozWjNEUUM1U0RFMjBUUUU3UDRZR1RNSDRIRUdMUkMySzk3MjJMSE1PMlBPVUNaUDJFVVo0UDc1N1RLQw%3D%3D%22%2C%22email%22%3A%22jgoldberg%40allcovered.com%22%7D%2C%22registry.connect.redhat.com%22%3A%7B%22auth%22%3A%22fHVoYy1wb29sLTljZTJiZWU4LTUwYWQtNDVlNC04NDExLTNkNjQ1NWNkODI1NjpleUpoYkdjaU9pSlNVelV4TWlKOS5leUp6ZFdJaU9pSTNaakppTldOallXWXhZVEEwWXpZMVlUSTFaRGN6TjJSa05UVXlNbVJqWWlKOS5NZHFkUUgzenYyMHFzQ0dfR2hGYy1WSzFRNGRsOW05TFhqcmhQNjNjUDh0dDVGX25Wc1U5NGxlcmVVSEQ4R1FXRUxDZlIzeE5HQ2dOSXFPNWUyNC02U3NGOFNTQV9RSnZIODVzLTBBWXlWMHY2QnJxV21CRHNLSWdnSzE2SFhWUzd4cTlSZ05hN200RFRMdUF2RUdtVkRSQ05VUVNFN1FMTWMxaUVhSVI4RVdrT0pPUklQd3hQM3YyUDlsTHpSRWtKYl82WVRjUWRjQUR3T0d1OWkzUHIwMWRHX1d4QU90NkFxcFZBX0JSaHRhNFRjWTFwSHk1bXBlWWVIVnE3Q3hzZWFRV3FzR01Oc0lObkFFNGdjV0MyekVXVl9NZHpIQXVad203WWsxMjg5VVhfYnhVMWhDUkVzdG5zdGdCSERheFRpSTFjalZSZkJ4X05hb0RMU01GVXBzNmlDVXhTTUxzVmc3Mi04LVJHal9nVmMxRDZPNjJkODJoakdaaW5HekJsendzMkZLYlFnNDRjb1VWcWpDdUMwdktCdVJRbDhkX0taVGZTWFVSTS0wOE91YjBNdDRIMjVjZmx6bjNERWdDcUtlSVlUYVdMS3ZranRKVy1MaGdLRjlDUHFqWmozUjhwN2xja2ZkR0lPbHRvY0hZY0xXVlM3QURjdmRNaWVLa3p5STRHb2RPamp2NU5OVF9UWDdjRHBRRVdWUnlENkxkOElXODA4SHVoSmtfa2R0MWVDSkxSTTVUdFBSRHVxZ3UwODlqcWM4WXRVWFhfcm9KcFhoSE5iMUlnekZTdFJqZktTSVJ6YTdlV2g4VWxvRmNwNXJZOV9VeDFTaFVnZ3JlQXFmQ1Y4NXF5Wjlya2RibVNZUE5PRVdzTmtUeGJoY0Q4YWpkYlJrWkFCRQ%3D%3D%22%2C%22email%22%3A%22jgoldberg%40allcovered.com%22%7D%2C%22registry.redhat.io%22%3A%7B%22auth%22%3A%22fHVoYy1wb29sLTljZTJiZWU4LTUwYWQtNDVlNC04NDExLTNkNjQ1NWNkODI1NjpleUpoYkdjaU9pSlNVelV4TWlKOS5leUp6ZFdJaU9pSTNaakppTldOallXWXhZVEEwWXpZMVlUSTFaRGN6TjJSa05UVXlNbVJqWWlKOS5NZHFkUUgzenYyMHFzQ0dfR2hGYy1WSzFRNGRsOW05TFhqcmhQNjNjUDh0dDVGX25Wc1U5NGxlcmVVSEQ4R1FXRUxDZlIzeE5HQ2dOSXFPNWUyNC02U3NGOFNTQV9RSnZIODVzLTBBWXlWMHY2QnJxV21CRHNLSWdnSzE2SFhWUzd4cTlSZ05hN200RFRMdUF2RUdtVkRSQ05VUVNFN1FMTWMxaUVhSVI4RVdrT0pPUklQd3hQM3YyUDlsTHpSRWtKYl82WVRjUWRjQUR3T0d1OWkzUHIwMWRHX1d4QU90NkFxcFZBX0JSaHRhNFRjWTFwSHk1bXBlWWVIVnE3Q3hzZWFRV3FzR01Oc0lObkFFNGdjV0MyekVXVl9NZHpIQXVad203WWsxMjg5VVhfYnhVMWhDUkVzdG5zdGdCSERheFRpSTFjalZSZkJ4X05hb0RMU01GVXBzNmlDVXhTTUxzVmc3Mi04LVJHal9nVmMxRDZPNjJkODJoakdaaW5HekJsendzMkZLYlFnNDRjb1VWcWpDdUMwdktCdVJRbDhkX0taVGZTWFVSTS0wOE91YjBNdDRIMjVjZmx6bjNERWdDcUtlSVlUYVdMS3ZranRKVy1MaGdLRjlDUHFqWmozUjhwN2xja2ZkR0lPbHRvY0hZY0xXVlM3QURjdmRNaWVLa3p5STRHb2RPamp2NU5OVF9UWDdjRHBRRVdWUnlENkxkOElXODA4SHVoSmtfa2R0MWVDSkxSTTVUdFBSRHVxZ3UwODlqcWM4WXRVWFhfcm9KcFhoSE5iMUlnekZTdFJqZktTSVJ6YTdlV2g4VWxvRmNwNXJZOV9VeDFTaFVnZ3JlQXFmQ1Y4NXF5Wjlya2RibVNZUE5PRVdzTmtUeGJoY0Q4YWpkYlJrWkFCRQ%3D%3D%22%2C%22email%22%3A%22jgoldberg%40allcovered.com%22%7D%7D%7D%0A
          mode: 384
          overwrite: true
          path: /var/lib/kubelet/config.json
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-eo%20pipefail%0A%0Afunction%20pull_baremetal_runtime_cfg_image%20%7B%0A%20%20%20%20%23%20By%20default%20podman%20retries%20to%20pull%20an%20image%203%20times%20with%201%20second%20back-off.%20It%20is%20not%20configurable.%20For%20this%0A%20%20%20%20%23%20reason%20we%20are%20implementing%20our%20own%20logic%20of%20pulling%20image%20and%20retrying%20indefinitely.%0A%20%20%20%20%23%20Ref.%3A%20https%3A%2F%2Fgithub.com%2Fcontainers%2Fcommon%2Fblob%2Fe028741ef77fdfa3ae261b9d23cdd50253d586c4%2Flibimage%2Fcopier.go%23L27-L30%0A%0A%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Checking%20if%20baremetal%20runtime%20cfg%20image%20already%20exists%22%0A%20%20%20%20if%20!%20%2Fusr%2Fbin%2Fpodman%20image%20exists%20%22quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A93e7b8c870261726d44bddc7ba0a702d3720d1838141dac837fb8c3be7c6e1a1%22%3B%20then%0A%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Starting%20download%20of%20baremetal%20runtime%20cfg%20image%22%0A%20%20%20%20%20%20while%20!%20%2Fusr%2Fbin%2Fpodman%20pull%20--authfile%20%2Fvar%2Flib%2Fkubelet%2Fconfig.json%20%22quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A93e7b8c870261726d44bddc7ba0a702d3720d1838141dac837fb8c3be7c6e1a1%22%3B%20do%20sleep%201%3B%20done%0A%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Download%20of%20baremetal%20runtime%20cfg%20image%20completed%22%0A%20%20%20%20else%0A%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Image%20exists%2C%20no%20need%20to%20download%22%0A%20%20%20%20fi%0A%7D%0A%0Afunction%20resolv_prepender%20%7B%0A%20%20%20%20%20%20%20%20%23%20In%20DHCP%20connections%2C%20the%20resolv.conf%20content%20may%20be%20late%2C%20thus%20we%20wait%20for%20nameservers%0A%20%20%20%20%20%20%20%20while%20!%20grep%20nameserver%20%2Fvar%2Frun%2FNetworkManager%2Fresolv.conf%3B%20do%0A%20%20%20%20%20%20%20%20%20%20%20%20%3E%262%20echo%20%20%22NM%20resolv-prepender%3A%20NM%20resolv.conf%20still%20empty%20of%20nameserver%22%0A%20%20%20%20%20%20%20%20%20%20%20%20sleep%200.5%0A%20%20%20%20%20%20%20%20done%0A%0A%20%20%20%20%20%20%20%20%23%20Ensure%20resolv.conf%20exists%20and%20contains%20nameservers%20before%20we%20try%20to%20pull%20image%20or%20run%20podman%0A%20%20%20%20%20%20%20%20if%20%5B%5B%20!%20-e%20%2Fetc%2Fresolv.conf%20%5D%5D%20%7C%7C%20!%20grep%20-q%20nameserver%20%2Fetc%2Fresolv.conf%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20cp%20%2Fvar%2Frun%2FNetworkManager%2Fresolv.conf%20%2Fetc%2Fresolv.conf%0A%20%20%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20%20%20%23%20Ensure%20baremetalRuntimeCfgImage%20is%20pulled%20in%20a%20reliable%20way%20before%20trying%20to%20use%20it%0A%20%20%20%20%20%20%20%20%23%20in%20the%20subsequent%20code%0A%20%20%20%20%20%20%20%20pull_baremetal_runtime_cfg_image%0A%0A%20%20%20%20%20%20%20%20NAMESERVER_IP%3D%22%24(%2Fusr%2Fbin%2Fpodman%20run%20--rm%20%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20--authfile%20%2Fvar%2Flib%2Fkubelet%2Fconfig.json%20%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20--net%3Dhost%20%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A93e7b8c870261726d44bddc7ba0a702d3720d1838141dac837fb8c3be7c6e1a1%20%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20node-ip%20%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20show%20%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%2210.100.0.50%22%20%20%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%2210.100.0.51%22%20)%22%0A%20%20%20%20%20%20%20%20DOMAINS%3D%22%24%7BIP4_DOMAINS%3A-%7D%20%24%7BIP6_DOMAINS%3A-%7D%20comp-poc-rh01.rhpoc.int%22%0A%20%20%20%20%20%20%20%20if%20%5B%5B%20-n%20%22%24NAMESERVER_IP%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20KNICONFDONEPATH%3D%22%2Frun%2Fresolv-prepender-kni-conf-done%22%0A%20%20%20%20%20%20%20%20%20%20%20%20if%20systemctl%20-q%20is-enabled%20systemd-resolved%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Configure%20for%20OKD%20domain%20and%20local%20IP%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20mkdir%20-p%20%2Fetc%2Fsystemd%2Fresolved.conf.d%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20KNICONFTMPPATH%3D%22%24(mktemp)%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20KNICONFPATH%3D%22%2Fetc%2Fsystemd%2Fresolved.conf.d%2F60-kni.conf%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20echo%20%22%5BResolve%5D%22%20%3E%20%22%24%7BKNICONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20echo%20%22DNS%3D%24NAMESERVER_IP%22%20%3E%3E%20%22%24%7BKNICONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20echo%20%22Domains%3D%24%7BDOMAINS%7D%22%20%3E%3E%20%22%24%7BKNICONFTMPPATH%7D%22%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20If%20KNI%20conf%20is%20not%20created%20or%20doesn't%20match%20what%20is%20generated%20or%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20if%20we%20haven't%20completed%20a%20full%20update%20-%20create%20or%20update%20it%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20%5B%5B%20!%20-f%20%22%24%7BKNICONFPATH%7D%22%20%5D%5D%20%7C%7C%20%5B%5B%20!%20-f%20%22%24%7BKNICONFDONEPATH%7D%22%20%5D%5D%20%7C%7C%20!%20cmp%20--silent%20%22%24%7BKNICONFPATH%7D%22%20%22%24%7BKNICONFTMPPATH%7D%22%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Creating%2Fupdating%20%2Fetc%2Fsystemd%2Fresolved.conf.d%2F60-kni.conf%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Remove%20the%20done%20file%20flag%20before%20writing%20the%20config%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20This%20would%20guard%20against%20interruptions%20and%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20prevent%20double%20restart%20of%20systemd-resolved%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20rm%20-f%20%22%24%7BKNICONFDONEPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Copy%20tmp%20file%20contents%20to%20preserve%20permissions%20and%20SELinux%20label%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20cat%20%22%24%7BKNICONFTMPPATH%7D%22%20%3E%20%22%24%7BKNICONFPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20%5B%5B%20!%20-f%20%22%24%7BKNICONFDONEPATH%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20systemctl%20-q%20is-active%20systemd-resolved%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Restarting%20systemd-resolved%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20systemctl%20restart%20systemd-resolved%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20touch%20%22%24%7BKNICONFDONEPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20rm%20-rf%20%22%24%7BKNICONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Prepending%20'nameserver%20%24NAMESERVER_IP'%20to%20%2Fetc%2Fresolv.conf%20(other%20nameservers%20from%20%2Fvar%2Frun%2FNetworkManager%2Fresolv.conf)%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20RESOLVCONFTMPPATH%3D%22%24(mktemp)%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20sed%20-e%20%22%2FGenerated%20by%2Fc%23%20Generated%20by%20KNI%20resolv%20prepender%20NM%20dispatcher%20script%22%20%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%2Fvar%2Frun%2FNetworkManager%2Fresolv.conf%20%3E%20%22%24%7BRESOLVCONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20sed%20-i%20%220%2C%2F%5Enameserver.*%2Fs%2F%2Fnameserver%20%24NAMESERVER_IP%5Cn%5C0%2F%22%20%22%24%7BRESOLVCONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20!%20grep%20-q%20search%20%22%24%7BRESOLVCONFTMPPATH%7D%22%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Make%20sure%20we%20have%20a%20search%20entry%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20echo%20%22search%20comp-poc-rh01.rhpoc.int%22%20%3E%3E%20%22%24%7BRESOLVCONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Make%20sure%20cluster%20domain%20is%20first%20in%20the%20search%20list%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20sed%20-i%20%22s%2F%5Esearch%20%5C(.*%5C)%2Fsearch%20comp-poc-rh01.rhpoc.int%20%5C1%2F%22%20%22%24%7BRESOLVCONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Remove%20duplicate%20cluster%20domain%20entries%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20sed%20-i%20%22s%2F%5C(search%20comp-poc-rh01.rhpoc.int.*%5C)%20comp-poc-rh01.rhpoc.int%5C(%20.*%5C%7C%24%5C)%2F%5C1%5C2%2F%22%20%22%24%7BRESOLVCONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Only%20leave%20the%20first%203%20nameservers%20in%20%2Fetc%2Fresolv.conf%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20sed%20-i%20'%3Aa%20%24!%7BN%3B%20ba%7D%3B%20s%2F%5C(%5E%5C%7C%5Cn%5C)nameserver%2F%5Cn%23%20nameserver%2F4g'%20%22%24%7BRESOLVCONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Only%20touch%20existing%20resolv.conf%20if%20files%20actually%20differ%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20!%20cmp%20-s%20%22%24%7BRESOLVCONFTMPPATH%7D%22%20%2Fetc%2Fresolv.conf%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20chmod%20644%20%22%24%7BRESOLVCONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20mv%20-Zf%20%22%24%7BRESOLVCONFTMPPATH%7D%22%20%2Fetc%2Fresolv.conf%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Workaround%20for%20bz%201929160.%20Reload%20NetworkManager%20to%20force%20it%20to%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20re-run%20the%20lookup%20of%20the%20hostname%20now%20that%20we%20know%20we%20have%20DNS%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20servers%20configured%20correctly%20in%20resolv.conf.%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20nmcli%20general%20reload%20dns-rc%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20touch%20%22%24%7BKNICONFDONEPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20rm%20-rf%20%22%24%7BRESOLVCONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20fi%0A%7D%0A%0Aresolv_prepender%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/resolv-prepender.sh
        - contents:
            source: data:,%23%20Needed%20by%20the%20OpenShift%20SDN.%20See%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1758552%0Anet.ipv4.conf.all.arp_announce%20%3D%202%0A
          mode: 420
          overwrite: true
          path: /etc/sysctl.d/arp.conf
        - contents:
            source: data:,%23%20See%3A%20rhbz%231384746%2C%20OCPBUGS-24012%0Anet.ipv4.neigh.default.gc_thresh1%3D8192%0Anet.ipv4.neigh.default.gc_thresh2%3D32768%0Anet.ipv4.neigh.default.gc_thresh3%3D65536%0Anet.ipv6.neigh.default.gc_thresh1%3D8192%0Anet.ipv6.neigh.default.gc_thresh2%3D32768%0Anet.ipv6.neigh.default.gc_thresh3%3D65536%0A
          mode: 420
          overwrite: true
          path: /etc/sysctl.d/gc-thresh.conf
        - contents:
            source: data:,%0Afs.inotify.max_user_watches%20%3D%2065536%0Afs.inotify.max_user_instances%20%3D%208192%0A
          mode: 420
          overwrite: true
          path: /etc/sysctl.d/inotify.conf
        - contents:
            source: data:,vm.unprivileged_userfaultfd%20%3D%201
          mode: 420
          overwrite: true
          path: /etc/sysctl.d/enable-userfaultfd.conf
        - contents:
            source: data:,%23%20Needed%20for%20OpenShift%20Logging%20(ElasticSearch).%20See%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1793714%0Avm.max_map_count%20%3D%20262144%0A
          mode: 420
          overwrite: true
          path: /etc/sysctl.d/vm-max-map.conf
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-euo%20pipefail%0A%0A%23%20First%2C%20we%20need%20to%20wait%20until%20DHCP%20finishes%20and%20the%20node%20has%20a%20non-%60localhost%60%0A%23%20hostname%20before%20%60kubelet.service%60%20starts.%0A%23%20That's%20the%20%60--wait%60%20argument%20as%20used%20by%20%60node-valid-hostname.service%60.%0A%23%0A%23%20Second%2C%20on%20GCP%20specifically%20we%20truncate%20the%20hostname%20if%20it's%20%3E63%20characters.%0A%23%20That's%20%60gcp-hostname.service%60.%0A%0A%23%20Block%20indefinitely%20until%20the%20host%20gets%20a%20non-localhost%20name.%0A%23%20Note%20node-valid-hostname.service%20uses%20systemd%20to%20abort%20if%20this%20takes%20too%20long.%0Await_localhost()%20%7B%0A%20%20%20%20echo%20%22waiting%20for%20non-localhost%20hostname%20to%20be%20assigned%22%0A%20%20%20%20while%20%5B%5B%20%22%24(%3C%20%2Fproc%2Fsys%2Fkernel%2Fhostname)%22%20%3D~%20(localhost%7Clocalhost.localdomain)%20%5D%5D%3B%0A%20%20%20%20do%0A%20%20%20%20%20%20%20%20sleep%201%0A%20%20%20%20done%0A%20%20%20%20echo%20%22node%20identified%20as%20%24(%3C%2Fproc%2Fsys%2Fkernel%2Fhostname)%22%0A%20%20%20%20echo%20%22saving%20hostname%20to%20prevent%20NetworkManager%20from%20ever%20unsetting%20it%22%0A%20%20%20%20hostnamectl%20set-hostname%20--static%20--transient%20%24(%3C%2Fproc%2Fsys%2Fkernel%2Fhostname)%0A%20%20%20%20exit%200%0A%7D%0A%0Aset_gcp_hostname()%20%7B%0A%20%20%20%20%2Fusr%2Fbin%2Fafterburn%20--provider%20gcp%20--hostname%3D%2Frun%2Fafterburn.hostname%0A%0A%20%20%20%20local%20host_name%3D%24(cat%20%2Frun%2Fafterburn.hostname)%0A%20%20%20%20local%20type_arg%3D%22transient%22%0A%0A%20%20%20%20%23%20%2Fetc%2Fhostname%20is%20used%20for%20static%20hostnames%20and%20is%20authoritative.%0A%20%20%20%20%23%20This%20will%20check%20to%20make%20sure%20that%20the%20static%20hostname%20is%20the%0A%20%20%20%20%23%20less%20than%20or%20equal%20to%2063%20characters%20in%20length.%0A%20%20%20%20if%20%5B%20-f%20%2Fetc%2Fhostname%20%5D%20%26%26%20%5B%20%22%24(cat%20%2Fetc%2Fhostname%20%7C%20wc%20-m)%22%20-gt%200%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20etc_name%3D%22%24(%3C%20%2Fetc%2Fhostname)%22%0A%20%20%20%20%20%20%20%20type_arg%3D%22static%22%0A%20%20%20%20%20%20%20%20if%20%5B%20%22%24%7Betc_name%7D%22%20!%3D%20%22%24%7Bhost_name%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20echo%20%22%2Fetc%2Fhostname%20is%20set%20to%20%24%7Betc_name%7D%20but%20does%20not%20match%20%24%7Bhost_name%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20echo%20%22using%20%2Fetc%2Fhostname%20as%20the%20authoritative%20name%22%0A%20%20%20%20%20%20%20%20%20%20%20%20host_name%3D%22%24%7Betc_name%7D%22%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Only%20mutate%20the%20hostname%20if%20the%20length%20is%20longer%20than%2063%20characters.%20The%0A%20%20%20%20%23%20hostname%20will%20be%20the%20lesser%20of%2063%20characters%20after%20the%20first%20dot%20in%20the%0A%20%20%20%20%23%20FQDN.%20%20This%20algorithm%20is%20only%20known%20to%20work%20in%20GCP%2C%20and%20hence%20is%20only%0A%20%20%20%20%23%20executed%20in%20GCP.%0A%20%20%20%20if%20%5B%20%22%24%7B%23host_name%7D%22%20-gt%2063%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20alt_name%3D%24(printf%20%22%24%7Bhost_name%7D%22%20%7C%20cut%20-f1%20-d'.'%20%7C%20cut%20-c%20-63)%0A%20%20%20%20%20%20%20%20echo%20%22%24%7Bhost_name%7D%20is%20longer%20than%2063%20characters%2C%20using%20truncated%20hostname%22%0A%20%20%20%20%20%20%20%20host_name%3D%22%24%7Balt_name%7D%22%0A%20%20%20%20fi%0A%20%20%20%20echo%20%22setting%20%24%7Btype_arg%7D%20hostname%20to%20%24%7Bhost_name%7D%22%0A%20%20%20%20%2Fbin%2Fhostnamectl%20%22--%24%7Btype_arg%7D%22%20set-hostname%20%22%24%7Bhost_name%7D%22%0A%20%20%20%20exit%200%0A%7D%0A%0Aset_openstack_hostname()%20%7B%0A%20%20%20%20%23%20Read%20metadata%20written%20by%20afterburn%20service%0A%20%20%20%20.%20%2Frun%2Fmetadata%2Fafterburn%0A%0A%20%20%20%20%23%20node-valid-hostname%20sets%20persistent%20hostname%20from%20%2Fproc%2Fsys%2Fkernel%2Fhostname%0A%20%20%20%20echo%20%22%24AFTERBURN_OPENSTACK_HOSTNAME%22%20%3E%20%2Fproc%2Fsys%2Fkernel%2Fhostname%0A%7D%0A%0Aset_powervs_hostname()%20%7B%0A%20%20%20%20%23%20Read%20metadata%20written%20by%20afterburn%20service%0A%20%20%20%20.%20%2Frun%2Fmetadata%2Fafterburn%0A%0A%20%20%20%20%23%20node-valid-hostname%20sets%20persistent%20hostname%20from%20%2Fproc%2Fsys%2Fkernel%2Fhostname%0A%20%20%20%20echo%20%22%24AFTERBURN_POWERVS_LOCAL_HOSTNAME%22%20%3E%20%2Fproc%2Fsys%2Fkernel%2Fhostname%0A%7D%0A%0Aarg%3D%24%7B1%7D%3B%20shift%3B%0Acase%20%22%24%7Barg%7D%22%20in%0A%20%20%20%20--wait)%20wait_localhost%3B%3B%0A%20%20%20%20--gcp)%20set_gcp_hostname%3B%3B%0A%20%20%20%20--openstack)%20set_openstack_hostname%3B%3B%0A%20%20%20%20--powervs)%20set_powervs_hostname%3B%3B%0A%20%20%20%20*)%20echo%20%22Unhandled%20arg%20%24arg%22%3B%20exit%201%0Aesac%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/mco-hostname
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%0Aset%20-eou%20pipefail%0A%0A%23%20context%0Aintapi%3D%24(oc%20get%20infrastructures.config.openshift.io%20cluster%20-o%20%22jsonpath%3D%7B.status.apiServerInternalURI%7D%22)%0Acontext%3D%22%24(oc%20config%20current-context)%22%0A%23%20cluster%0Acluster%3D%22%24(oc%20config%20view%20-o%20%22jsonpath%3D%7B.contexts%5B%3F(%40.name%3D%3D%5C%22%24context%5C%22)%5D.context.cluster%7D%22)%22%0Aserver%3D%22%24(oc%20config%20view%20-o%20%22jsonpath%3D%7B.clusters%5B%3F(%40.name%3D%3D%5C%22%24cluster%5C%22)%5D.cluster.server%7D%22)%22%0A%23%20token%0Aca_crt_data%3D%22%24(oc%20get%20secret%20-n%20openshift-machine-config-operator%20node-bootstrapper-token%20-o%20%22jsonpath%3D%7B.data.ca%5C.crt%7D%22%20%7C%20base64%20--decode)%22%0Anamespace%3D%22%24(oc%20get%20secret%20-n%20openshift-machine-config-operator%20node-bootstrapper-token%20%20-o%20%22jsonpath%3D%7B.data.namespace%7D%22%20%7C%20base64%20--decode)%22%0Atoken%3D%22%24(oc%20get%20secret%20-n%20openshift-machine-config-operator%20node-bootstrapper-token%20-o%20%22jsonpath%3D%7B.data.token%7D%22%20%7C%20base64%20--decode)%22%0A%0Aexport%20KUBECONFIG%3D%22%24(mktemp)%22%0Akubectl%20config%20set-credentials%20%22kubelet%22%20--token%3D%22%24token%22%20%3E%2Fdev%2Fnull%0Aca_crt%3D%22%24(mktemp)%22%3B%20echo%20%22%24ca_crt_data%22%20%3E%20%24ca_crt%0Akubectl%20config%20set-cluster%20%24cluster%20--server%3D%22%24intapi%22%20--certificate-authority%3D%22%24ca_crt%22%20--embed-certs%20%3E%2Fdev%2Fnull%0Akubectl%20config%20set-context%20kubelet%20--cluster%3D%22%24cluster%22%20--user%3D%22kubelet%22%20%3E%2Fdev%2Fnull%0Akubectl%20config%20use-context%20kubelet%20%3E%2Fdev%2Fnull%0Acat%20%22%24KUBECONFIG%22%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/recover-kubeconfig.sh
        - contents:
            source: data:,
          mode: 493
          overwrite: true
          path: /etc/kubernetes/kubelet-plugins/volume/exec/.dummy
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%23%20Workaround%3A%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1941714%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1935539%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1987108%0A%0Adriver%3D%24(nmcli%20-t%20-m%20tabular%20-f%20general.driver%20dev%20show%20%22%24%7BDEVICE_IFACE%7D%22)%0A%0Aif%20%5B%5B%20%22%242%22%20%3D%3D%20%22up%22%20%26%26%20%22%24%7Bdriver%7D%22%20%3D%3D%20%22vmxnet3%22%20%5D%5D%3B%20then%0A%20%20logger%20-s%20%2299-vsphere-disable-tx-udp-tnl%20triggered%20by%20%24%7B2%7D%20on%20device%20%24%7BDEVICE_IFACE%7D.%22%0A%20%20ethtool%20-K%20%24%7BDEVICE_IFACE%7D%20tx-udp_tnl-segmentation%20off%0A%20%20ethtool%20-K%20%24%7BDEVICE_IFACE%7D%20tx-udp_tnl-csum-segmentation%20off%0A%20%20ethtool%20-K%20%24%7BDEVICE_IFACE%7D%20tx-checksum-ip-generic%20off%0Afi%0A
          mode: 484
          overwrite: true
          path: /etc/NetworkManager/dispatcher.d/99-vsphere-disable-tx-udp-tnl
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%0Auntil%20%5B%20-e%20%2Frun%2Fnodeip-configuration%2Fbr-ex-up%20%5D%0Ado%0A%20%20sleep%201%0Adone%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/wait-for-br-ex-up.sh
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-x%0A%0Aif%20%5B%20!%20-e%20%22%2Fetc%2Fipsec.d%2Fopenshift.conf%22%20%5D%3B%20then%0A%20%20exit%200%0Afi%0A%0A%23%20Modify%20existing%20IPsec%20connection%20entries%20with%20%22auto%3Dstart%22%0A%23%20option%20and%20restart%20ipsec%20systemd%20service.%20This%20helps%20to%0A%23%20establish%20IKE%20SAs%20for%20the%20existing%20IPsec%20connections%20with%0A%23%20peer%20nodes.%20This%20option%20will%20be%20deleted%20from%20connections%0A%23%20once%20ovs-monitor-ipsec%20process%20spinned%20up%20on%20the%20node%20by%0A%23%20ovn-ipsec-host%20pod%2C%20but%20still%20it%20won't%20reestablish%20IKE%20SAs%0A%23%20again%20with%20peer%20nodes%2C%20so%20it%20shouldn't%20be%20a%20problem.%0Aif%20!%20grep%20-q%20%22auto%3Dstart%22%20%2Fetc%2Fipsec.d%2Fopenshift.conf%3B%20then%0A%20%20sed%20-i%20'%2F%5E.*conn%20ovn.*%24%2Fa%5C%20%20%20%20auto%3Dstart'%20%2Fetc%2Fipsec.d%2Fopenshift.conf%0Afi%0Achroot%20%2Fproc%2F1%2Froot%20ipsec%20restart%0A%0A%23%20Wait%20for%20upto%2060s%20to%20get%20IPsec%20SAs%20to%20establish%20with%20peer%20nodes.%0Atimeout%3D60%0Aelapsed%3D0%0Adesiredconn%3D%22%22%0Aestablishedsa%3D%22%22%0Awhile%20%5B%5B%20%24elapsed%20-lt%20%24timeout%20%5D%5D%3B%20do%0A%20%20desiredconn%3D%24(grep%20-E%20'%5E%5Cs*conn%5Cs%2B'%20%2Fetc%2Fipsec.d%2Fopenshift.conf%20%7C%20grep%20-v%20'%25default'%20%7C%20awk%20'%7Bprint%20%242%7D'%20%7C%20tr%20'%20'%20'%5Cn'%20%7C%20sort%20%7C%20tr%20'%5Cn'%20'%20')%0A%20%20establishedsa%3D%24(ipsec%20showstates%20%7C%20grep%20STATE_V2_ESTABLISHED_CHILD_SA%20%7C%20grep%20-o%20'%22%5B%5E%22%5D*%22'%20%7C%20sed%20's%2F%22%2F%2Fg'%20%7C%20tr%20'%20'%20'%5Cn'%20%7C%20sort%20%7C%20uniq%20%7C%20tr%20'%5Cn'%20'%20')%0A%20%20if%20%5B%20%22%24desiredconn%22%20%3D%3D%20%22%24establishedsa%22%20%5D%3B%20then%0A%20%20%20%20echo%20%22IPsec%20SAs%20are%20established%20for%20desired%20connections%20after%20%24%7Belapsed%7Ds%22%0A%20%20%20%20break%0A%20%20else%0A%20%20%20%20echo%20%22IPsec%20SAs%20are%20not%20established%20yet%2C%20total%20waited%20time%20%24%7Belapsed%7Ds%22%0A%20%20%20%20sleep%202s%0A%20%20fi%0A%20%20elapsed%3D%24((elapsed%20%2B%202))%0Adone%0A%0Aif%20%5B%5B%20%24elapsed%20-ge%20%24timeout%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22Timed%20out%20waiting%2C%20some%20connections%20are%20not%20established%2C%20desired%20conns%20%24desiredconn%2C%20established%20conns%20%24establishedsa%22%0Afi%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/ipsec-connect-wait.sh
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-eux%0A%0Aif%20%5B%20!%20-e%20%2Fetc%2Fnmstate%2Fopenshift%2Fapplied%20%5D%3B%20then%0A%20%20%23%20No%20need%20to%20do%20this%20if%20no%20NMState%20configuration%20was%20applied%0A%20%20exit%200%0Afi%0A%0A%23%20This%20logic%20is%20borrowed%20from%20configure-ovs.sh%0A%23%20TODO%3A%20Find%20a%20platform-agnostic%20way%20to%20do%20this.%20It%20won't%20work%20on%20platforms%20where%0A%23%20nodeip-configuration%20is%20not%20used.%0Aip%3D%24(cat%20%2Frun%2Fnodeip-configuration%2Fprimary-ip)%0Aif%20%5B%5B%20%22%24%7Bip%7D%22%20%3D%3D%20%22%22%20%5D%5D%3B%20then%0A%20%20echo%20%22No%20ip%20to%20bind%20was%20found%22%0A%20%20exit%201%0Afi%0Awhile%20%3A%0Ado%0A%20%20random_port%3D%24(shuf%20-i%2050000-60000%20-n%201)%0A%20%20echo%20%22Trying%20to%20bind%20%24%7Bip%7D%20on%20port%20%24%7Brandom_port%7D%22%0A%20%20exit_code%3D%24(timeout%202s%20nc%20-l%20%22%24%7Bip%7D%22%20%24%7Brandom_port%7D%3B%20echo%20%24%3F)%0A%20%20if%20%5B%5B%20exit_code%20-eq%20124%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22Address%20bound%20successfully%22%0A%20%20%20%20exit%200%0A%20%20fi%0A%20%20sleep%2010%0Adone%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/wait-for-primary-ip.sh
        - contents:
            source: data:,unqualified-search-registries%20%3D%20%5B'registry.access.redhat.com'%2C%20'docker.io'%5D%0A
          mode: 420
          overwrite: true
          path: /etc/containers/registries.conf
        - contents:
            source: data:,%5Bcrio%5D%0Ainternal_wipe%20%3D%20true%0Ainternal_repair%20%3D%20true%0A%0A%5Bcrio.api%5D%0Astream_address%20%3D%20%22127.0.0.1%22%0Astream_port%20%3D%20%220%22%0A%0A%5Bcrio.runtime%5D%0Aselinux%20%3D%20true%0Aconmon%20%3D%20%22%22%0Aconmon_cgroup%20%3D%20%22pod%22%0Adefault_env%20%3D%20%5B%0A%20%20%20%20%22NSS_SDB_USE_CACHE%3Dno%22%2C%0A%5D%0Adefault_runtime%20%3D%20%22crun%22%0Alog_level%20%3D%20%22info%22%0Acgroup_manager%20%3D%20%22systemd%22%0Adefault_sysctls%20%3D%20%5B%0A%20%20%20%20%22net.ipv4.ping_group_range%3D0%202147483647%22%2C%0A%5D%0Ahooks_dir%20%3D%20%5B%0A%20%20%20%20%22%2Fetc%2Fcontainers%2Foci%2Fhooks.d%22%2C%0A%20%20%20%20%22%2Frun%2Fcontainers%2Foci%2Fhooks.d%22%2C%0A%20%20%20%20%22%2Fusr%2Fshare%2Fcontainers%2Foci%2Fhooks.d%22%2C%0A%5D%0Amanage_ns_lifecycle%20%3D%20true%0Aabsent_mount_sources_to_reject%20%3D%20%5B%0A%20%20%20%20%22%2Fetc%2Fhostname%22%2C%0A%5D%0Adrop_infra_ctr%20%3D%20true%0A%0A%5Bcrio.runtime.runtimes.runc%5D%0Aruntime_root%20%3D%20%22%2Frun%2Frunc%22%0Aallowed_annotations%20%3D%20%5B%0A%20%20%20%20%22io.containers.trace-syscall%22%2C%0A%20%20%20%20%22io.kubernetes.cri-o.Devices%22%2C%0A%20%20%20%20%22io.kubernetes.cri-o.LinkLogs%22%2C%0A%5D%0A%0A%5Bcrio.runtime.runtimes.crun%5D%0Aruntime_root%20%3D%20%22%2Frun%2Fcrun%22%0Aallowed_annotations%20%3D%20%5B%0A%20%20%20%20%22io.containers.trace-syscall%22%2C%0A%20%20%20%20%22io.kubernetes.cri-o.Devices%22%2C%0A%20%20%20%20%22io.kubernetes.cri-o.LinkLogs%22%2C%0A%5D%0A%23%20Based%20on%20https%3A%2F%2Fgithub.com%2Fcontainers%2Fcrun%2Fblob%2F27d7dd3a0%2FREADME.md%3Fplain%3D1%23L48%0Acontainer_min_memory%20%3D%20%22512KiB%22%0Adefault_annotations%20%3D%20%7B%22run.oci.systemd.subgroup%22%20%3D%20%22%22%7D%0A%0A%5Bcrio.runtime.workloads.openshift-builder%5D%0Aactivation_annotation%20%3D%20%22io.openshift.builder%22%0Aallowed_annotations%20%3D%20%5B%0A%20%20%22io.kubernetes.cri-o.userns-mode%22%2C%0A%20%20%22io.kubernetes.cri-o.Devices%22%0A%5D%0A%5Bcrio.runtime.workloads.openshift-builder.resources%5D%0A%0A%5Bcrio.image%5D%0Aglobal_auth_file%20%3D%20%22%2Fvar%2Flib%2Fkubelet%2Fconfig.json%22%0Apause_image%20%3D%20%22quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A2f61599219ee63c77391e05d2e02a8a5baae1c463d0ef965c49a5c470546db90%22%0Apause_image_auth_file%20%3D%20%22%2Fvar%2Flib%2Fkubelet%2Fconfig.json%22%0Apause_command%20%3D%20%22%2Fusr%2Fbin%2Fpod%22%0A%0A%5Bcrio.network%5D%0Anetwork_dir%20%3D%20%22%2Fetc%2Fkubernetes%2Fcni%2Fnet.d%2F%22%0Aplugin_dirs%20%3D%20%5B%0A%20%20%20%20%22%2Fvar%2Flib%2Fcni%2Fbin%22%2C%0A%20%20%20%20%22%2Fusr%2Flibexec%2Fcni%22%2C%0A%5D%0A%0A%5Bcrio.metrics%5D%0Aenable_metrics%20%3D%20true%0Ametrics_host%20%3D%20%22127.0.0.1%22%0Ametrics_port%20%3D%209537%0Ametrics_collectors%20%3D%20%5B%0A%20%20%22operations%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22operations_total%22%0A%20%20%22operations_latency_microseconds_total%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22operations_latency_seconds_total%22%0A%20%20%22operations_latency_microseconds%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22operations_latency_seconds%22%0A%20%20%22operations_errors%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22operations_errors_total%22%0A%20%20%22image_pulls_layer_size%22%2C%0A%20%20%22containers_oom_total%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22containers_oom_count_total%22%0A%20%20%22containers_oom%22%2C%0A%20%20%23%20Drop%20metrics%20with%20excessive%20label%20cardinality.%0A%20%20%23%20%22image_pulls_by_digest%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_pulls_bytes_total%22%0A%20%20%23%20%22image_pulls_by_name%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_pulls_bytes_total%22%0A%20%20%23%20%22image_pulls_by_name_skipped%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_pulls_skipped_bytes_total%22%0A%20%20%23%20%22image_pulls_failures%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_pulls_failure_total%22%0A%20%20%23%20%22image_pulls_successes%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_pulls_success_total%22%0A%20%20%23%20%22image_layer_reuse%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_layer_reuse_total%22%0A%20%20%22operations_total%22%2C%0A%20%20%22operations_latency_seconds_total%22%2C%0A%20%20%22operations_latency_seconds%22%2C%0A%20%20%22operations_errors_total%22%2C%0A%20%20%22image_pulls_bytes_total%22%2C%0A%20%20%22image_pulls_skipped_bytes_total%22%2C%0A%20%20%22image_pulls_success_total%22%2C%0A%20%20%22image_pulls_failure_total%22%2C%0A%20%20%22image_layer_reuse_total%22%2C%0A%20%20%22containers_oom_count_total%22%2C%0A%20%20%22processes_defunct%22%0A%5D%0A
          mode: 420
          overwrite: true
          path: /etc/crio/crio.conf.d/00-default
        - contents:
            source: data:,%7B%0A%20%20%20%20%22default%22%3A%20%5B%0A%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%22type%22%3A%20%22insecureAcceptAnything%22%0A%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%5D%2C%0A%20%20%20%20%22transports%22%3A%0A%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%22docker-daemon%22%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22%22%3A%20%5B%7B%22type%22%3A%22insecureAcceptAnything%22%7D%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20%20%20%7D%0A%7D%0A
          mode: 420
          overwrite: true
          path: /etc/machine-config-daemon/policy-for-old-podman.json
        - contents:
            source: data:,%7B%0A%20%20%20%20%22default%22%3A%20%5B%0A%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%22type%22%3A%20%22insecureAcceptAnything%22%0A%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%5D%2C%0A%20%20%20%20%22transports%22%3A%0A%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%22docker-daemon%22%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22%22%3A%20%5B%7B%22type%22%3A%22insecureAcceptAnything%22%7D%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20%20%20%7D%0A%7D
          mode: 420
          overwrite: true
          path: /etc/containers/policy.json
        - contents:
            source: data:,
          mode: 420
          overwrite: true
          path: /etc/kubernetes/cloud.conf
        - contents:
            source: data:,authorization%3A%0A%20%20static%3A%0A%20%20%20%20-%20resourceRequest%3A%20false%0A%20%20%20%20%20%20path%3A%20%2Fmetrics%0A%20%20%20%20%20%20verb%3A%20get%0A%20%20%20%20%20%20user%3A%0A%20%20%20%20%20%20%20%20name%3A%20system%3Aserviceaccount%3Aopenshift-monitoring%3Aprometheus-k8s
          mode: 420
          overwrite: true
          path: /etc/kubernetes/crio-metrics-proxy.cfg
        - contents:
            source: data:,apiVersion%3A%20v1%0Akind%3A%20Pod%0Ametadata%3A%0A%20%20name%3A%20kube-rbac-proxy-crio%0A%20%20namespace%3A%20openshift-machine-config-operator%0A%20%20annotations%3A%0A%20%20%20%20target.workload.openshift.io%2Fmanagement%3A%20'%7B%22effect%22%3A%20%22PreferredDuringScheduling%22%7D'%0A%20%20%20%20openshift.io%2Frequired-scc%3A%20privileged%0Aspec%3A%0A%20%20volumes%3A%0A%20%20-%20name%3A%20etc-kube%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fetc%2Fkubernetes%22%0A%20%20-%20name%3A%20var-lib-kubelet%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20hostNetwork%3A%20true%0A%20%20priorityClassName%3A%20system-cluster-critical%0A%20%20initContainers%3A%0A%20%20-%20name%3A%20setup%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3Ab6413e64e7d5885315b3cabc65c2af82135ee649b1664976b3d300884d302414%0A%20%20%20%20imagePullPolicy%3A%20IfNotPresent%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20var-lib-kubelet%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20command%3A%20%5B'%2Fbin%2Fbash'%2C%20'-ec'%5D%0A%20%20%20%20args%3A%0A%20%20%20%20-%20%7C%0A%20%20%20%20%20%20echo%20-n%20%22Waiting%20for%20kubelet%20key%20and%20certificate%20to%20be%20available%22%0A%20%20%20%20%20%20while%20%5B%20-n%20%22%24(test%20-e%20%2Fvar%2Flib%2Fkubelet%2Fpki%2Fkubelet-server-current.pem)%22%20%5D%20%3B%20do%0A%20%20%20%20%20%20%20%20echo%20-n%20%22.%22%0A%20%20%20%20%20%20%20%20sleep%201%0A%20%20%20%20%20%20%20%20((%20tries%20%2B%3D%201%20))%0A%20%20%20%20%20%20%20%20if%20%5B%5B%20%22%24%7Btries%7D%22%20-gt%2010%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20echo%20%22Timed%20out%20waiting%20for%20kubelet%20key%20and%20cert.%22%0A%20%20%20%20%20%20%20%20%20%20exit%201%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20done%0A%20%20%20%20securityContext%3A%0A%20%20%20%20%20%20privileged%3A%20true%0A%20%20%20%20resources%3A%0A%20%20%20%20%20%20requests%3A%0A%20%20%20%20%20%20%20%20memory%3A%2050Mi%0A%20%20%20%20%20%20%20%20cpu%3A%205m%0A%20%20containers%3A%0A%20%20-%20name%3A%20kube-rbac-proxy-crio%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3Ab6413e64e7d5885315b3cabc65c2af82135ee649b1664976b3d300884d302414%0A%20%20%20%20securityContext%3A%0A%20%20%20%20%20%20privileged%3A%20true%0A%20%20%20%20ports%3A%0A%20%20%20%20-%20containerPort%3A%209637%0A%20%20%20%20args%3A%0A%20%20%20%20-%20--secure-listen-address%3D%3A9637%0A%20%20%20%20-%20--config-file%3D%2Fetc%2Fkubernetes%2Fcrio-metrics-proxy.cfg%0A%20%20%20%20-%20--client-ca-file%3D%2Fetc%2Fkubernetes%2Fkubelet-ca.crt%0A%20%20%20%20-%20--logtostderr%3Dtrue%0A%20%20%20%20-%20--kubeconfig%3D%2Fvar%2Flib%2Fkubelet%2Fkubeconfig%0A%20%20%20%20-%20--tls-cipher-suites%3DTLS_AES_128_GCM_SHA256%2CTLS_AES_256_GCM_SHA384%2CTLS_CHACHA20_POLY1305_SHA256%2CTLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256%2CTLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256%2CTLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384%2CTLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384%2CTLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256%2CTLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256%20%0A%20%20%20%20-%20--tls-min-version%3DVersionTLS12%0A%20%20%20%20-%20--upstream%3Dhttp%3A%2F%2F127.0.0.1%3A9537%0A%20%20%20%20-%20--tls-cert-file%3D%2Fvar%2Flib%2Fkubelet%2Fpki%2Fkubelet-server-current.pem%0A%20%20%20%20-%20--tls-private-key-file%3D%2Fvar%2Flib%2Fkubelet%2Fpki%2Fkubelet-server-current.pem%0A%20%20%20%20resources%3A%0A%20%20%20%20%20%20requests%3A%0A%20%20%20%20%20%20%20%20cpu%3A%2020m%0A%20%20%20%20%20%20%20%20memory%3A%2050Mi%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20etc-kube%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fkubernetes%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20%20%20readOnly%3A%20true%0A%20%20%20%20-%20name%3A%20var-lib-kubelet%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20%20%20readOnly%3A%20true
          mode: 420
          overwrite: true
          path: /etc/kubernetes/manifests/criometricsproxy.yaml
        - contents:
            compression: ""
            source: data:text/plain;charset=utf-8;base64,YXBpVmVyc2lvbjoga3ViZWxldC5jb25maWcuazhzLmlvL3YxYmV0YTEKYXV0aGVudGljYXRpb246CiAgYW5vbnltb3VzOgogICAgZW5hYmxlZDogZmFsc2UKICB3ZWJob29rOgogICAgY2FjaGVUVEw6IDBzCiAgeDUwOToKICAgIGNsaWVudENBRmlsZTogL2V0Yy9rdWJlcm5ldGVzL2t1YmVsZXQtY2EuY3J0CmF1dGhvcml6YXRpb246CiAgd2ViaG9vazoKICAgIGNhY2hlQXV0aG9yaXplZFRUTDogMHMKICAgIGNhY2hlVW5hdXRob3JpemVkVFRMOiAwcwpjZ3JvdXBEcml2ZXI6IHN5c3RlbWQKY2dyb3VwUm9vdDogLwpjbHVzdGVyRE5TOgotIDE3Mi4zMC4wLjEwCmNsdXN0ZXJEb21haW46IGNsdXN0ZXIubG9jYWwKY29udGFpbmVyTG9nTWF4U2l6ZTogNTBNaQpjb250YWluZXJSdW50aW1lRW5kcG9pbnQ6ICIiCmNwdU1hbmFnZXJSZWNvbmNpbGVQZXJpb2Q6IDBzCmVuYWJsZVN5c3RlbUxvZ1F1ZXJ5OiB0cnVlCmV2aWN0aW9uUHJlc3N1cmVUcmFuc2l0aW9uUGVyaW9kOiAwcwpmZWF0dXJlR2F0ZXM6CiAgQVdTQ2x1c3Rlckhvc3RlZEROUzogZmFsc2UKICBBV1NFRlNEcml2ZXJWb2x1bWVNZXRyaWNzOiB0cnVlCiAgQWRkaXRpb25hbFJvdXRpbmdDYXBhYmlsaXRpZXM6IGZhbHNlCiAgQWRtaW5OZXR3b3JrUG9saWN5OiB0cnVlCiAgQWxpYmFiYVBsYXRmb3JtOiB0cnVlCiAgQXV0b21hdGVkRXRjZEJhY2t1cDogZmFsc2UKICBBenVyZVdvcmtsb2FkSWRlbnRpdHk6IHRydWUKICBCYXJlTWV0YWxMb2FkQmFsYW5jZXI6IHRydWUKICBCb290Y05vZGVNYW5hZ2VtZW50OiBmYWxzZQogIEJ1aWxkQ1NJVm9sdW1lczogdHJ1ZQogIENTSURyaXZlclNoYXJlZFJlc291cmNlOiBmYWxzZQogIENodW5rU2l6ZU1pQjogdHJ1ZQogIENsb3VkRHVhbFN0YWNrTm9kZUlQczogdHJ1ZQogIENsdXN0ZXJBUElJbnN0YWxsOiBmYWxzZQogIENsdXN0ZXJBUElJbnN0YWxsSUJNQ2xvdWQ6IGZhbHNlCiAgQ2x1c3Rlck1vbml0b3JpbmdDb25maWc6IGZhbHNlCiAgQ29uc29sZVBsdWdpbkNvbnRlbnRTZWN1cml0eVBvbGljeTogZmFsc2UKICBETlNOYW1lUmVzb2x2ZXI6IGZhbHNlCiAgRGlzYWJsZUt1YmVsZXRDbG91ZENyZWRlbnRpYWxQcm92aWRlcnM6IHRydWUKICBEeW5hbWljUmVzb3VyY2VBbGxvY2F0aW9uOiBmYWxzZQogIEV0Y2RCYWNrZW5kUXVvdGE6IGZhbHNlCiAgRXZlbnRlZFBMRUc6IGZhbHNlCiAgRXhhbXBsZTogZmFsc2UKICBFeHRlcm5hbE9JREM6IGZhbHNlCiAgRXh0ZXJuYWxPSURDV2l0aFVJREFuZEV4dHJhQ2xhaW1NYXBwaW5nczogZmFsc2UKICBHQ1BDbHVzdGVySG9zdGVkRE5TOiBmYWxzZQogIEdDUExhYmVsc1RhZ3M6IHRydWUKICBHYXRld2F5QVBJOiBmYWxzZQogIEhhcmR3YXJlU3BlZWQ6IHRydWUKICBJbWFnZVN0cmVhbUltcG9ydE1vZGU6IGZhbHNlCiAgSW5ncmVzc0NvbnRyb2xsZXJEeW5hbWljQ29uZmlndXJhdGlvbk1hbmFnZXI6IGZhbHNlCiAgSW5ncmVzc0NvbnRyb2xsZXJMQlN1Ym5ldHNBV1M6IHRydWUKICBJbnNpZ2h0c0NvbmZpZzogZmFsc2UKICBJbnNpZ2h0c0NvbmZpZ0FQSTogZmFsc2UKICBJbnNpZ2h0c09uRGVtYW5kRGF0YUdhdGhlcjogZmFsc2UKICBJbnNpZ2h0c1J1bnRpbWVFeHRyYWN0b3I6IGZhbHNlCiAgS01TdjE6IHRydWUKICBNYWNoaW5lQVBJTWlncmF0aW9uOiBmYWxzZQogIE1hY2hpbmVBUElPcGVyYXRvckRpc2FibGVNYWNoaW5lSGVhbHRoQ2hlY2tDb250cm9sbGVyOiBmYWxzZQogIE1hY2hpbmVBUElQcm92aWRlck9wZW5TdGFjazogZmFsc2UKICBNYWNoaW5lQ29uZmlnTm9kZXM6IGZhbHNlCiAgTWFuYWdlZEJvb3RJbWFnZXM6IHRydWUKICBNYW5hZ2VkQm9vdEltYWdlc0FXUzogdHJ1ZQogIE1heFVuYXZhaWxhYmxlU3RhdGVmdWxTZXQ6IGZhbHNlCiAgTWV0cmljc0NvbGxlY3Rpb25Qcm9maWxlczogZmFsc2UKICBNaW5pbXVtS3ViZWxldFZlcnNpb246IGZhbHNlCiAgTWl4ZWRDUFVzQWxsb2NhdGlvbjogZmFsc2UKICBNdWx0aUFyY2hJbnN0YWxsQVdTOiB0cnVlCiAgTXVsdGlBcmNoSW5zdGFsbEF6dXJlOiBmYWxzZQogIE11bHRpQXJjaEluc3RhbGxHQ1A6IHRydWUKICBOZXR3b3JrRGlhZ25vc3RpY3NDb25maWc6IHRydWUKICBOZXR3b3JrTGl2ZU1pZ3JhdGlvbjogdHJ1ZQogIE5ldHdvcmtTZWdtZW50YXRpb246IHRydWUKICBOZXdPTE06IHRydWUKICBOb2RlRGlzcnVwdGlvblBvbGljeTogdHJ1ZQogIE5vZGVTd2FwOiBmYWxzZQogIE51dGFuaXhNdWx0aVN1Ym5ldHM6IGZhbHNlCiAgT1ZOT2JzZXJ2YWJpbGl0eTogZmFsc2UKICBPbkNsdXN0ZXJCdWlsZDogdHJ1ZQogIE9wZW5TaGlmdFBvZFNlY3VyaXR5QWRtaXNzaW9uOiBmYWxzZQogIFBlcnNpc3RlbnRJUHNGb3JWaXJ0dWFsaXphdGlvbjogdHJ1ZQogIFBpbm5lZEltYWdlczogZmFsc2UKICBQbGF0Zm9ybU9wZXJhdG9yczogZmFsc2UKICBQcml2YXRlSG9zdGVkWm9uZUFXUzogdHJ1ZQogIFByb2NNb3VudFR5cGU6IGZhbHNlCiAgUm91dGVBZHZlcnRpc2VtZW50czogZmFsc2UKICBSb3V0ZUV4dGVybmFsQ2VydGlmaWNhdGU6IGZhbHNlCiAgU2VydmljZUFjY291bnRUb2tlbk5vZGVCaW5kaW5nOiBmYWxzZQogIFNldEVJUEZvck5MQkluZ3Jlc3NDb250cm9sbGVyOiB0cnVlCiAgU2lnbmF0dXJlU3RvcmVzOiBmYWxzZQogIFNpZ3N0b3JlSW1hZ2VWZXJpZmljYXRpb246IGZhbHNlCiAgVHJhbnNsYXRlU3RyZWFtQ2xvc2VXZWJzb2NrZXRSZXF1ZXN0czogZmFsc2UKICBVcGdyYWRlU3RhdHVzOiBmYWxzZQogIFVzZXJOYW1lc3BhY2VzUG9kU2VjdXJpdHlTdGFuZGFyZHM6IGZhbHNlCiAgVXNlck5hbWVzcGFjZXNTdXBwb3J0OiBmYWxzZQogIFZTcGhlcmVDb250cm9sUGxhbmVNYWNoaW5lU2V0OiB0cnVlCiAgVlNwaGVyZURyaXZlckNvbmZpZ3VyYXRpb246IHRydWUKICBWU3BoZXJlTXVsdGlOZXR3b3JrczogZmFsc2UKICBWU3BoZXJlTXVsdGlWQ2VudGVyczogdHJ1ZQogIFZTcGhlcmVTdGF0aWNJUHM6IHRydWUKICBWYWxpZGF0aW5nQWRtaXNzaW9uUG9saWN5OiB0cnVlCiAgVm9sdW1lQXR0cmlidXRlc0NsYXNzOiBmYWxzZQogIFZvbHVtZUdyb3VwU25hcHNob3Q6IGZhbHNlCmZpbGVDaGVja0ZyZXF1ZW5jeTogMHMKaHR0cENoZWNrRnJlcXVlbmN5OiAwcwppbWFnZU1heGltdW1HQ0FnZTogMHMKaW1hZ2VNaW5pbXVtR0NBZ2U6IDBzCmtpbmQ6IEt1YmVsZXRDb25maWd1cmF0aW9uCmt1YmVBUElCdXJzdDogMTAwCmt1YmVBUElRUFM6IDUwCmxvZ2dpbmc6CiAgZmx1c2hGcmVxdWVuY3k6IDAKICBvcHRpb25zOgogICAganNvbjoKICAgICAgaW5mb0J1ZmZlclNpemU6ICIwIgogICAgdGV4dDoKICAgICAgaW5mb0J1ZmZlclNpemU6ICIwIgogIHZlcmJvc2l0eTogMAptYXhQb2RzOiAyNTAKbWVtb3J5U3dhcDoge30Kbm9kZVN0YXR1c1JlcG9ydEZyZXF1ZW5jeTogNW0wcwpub2RlU3RhdHVzVXBkYXRlRnJlcXVlbmN5OiAxMHMKcG9kUGlkc0xpbWl0OiA0MDk2CnByb3RlY3RLZXJuZWxEZWZhdWx0czogdHJ1ZQpyb3RhdGVDZXJ0aWZpY2F0ZXM6IHRydWUKcnVudGltZVJlcXVlc3RUaW1lb3V0OiAwcwpzZXJpYWxpemVJbWFnZVB1bGxzOiBmYWxzZQpzZXJ2ZXJUTFNCb290c3RyYXA6IHRydWUKc2h1dGRvd25HcmFjZVBlcmlvZDogMHMKc2h1dGRvd25HcmFjZVBlcmlvZENyaXRpY2FsUG9kczogMHMKc3RhdGljUG9kUGF0aDogL2V0Yy9rdWJlcm5ldGVzL21hbmlmZXN0cwpzdHJlYW1pbmdDb25uZWN0aW9uSWRsZVRpbWVvdXQ6IDBzCnN5bmNGcmVxdWVuY3k6IDBzCnN5c3RlbUNncm91cHM6IC9zeXN0ZW0uc2xpY2UKdGxzQ2lwaGVyU3VpdGVzOgotIFRMU19BRVNfMTI4X0dDTV9TSEEyNTYKLSBUTFNfQUVTXzI1Nl9HQ01fU0hBMzg0Ci0gVExTX0NIQUNIQTIwX1BPTFkxMzA1X1NIQTI1NgotIFRMU19FQ0RIRV9FQ0RTQV9XSVRIX0FFU18xMjhfR0NNX1NIQTI1NgotIFRMU19FQ0RIRV9SU0FfV0lUSF9BRVNfMTI4X0dDTV9TSEEyNTYKLSBUTFNfRUNESEVfRUNEU0FfV0lUSF9BRVNfMjU2X0dDTV9TSEEzODQKLSBUTFNfRUNESEVfUlNBX1dJVEhfQUVTXzI1Nl9HQ01fU0hBMzg0Ci0gVExTX0VDREhFX0VDRFNBX1dJVEhfQ0hBQ0hBMjBfUE9MWTEzMDVfU0hBMjU2Ci0gVExTX0VDREhFX1JTQV9XSVRIX0NIQUNIQTIwX1BPTFkxMzA1X1NIQTI1Ngp0bHNNaW5WZXJzaW9uOiBWZXJzaW9uVExTMTIKdm9sdW1lU3RhdHNBZ2dQZXJpb2Q6IDBzCg==
          mode: 420
          overwrite: true
          path: /etc/kubernetes/kubelet.conf
        - contents:
            source: data:,%23!%2Fbin%2Fsh%0Aif%20%5B%20-x%20%2Fusr%2Fbin%2Fkubensenter%20%5D%3B%20then%0A%20%20exec%20%2Fusr%2Fbin%2Fkubensenter%20%22%24%40%22%0Aelse%0A%20%20exec%20%22%24%40%22%0Afi%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/kubenswrapper
        - contents:
            source: data:text/plain;charset=utf-8;base64,CnBvb2wgMC5yaGVsLnBvb2wubnRwLm9yZyBpYnVyc3QKZHJpZnRmaWxlIC92YXIvbGliL2Nocm9ueS9kcmlmdAptYWtlc3RlcCAxLjAgMwpydGNzeW5jCmxvZ2RpciAvdmFyL2xvZy9jaHJvbnkKc2VydmVyIDc0LjIwOC4yNS40NiBpYnVyc3QKc2VydmVyIHRpbWUubG10bGFicy5jb20gaWJ1cnN0CnNlcnZlciBsaXRoaXVtLmNvbnN0YW50LmNvbSBpYnVyc3QKc2VydmVyIDY5LjE3Ni44NC4zOCBpYnVyc3QKc2VydmVyIGFybTEubWF4aG9zdC5pbyBpYnVyc3QKc2VydmVyIG50cDEubGF4LnVzLmhvam1hcmsubmV0IGlidXJzdApzZXJ2ZXIgbnRwMTEua2VybmZ1c2lvbi5hdCBpYnVyc3QKc2VydmVyIHRyaWFuZ2xlLmthbnNhcy5uZXQgaWJ1cnN0
          mode: 420
          overwrite: true
          path: /etc/chrony.conf
        - contents:
            source: data:text/plain;charset=utf-8;base64,W0dlbmVyYWxdCkRvbWFpbiA9IHJocG9jLmludAoKW01hcHBpbmddCgpOb2JvZHktVXNlciA9IG5vYm9keQpOb2JvZHktR3JvdXAgPSBub2JvZHkK
          mode: 420
          overwrite: true
          path: /etc/idmapd.conf
      systemd:
        units:
        - contents: |
            [Unit]
            Description=Cleans NetworkManager state generated by dracut
            # Removal of this file signals firstboot completion
            ConditionPathExists=!/etc/ignition-machine-config-encapsulated.json
            # This is opt-in for some deployment types, and opt-out for others.
            ConditionPathExists=/var/lib/mco/nm-clean-initrd-state
            Wants=network-pre.target
            Before=network-pre.target

            [Service]
            Type=oneshot
            # Remove any existing state possibly generated NM run by dracut. We want NM to
            # consider all profiles autoconnect priority when it starts instead of
            # remembering which profile was a device activated with when NM is run by
            # dracut.
            ExecStart=/usr/local/bin/nm-clean-initrd-state.sh
            StandardOutput=journal+console
            StandardError=journal+console

            [Install]
            WantedBy=network-online.target
          enabled: true
          name: NetworkManager-clean-initrd-state.service
        - dropins:
          - contents: |
              # vim:set ft=systemd :
              #
              # This drop-in will enable any service built with this
              # github.com/containers/kubemntns library to properly join the mount namespace
              # managed by kubens.service
              #

              [Unit]
              After=kubens.service

              [Service]
              EnvironmentFile=-/run/kubens/env
            name: 01-kubens.conf
          - contents: ""
            name: 10-mco-default-env.conf
          - contents: |
              [Service]
              Environment="ENABLE_PROFILE_UNIX_SOCKET=true"
            name: 10-mco-profile-unix-socket.conf
          - contents: |
              [Unit]
              After=kubelet-dependencies.target
              Requires=kubelet-dependencies.target
            name: 05-mco-ordering.conf
          - contents: |
              [Service]
              Environment="GODEBUG=x509ignoreCN=0,madvdontneed=1"
            name: 10-mco-default-madv.conf
          name: crio.service
        - dropins:
          - contents: |
              [Unit]
              ConditionPathExists=/enoent
            name: mco-disabled.conf
          name: docker.socket
        - contents: |
            [Unit]
            Description=The firstboot OS update has completed
            Documentation=https://github.com/openshift/machine-config-operator/
            Requires=basic.target

            [Install]
            WantedBy=default.target
          enabled: true
          name: firstboot-osupdate.target
        - dropins:
          - contents: |
              [Unit]
              After=ovs-configuration.service
              Before=crio.service
            name: 01-after-configure-ovs.conf
          name: ipsec.service
        - contents: |
            [Unit]
            Description=Dynamically sets the system reserved for the kubelet
            Wants=network-online.target
            After=network-online.target firstboot-osupdate.target
            Before=kubelet-dependencies.target

            [Service]
            # Need oneshot to delay kubelet
            Type=oneshot
            RemainAfterExit=yes
            EnvironmentFile=/etc/node-sizing-enabled.env
            ExecStart=/bin/bash /usr/local/sbin/dynamic-system-reserved-calc.sh ${NODE_SIZING_ENABLED} ${SYSTEM_RESERVED_MEMORY} ${SYSTEM_RESERVED_CPU} ${SYSTEM_RESERVED_ES}
            [Install]
            RequiredBy=kubelet-dependencies.target
          enabled: true
          name: kubelet-auto-node-size.service
        - contents: |
            [Unit]
            Description=Dependencies necessary to run kubelet
            Documentation=https://github.com/openshift/machine-config-operator/
            Requires=basic.target network-online.target
            Wants=NetworkManager-wait-online.service crio-wipe.service
            Wants=rpc-statd.service chrony-wait.service
          name: kubelet-dependencies.target
        - contents: |
            [Unit]
            Description=Kubernetes Kubelet
            Requires=crio.service kubelet-dependencies.target
            After=kubelet-dependencies.target
            After=ostree-finalize-staged.service

            [Service]
            Type=notify
            ExecStartPre=/bin/mkdir --parents /etc/kubernetes/manifests
            ExecStartPre=-/usr/sbin/restorecon -ri /var/lib/kubelet/pod-resources /usr/local/bin/kubenswrapper /usr/bin/kubensenter
            Environment="KUBELET_NODE_IP=0.0.0.0"
            EnvironmentFile=/etc/os-release
            EnvironmentFile=-/etc/kubernetes/kubelet-workaround
            EnvironmentFile=-/etc/kubernetes/kubelet-env
            EnvironmentFile=/etc/node-sizing.env

            ExecStart=/usr/local/bin/kubenswrapper \
                /usr/bin/kubelet \
                  --config=/etc/kubernetes/kubelet.conf \
                  --bootstrap-kubeconfig=/etc/kubernetes/kubeconfig \
                  --kubeconfig=/var/lib/kubelet/kubeconfig \
                  --container-runtime-endpoint=/var/run/crio/crio.sock \
                  --runtime-cgroups=/system.slice/crio.service \
                  --node-labels=node-role.kubernetes.io/control-plane,node-role.kubernetes.io/master,node.openshift.io/os_id=${ID} \
                  --node-ip=${KUBELET_NODE_IP} \
                  --address=${KUBELET_NODE_IP} \
                  --minimum-container-ttl-duration=6m0s \
                  --cloud-provider= \
                  --volume-plugin-dir=/etc/kubernetes/kubelet-plugins/volume/exec \
                  --hostname-override=${KUBELET_NODE_NAME} \
                  --register-with-taints=node-role.kubernetes.io/master=:NoSchedule \
                  --pod-infra-container-image=quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:2f61599219ee63c77391e05d2e02a8a5baae1c463d0ef965c49a5c470546db90 \
                  --system-reserved=cpu=${SYSTEM_RESERVED_CPU},memory=${SYSTEM_RESERVED_MEMORY},ephemeral-storage=${SYSTEM_RESERVED_ES} \
                  --v=${KUBELET_LOG_LEVEL}

            Restart=always
            RestartSec=10

            [Install]
            WantedBy=multi-user.target
          dropins:
          - contents: |
              # vim:set ft=systemd :
              #
              # This drop-in will enable any service built with this
              # github.com/containers/kubemntns library to properly join the mount namespace
              # managed by kubens.service
              #

              [Unit]
              After=kubens.service

              [Service]
              EnvironmentFile=-/run/kubens/env
            name: 01-kubens.conf
          - contents: ""
            name: 10-mco-default-env.conf
          - contents: |
              [Service]
              # Wait for resolv-prepender to configure nameservers, exit 255 otherwise
              # to mark the unit as failed and retry later
              ExecCondition=/bin/bash -c '[ -f /run/resolv-prepender-kni-conf-done ] || { echo "NM resolv-prepender failed"; exit 255; }'
            name: 10-mco-on-prem-wait-resolv.conf
          - contents: |
              [Service]
              Environment="GODEBUG=x509ignoreCN=0,madvdontneed=1"
            name: 10-mco-default-madv.conf
          enabled: true
          name: kubelet.service
        - contents: |
            [Unit]
            Description=Manages a mount namespace for kubernetes-specific mounts

            [Service]
            Type=oneshot
            RemainAfterExit=yes
            RuntimeDirectory=kubens
            Environment=RUNTIME_DIRECTORY=%t/kubens
            Environment=BIND_POINT=%t/kubens/mnt
            Environment=ENVFILE=%t/kubens/env

            # Set up the runtime directory as an unbindable mountpoint
            ExecStartPre=bash -c "findmnt ${RUNTIME_DIRECTORY} || mount --make-unbindable --bind ${RUNTIME_DIRECTORY} ${RUNTIME_DIRECTORY}"
            # Ensure the bind point exists
            ExecStartPre=touch ${BIND_POINT}
            # Use 'unshare' to create the new mountpoint, then 'mount --make-rshared' so it cascades internally
            ExecStart=unshare --mount=${BIND_POINT} --propagation slave mount --make-rshared /
            # Finally, set an env pointer for ease-of-use
            ExecStartPost=bash -c 'echo "KUBENSMNT=${BIND_POINT}" > "${ENVFILE}"'

            # On stop, a recursive unmount cleans up the namespace and bind-mounted unbindable parent directory
            ExecStop=umount -R ${RUNTIME_DIRECTORY}

            [Install]
            WantedBy=multi-user.target
          enabled: false
          name: kubens.service
        - contents: |
            [Unit]
            Description=Machine Config Daemon Firstboot
            # Make sure it runs only on OSTree booted system
            ConditionPathExists=/run/ostree-booted
            # Removal of this file signals firstboot completion
            ConditionPathExists=/etc/ignition-machine-config-encapsulated.json
            After=machine-config-daemon-pull.service
            Before=kubelet-dependencies.target

            [Service]
            Type=oneshot
            RemainAfterExit=yes
            # Disable existing repos (if any) so that OS extensions would use embedded RPMs only
            ExecStartPre=-/usr/bin/sh -c "sed -i 's/enabled=1/enabled=0/' /etc/yum.repos.d/*.repo"
            # Run this via podman because we want to use the nmstatectl binary in our container
            ExecStart=/usr/bin/podman run --rm --privileged --net=host -v /:/rootfs  --entrypoint machine-config-daemon 'quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:94bac6c3782cf6579032c7c9dabca74146753d9a44591125acd30d606d7d340c' firstboot-complete-machineconfig --persist-nics
            ExecStart=/usr/bin/podman run --rm --privileged --pid=host --net=host -v /:/rootfs  --entrypoint machine-config-daemon 'quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:94bac6c3782cf6579032c7c9dabca74146753d9a44591125acd30d606d7d340c' firstboot-complete-machineconfig
            [Install]
            RequiredBy=firstboot-osupdate.target
          enabled: true
          name: machine-config-daemon-firstboot.service
        - contents: |
            [Unit]
            Description=Machine Config Daemon Pull
            # Make sure it runs only on OSTree booted system
            ConditionPathExists=/run/ostree-booted
            # This "stamp file" is unlinked when we complete
            # machine-config-daemon-firstboot.service
            ConditionPathExists=/etc/ignition-machine-config-encapsulated.json
            # Run after crio-wipe so the pulled MCD image is protected against a corrupted storage from a forced shutdown
            Wants=crio-wipe.service NetworkManager-wait-online.service
            After=crio-wipe.service NetworkManager-wait-online.service network.service

            [Service]
            Type=oneshot
            RemainAfterExit=yes
            ExecStartPre=/etc/machine-config-daemon/generate_podman_policy_args.sh
            ExecStart=/bin/sh -c "while ! /usr/bin/podman pull $(cat /tmp/podman_policy_args) --authfile=/var/lib/kubelet/config.json 'quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:94bac6c3782cf6579032c7c9dabca74146753d9a44591125acd30d606d7d340c'; do sleep 1; done"

            [Install]
            RequiredBy=machine-config-daemon-firstboot.service
          enabled: true
          name: machine-config-daemon-pull.service
        - contents: |
            [Unit]
            Description=Applies per-node NMState network configuration
            Requires=openvswitch.service
            Wants=NetworkManager-wait-online.service
            After=NetworkManager-wait-online.service openvswitch.service network.service nodeip-configuration.service
            Before=nmstate.service kubelet-dependencies.target ovs-configuration.service node-valid-hostname.service

            [Service]
            Type=oneshot
            # Would prefer to do Restart=on-failure instead of this bash retry loop, but
            # the version of systemd we have right now doesn't support it. It should be
            # available in systemd v244 and higher.
            ExecStart=/usr/local/bin/nmstate-configuration.sh
            StandardOutput=journal+console
            StandardError=journal+console

            [Install]
            WantedBy=network-online.target
          enabled: true
          name: nmstate-configuration.service
        - contents: |
            [Unit]
            Description=Apply nmstate on-disk state
            Documentation=man:nmstate.service(8) https://www.nmstate.io
            After=NetworkManager-wait-online.service
            Before=network-online.target
            Wants=NetworkManager-wait-online.service
            Requires=NetworkManager.service

            [Service]
            Type=oneshot
            ExecStart=/usr/bin/nmstatectl service
            RemainAfterExit=yes

            [Install]
            WantedBy=NetworkManager.service
          enabled: true
          name: nmstate.service
        - contents: |
            [Unit]
            Description=Wait for a non-localhost hostname
            Before=kubelet-dependencies.target

            [Service]
            Type=oneshot
            RemainAfterExit=yes
            User=root
            ExecStart=/usr/local/bin/mco-hostname --wait

            # Wait up to 5min for the node to get a non-localhost name
            TimeoutSec=300

            [Install]
            # TODO: Change this to RequiredBy after we fix https://github.com/openshift/machine-config-operator/pull/3865#issuecomment-1746963115
            WantedBy=kubelet-dependencies.target
          enabled: true
          name: node-valid-hostname.service
        - contents: |
            [Unit]
            Description=Writes IP address configuration so that kubelet and crio services select a valid node IP
            # This only applies to VIP managing environments where the kubelet and crio IP
            # address picking logic is flawed and may end up selecting an address from a
            # different subnet or a deprecated address
            Wants=NetworkManager-wait-online.service
            After=NetworkManager-wait-online.service firstboot-osupdate.target
            Before=kubelet-dependencies.target ovs-configuration.service

            [Service]
            # Need oneshot to delay kubelet
            Type=oneshot
            # Would prefer to do Restart=on-failure instead of this bash retry loop, but
            # the version of systemd we have right now doesn't support it. It should be
            # available in systemd v244 and higher.
            ExecStart=/bin/bash -c " \
              until \
              /usr/bin/podman run --rm \
              --authfile /var/lib/kubelet/config.json \
              --net=host \
              --security-opt label=disable \
              --volume /etc/systemd/system:/etc/systemd/system \
              --volume /run/nodeip-configuration:/run/nodeip-configuration \
              quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:93e7b8c870261726d44bddc7ba0a702d3720d1838141dac837fb8c3be7c6e1a1 \
              node-ip \
              set \
              --platform BareMetal \
              --retry-on-failure \
              ${NODEIP_HINT:-} \
              10.100.0.50  \
              10.100.0.51 ; \
              do \
              sleep 5; \
              done"
            ExecStart=/bin/systemctl daemon-reload
            ExecStartPre=/bin/mkdir -p /run/nodeip-configuration
            ExecStartPost=+/usr/local/bin/configure-ip-forwarding.sh
            StandardOutput=journal+console
            StandardError=journal+console
            EnvironmentFile=-/etc/default/nodeip-configuration

            [Install]
            RequiredBy=kubelet-dependencies.target
          enabled: true
          name: nodeip-configuration.service
        - contents: |
            [Unit]
            Description=Watches for changes in /var/run/NetworkManager/resolv.conf according to on-prem IPI needs
            [Path]
            PathModified=/var/run/NetworkManager/resolv.conf
            PathModified=/run/resolv-prepender/env
            Unit=on-prem-resolv-prepender.service
            [Install]
            WantedBy=multi-user.target
          enabled: true
          name: on-prem-resolv-prepender.path
        - contents: |
            [Unit]
            Description=Populates resolv.conf according to on-prem IPI needs
            # Per https://issues.redhat.com/browse/OCPBUGS-27162 there is a problem if this is started before crio-wipe
            After=crio-wipe.service
            StartLimitIntervalSec=0
            [Service]
            Type=oneshot
            # Would prefer to do Restart=on-failure instead of this bash retry loop, but
            # the version of systemd we have right now doesn't support it. It should be
            # available in systemd v244 and higher.
            ExecStart=/bin/bash -c " \
              until \
              /usr/local/bin/resolv-prepender.sh; \
              do \
              sleep 10; \
              done"
            EnvironmentFile=-/run/resolv-prepender/env
          enabled: false
          name: on-prem-resolv-prepender.service
        - enabled: true
          name: openvswitch.service
        - contents: |
            [Unit]
            # Kdump will generate it's initramfs based on the running state when kdump.service run
            # If OVS has already run, the kdump fails to gather a working network config,
            # which prevent network log exports, sush as SSH.
            # See https://issues.redhat.com/browse/OCPBUGS-28239
            After=kdump.service
            Description=Configures OVS with proper host networking configuration
            # This service is used to move a physical NIC into OVS and reconfigure OVS to use the host IP
            Requires=openvswitch.service
            Wants=NetworkManager-wait-online.service
            After=firstboot-osupdate.target
            After=NetworkManager-wait-online.service openvswitch.service network.service nodeip-configuration.service nmstate.service
            Before=kubelet-dependencies.target node-valid-hostname.service

            [Service]
            # Need oneshot to delay kubelet
            Type=oneshot
            ExecStart=/usr/local/bin/configure-ovs.sh OVNKubernetes
            StandardOutput=journal+console
            StandardError=journal+console

            [Install]
            RequiredBy=kubelet-dependencies.target
          enabled: true
          name: ovs-configuration.service
        - dropins:
          - contents: |
              [Service]
              Restart=always
              ExecStartPre=-/bin/sh -c '/usr/bin/chown -R :$${OVS_USER_ID##*:} /var/lib/openvswitch'
              ExecStartPre=-/bin/sh -c '/usr/bin/chown -R :$${OVS_USER_ID##*:} /etc/openvswitch'
              ExecStartPre=-/bin/sh -c '/usr/bin/chown -R :$${OVS_USER_ID##*:} /run/openvswitch'
              ExecStartPost=-/usr/bin/ovs-appctl vlog/set syslog:info
              ExecReload=-/usr/bin/ovs-appctl vlog/set syslog:info
            name: 10-ovs-vswitchd-restart.conf
          name: ovs-vswitchd.service
        - dropins:
          - contents: |
              [Service]
              Restart=always
            name: 10-ovsdb-restart.conf
          enabled: true
          name: ovsdb-server.service
        - dropins:
          - contents: ""
            name: 10-mco-default-env.conf
          - contents: |
              # See https://github.com/openshift/machine-config-operator/issues/1897
              [Service]
              Nice=10
              IOSchedulingClass=best-effort
              IOSchedulingPriority=6
            name: mco-controlplane-nice.conf
          name: rpm-ostreed.service
        - contents: |
            [Unit]
            Description=Wait for br-ex up event from NetworkManager
            Wants=ovs-configuration.service
            After=ovs-configuration.service
            Before=node-valid-hostname.service

            [Service]
            Type=oneshot
            ExecStart=/usr/local/bin/wait-for-br-ex-up.sh

            [Install]
            RequiredBy=node-valid-hostname.service
          enabled: true
          name: wait-for-br-ex-up.service
        - contents: |
            [Unit]
            Description=Ensure IKE SA established for existing IPsec connections.
            After=ipsec.service
            Before=kubelet-dependencies.target node-valid-hostname.service

            [Service]
            Type=oneshot
            ExecStart=/usr/local/bin/ipsec-connect-wait.sh
            StandardOutput=journal+console
            StandardError=journal+console

            [Install]
            WantedBy=ipsec.service
          enabled: true
          name: wait-for-ipsec-connect.service
        - contents: |
            [Unit]
            Description=Ensure primary IP is assigned and usable
            Requires=nmstate.service
            After=nmstate.service
            Before=kubelet-dependencies.target

            [Service]
            Type=oneshot
            # Would prefer to do Restart=on-failure instead of this bash retry loop, but
            # the version of systemd we have right now doesn't support it. It should be
            # available in systemd v244 and higher.
            ExecStart=/bin/bash -c " \
              until \
              /usr/local/bin/wait-for-primary-ip.sh; \
              do \
              sleep 10; \
              done"
            StandardOutput=journal+console
            StandardError=journal+console

            [Install]
            WantedBy=network-online.target
          enabled: true
          name: wait-for-primary-ip.service
        - dropins:
          - contents: |
              [Unit]
              ConditionPathExists=/enoent
            name: mco-disabled.conf
          name: zincati.service
        - contents: |
            [Unit]
            Description=Kubernetes Kubelet After Reboot Cleanup
            Before=kubelet.service

            [Service]
            Type=oneshot
            ExecStart=/bin/rm -f /var/lib/kubelet/cpu_manager_state
            ExecStart=/bin/rm -f /var/lib/kubelet/memory_manager_state
            ExecStart=-/bin/rm -f /var/lib/kubelet/dra_manager_state

            [Install]
            WantedBy=multi-user.target
          enabled: true
          name: kubelet-cleanup.service
    extensions: []
    fips: false
    kernelArguments:
    - schedstats=enable
    - systemd.unified_cgroup_hierarchy=1
    - cgroup_no_v1="all"
    - psi=0
    - psi=1
    kernelType: default
    osImageURL: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4e309dd906392e783a404b92dfd4fa4c32d74e2804ee37d1fb8a00c9355d5978
- apiVersion: machineconfiguration.openshift.io/v1
  kind: MachineConfig
  metadata:
    annotations:
      machineconfiguration.openshift.io/generated-by-controller-version: fcf8f254943cbcba1400ba55f3978cc292b6460b
      machineconfiguration.openshift.io/release-image-version: 4.18.26
    creationTimestamp: "2025-11-04T16:09:19Z"
    generation: 1
    name: rendered-master-876fc094a44440ea63dba09f335f5792
    ownerReferences:
    - apiVersion: machineconfiguration.openshift.io/v1
      blockOwnerDeletion: true
      controller: true
      kind: MachineConfigPool
      name: master
      uid: 94ee58c6-d020-4644-985a-6daad3eb3116
    resourceVersion: "11166"
    uid: 7fed6f14-67d7-422b-a85f-4ab767ea9ea0
  spec:
    baseOSExtensionsContainerImage: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:7033f46996eddcbad8c8b8aeb18e601bdeef3d04bd7f79cd194db5e6346a7fc4
    config:
      ignition:
        version: 3.4.0
      passwd:
        users:
        - name: core
          sshAuthorizedKeys:
          - ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQD7F2mFgxGcyTmG/KTR+D0wnMAM1rlaaaqGMz5ueugnUjlWxtssJLq1TIQSwOdllxWgzJt9LXHQZNVqxpLk/imx7UqnRYohX+10WNtxRQ8O/HqMpdngMgYlBVHwmgsQeDle441kUv/NFAwLGpRK4zvNwxcUMu2z4sajxqxc0sGqvqpVYsOq7jnFbWELgRX+JyZmWGhGfdHwySraydgV0NtSEANksJO1H0220vnrpMnGtyyOkiqDi4LnT1iAs+VvqZl0EaPxOzCMPTVQqqeH19bBKKnbmQABRZxlI7o4vvRH8p/YXG301cCgfVXfdbFuU7OLiHDA73nd9zk+AyEm/8ssq9rSAzleFaP3I9RqNvK/YWLoC/DHwZeCGrvva/JpPdw3TY3eE9mVVlonz59SjSi3V8Go8bveYSUHm/2oGfCn9ziCH40htpYLllQZfSBqH0IF1BrsQ62o9LWwKyp1vrmlEiijQy5mClTOHbeC2EHSP04u8+v5EC8UA1Jh2f1kers=
            root@localhost.localdomain
          - ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQDaG45aoa4HpJ+V029gSYKSv5IenhVmZcJvicGrs+D0PgzzwNIGG52iK4r3YOoEYJn4nX80OHf4ob23avJ1ruDPR9inD1c+oiAk5BLRE7CNdU1mllWE0l6pYRHfpIuCOXC6iWpX1kXbVPJZk3ytVZOgff7LkaIIzbAjDjJ+N1MQSUmKvnioh8c6WtFfQNAZ2gFBCRWPLxcjHdyTYvy+oB0qR10WpQYHrGVB0LawtudQrO/8zHcfZJpI0uFwSAvYqspgiO3hPfuT0Fx8xzAb66AK/2vF/WrMOH3AbBu5S954B+xZI4apPJN/Yy5ENRVIoL7w9V5pV5FENtsSvQ+fpFat9yoVewvy5CMo8qJHrvAqlBJ9JriVX2mnigJRkshG0F+Z7BLZUjMcueSIIzasQ2igc8nbpfElSnTmoyweiMbFIXNJJwaV/tKbFkF3J7A3fz1qbfSQ7AIHAigoUf/CnCr+j+BQs1ZZMoWGQOPwFo00OBDICnP0Pc6wBr4iN6gnDFs=
            jnakamura@JNakamura-22
      storage:
        files:
        - contents:
            source: data:,%23%20This%20file%20signals%20NetworkManager-clean-initrd-state%20service%20to%20run%20on%0A%23%20boot.%20This%20service%20is%20used%20to%20clean%20up%20the%20network%20activation%20state%0A%23%20generated%20by%20dracut%20so%20that%20other%20network%20configuration%20deployed%20by%20the%0A%23%20user%20can%20be%20activated.%20This%20only%20happens%20if%20dracut%20activated%20a%20default%0A%23%20network%20configuration%20and%20there%20is%20an%20alternate%20configuration%20available%20in%0A%23%20the%20root%20filesystem.%20Otherwise%2C%20it%20is%20assumed%20that%20the%20network%0A%23%20configuration%20activated%20by%20dracut%20is%20the%20one%20that%20is%20intended%20to%20be%20used%0A%23%20throughout%20the%20life%20of%20the%20system.%0A%23%20Opt-out%20for%20baremetal%20IPI%20deplyments%2C%20opt-in%20otherwise.%0A
          mode: 493
          overwrite: true
          path: /var/lib/mco/nm-clean-initrd-state
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-ex%20-o%20pipefail%0A%0ANM_DEVICES_DIR%3D%2Frun%2FNetworkManager%2Fdevices%0ANM_RUN_CONN_DIR%3D%2Frun%2FNetworkManager%2Fsystem-connections%0ANM_ETC_CONN_DIR%3D%2Fetc%2FNetworkManager%2Fsystem-connections%0A%0Alogger%20-t%20nm-clean-initrd-state%20%22Cleaning%20network%20activation%20state%20generated%20by%20dracut...%22%0Alogger%20-t%20nm-clean-initrd-state%20%22To%20disable%2C%20remove%20%2Fvar%2Flib%2Fmco%2Fnm-clean-initrd-state%22%0A%0Aif%20%5B%20!%20-e%20%22%24NM_DEVICES_DIR%22%20%5D%20%7C%7C%20%5B%20!%20-e%20%22%24NM_RUN_CONN_DIR%22%20%5D%20%7C%7C%20%5B%20!%20-e%20%22%24NM_ETC_CONN_DIR%22%20%5D%3B%20then%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22There%20is%20no%20network%20activation%20state%20to%20clean%22%0A%20%20exit%0Afi%0A%0A%23%20Some%20deployments%20require%20an%20active%20network%20early%20in%20the%20boot%20process.%20To%0A%23%20achieve%20this%2C%20dracut%20runs%20specific%20NetworkManager%20modules.%20This%20results%20in%0A%23%20NetworkManager%20keyfiles%20being%20generated%20(either%20default%20or%20from%20ip%20kernel%0A%23%20arguments)%20and%20activated.%20This%20activation%20generates%20state%20that%20makes%20those%0A%23%20profiles%20to%20be%20re-activated%20by%20the%20NetworkManager%20service%20later%20in%20the%0A%23%20boot%20process.%20And%20this%20has%20the%20effect%20that%20other%20profiles%20deployed%20by%20the%0A%23%20user%20for%20the%20same%20set%20of%20devices%20are%20ignored.%0A%0A%23%20Most%20of%20the%20time%20this%20is%20the%20desired%20behavior.%20The%20exception%20to%20this%20rule%0A%23%20is%20when%20the%20user%20wants%20to%20run%20the%20boot%20process%20with%20a%20different%20network%0A%23%20setup%20than%20the%20real%20root%20which%20is%20usually%20related%20to%20the%20fact%20that%0A%23%20generating%20images%20with%20customized%20kernel%20arguments%20is%20a%20complication%20in%0A%23%20the%20deployment%20pipeline.%0A%0A%23%20This%20need%20has%20been%20exacerbated%20by%20past%20NetworkManager%20bugs%20that%20activated%0A%23%20the%20network%20on%20boot%20when%20it%20was%20not%20really%20needed.%20Most%20notably%20when%20ip%0A%23%20kernel%20argument%20is%20present%2C%20something%20that%20the%20baremetal%20installer%20adds%20by%0A%23%20default.%0A%0A%23%20The%20intention%20here%20is%20to%20remove%20the%20state%20that%20was%20generated%20with%20the%0A%23%20activation%20of%20those%20profiles%20during%20dracut%20execution.%20Then%20when%0A%23%20NetworkManager%20service%20runs%2C%20the%20profiles%20generated%20by%20dracut%2C%20along%20with%0A%23%20other%20profiles%20configured%20by%20the%20user%2C%20are%20evaluated%20towards%20finding%20the%0A%23%20most%20appropriate%20profile%20to%20connect%20a%20device%20with.%20As%20a%20precaution%2C%20clean%0A%23%20state%20only%20for%20devices%20that%3A%0A%23%20-%20have%20been%20activated%20with%20a%20default%20profile%20(assume%20that%20a%20non-default%0A%23%20%20%20configuration%20expresses%20intention%20by%20user%20to%20run%20with%20it%20permanently)%0A%23%20-%20have%20a%20specific%20configured%20profile%20set%20to%20auto-connect%20(if%20there%20is%20no%0A%23%20%20%20alternate%20configured%20profile%20for%20a%20device%20it%20makes%20no%20sense%20to%0A%23%20%20%20de-activate%20anything)%0A%23%0A%23%20Although%20this%20can%20theoretically%20happen%20on%20any%20deployment%20type%2C%20need%20has%0A%23%20mostly%20come%20from%20IPI%20bare%20metal%20deployments.%20For%20the%20time%20being%2C%20this%0A%23%20should%20be%20opt-in%20in%20any%20other%20deploment%20type.%0A%23%0A%23%20There%20is%20an%20RFE%20filed%20against%20NM%20that%20once%20implemented%20would%20make%20this%0A%23%20script%20unnecessary%3A%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D2089707%0A%0Afor%20device%20in%20%22%24%7BNM_DEVICES_DIR%7D%22%2F*%3B%20do%0A%20%20if%20%5B%20!%20-e%20%22%24device%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20the%20device%20file%20name%20is%20the%20ifindex%0A%20%20ifindex%3D%24(basename%20%22%24device%22)%0A%20%20%0A%20%20%23%20get%20the%20interface%20name%20by%20ifindex%0A%20%20ifname%3D%24(ip%20-j%20link%20show%20%7C%20jq%20-r%20%22.%5B%5D%20%7C%20select(.ifindex%20%3D%3D%20%24%7Bifindex%7D)%20%7C%20.ifname%20%2F%2F%20empty%22)%0A%0A%20%20%23%20no%20interface%20name%20found%2C%20ignore%0A%20%20if%20%5B%20-z%20%22%24ifname%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20get%20the%20uuid%20of%20the%20profile%20the%20device%20has%20been%20activated%20with%0A%20%20active_profile_uuid%3D%24(sed%20-nr%20'%2F%5E%5C%5Bdevice%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Econnection-uuid%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24device%22)%0A%0A%20%20%23%20the%20device%20was%20not%20activated%20with%20any%20profile%2C%20ignore%0A%20%20if%20%5B%20-z%20%22%24active_profile_uuid%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20find%20the%20generated%20profile%20by%20uuid%0A%20%20for%20profile%20in%20%22%24%7BNM_RUN_CONN_DIR%7D%22%2F*%3B%20do%0A%20%20%20%20generated_profile_uuid%3D%24(sed%20-nr%20'%2F%5E%5C%5Bconnection%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Euuid%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20%20%20if%20%5B%20%22%24active_profile_uuid%22%20%3D%20%22%24generated_profile_uuid%22%20%5D%3B%20then%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20done%0A%0A%20%20%23%20generated%20profile%20not%20found%2C%20ignore%0A%20%20if%20%5B%20%22%24active_profile_uuid%22%20!%3D%20%22%24generated_profile_uuid%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20check%20that%20it%20is%20not%20specific%20for%20the%20device%2C%20otherwise%20ignore%0A%20%20profile_ifname%3D%24(sed%20-nr%20'%2F%5E%5C%5Bconnection%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Einterface-name%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20if%20%5B%20-n%20%22%24profile_ifname%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20profile%20not%20generated%20by%20nm-initrd-generator%2C%20ignore%0A%20%20%23%20only%20check%20it%20if%20the%20key%20is%20set%20(from%20NM%201.32.4)%0A%20%20origin%3D%24(sed%20-nr%20'%2F%5E%5C%5Buser%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Eorg.freedesktop.NetworkManager.origin%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20if%20%5B%20-n%20%22%24origin%22%20%5D%20%26%26%20%5B%20%22%24origin%22%20!%3D%20%22nm-initrd-generator%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20find%20the%20configured%20profile%20by%20name%20with%20auto-connect%20set%0A%20%20for%20profile%20in%20%22%24%7BNM_ETC_CONN_DIR%7D%22%2F*%3B%20do%0A%20%20%20%20profile_ifname%3D%24(sed%20-nr%20'%2F%5E%5C%5Bconnection%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Einterface-name%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20%20%20autoconnect%3D%24(sed%20-nr%20'%2F%5E%5C%5Bconnection%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Eautoconnect%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20%20%20if%20%5B%20%22%24profile_ifname%22%20%3D%20%22%24ifname%22%20%5D%20%26%26%20%5B%20%22%24autoconnect%22%20!%3D%20%22false%22%20%5D%3B%20then%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20done%0A%0A%20%20%23%20configured%20profile%20not%20found%2C%20ignore%0A%20%20if%20%5B%20%22%24profile_ifname%22%20!%3D%20%22%24ifname%22%20%5D%20%7C%7C%20%5B%20%22%24autoconnect%22%20%3D%20%22false%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20configured_profile_uuid%3D%24(sed%20-nr%20'%2F%5E%5C%5Bconnection%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Euuid%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22%24ifname%20activated%20with%20default%20generated%20profile%20%24generated_profile_uuid%22%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22%24ifname%20has%20different%20configured%20specific%20profile%20%24configured_profile_uuid%22%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22%24ifname%3A%20removing%20state...%22%0A%20%20%0A%20%20%23%20NM%20can%20still%20generate%20internal%20profiles%20from%20the%20IP%20address%0A%20%20%23%20configuration%20of%20devices%2C%20so%20flush%20addresses%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22Flushing%20IP%20addresses%20from%20%24ifname%22%0A%20%20ip%20addr%20flush%20%22%24ifname%22%0A%20%20ip%20-6%20addr%20flush%20%22%24ifname%22%0A%0A%20%20%23%20remove%20device%20state%20file%20to%20prevent%20NM%20to%20unilaterally%20connect%20with%20the%0A%20%20%23%20latest%20activated%20profile%20without%20evaluating%20other%20profiles%20%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22Removing%20%24device%22%0A%20%20rm%20-f%20--%20%22%24device%22%0A%0Adone%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/nm-clean-initrd-state.sh
        - contents:
            source: data:,%5Bconnection%5D%0Aipv6.dhcp-duid%3Dll%0Aipv6.dhcp-iaid%3Dmac%0A
          mode: 420
          overwrite: true
          path: /etc/NetworkManager/conf.d/01-ipv6.conf
        - contents:
            source: data:,%5Bmain%5D%0Aplugins%3Dkeyfile%2Cifcfg-rh%0A%5Bkeyfile%5D%0Apath%3D%2Fetc%2FNetworkManager%2Fsystem-connections%0A
          mode: 420
          overwrite: true
          path: /etc/NetworkManager/conf.d/20-keyfiles.conf
        - contents:
            source: data:,%5Bmain%5D%0Arc-manager%3Dunmanaged%0A
          mode: 420
          overwrite: true
          path: /etc/NetworkManager/conf.d/99-kni.conf
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-eo%20pipefail%0AIFACE%3D%241%0ASTATUS%3D%242%0A%0Afunction%20resolv_prepender%20%7B%0A%20%20mkdir%20-p%20%2Frun%2Fresolv-prepender%0A%20%20echo%20%22IP4_DOMAINS%3D%24IP4_DOMAINS%22%20%3E%20%2Frun%2Fresolv-prepender%2Fenv.new%0A%20%20echo%20%22IP6_DOMAINS%3D%24IP6_DOMAINS%22%20%3E%3E%20%2Frun%2Fresolv-prepender%2Fenv.new%0A%0A%20%20if%20!%20diff%20-q%20%2Frun%2Fresolv-prepender%2Fenv%20%2Frun%2Fresolv-prepender%2Fenv.new%3B%20then%0A%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Environment%20variable(s)%20changed.%20Systemd%20path%20unit%20will%20pick%20the%20change.%22%0A%20%20%20%20mv%20-f%20%2Frun%2Fresolv-prepender%2Fenv.new%20%2Frun%2Fresolv-prepender%2Fenv%0A%20%20fi%0A%7D%0A%0Aexport%20IP4_DOMAINS%20IP6_DOMAINS%0Aexport%20-f%20resolv_prepender%0A%0A%23%20For%20RHEL8%20with%20NetworkManager%20%3E%3D%201.36%20and%20RHEL9%20with%20NetworkManager%20%3E%3D1.42%20we%20can%20use%20simplified%20logic%0A%23%20of%20observing%20only%20a%20single%20%22dns-change%22%20event.%20Older%20version%20of%20NetworkManager%20require%20however%20that%20we%0A%23%20react%20on%20a%20set%20of%20multiple%20events.%20Once%20dns-change%20event%20is%20detected%20we%20create%20a%20flag%20file%20to%20ignore%0A%23%20subsequent%20up%26co.%20events%20as%20undesired.%0A%23%0A%23%20Given%20an%20overall%20Network%20Manager%20dispatcher%20timeout%20of%2090%20seconds%2C%20we%20are%20enforcing%20a%20slightly%20shorter%0A%23%20timeout%20for%20the%20observed%20events.%20It%20is%20not%20really%20required%20because%20all%20we%20do%20in%20this%20function%20is%20to%20write%20a%20file.%0A%23%20We%20could%20get%20rid%20of%20this%20timeout%20completely%2C%20but%20it%20also%20does%20not%20cost%20much%20to%20keep%20it.%0Acase%20%22%24STATUS%22%20in%0A%20%20dns-change)%0A%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%20triggered%20by%20%24%7BIFACE%7D%20%24%7BSTATUS%7D.%22%0A%20%20%20%20if%20%5B%20!%20-f%20%22%2Frun%2Fnetworkmanager-dns-event-detected%22%20%5D%3B%20then%0A%20%20%20%20%20%20touch%20%2Frun%2Fnetworkmanager-dns-event-detected%0A%20%20%20%20fi%0A%20%20%20%20if%20!%20timeout%2060s%20bash%20-c%20resolv_prepender%3B%20then%0A%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Timeout%20occurred%22%0A%20%20%20%20%20%20exit%201%0A%20%20%20%20fi%0A%20%20%3B%3B%0A%0A%20%20up%7Cdhcp4-change%7Cdhcp6-change%7Creapply)%0A%20%20%20%20if%20%5B%20!%20-f%20%22%2Frun%2Fnetworkmanager-dns-event-detected%22%20%5D%3B%20then%0A%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%20triggered%20by%20%24%7BIFACE%7D%20%24%7BSTATUS%7D.%22%0A%20%20%20%20%20%20if%20!%20timeout%2030s%20bash%20-c%20resolv_prepender%3B%20then%0A%20%20%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Timeout%20occurred%22%0A%20%20%20%20%20%20%20%20exit%201%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20If%20%24DHCP6_FQDN_FQDN%20is%20not%20empty%20and%20is%20not%20localhost.localdomain%20and%20static%20hostname%20was%20not%20already%20set%0A%20%20%20%20if%20%5B%5B%20-n%20%22%24DHCP6_FQDN_FQDN%22%20%26%26%20%22%24DHCP6_FQDN_FQDN%22%20!%3D%20%22localhost.localdomain%22%20%26%26%20%22%24DHCP6_FQDN_FQDN%22%20%3D~%20%22.%22%20%5D%5D%20%3B%20then%0A%20%20%20%20%20%20%20STATIC_HOSTNAME%3D%22%24(test%20!%20-e%20%2Fetc%2Fhostname%20%26%26%20echo%20-n%20%7C%7C%20cat%20%2Fetc%2Fhostname%20%7C%20xargs)%22%0A%0A%20%20%20%20%20%20%20if%20%5B%5B%20-z%20%22%24STATIC_HOSTNAME%22%20%7C%7C%20%22%24STATIC_HOSTNAME%22%20%3D%3D%20%22localhost.localdomain%22%20%5D%5D%20%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%23%20run%20with%20systemd-run%20to%20avoid%20selinux%20problems%0A%20%20%20%20%20%20%20%20%20%20systemd-run%20--property%3DType%3Doneshot%20--unit%20resolve-prepender-hostnamectl%20-Pq%20%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20hostnamectl%20set-hostname%20--static%20--transient%20%24DHCP6_FQDN_FQDN%0A%20%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20if%20%5B%5B%20%22%24STATUS%22%20%3D%3D%20%22up%22%20%5D%5D%20%26%26%20%5B%5B%20%24IFACE%20%3D%3D%20%22br-ex%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20%2Fbin%2Fmkdir%20-p%20%2Frun%2Fnodeip-configuration%0A%20%20%20%20%20%20%20%20touch%20%2Frun%2Fnodeip-configuration%2Fbr-ex-up%0A%20%20%20%20fi%0A%20%20%3B%3B%0A%20%20*)%0A%20%20%3B%3B%0Aesac%0A
          mode: 493
          overwrite: true
          path: /etc/NetworkManager/dispatcher.d/30-resolv-prepender
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-ex%20-o%20pipefail%0A%0Aif%20%5B%5B%20%22OVNKubernetes%22%20%3D%3D%20%22OVNKubernetes%22%20%26%26%20%22%24CONNECTION_ID%22%20%3D%3D%20%22Wired%20Connection%22%20%5D%5D%0Athen%0A%20%20%20%20%3E%262%20echo%20%22Refusing%20to%20modify%20default%20connection.%22%0A%20%20%20%20exit%200%0Afi%0A%0Aif%20%5B%20-z%20%24%7BDHCP4_IP_ADDRESS%3A-%7D%20%5D%0Athen%0A%20%20%20%20%3E%262%20echo%20%22Not%20a%20DHCP4%20address.%20Ignoring.%22%0A%20%20%20%20exit%200%0Afi%0A%0Aif%20%5B%20%24%7BDHCP4_DHCP_LEASE_TIME%3A-0%7D%20-lt%204294967295%20%5D%0Athen%0A%20%20%20%20%3E%262%20echo%20%22Not%20an%20infinite%20DHCP4%20lease.%20Ignoring.%22%0A%20%20%20%20exit%200%0Afi%0A%0AIPS%3D(%24IP4_ADDRESS_0)%0ACIDR%3D%24%7BIPS%5B0%5D%7D%0AGATEWAY%3D%24%7BIPS%5B1%5D%7D%0A%0ATYPE%3D%24(nmcli%20--get-values%20connection.type%20connection%20show%20%22%24CONNECTION_ID%22)%0A%0A%23%20Modifying%20the%20default%20connection%20id%20directly%20doesn't%20do%20what%20we%20want.%0A%23%20If%20we%20see%20that%2C%20then%20we%20need%20to%20create%20a%20new%20connection.%0Aif%20%5B%20%22%24CONNECTION_ID%22%20%3D%3D%20%22Wired%20Connection%22%20%5D%0Athen%0A%20%20%20%20if%20!%20nmcli%20con%20show%20inf-lease-to-static%0A%20%20%20%20then%0A%20%20%20%20%20%20%20%20nmcli%20con%20add%20type%20%22%24TYPE%22%20con-name%20inf-lease-to-static%0A%20%20%20%20fi%0A%20%20%20%20STATIC_INT_NAME%3Dinf-lease-to-static%0Aelse%0A%20%20%20%20STATIC_INT_NAME%3D%22%24CONNECTION_ID%22%0Afi%0Anmcli%20con%20mod%20%22%24STATIC_INT_NAME%22%20%5C%0A%20%20conn.interface%20%22%241%22%20%5C%0A%20%20connection.autoconnect%20yes%20%5C%0A%20%20ipv4.addresses%20%22%24CIDR%22%20%5C%0A%20%20ipv4.method%20manual%20%5C%0A%20%20ipv4.gateway%20%22%24GATEWAY%22%20%5C%0A%20%20ipv4.dns%20%22%24IP4_NAMESERVERS%22%0A%0Aif%20%5B%20-n%20%22%24IP4_DOMAINS%22%20%5D%3B%20then%0A%20%20%20%20nmcli%20con%20mod%20%22%24STATIC_INT_NAME%22%20ipv4.dns-search%20%22%24IP4_DOMAINS%22%0Afi%0Aplus%3D''%0Afor%20i%20in%20%24(seq%200%20%24((%24IP4_NUM_ROUTES-1))%20)%0Ado%0A%20%20%20%20varname%3D%22IP4_ROUTE_%24i%22%0A%20%20%20%20nmcli%20con%20mod%20%22%24STATIC_INT_NAME%22%20%24%7Bplus%7Dipv4.routes%20%22%24%7B!varname%7D%22%0A%20%20%20%20plus%3D'%2B'%0Adone%0A%0Anmcli%20con%20up%20%22%24STATIC_INT_NAME%22%0A%0Aif%20%5B%20-n%20%22%24%7BDHCP4_HOST_NAME%3A-%7D%22%20%5D%0Athen%0A%20%20%20%20systemd-run%20--property%3DType%3Doneshot%20--unit%20static-dhcp-hostnamectl%20-Pq%20%5C%0A%20%20%20%20%20%20hostnamectl%20set-hostname%20--static%20--transient%20%22%24DHCP4_HOST_NAME%22%0Afi%0A
          mode: 493
          overwrite: true
          path: /etc/NetworkManager/dispatcher.d/30-static-dhcp
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-ex%20-o%20pipefail%0A%0Aif%20%5B%20-z%20%22%24DHCP6_IP6_ADDRESS%22%20%5D%0Athen%0A%20%20%20%20%3E%262%20echo%20%22Not%20a%20DHCP6%20address.%20Ignoring.%22%0A%20%20%20%20exit%200%0Afi%0A%0ALEASE_TIME%3D%24(ip%20-j%20-6%20a%20show%20%22%24DEVICE_IFACE%22%20%7C%20jq%20-r%20%22.%5B%5D.addr_info%5B%5D%20%7C%20select(.scope%3D%3D%5C%22global%5C%22)%20%7C%20select(.deprecated!%3Dtrue)%20%7C%20select(.local%3D%3D%5C%22%24DHCP6_IP6_ADDRESS%5C%22)%20%7C%20.preferred_life_time%22)%0APREFIX_LEN%3D%24(ip%20-j%20-6%20a%20show%20%22%24DEVICE_IFACE%22%20%7C%20jq%20-r%20%22.%5B%5D.addr_info%5B%5D%20%7C%20select(.scope%3D%3D%5C%22global%5C%22)%20%7C%20select(.deprecated!%3Dtrue)%20%7C%20select(.local%3D%3D%5C%22%24DHCP6_IP6_ADDRESS%5C%22)%20%7C%20.prefixlen%22)%0A%0Aif%20%5B%20%24%7BLEASE_TIME%3A-0%7D%20-lt%204294967295%20%5D%0Athen%0A%20%20%20%20%3E%262%20echo%20%22Not%20an%20infinite%20DHCP6%20lease.%20Ignoring.%22%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20We%20don't%20want%20this%20to%20run%20before%20OVNKubernetes%20creates%20its%20bridge.%20If%20we%0A%23%20see%20the%20default%20CONNECTION_ID%20we%20know%20to%20wait.%0Aif%20%5B%20%22%24CONNECTION_ID%22%20%3D%3D%20%22Wired%20Connection%22%20%5D%0Athen%0A%20%20%20%20%3E%262%20echo%20%22Refusing%20to%20modify%20default%20connection.%22%0A%20%20%20%20exit%200%0Afi%0A%0ACIDR%3D%22%24DHCP6_IP6_ADDRESS%2F%24PREFIX_LEN%22%0Anmcli%20con%20mod%20%22%24CONNECTION_ID%22%20ipv6.addresses%20%22%24CIDR%22%0Anmcli%20con%20mod%20%22%24CONNECTION_ID%22%20connection.autoconnect%20%22yes%22%0Anmcli%20con%20mod%20%22%24CONNECTION_ID%22%20ipv6.method%20%22manual%22%0Anmcli%20con%20mod%20%22%24CONNECTION_ID%22%20ipv6.gateway%20%22%24IP6_GATEWAY%22%0Anmcli%20con%20mod%20%22%24CONNECTION_ID%22%20ipv6.dns%20%22%24IP6_NAMESERVERS%22%0ASEARCH_DOMAIN%3D%22%24%7BDHCP6_FQDN_FQDN%23*.%7D%22%0Aif%20%5B%20-n%20%22%24SEARCH_DOMAIN%22%20%5D%3B%20then%0A%20%20%20%20nmcli%20con%20mod%20%22%24CONNECTION_ID%22%20ipv6.dns-search%20%22%24SEARCH_DOMAIN%22%0Afi%0Aplus%3D''%0Afor%20i%20in%20%24(seq%200%20%24((%24IP6_NUM_ROUTES-1))%20)%0Ado%0A%20%20%20%20varname%3D%22IP6_ROUTE_%24i%22%0A%20%20%20%20nmcli%20con%20mod%20%22%24CONNECTION_ID%22%20%24%7Bplus%7Dipv6.routes%20%22%24%7B!varname%7D%22%0A%20%20%20%20plus%3D'%2B'%0Adone%0A%0A%23%20Copy%20it%20from%20the%20OverlayFS%20mount%20to%20the%20persistent%20lowerdir%0Acp%20%22%24CONNECTION_FILENAME%22%20%2Fetc%2FNetworkManager%2Fsystem-connections%0A
          mode: 493
          overwrite: true
          path: /etc/NetworkManager/dispatcher.d/30-static-dhcpv6
        - contents:
            source: data:,
          mode: 384
          overwrite: true
          path: /etc/pki/ca-trust/source/anchors/openshift-config-user-ca-bundle.crt
        - contents:
            source: data:,KUBERNETES_SERVICE_HOST%3D'api-int.comp-poc-rh01.rhpoc.int'%0AKUBERNETES_SERVICE_PORT%3D'6443'%0A
          mode: 420
          overwrite: true
          path: /etc/kubernetes/apiserver-url.env
        - contents:
            source: data:,%23%20This%20file%20is%20managed%20by%20machine-config-operator.%0A%23%20Suppress%20audit%20rules%20which%20always%20trigger%20for%20container%0A%23%20workloads%2C%20as%20they%20spam%20the%20audit%20log.%20%20Workloads%20are%20expected%0A%23%20to%20be%20dynamic%2C%20and%20the%20networking%20stack%20uses%20iptables.%0A-a%20exclude%2Calways%20-F%20msgtype%3DNETFILTER_CFG%0A%23%20The%20default%20bridged%20networking%20enables%20promiscuous%20on%20the%20veth%0A%23%20device.%20%20Ideally%2C%20we'd%20teach%20audit%20to%20ignore%20only%20veth%20devices%2C%0A%23%20since%20one%20might%20legitimately%20care%20about%20promiscuous%20on%20real%20physical%0A%23%20devices.%20%20But%20we%20can't%20currently%20differentiate.%0A-a%20exclude%2Calways%20-F%20msgtype%3DANOM_PROMISCUOUS%0A
          mode: 420
          overwrite: true
          path: /etc/audit/rules.d/mco-audit-quiet-containers.rules
        - contents:
            source: data:,mode%3A%20unicast%0A
          mode: 420
          overwrite: true
          path: /etc/keepalived/monitor.conf
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%0A%23%20ESP%20offload%2C%20either%20in%20actual%20hardware%20or%20as%20part%20as%20GRO%20(generic%0A%23%20recieve%20offload)%20does%20not%20work%20for%20interfaces%20attached%20to%20an%20OVS%20bridge%0A%23%20so%20turn%20it%20off%20for%20the%20time%20being.%0A%23%20https%3A%2F%2Fissues.redhat.com%2Fbrowse%2FRHEL-58811%0A%0A%23%20Depends%20on%20ipsec%20service%20drop-in%20to%20start%20it%20after%20configure-ovs%20to%20make%0A%23%20sure%20offloads%20are%20disabled%20before%20ipsec%20starts.%0A%0Aif%20%5B%5B%20%22%242%22%20!%3D%20%22up%22%20%5D%5D%3B%20then%0A%20%20exit%0Afi%0A%0Adevice%3D%24DEVICE_IFACE%0Akind_slave%3D%24(ip%20-j%20-d%20link%20show%20%22%24device%22%20%7C%20jq%20-r%20'.%5B0%5D%20%7C%20.linkinfo.info_slave_kind%20%2F%2F%20empty')%0A%0Aif%20%5B%20%22%24kind_slave%22%20%3D%20%22openvswitch%22%20%5D%3B%20then%0A%20%20for%20feature%20in%20tx-esp-segmentation%20esp-hw-offload%20esp-tx-csum-hw-offload%3B%20do%0A%20%20%20%20if%20ethtool%20-k%20%22%24device%22%20%7C%20grep%20-qE%20%22%5E%24%7Bfeature%7D%3A%20off%22%3B%20then%0A%20%20%20%20%20%20%23%20already%20disabled%2C%20nothing%20to%20do%0A%20%20%20%20%20%20continue%0A%20%20%20%20fi%0A%20%20%20%20%0A%20%20%20%20logger%20-t%2099-esp-offload%20-s%20%22Setting%20%24feature%20off%20for%20%24device%3A%20unsupported%20when%20attached%20to%20Open%20vSwitch%20bridge%22%0A%20%20%20%20ethtool%20-K%20%22%24device%22%20%22%24feature%22%20off%0A%20%20done%0Afi%0A
          mode: 484
          overwrite: true
          path: /etc/NetworkManager/dispatcher.d/99-esp-offload
        - contents:
            source: data:,r%20%2Fetc%2Fkubernetes%2Fcni%2Fnet.d%2F80-openshift-network.conf%0Ar%20%2Fetc%2Fkubernetes%2Fcni%2Fnet.d%2F10-ovn-kubernetes.conf%0Ad%20%2Frun%2Fmultus%2Fcni%2Fnet.d%2F%200755%20root%20root%20-%20-%0AD%20%2Fvar%2Flib%2Fcni%2Fnetworks%2Fopenshift-sdn%2F%200755%20root%20root%20-%20-%0A
          mode: 420
          overwrite: true
          path: /etc/tmpfiles.d/cleanup-cni.conf
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-ex%0A%0A%23%20Used%20for%20on-prem%20deployments%20to%20enable%20ip%20forwarding%20as%20part%20of%20nodeip-configuration%20service.%0A%23%20IP%20forwarding%20is%20required%20on%20the%20node%20IP%20(k8s%20API)%20interface%20in%20order%20for%20keepalived%20to%20function.%0A%0Aecho%20%22Configuring%20IP%20Forwarding...%22%0Aovnk_config_dir%3D'%2Fetc%2Fovnk'%0Aip_hint_file%3D%22%2Frun%2Fnodeip-configuration%2Fprimary-ip%22%0A%0Aget_ip_from_ip_hint_file()%20%7B%0A%20%20local%20ip_hint_file%3D%22%241%22%0A%20%20if%20%5B%5B%20!%20-f%20%22%24%7Bip_hint_file%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22error%3A%20unable%20to%20enable%20IP%20forwarding.%20IP%20hint%20file%3A%20%24%7Bip_hint_file%7D%20does%20not%20exist!%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%20%20ip_hint%3D%24(cat%20%22%24%7Bip_hint_file%7D%22)%0A%20%20echo%20%22%24%7Bip_hint%7D%22%0A%7D%0A%0Aget_nodeip_hint_interface()%20%7B%0A%20%20local%20ip_hint%3D%22%22%0A%20%20local%20ip_hint_file%3D%22%241%22%0A%20%20local%20iface%3D%22%22%0A%0A%20%20ip_hint%3D%24(get_ip_from_ip_hint_file%20%22%24%7Bip_hint_file%7D%22)%0A%20%20if%20%5B%5B%20-z%20%22%24%7Bip_hint%7D%22%20%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22error%3A%20unable%20to%20enable%20IP%20forwarding.%20IP%20hint%20file%3A%20%24%7Bip_hint_file%7D%20is%20empty!%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%0A%20%20iface%3D%24(ip%20-j%20addr%20%7C%20jq%20-r%20%22first(.%5B%5D%20%7C%20select(any(.addr_info%5B%5D%3B%20.local%3D%3D%5C%22%24%7Bip_hint%7D%5C%22)))%20%7C%20.ifname%22)%0A%20%20if%20%5B%5B%20-z%20%22%24%7Biface%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22error%3A%20unable%20to%20enable%20IP%20forwarding.%20Cannot%20detect%20valid%20interface%20within%20file%3A%20%24%7Bip_hint_file%7D%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%20%20echo%20%22%24%7Biface%7D%22%0A%7D%0A%0Aiface%3D%24(get_nodeip_hint_interface%20%22%24%7Bip_hint_file%7D%22)%0A%0Aecho%20%22Node%20IP%20interface%20determined%20as%3A%20%24%7Biface%7D.%20Enabling%20IP%20forwarding...%22%0Afile_paths%3D(%22%2Fproc%2Fsys%2Fnet%2Fipv4%2Fconf%2F%24%7Biface%7D%2Fforwarding%22%20%22%2Fproc%2Fsys%2Fnet%2Fipv6%2Fconf%2F%24%7Biface%7D%2Fforwarding%22)%0Afor%20file_path%20in%20%22%24%7Bfile_paths%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20if%20%5B%20-f%20%22%24%7Bfile_path%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%221%22%20%3E%20%22%24%7Bfile_path%7D%22%0A%20%20%20%20fi%0Adone%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/configure-ip-forwarding.sh
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-x%0A%0Aif%20%5B%20-e%20%2Fetc%2Fnmstate%2Fopenshift%2Fapplied%20%5D%3B%20then%0A%20%20echo%20%22Skipping%20configure-ovs%20due%20to%20manual%20network%20configuration%22%0A%20%20exit%200%0Afi%0A%0A%23%20This%20file%20is%20not%20needed%20anymore%20in%204.7%2B%2C%20but%20when%20rolling%20back%20to%204.6%0A%23%20the%20ovs%20pod%20needs%20it%20to%20know%20ovs%20is%20running%20on%20the%20host.%0Atouch%20%2Fvar%2Frun%2Fovs-config-executed%0A%0A%23%20These%20are%20well%20knwon%20NM%20default%20paths%0ANM_CONN_ETC_PATH%3D%22%2Fetc%2FNetworkManager%2Fsystem-connections%22%0ANM_CONN_RUN_PATH%3D%22%2Frun%2FNetworkManager%2Fsystem-connections%22%0A%0A%23%20This%20is%20the%20path%20where%20NM%20is%20known%20to%20be%20configured%20to%20store%20user%20keyfiles%20%0ANM_CONN_CONF_PATH%3D%22%24NM_CONN_ETC_PATH%22%0A%0A%23%20This%20is%20where%20we%20want%20our%20keyfiles%20to%20finally%20reside.%20configure-ovs%0A%23%20operates%20with%20temporary%20keyfiles%20in%20NM_CONN_RUN_PATH%20and%20then%20as%20a%20last%0A%23%20step%20moves%20those%20keyfiles%20to%20NM_CONN_SET_PATH%20if%20it%20is%20a%20different%20path%0A%23%20(not%20by%20default).%20This%20mitigates%20hard%20interruptions%20(SIGKILL%2C%20hard%20reboot)%0A%23%20of%20configure-ovs%20leaving%20the%20machine%20with%20a%20half-baked%20set%20of%20keyfiles%0A%23%20that%20might%20prevent%20machine%20networking%20from%20working%20correctly.%0ANM_CONN_SET_PATH%3D%22%24%7BNM_CONN_SET_PATH%3A-%24NM_CONN_RUN_PATH%7D%22%0A%0AMANAGED_NM_CONN_SUFFIX%3D%22-slave-ovs-clone%22%0A%23%20Workaround%20to%20ensure%20OVS%20is%20installed%20due%20to%20bug%20in%20systemd%20Requires%3A%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1888017%0Acopy_nm_conn_files()%20%7B%0A%20%20local%20dst_path%3D%22%241%22%0A%20%20for%20src%20in%20%22%24%7BMANAGED_NM_CONN_FILES%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20src_path%3D%24(dirname%20%22%24src%22)%0A%20%20%20%20file%3D%24(basename%20%22%24src%22)%0A%20%20%20%20if%20%5B%20-f%20%22%24src_path%2F%24file%22%20%5D%3B%20then%0A%20%20%20%20%20%20if%20%5B%20!%20-f%20%22%24dst_path%2F%24file%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22Copying%20configuration%20%24file%22%0A%20%20%20%20%20%20%20%20cp%20%22%24src_path%2F%24file%22%20%22%24dst_path%2F%24file%22%0A%20%20%20%20%20%20elif%20!%20cmp%20--silent%20%22%24src_path%2F%24file%22%20%22%24dst_path%2F%24file%22%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22Copying%20updated%20configuration%20%24file%22%0A%20%20%20%20%20%20%20%20cp%20-f%20%22%24src_path%2F%24file%22%20%22%24dst_path%2F%24file%22%0A%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20echo%20%22Skipping%20%24file%20since%20it's%20equal%20at%20destination%22%0A%20%20%20%20%20%20fi%0A%20%20%20%20else%0A%20%20%20%20%20%20echo%20%22Skipping%20%24file%20since%20it%20does%20not%20exist%20at%20source%22%0A%20%20%20%20fi%0A%20%20done%0A%7D%0A%0Aupdate_nm_conn_files_base()%20%7B%0A%20%20base_path%3D%24%7B1%7D%0A%20%20bridge_name%3D%24%7B2%7D%0A%20%20port_name%3D%24%7B3%7D%0A%20%20ovs_port%3D%22ovs-port-%24%7Bbridge_name%7D%22%0A%20%20ovs_interface%3D%22ovs-if-%24%7Bbridge_name%7D%22%0A%20%20default_port_name%3D%22ovs-port-%24%7Bport_name%7D%22%20%23%20ovs-port-phys0%0A%20%20bridge_interface_name%3D%22ovs-if-%24%7Bport_name%7D%22%20%23%20ovs-if-phys0%0A%20%20%23%20In%20RHEL7%20files%20in%20%2F%7Betc%2Crun%7D%2FNetworkManager%2Fsystem-connections%20end%20without%20the%20suffix%20'.nmconnection'%2C%20whereas%20in%20RHCOS%20they%20end%20with%20the%20suffix.%0A%20%20MANAGED_NM_CONN_FILES%3D(%24(echo%20%22%24%7Bbase_path%7D%22%2F%7B%22%24bridge_name%22%2C%22%24ovs_interface%22%2C%22%24ovs_port%22%2C%22%24bridge_interface_name%22%2C%22%24default_port_name%22%7D%7B%2C.nmconnection%7D))%0A%20%20shopt%20-s%20nullglob%0A%20%20MANAGED_NM_CONN_FILES%2B%3D(%24%7Bbase_path%7D%2F*%24%7BMANAGED_NM_CONN_SUFFIX%7D.nmconnection%20%24%7Bbase_path%7D%2F*%24%7BMANAGED_NM_CONN_SUFFIX%7D)%0A%20%20shopt%20-u%20nullglob%0A%7D%0A%0Aupdate_nm_conn_run_files()%20%7B%0A%20%20update_nm_conn_files_base%20%22%24%7BNM_CONN_RUN_PATH%7D%22%20%22%24%7B1%7D%22%20%22%24%7B2%7D%22%0A%7D%0A%0Aupdate_nm_conn_set_files()%20%7B%0A%20%20update_nm_conn_files_base%20%22%24%7BNM_CONN_SET_PATH%7D%22%20%22%24%7B1%7D%22%20%22%24%7B2%7D%22%0A%7D%0A%0Aupdate_nm_conn_etc_files()%20%7B%0A%20%20update_nm_conn_files_base%20%22%24%7BNM_CONN_ETC_PATH%7D%22%20%22%24%7B1%7D%22%20%22%24%7B2%7D%22%0A%7D%0A%0A%23%20Move%20and%20reload%20keyfiles%20at%20their%20final%20destination%0Aset_nm_conn_files()%20%7B%0A%20%20if%20%5B%20%22%24NM_CONN_RUN_PATH%22%20!%3D%20%22%24NM_CONN_SET_PATH%22%20%5D%3B%20then%0A%20%20%20%20update_nm_conn_run_files%20br-ex%20phys0%0A%20%20%20%20copy_nm_conn_files%20%22%24NM_CONN_SET_PATH%22%0A%20%20%20%20rm_nm_conn_files%0A%20%20%20%20update_nm_conn_run_files%20br-ex1%20phys1%0A%20%20%20%20copy_nm_conn_files%20%22%24NM_CONN_SET_PATH%22%0A%20%20%20%20rm_nm_conn_files%0A%0A%20%20%20%20%23%20reload%20keyfiles%0A%20%20%20%20nmcli%20connection%20reload%0A%20%20fi%0A%7D%0A%0A%23%20Used%20to%20remove%20files%20managed%20by%20configure-ovs%20and%20temporary%20leftover%20files%20from%20network%20manager%0Arm_nm_conn_files()%20%7B%0A%20%20for%20file%20in%20%22%24%7BMANAGED_NM_CONN_FILES%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20if%20%5B%20-f%20%22%24file%22%20%5D%3B%20then%0A%20%20%20%20%20%20rm%20-f%20%22%24file%22%0A%20%20%20%20%20%20echo%20%22Removed%20nmconnection%20file%20%24file%22%0A%20%20%20%20%20%20nm_config_changed%3D1%0A%20%20%20%20fi%0A%20%20done%0A%20%20for%20file%20in%20%22%24%7BMANAGED_NM_CONN_FILES%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20for%20temp%20in%20%24(compgen%20-G%20%22%24%7Bfile%7D.*%22)%3B%20do%0A%20%20%20%20%20%20rm%20-f%20%22%24temp%22%0A%20%20%20%20%20%20echo%20%22Removed%20nmconnection%20temporary%20file%20%24temp%22%0A%20%20%20%20%20%20nm_config_changed%3D1%0A%20%20%20%20done%0A%20%20done%0A%7D%0A%0A%23%20Used%20to%20clone%20a%20slave%20connection%20by%20uuid%2C%20returns%20new%20name%0Aclone_slave_connection()%20%7B%0A%20%20local%20uuid%3D%22%241%22%0A%20%20local%20old_name%0A%20%20old_name%3D%22%24(nmcli%20-g%20connection.id%20connection%20show%20uuid%20%22%24uuid%22)%22%0A%20%20local%20new_name%3D%22%24%7Bold_name%7D%24%7BMANAGED_NM_CONN_SUFFIX%7D%22%0A%20%20if%20nmcli%20connection%20show%20id%20%22%24%7Bnew_name%7D%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20echo%20%22WARNING%3A%20existing%20ovs%20slave%20%24%7Bnew_name%7D%20connection%20profile%20file%20found%2C%20overwriting...%22%20%3E%262%0A%20%20%20%20nmcli%20connection%20delete%20id%20%22%24%7Bnew_name%7D%22%20%26%3E%20%2Fdev%2Fnull%0A%20%20fi%0A%20%20clone_nm_conn%20%24uuid%20%22%24%7Bnew_name%7D%22%0A%20%20echo%20%22%24%7Bnew_name%7D%22%0A%7D%0A%0A%23%20Used%20to%20replace%20an%20old%20master%20connection%20uuid%20with%20a%20new%20one%20on%20all%20connections%0Areplace_connection_master()%20%7B%0A%20%20local%20old%3D%22%241%22%0A%20%20local%20new%3D%22%242%22%0A%20%20for%20conn_uuid%20in%20%24(nmcli%20-g%20UUID%20connection%20show)%20%3B%20do%0A%20%20%20%20if%20%5B%20%22%24(nmcli%20-g%20connection.master%20connection%20show%20uuid%20%22%24conn_uuid%22)%22%20!%3D%20%22%24old%22%20%5D%3B%20then%0A%20%20%20%20%20%20continue%0A%20%20%20%20fi%0A%0A%20%20%20%20local%20active_state%3D%24(nmcli%20-g%20GENERAL.STATE%20connection%20show%20%22%24conn_uuid%22)%0A%20%20%20%20local%20autoconnect%3D%24(nmcli%20-g%20connection.autoconnect%20connection%20show%20%22%24conn_uuid%22)%0A%20%20%20%20if%20%5B%20%22%24active_state%22%20!%3D%20%22activated%22%20%5D%20%26%26%20%5B%20%22%24autoconnect%22%20!%3D%20%22yes%22%20%5D%3B%20then%0A%20%20%20%20%20%20%23%20Assume%20that%20slave%20profiles%20intended%20to%20be%20used%20are%20those%20that%20are%3A%0A%20%20%20%20%20%20%23%20-%20active%0A%20%20%20%20%20%20%23%20-%20or%20inactive%20(which%20might%20be%20due%20to%20link%20being%20down)%20but%20to%20be%20autoconnected.%0A%20%20%20%20%20%20%23%20Otherwise%2C%20ignore%20them.%0A%20%20%20%20%20%20continue%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20make%20changes%20for%20slave%20profiles%20in%20a%20new%20clone%0A%20%20%20%20local%20new_name%0A%20%20%20%20new_name%3D%24(clone_slave_connection%20%24conn_uuid)%0A%0A%20%20%20%20mod_nm_conn%20%22%24new_name%22%20connection.master%20%22%24new%22%20connection.autoconnect-priority%20100%20connection.autoconnect%20no%20%0A%20%20%20%20echo%20%22Replaced%20master%20%24old%20with%20%24new%20for%20slave%20profile%20%24new_name%22%0A%20%20done%0A%7D%0A%0A%23%20when%20creating%20the%20bridge%2C%20we%20use%20a%20value%20lower%20than%20NM's%20ethernet%20device%20default%20route%20metric%0A%23%20(we%20pick%2048%20and%2049%20to%20be%20lower%20than%20anything%20that%20NM%20chooses%20by%20default)%0ABRIDGE_METRIC%3D%2248%22%0ABRIDGE1_METRIC%3D%2249%22%0A%23%20Given%20an%20interface%2C%20generates%20NM%20configuration%20to%20add%20to%20an%20OVS%20bridge%0Aconvert_to_bridge()%20%7B%0A%20%20local%20iface%3D%24%7B1%7D%0A%20%20local%20bridge_name%3D%24%7B2%7D%0A%20%20local%20port_name%3D%24%7B3%7D%0A%20%20local%20bridge_metric%3D%24%7B4%7D%0A%20%20local%20ovs_port%3D%22ovs-port-%24%7Bbridge_name%7D%22%0A%20%20local%20ovs_interface%3D%22ovs-if-%24%7Bbridge_name%7D%22%0A%20%20local%20default_port_name%3D%22ovs-port-%24%7Bport_name%7D%22%20%23%20ovs-port-phys0%0A%20%20local%20bridge_interface_name%3D%22ovs-if-%24%7Bport_name%7D%22%20%23%20ovs-if-phys0%0A%0A%20%20if%20%5B%20%22%24iface%22%20%3D%20%22%24bridge_name%22%20%5D%3B%20then%0A%20%20%20%20%23%20handle%20vlans%20and%20bonds%20etc%20if%20they%20have%20already%20been%0A%20%20%20%20%23%20configured%20via%20nm%20key%20files%20and%20br-ex%20is%20already%20up%0A%20%20%20%20ifaces%3D%24(ovs-vsctl%20list-ifaces%20%24%7Biface%7D)%0A%20%20%20%20for%20intf%20in%20%24ifaces%3B%20do%20configure_driver_options%20%24intf%3B%20done%0A%20%20%20%20echo%20%22Networking%20already%20configured%20and%20up%20for%20%24%7Bbridge-name%7D!%22%0A%20%20%20%20return%0A%20%20fi%0A%0A%20%20%23%20flag%20to%20reload%20NM%20to%20account%20for%20all%20the%20configuration%20changes%0A%20%20%23%20going%20forward%0A%20%20nm_config_changed%3D1%0A%0A%20%20if%20%5B%20-z%20%22%24iface%22%20%5D%3B%20then%0A%20%20%20%20echo%20%22ERROR%3A%20Unable%20to%20find%20default%20gateway%20interface%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%20%20%23%20find%20the%20MAC%20from%20OVS%20config%20or%20the%20default%20interface%20to%20use%20for%20OVS%20internal%20port%0A%20%20%23%20this%20prevents%20us%20from%20getting%20a%20different%20DHCP%20lease%20and%20dropping%20connection%0A%20%20if%20!%20iface_mac%3D%24(%3C%22%2Fsys%2Fclass%2Fnet%2F%24%7Biface%7D%2Faddress%22)%3B%20then%0A%20%20%20%20echo%20%22Unable%20to%20determine%20default%20interface%20MAC%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%0A%20%20echo%20%22MAC%20address%20found%20for%20iface%3A%20%24%7Biface%7D%3A%20%24%7Biface_mac%7D%22%0A%0A%20%20%23%20find%20MTU%20from%20original%20iface%0A%20%20iface_mtu%3D%24(ip%20link%20show%20%22%24iface%22%20%7C%20awk%20'%7Bprint%20%245%3B%20exit%7D')%0A%20%20if%20%5B%5B%20-z%20%22%24iface_mtu%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22Unable%20to%20determine%20default%20interface%20MTU%2C%20defaulting%20to%201500%22%0A%20%20%20%20iface_mtu%3D1500%0A%20%20else%0A%20%20%20%20echo%20%22MTU%20found%20for%20iface%3A%20%24%7Biface%7D%3A%20%24%7Biface_mtu%7D%22%0A%20%20fi%0A%0A%20%20%23%20store%20old%20conn%20for%20later%0A%20%20old_conn%3D%24(nmcli%20--fields%20UUID%2CDEVICE%20conn%20show%20--active%20%7C%20awk%20%22%2F%5Cs%24%7Biface%7D%5Cs*%5C%24%2F%20%7Bprint%20%5C%241%7D%22)%0A%0A%20%20if%20%5B%5B%20-z%20%22%24old_conn%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22ERROR%3A%20cannot%20find%20connection%20for%20interface%3A%20%24%7Biface%7D%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%0A%20%20%23%20create%20bridge%0A%20%20if%20!%20nmcli%20connection%20show%20%22%24bridge_name%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-br%20%22%24bridge_name%22%0A%20%20%20%20add_nm_conn%20%22%24bridge_name%22%20type%20ovs-bridge%20conn.interface%20%22%24bridge_name%22%20802-3-ethernet.mtu%20%24%7Biface_mtu%7D%20%5C%0A%20%20%20%20connection.autoconnect-slaves%201%0A%20%20fi%0A%0A%20%20%23%20find%20default%20port%20to%20add%20to%20bridge%0A%20%20if%20!%20nmcli%20connection%20show%20%22%24default_port_name%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-port%20%22%24bridge_name%22%20%24%7Biface%7D%0A%20%20%20%20add_nm_conn%20%22%24default_port_name%22%20type%20ovs-port%20conn.interface%20%24%7Biface%7D%20slave-type%20ovs-bridge%20master%20%22%24bridge_name%22%20%5C%0A%20%20%20%20connection.autoconnect-slaves%201%0A%20%20fi%0A%0A%20%20if%20!%20nmcli%20connection%20show%20%22%24ovs_port%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-port%20%22%24bridge_name%22%20%22%24bridge_name%22%0A%20%20%20%20add_nm_conn%20%22%24ovs_port%22%20type%20ovs-port%20conn.interface%20%22%24bridge_name%22%20slave-type%20ovs-bridge%20master%20%22%24bridge_name%22%0A%20%20fi%0A%0A%20%20extra_phys_args%3D()%0A%20%20%23%20check%20if%20this%20interface%20is%20a%20vlan%2C%20bond%2C%20team%2C%20or%20ethernet%20type%0A%20%20if%20%5B%20%22%24(nmcli%20--get-values%20connection.type%20conn%20show%20%24%7Bold_conn%7D)%22%20%3D%3D%20%22vlan%22%20%5D%3B%20then%0A%20%20%20%20iface_type%3Dvlan%0A%20%20%20%20vlan_id%3D%24(nmcli%20--get-values%20vlan.id%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20if%20%5B%20-z%20%22%24vlan_id%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22ERROR%3A%20unable%20to%20determine%20vlan_id%20for%20vlan%20connection%3A%20%24%7Bold_conn%7D%22%0A%20%20%20%20%20%20exit%201%0A%20%20%20%20fi%0A%20%20%20%20vlan_parent%3D%24(nmcli%20--get-values%20vlan.parent%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20if%20%5B%20-z%20%22%24vlan_parent%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22ERROR%3A%20unable%20to%20determine%20vlan_parent%20for%20vlan%20connection%3A%20%24%7Bold_conn%7D%22%0A%20%20%20%20%20%20exit%201%0A%20%20%20%20fi%0A%0A%20%20%20%20if%20nmcli%20connection%20show%20uuid%20%22%24vlan_parent%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20%20%20%23%20if%20the%20VLAN%20connection%20is%20configured%20with%20a%20connection%20UUID%20as%20parent%2C%20we%20need%20to%20find%20the%20underlying%20device%0A%20%20%20%20%20%20%23%20and%20create%20the%20bridge%20against%20it%2C%20as%20the%20parent%20connection%20can%20be%20replaced%20by%20another%20bridge.%0A%20%20%20%20%20%20vlan_parent%3D%24(nmcli%20--get-values%20GENERAL.DEVICES%20conn%20show%20uuid%20%24%7Bvlan_parent%7D)%0A%20%20%20%20fi%0A%0A%20%20%20%20extra_phys_args%3D(%20dev%20%22%24%7Bvlan_parent%7D%22%20id%20%22%24%7Bvlan_id%7D%22%20)%0A%20%20elif%20%5B%20%22%24(nmcli%20--get-values%20connection.type%20conn%20show%20%24%7Bold_conn%7D)%22%20%3D%3D%20%22bond%22%20%5D%3B%20then%0A%20%20%20%20iface_type%3Dbond%0A%20%20%20%20%23%20check%20bond%20options%0A%20%20%20%20bond_opts%3D%24(nmcli%20--get-values%20bond.options%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20if%20%5B%20-n%20%22%24bond_opts%22%20%5D%3B%20then%0A%20%20%20%20%20%20extra_phys_args%2B%3D(%20bond.options%20%22%24%7Bbond_opts%7D%22%20)%0A%20%20%20%20%20%20MODE_REGEX%3D%22(%5E%7C%2C)mode%3Dactive-backup(%2C%7C%24)%22%0A%20%20%20%20%20%20MAC_REGEX%3D%22(%5E%7C%2C)fail_over_mac%3D(1%7Cactive%7C2%7Cfollow)(%2C%7C%24)%22%0A%20%20%20%20%20%20if%20%5B%5B%20%24bond_opts%20%3D~%20%24MODE_REGEX%20%5D%5D%20%26%26%20%5B%5B%20%24bond_opts%20%3D~%20%24MAC_REGEX%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20clone_mac%3D0%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%20%20elif%20%5B%20%22%24(nmcli%20--get-values%20connection.type%20conn%20show%20%24%7Bold_conn%7D)%22%20%3D%3D%20%22team%22%20%5D%3B%20then%0A%20%20%20%20iface_type%3Dteam%0A%20%20%20%20%23%20check%20team%20config%20options%0A%20%20%20%20team_config_opts%3D%24(nmcli%20--get-values%20team.config%20-e%20no%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20if%20%5B%20-n%20%22%24team_config_opts%22%20%5D%3B%20then%0A%20%20%20%20%20%20%23%20team.config%20is%20json%2C%20remove%20spaces%20to%20avoid%20problems%20later%20on%0A%20%20%20%20%20%20extra_phys_args%2B%3D(%20team.config%20%22%24%7Bteam_config_opts%2F%2F%5B%5B%3Aspace%3A%5D%5D%2F%7D%22%20)%0A%20%20%20%20%20%20team_mode%3D%24(echo%20%22%24%7Bteam_config_opts%7D%22%20%7C%20jq%20-r%20%22.runner.name%20%2F%2F%20empty%22)%0A%20%20%20%20%20%20team_mac_policy%3D%24(echo%20%22%24%7Bteam_config_opts%7D%22%20%7C%20jq%20-r%20%22.runner.hwaddr_policy%20%2F%2F%20empty%22)%0A%20%20%20%20%20%20MAC_REGEX%3D%22(by_active%7Conly_active)%22%0A%20%20%20%20%20%20if%20%5B%20%22%24team_mode%22%20%3D%20%22activebackup%22%20%5D%20%26%26%20%5B%5B%20%22%24team_mac_policy%22%20%3D~%20%24MAC_REGEX%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20clone_mac%3D0%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%20%20elif%20%5B%20%22%24(nmcli%20--get-values%20connection.type%20conn%20show%20%24%7Bold_conn%7D)%22%20%3D%3D%20%22tun%22%20%5D%3B%20then%0A%20%20%20%20iface_type%3Dtun%0A%20%20%20%20tun_mode%3D%24(nmcli%20--get-values%20tun.mode%20-e%20no%20connection%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20extra_phys_args%2B%3D(%20tun.mode%20%22%24%7Btun_mode%7D%22%20)%0A%20%20elif%20%5B%20%22%24(nmcli%20--get-values%20connection.type%20conn%20show%20%24%7Bold_conn%7D)%22%20%3D%3D%20%22bridge%22%20%5D%3B%20then%0A%20%20%20%20iface_type%3Dbridge%0A%20%20else%0A%20%20%20%20iface_type%3D802-3-ethernet%0A%20%20fi%0A%0A%20%20if%20%5B%20!%20%22%24%7Bclone_mac%3A-%7D%22%20%3D%20%220%22%20%5D%3B%20then%0A%20%20%20%20%23%20In%20active-backup%20link%20aggregation%2C%20with%20fail_over_mac%20mode%20enabled%2C%0A%20%20%20%20%23%20cloning%20the%20mac%20address%20is%20not%20supported.%20It%20is%20possible%20then%20that%0A%20%20%20%20%23%20br-ex%20has%20a%20different%20mac%20address%20than%20the%20bond%20which%20might%20be%0A%20%20%20%20%23%20troublesome%20on%20some%20platforms%20where%20the%20nic%20won't%20accept%20packets%20with%0A%20%20%20%20%23%20a%20different%20destination%20mac.%20But%20nobody%20has%20complained%20so%20far%20so%20go%20on%0A%20%20%20%20%23%20with%20what%20we%20got.%20%0A%20%20%20%20%0A%20%20%20%20%23%20Do%20set%20it%20though%20for%20other%20link%20aggregation%20configurations%20where%20the%0A%20%20%20%20%23%20mac%20address%20would%20otherwise%20depend%20on%20enslave%20order%20for%20which%20we%20have%0A%20%20%20%20%23%20no%20control%20going%20forward.%0A%20%20%20%20extra_phys_args%2B%3D(%20802-3-ethernet.cloned-mac-address%20%22%24%7Biface_mac%7D%22%20)%0A%20%20fi%0A%0A%20%20%23%20use%20%24%7Bextra_phys_args%5B%40%5D%2B%22%24%7Bextra_phys_args%5B%40%5D%7D%22%7D%20instead%20of%20%24%7Bextra_phys_args%5B%40%5D%7D%20to%20be%20compatible%20with%20bash%204.2%20in%20RHEL7.9%0A%20%20if%20!%20nmcli%20connection%20show%20%22%24bridge_interface_name%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20destroy%20interface%20%24%7Biface%7D%0A%20%20%20%20ovs_default_port_conn%3D%24(nmcli%20-g%20connection.uuid%20conn%20show%20%22%24default_port_name%22)%0A%20%20%20%20add_nm_conn%20%22%24bridge_interface_name%22%20type%20%24%7Biface_type%7D%20conn.interface%20%24%7Biface%7D%20master%20%22%24ovs_default_port_conn%22%20%5C%0A%20%20%20%20%20%20slave-type%20ovs-port%20connection.autoconnect-priority%20100%20connection.autoconnect-slaves%201%20802-3-ethernet.mtu%20%24%7Biface_mtu%7D%20%5C%0A%20%20%20%20%20%20%24%7Bextra_phys_args%5B%40%5D%2B%22%24%7Bextra_phys_args%5B%40%5D%7D%22%7D%0A%20%20fi%0A%0A%20%20%23%20Get%20the%20new%20connection%20uuids%0A%20%20new_conn%3D%24(nmcli%20-g%20connection.uuid%20conn%20show%20%22%24bridge_interface_name%22)%0A%20%20ovs_port_conn%3D%24(nmcli%20-g%20connection.uuid%20conn%20show%20%22%24ovs_port%22)%0A%0A%20%20%23%20Update%20connections%20with%20master%20property%20set%20to%20use%20the%20new%20connection%0A%20%20replace_connection_master%20%24old_conn%20%24new_conn%0A%20%20replace_connection_master%20%24iface%20%24new_conn%0A%0A%20%20ipv4_method%3D%24(nmcli%20-g%20ipv4.method%20conn%20show%20%22%24old_conn%22)%0A%20%20ipv6_method%3D%24(nmcli%20-g%20ipv6.method%20conn%20show%20%22%24old_conn%22)%0A%0A%20%20ipv4_addresses%3D%24(nmcli%20-g%20ipv4.addresses%20conn%20show%20%22%24old_conn%22)%0A%20%20ipv6_addresses%3D%24(nmcli%20-g%20ipv6.addresses%20conn%20show%20%22%24old_conn%22)%0A%0A%20%20%23%20Warn%20about%20an%20invalid%20MTU%20that%20will%20most%20likely%20fail%20in%20one%20way%20or%0A%20%20%23%20another%0A%20%20if%20%5B%20%24%7Biface_mtu%7D%20-lt%201280%20%5D%20%26%26%20%5B%20%22%24%7Bipv6_method%7D%22%20!%3D%20%22disabled%22%20%5D%3B%20then%0A%20%20%20%20echo%20%22WARNING%3A%20MTU%20%24%7Biface_mtu%7D%20is%20lower%20than%20the%20minimum%20required%20of%201280%20for%20IPv6%22%0A%20%20fi%0A%0A%20%20if%20!%20nmcli%20connection%20show%20%22%24ovs_interface%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20destroy%20interface%20%22%24bridge_name%22%0A%20%20%20%20%23%20Clone%20the%20connection%20in%20case%20the%20method%20is%20manual%20or%20in%20case%20the%20an%20address%20is%20set%20(DHCP%20%2B%20static%20IP)%0A%20%20%20%20if%20%5B%20%22%24%7Bipv4_method%7D%22%20%3D%20%22manual%22%20%5D%20%7C%7C%20%5B%20%22%24%7Bipv4_addresses%7D%22%20!%3D%20%22%22%20%5D%20%7C%7C%20%5B%20%22%24%7Bipv6_method%7D%22%20%3D%20%22manual%22%20%5D%20%7C%7C%20%5B%20%22%24%7Bipv6_addresses%7D%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22Static%20IP%20addressing%20detected%20on%20default%20gateway%20connection%3A%20%24%7Bold_conn%7D%22%0A%20%20%20%20%20%20%23%20clone%20the%20old%20connection%20to%20get%20the%20address%20settings%0A%20%20%20%20%20%20%23%20prefer%20cloning%20vs%20copying%20the%20connection%20file%20to%20avoid%20problems%20with%20selinux%0A%20%20%20%20%20%20clone_nm_conn%20%22%24%7Bold_conn%7D%22%20%22%24%7Bovs_interface%7D%22%0A%20%20%20%20%20%20shopt%20-s%20nullglob%0A%20%20%20%20%20%20new_conn_files%3D(%24%7BNM_CONN_RUN_PATH%7D%2F%22%24%7Bovs_interface%7D%22*)%0A%20%20%20%20%20%20shopt%20-u%20nullglob%0A%20%20%20%20%20%20if%20%5B%20%24%7B%23new_conn_files%5B%40%5D%7D%20-ne%201%20%5D%20%7C%7C%20%5B%20!%20-f%20%22%24%7Bnew_conn_files%5B0%5D%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22ERROR%3A%20could%20not%20find%20%24%7Bovs_interface%7D%20conn%20file%20after%20cloning%20from%20%24%7Bold_conn%7D%22%0A%20%20%20%20%20%20%20%20exit%201%0A%20%20%20%20%20%20fi%0A%20%20%20%20%20%20new_conn_file%3D%22%24%7Bnew_conn_files%5B0%5D%7D%22%0A%0A%20%20%20%20%20%20%23%20modify%20the%20connection%20type%20directly%20because%20it%20can't%20be%20modified%0A%20%20%20%20%20%20%23%20through%20nmcli%0A%20%20%20%20%20%20sed%20-i%20'%2F%5E%5C%5Bconnection%5C%5D%24%2F%2C%2F%5E%5C%5B%2F%20s%2F%5Etype%3D.*%24%2Ftype%3Dovs-interface%2F'%20%24%7Bnew_conn_file%7D%0A%0A%20%20%20%20%20%20%23%20modify%20some%20more%20settings%20through%20nmcli%0A%20%20%20%20%20%20mod_nm_conn%20%22%24%7Bovs_interface%7D%22%20conn.interface%20%22%24bridge_name%22%20%5C%0A%20%20%20%20%20%20%20%20connection.multi-connect%20%22%22%20connection.autoconnect%20no%20%5C%0A%20%20%20%20%20%20%20%20connection.master%20%22%24ovs_port_conn%22%20connection.slave-type%20ovs-port%20%5C%0A%20%20%20%20%20%20%20%20ovs-interface.type%20internal%20%5C%0A%20%20%20%20%20%20%20%20802-3-ethernet.mtu%20%24%7Biface_mtu%7D%20802-3-ethernet.cloned-mac-address%20%24%7Biface_mac%7D%20%5C%0A%20%20%20%20%20%20%20%20ipv4.route-metric%20%22%24%7Bbridge_metric%7D%22%20ipv6.route-metric%20%22%24%7Bbridge_metric%7D%22%0A%0A%20%20%20%20%20%20echo%20%22Loaded%20new%20%24ovs_interface%20connection%20file%3A%20%24%7Bnew_conn_file%7D%22%0A%20%20%20%20else%0A%20%20%20%20%20%20extra_if_brex_args%3D%22%22%0A%20%20%20%20%20%20%23%20check%20if%20interface%20had%20ipv4%2Fipv6%20addresses%20assigned%0A%20%20%20%20%20%20num_ipv4_addrs%3D%24(ip%20-j%20a%20show%20dev%20%24%7Biface%7D%20%7C%20jq%20%22.%5B0%5D.addr_info%20%7C%20map(.%20%7C%20select(.family%20%3D%3D%20%5C%22inet%5C%22))%20%7C%20length%22)%0A%20%20%20%20%20%20if%20%5B%20%22%24num_ipv4_addrs%22%20-gt%200%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20extra_if_brex_args%2B%3D%22ipv4.may-fail%20no%20%22%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20%23%20IPV6%20should%20have%20at%20least%20a%20link%20local%20address.%20Check%20for%20more%20than%201%20to%20see%20if%20there%20is%20an%0A%20%20%20%20%20%20%23%20assigned%20address.%0A%20%20%20%20%20%20num_ip6_addrs%3D%24(ip%20-j%20a%20show%20dev%20%24%7Biface%7D%20%7C%20jq%20%22.%5B0%5D.addr_info%20%7C%20map(.%20%7C%20select(.family%20%3D%3D%20%5C%22inet6%5C%22%20and%20.scope%20!%3D%20%5C%22link%5C%22))%20%7C%20length%22)%0A%20%20%20%20%20%20if%20%5B%20%22%24num_ip6_addrs%22%20-gt%200%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20extra_if_brex_args%2B%3D%22ipv6.may-fail%20no%20%22%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20%23%20check%20for%20dhcp%20client%20ids%0A%20%20%20%20%20%20dhcp_client_id%3D%24(nmcli%20--get-values%20ipv4.dhcp-client-id%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20%20%20if%20%5B%20-n%20%22%24dhcp_client_id%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20extra_if_brex_args%2B%3D%22ipv4.dhcp-client-id%20%24%7Bdhcp_client_id%7D%20%22%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20dhcp6_client_id%3D%24(nmcli%20--get-values%20ipv6.dhcp-duid%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20%20%20if%20%5B%20-n%20%22%24dhcp6_client_id%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20extra_if_brex_args%2B%3D%22ipv6.dhcp-duid%20%24%7Bdhcp6_client_id%7D%20%22%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20ipv6_addr_gen_mode%3D%24(nmcli%20--get-values%20ipv6.addr-gen-mode%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20%20%20if%20%5B%20-n%20%22%24ipv6_addr_gen_mode%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20extra_if_brex_args%2B%3D%22ipv6.addr-gen-mode%20%24%7Bipv6_addr_gen_mode%7D%20%22%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20add_nm_conn%20%22%24ovs_interface%22%20type%20ovs-interface%20slave-type%20ovs-port%20conn.interface%20%22%24bridge_name%22%20master%20%22%24ovs_port_conn%22%20%5C%0A%20%20%20%20%20%20%20%20802-3-ethernet.mtu%20%24%7Biface_mtu%7D%20802-3-ethernet.cloned-mac-address%20%24%7Biface_mac%7D%20%5C%0A%20%20%20%20%20%20%20%20ipv4.method%20%22%24%7Bipv4_method%7D%22%20ipv4.route-metric%20%22%24%7Bbridge_metric%7D%22%20%5C%0A%20%20%20%20%20%20%20%20ipv6.method%20%22%24%7Bipv6_method%7D%22%20ipv6.route-metric%20%22%24%7Bbridge_metric%7D%22%20%5C%0A%20%20%20%20%20%20%20%20%24%7Bextra_if_brex_args%7D%0A%20%20%20%20fi%0A%20%20fi%0A%0A%20%20configure_driver_options%20%22%24%7Biface%7D%22%0A%7D%0A%0A%23%20Used%20to%20remove%20a%20bridge%0Aremove_ovn_bridges()%20%7B%0A%20%20bridge_name%3D%24%7B1%7D%0A%20%20port_name%3D%24%7B2%7D%0A%0A%20%20%23%20Remove%20the%20keyfiles%20from%20known%20configuration%20paths%0A%20%20update_nm_conn_run_files%20%24%7Bbridge_name%7D%20%24%7Bport_name%7D%0A%20%20rm_nm_conn_files%0A%20%20update_nm_conn_set_files%20%24%7Bbridge_name%7D%20%24%7Bport_name%7D%0A%20%20rm_nm_conn_files%0A%20%20%23%20Shouldn't%20be%20necessary%2C%20workaround%20for%20https%3A%2F%2Fissues.redhat.com%2Fbrowse%2FOCPBUGS-41489%0A%20%20update_nm_conn_etc_files%20%24%7Bbridge_name%7D%20%24%7Bport_name%7D%0A%20%20rm_nm_conn_files%0A%0A%20%20%23%20NetworkManager%20will%20not%20remove%20%24%7Bbridge_name%7D%20if%20it%20has%20the%20patch%20port%20created%20by%20ovn-kubernetes%0A%20%20%23%20so%20remove%20explicitly%0A%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-br%20%24%7Bbridge_name%7D%0A%7D%0A%0A%23%20Removes%20any%20previous%20ovs%20configuration%0Aremove_all_ovn_bridges()%20%7B%0A%20%20echo%20%22Reverting%20any%20previous%20OVS%20configuration%22%0A%20%20%0A%20%20remove_ovn_bridges%20br-ex%20phys0%0A%20%20remove_ovn_bridges%20br-ex1%20phys1%0A%20%20%0A%20%20echo%20%22OVS%20configuration%20successfully%20reverted%22%0A%7D%0A%0A%23%20Reloads%20NM%20NetworkManager%20profiles%20if%20any%20configuration%20change%20was%20done.%0A%23%20Accepts%20a%20list%20of%20devices%20that%20should%20be%20re-connect%20after%20reload.%0Areload_profiles_nm()%20%7B%0A%20%20if%20%5B%20%24%7Bnm_config_changed%3A-0%7D%20-eq%200%20%5D%3B%20then%0A%20%20%20%20%23%20no%20config%20was%20changed%2C%20no%20need%20to%20reload%0A%20%20%20%20return%0A%20%20fi%0A%0A%20%20%23%20reload%20profiles%0A%20%20nmcli%20connection%20reload%0A%0A%20%20%23%20precautionary%20sleep%20of%2010s%20(default%20timeout%20of%20NM%20to%20bring%20down%20devices)%0A%20%20sleep%2010%0A%0A%20%20%23%20After%20reload%2C%20devices%20that%20were%20already%20connected%20should%20connect%20again%0A%20%20%23%20if%20any%20profile%20is%20available.%20If%20no%20profile%20is%20available%2C%20a%20device%20can%0A%20%20%23%20remain%20disconnected%20and%20we%20have%20to%20explicitly%20connect%20it%20so%20that%20a%0A%20%20%23%20profile%20is%20generated.%20This%20can%20happen%20for%20physical%20devices%20but%20should%0A%20%20%23%20not%20happen%20for%20software%20devices%20as%20those%20always%20require%20a%20profile.%0A%20%20for%20dev%20in%20%24%40%3B%20do%0A%20%20%20%20%23%20Only%20attempt%20to%20connect%20a%20disconnected%20device%0A%20%20%20%20local%20connected_state%3D%24(nmcli%20-g%20GENERAL.STATE%20device%20show%20%22%24dev%22%20%7C%7C%20echo%20%22%22)%0A%20%20%20%20if%20%5B%5B%20%22%24connected_state%22%20%3D~%20%22disconnected%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%23%20keep%20track%20if%20a%20profile%20by%20the%20same%20name%20as%20the%20device%20existed%20%0A%20%20%20%20%20%20%23%20before%20we%20attempt%20activation%0A%20%20%20%20%20%20local%20named_profile_existed%3D%24(%5B%20-f%20%22%24%7BNM_CONN_CONF_PATH%7D%2F%24%7Bdev%7D%22%20%5D%20%7C%7C%20%5B%20-f%20%22%24%7BNM_CONN_CONF_PATH%7D%2F%24%7Bdev%7D.nmconnection%22%20%5D%20%26%26%20echo%20%22yes%22)%0A%20%20%20%20%20%20%0A%20%20%20%20%20%20for%20i%20in%20%7B1..10%7D%3B%20do%0A%20%20%20%20%20%20%20%20%20%20echo%20%22Attempt%20%24i%20to%20connect%20device%20%24dev%22%0A%20%20%20%20%20%20%20%20%20%20nmcli%20device%20connect%20%22%24dev%22%20%26%26%20break%0A%20%20%20%20%20%20%20%20%20%20sleep%205%0A%20%20%20%20%20%20done%0A%0A%20%20%20%20%20%20%23%20if%20a%20profile%20did%20not%20exist%20before%20but%20does%20now%2C%20it%20was%20generated%0A%20%20%20%20%20%20%23%20but%20we%20want%20it%20to%20be%20ephemeral%2C%20so%20move%20it%20back%20to%20%2Frun%0A%20%20%20%20%20%20if%20%5B%20!%20%22%24named_profile_existed%22%20%3D%20%22yes%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20MANAGED_NM_CONN_FILES%3D(%22%24%7BNM_CONN_CONF_PATH%7D%2F%24%7Bdev%7D%22%20%22%24%7BNM_CONN_CONF_PATH%7D%2F%24%7Bdev%7D.nmconnection%22)%0A%20%20%20%20%20%20%20%20copy_nm_conn_files%20%22%24%7BNM_CONN_RUN_PATH%7D%22%0A%20%20%20%20%20%20%20%20rm_nm_conn_files%0A%20%20%20%20%20%20%20%20%23%20reload%20profiles%20so%20that%20NM%20notices%20that%20some%20might%20have%20been%20moved%0A%20%20%20%20%20%20%20%20nmcli%20connection%20reload%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20echo%20%22Waiting%20for%20interface%20%24dev%20to%20activate...%22%0A%20%20%20%20if%20!%20timeout%2060%20bash%20-c%20%22while%20!%20nmcli%20-g%20DEVICE%2CSTATE%20c%20%7C%20grep%20%22'%22'%22%24dev%22%3Aactivated'%22'%22%3B%20do%20sleep%205%3B%20done%22%3B%20then%0A%20%20%20%20%20%20echo%20%22WARNING%3A%20%24dev%20did%20not%20activate%22%0A%20%20%20%20fi%0A%20%20done%0A%0A%20%20nm_config_changed%3D0%0A%7D%0A%0A%23%20Removes%20all%20configuration%20and%20reloads%20NM%20if%20necessary%0Arollback_nm()%20%7B%0A%20%20phys0%3D%24(get_bridge_physical_interface%20ovs-if-phys0)%0A%20%20phys1%3D%24(get_bridge_physical_interface%20ovs-if-phys1)%0A%20%20%0A%20%20%23%20Revert%20changes%20made%20by%20%2Fusr%2Flocal%2Fbin%2Fconfigure-ovs.sh%20during%20SDN%20migration.%0A%20%20remove_all_ovn_bridges%0A%20%20%0A%20%20%23%20reload%20profiles%20so%20that%20NM%20notices%20that%20some%20were%20removed%0A%20%20reload_profiles_nm%20%22%24phys0%22%20%22%24phys1%22%0A%7D%0A%0A%23%20Add%20a%20temporary%20deactivated%20connection%20profile%20%0A%23%20First%20argument%20is%20the%20connection%20name%20folowed%20by%20arguments%20passed%20to%0A%23%20%60nmcli%20connection%20add%60%0Aadd_nm_conn()%20%7B%0A%20%20%23%20Use%20%60save%20no%60%20to%20add%20a%20temporary%20profile%0A%20%20nmcli%20c%20add%20save%20no%20con-name%20%22%24%40%22%20connection.autoconnect%20no%0A%7D%0A%0A%23%20Modify%20a%20temporary%20connection%20profile%20%0A%23%20First%20argument%20is%20the%20connection%20name%20followed%20by%20arguments%20passed%20to%0A%23%20%60nmcli%20connection%20modify%60%0Amod_nm_conn()%20%7B%0A%20%20%23%20the%20easiest%20thing%20to%20do%20here%20would%20be%20to%20use%20%60nmcli%20c%20mod%20--temporary%60%0A%20%20%23%20but%20there%20is%20a%20bug%20in%20selinux%20profiles%20that%20denies%20NM%20from%20performing%0A%20%20%23%20the%20operation%0A%20%20local%20dst_path%3D%24%7BNM_CONN_RUN_PATH%7D%2F%241.nmconnection%0A%20%20local%20src_path%0A%20%20src_path%3D%24(mktemp)%0A%20%20shift%0A%20%20cat%20%22%24dst_path%22%20%3E%20%22%24src_path%22%0A%20%20rm%20-f%20%22%24dst_path%22%0A%20%20nmcli%20--offline%20c%20mod%20%22%24%40%22%20%3C%20%22%24src_path%22%20%3E%20%22%24dst_path%22%0A%20%20rm%20-f%20%22%24src_path%22%0A%20%20chmod%20600%20%22%24dst_path%22%0A%20%20nmcli%20c%20load%20%22%24dst_path%22%0A%7D%0A%0A%23%20Clone%20to%20a%20temporary%20connection%20profile%20%0A%23%20First%20argument%20is%20the%20connection%20to%20clone%2C%20second%20argument%20is%20the%20clone%20name%0Aclone_nm_conn()%20%7B%0A%20%20%23%20clone%20as%20temporary%20so%20that%20it%20is%20generated%20in%20NM_CONN_RUN_PATH%0A%20%20nmcli%20connection%20clone%20--temporary%20%22%241%22%20%22%242%22%20%26%3E%20%2Fdev%2Fnull%0A%7D%0A%0A%23%20Activates%20an%20ordered%20set%20of%20NM%20connection%20profiles%0Aactivate_nm_connections()%20%7B%0A%20%20local%20connections%3D(%22%24%40%22)%0A%0A%20%20%23%20We%20want%20autoconnect%20set%20for%20our%20cloned%20slave%20profiles%20so%20that%20they%20are%0A%20%20%23%20used%20over%20the%20original%20profiles%20if%20implicitly%20re-activated%20with%20other%0A%20%20%23%20dependant%20profiles.%20Otherwise%20if%20a%20slave%20activates%20with%20an%20old%20profile%2C%0A%20%20%23%20the%20old%20master%20profile%20might%20activate%20as%20well%2C%20interfering%20and%20causing%0A%20%20%23%20further%20activations%20to%20fail.%0A%20%20%23%20Slave%20interfaces%20should%20already%20be%20active%20so%20setting%20autoconnect%20here%0A%20%20%23%20won't%20implicitly%20activate%20them%20but%20there%20is%20an%20edge%20case%20where%20a%20slave%0A%20%20%23%20might%20be%20inactive%20(link%20down%20for%20example)%20and%20in%20that%20case%20setting%0A%20%20%23%20autoconnect%20will%20cause%20an%20implicit%20activation.%20This%20is%20not%20necessarily%20a%0A%20%20%23%20problem%20and%20hopefully%20we%20can%20make%20sure%20everything%20is%20activated%20as%20we%0A%20%20%23%20want%20next.%0A%20%20for%20conn%20in%20%22%24%7Bconnections%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20local%20slave_type%3D%24(nmcli%20-g%20connection.slave-type%20connection%20show%20%22%24conn%22)%0A%20%20%20%20if%20%5B%20%22%24slave_type%22%20%3D%20%22team%22%20%5D%20%7C%7C%20%5B%20%22%24slave_type%22%20%3D%20%22bond%22%20%5D%3B%20then%0A%20%20%20%20%20%20mod_nm_conn%20%22%24conn%22%20connection.autoconnect%20yes%0A%20%20%20%20fi%0A%20%20done%0A%0A%20%20%23%20Activate%20all%20connections%20and%20fail%20if%20activation%20fails%0A%20%20%23%20For%20slave%20connections%20-%20for%20as%20long%20as%20at%20least%20one%20slave%20that%20belongs%20to%20a%20bond%2Fteam%0A%20%20%23%20comes%20up%2C%20we%20should%20not%20fail%0A%20%20declare%20-A%20master_interfaces%0A%20%20for%20conn%20in%20%22%24%7Bconnections%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20%23%20Get%20the%20slave%20type%0A%20%20%20%20local%20slave_type%3D%24(nmcli%20-g%20connection.slave-type%20connection%20show%20%22%24conn%22)%0A%20%20%20%20local%20is_slave%3Dfalse%0A%20%20%20%20if%20%5B%20%22%24slave_type%22%20%3D%20%22team%22%20%5D%20%7C%7C%20%5B%20%22%24slave_type%22%20%3D%20%22bond%22%20%5D%3B%20then%0A%20%20%20%20%20%20is_slave%3Dtrue%0A%20%20%20%20fi%20%0A%0A%20%20%20%20%23%20For%20slave%20interfaces%2C%20initialize%20the%20master%20interface%20to%20false%20if%20the%20key%20is%20not%20yet%20in%20the%20array%0A%20%20%20%20local%20master_interface%0A%20%20%20%20if%20%24is_slave%3B%20then%0A%20%20%20%20%20%20master_interface%3D%24(nmcli%20-g%20connection.master%20connection%20show%20%22%24conn%22)%0A%20%20%20%20%20%20if%20!%20%5B%5B%20-v%20%22master_interfaces%5B%24master_interface%5D%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20master_interfaces%5B%22%24master_interface%22%5D%3Dfalse%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20slaves%20should%20implicitly%20activate%2C%20give%20them%20a%20chance%20to%20do%20so%0A%20%20%20%20if%20%24is_slave%3B%20then%0A%20%20%20%20%20%20if%20!%20timeout%205%20bash%20-c%20%22while%20!%20nmcli%20-g%20GENERAL.STATE%20conn%20show%20%22%24conn%22%20%7C%20grep%20activated%3B%20do%20sleep%201%3B%20done%22%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22WARNING%3A%20slave%20%24conn%20did%20not%20implicitly%20activate%20in%205s%2C%20activating%20explicitly.%22%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Do%20not%20activate%20interfaces%20that%20are%20already%20active%0A%20%20%20%20%23%20But%20set%20the%20entry%20in%20master_interfaces%20to%20true%20if%20this%20is%20a%20slave%0A%20%20%20%20%23%20Also%20set%20autoconnect%20to%20yes%0A%20%20%20%20local%20active_state%3D%24(nmcli%20-g%20GENERAL.STATE%20conn%20show%20%22%24conn%22)%0A%20%20%20%20if%20%5B%20%22%24active_state%22%20%3D%3D%20%22activated%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22Connection%20%24conn%20already%20activated%22%0A%20%20%20%20%20%20if%20%24is_slave%3B%20then%0A%20%20%20%20%20%20%20%20master_interfaces%5B%24master_interface%5D%3Dtrue%0A%20%20%20%20%20%20fi%0A%20%20%20%20%20%20mod_nm_conn%20%22%24conn%22%20connection.autoconnect%20yes%0A%20%20%20%20%20%20continue%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Activate%20all%20interfaces%20that%20are%20not%20yet%20active%0A%20%20%20%20for%20i%20in%20%7B1..10%7D%3B%20do%0A%20%20%20%20%20%20echo%20%22Attempt%20%24i%20to%20bring%20up%20connection%20%24conn%22%0A%20%20%20%20%20%20nmcli%20conn%20up%20%22%24conn%22%20%26%26%20s%3D0%20%26%26%20break%20%7C%7C%20s%3D%24%3F%0A%20%20%20%20%20%20sleep%205%0A%20%20%20%20done%0A%20%20%20%20if%20%5B%20%24s%20-eq%200%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22Brought%20up%20connection%20%24conn%20successfully%22%0A%20%20%20%20%20%20if%20%24is_slave%3B%20then%0A%20%20%20%20%20%20%20%20master_interfaces%5B%22%24master_interface%22%5D%3Dtrue%0A%20%20%20%20%20%20fi%0A%20%20%20%20elif%20!%20%24is_slave%3B%20then%0A%20%20%20%20%20%20echo%20%22ERROR%3A%20Cannot%20bring%20up%20connection%20%24conn%20after%20%24i%20attempts%22%0A%20%20%20%20%20%20return%20%24s%0A%20%20%20%20fi%0A%20%20%20%20mod_nm_conn%20%22%24conn%22%20connection.autoconnect%20yes%0A%20%20done%0A%20%20%23%20Check%20that%20all%20master%20interfaces%20report%20at%20least%20a%20single%20active%20slave%0A%20%20%23%20Note%3A%20associative%20arrays%20require%20an%20exclamation%20mark%20when%20looping%0A%20%20for%20i%20in%20%22%24%7B!master_interfaces%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20if%20!%20%24%7Bmaster_interfaces%5B%22%24i%22%5D%7D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22ERROR%3A%20Cannot%20bring%20up%20any%20slave%20interface%20for%20master%20interface%3A%20%24i%22%0A%20%20%20%20%20%20%20%20return%201%0A%20%20%20%20fi%0A%20%20done%0A%7D%0A%0A%23%20Accepts%20parameters%20%24iface_default_hint_file%2C%20%24iface%0A%23%20Writes%20content%20of%20%24iface%20into%20%24iface_default_hint_file%0Awrite_iface_default_hint()%20%7B%0A%20%20local%20iface_default_hint_file%3D%22%241%22%0A%20%20local%20iface%3D%22%242%22%0A%0A%20%20echo%20%22%24%7Biface%7D%22%20%3E%7C%20%22%24%7Biface_default_hint_file%7D%22%0A%7D%0A%0A%23%20Accepts%20parameters%20%24iface_default_hint_file%0A%23%20Returns%20the%20stored%20interface%20default%20hint%20if%20the%20hint%20is%20non-empty%2C%0A%23%20not%20br-ex%2C%20not%20br-ex1%20and%20if%20the%20interface%20can%20be%20found%20in%20%2Fsys%2Fclass%2Fnet%0Aget_iface_default_hint()%20%7B%0A%20%20local%20iface_default_hint_file%3D%241%0A%20%20if%20%5B%20-f%20%22%24%7Biface_default_hint_file%7D%22%20%5D%3B%20then%0A%20%20%20%20local%20iface_default_hint%3D%24(cat%20%22%24%7Biface_default_hint_file%7D%22)%0A%20%20%20%20if%20%5B%20%22%24%7Biface_default_hint%7D%22%20!%3D%20%22%22%20%5D%20%26%26%0A%20%20%20%20%20%20%20%20%5B%20%22%24%7Biface_default_hint%7D%22%20!%3D%20%22br-ex%22%20%5D%20%26%26%0A%20%20%20%20%20%20%20%20%5B%20%22%24%7Biface_default_hint%7D%22%20!%3D%20%22br-ex1%22%20%5D%20%26%26%0A%20%20%20%20%20%20%20%20%5B%20-d%20%22%2Fsys%2Fclass%2Fnet%2F%24%7Biface_default_hint%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22%24%7Biface_default_hint%7D%22%0A%20%20%20%20%20%20%20%20return%0A%20%20%20%20fi%0A%20%20fi%0A%20%20echo%20%22%22%0A%7D%0A%0Aget_ip_from_ip_hint_file()%20%7B%0A%20%20local%20ip_hint_file%3D%22%241%22%0A%20%20if%20%5B%5B%20!%20-f%20%22%24%7Bip_hint_file%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20return%0A%20%20fi%0A%20%20ip_hint%3D%24(cat%20%22%24%7Bip_hint_file%7D%22)%0A%20%20echo%20%22%24%7Bip_hint%7D%22%0A%7D%0A%0A%23%20This%20function%20waits%20for%20ip%20address%20of%20br-ex%20to%20be%20bindable%20only%20in%20case%20of%20ipv6%0A%23%20This%20is%20workaround%20for%20OCPBUGS-673%20as%20it%20will%20not%20allow%20starting%20crio%0A%23%20before%20address%20is%20bindable%0Atry_to_bind_ipv6_address()%20%7B%0A%20%20%23%20Retry%20for%201%20minute%0A%20%20retries%3D60%0A%20%20until%20%5B%5B%20%24%7Bretries%7D%20-eq%200%20%5D%5D%3B%20do%0A%20%20%20%20ip%3D%24(ip%20-6%20-j%20addr%20%7C%20jq%20-r%20%22first(.%5B%5D%20%7C%20select(.ifname%3D%3D%5C%22br-ex%5C%22)%20%7C%20.addr_info%5B%5D%20%7C%20select(.scope%3D%3D%5C%22global%5C%22)%20%7C%20.local)%22)%0A%20%20%20%20if%20%5B%5B%20%22%24%7Bip%7D%22%20%3D%3D%20%22%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22No%20ipv6%20ip%20to%20bind%20was%20found%22%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20%20%20random_port%3D%24(shuf%20-i%2050000-60000%20-n%201)%0A%20%20%20%20echo%20%22Trying%20to%20bind%20%24%7Bip%7D%20on%20port%20%24%7Brandom_port%7D%22%0A%20%20%20%20exit_code%3D%24(timeout%202s%20nc%20-l%20%22%24%7Bip%7D%22%20%24%7Brandom_port%7D%3B%20echo%20%24%3F)%0A%20%20%20%20if%20%5B%5B%20exit_code%20-eq%20124%20%5D%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22Address%20bound%20successfully%22%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20%20%20sleep%201%0A%20%20%20%20((%20retries--%20))%0A%20%20done%0A%20%20if%20%5B%5B%20%24%7Bretries%7D%20-eq%200%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22Failed%20to%20bind%20ip%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%7D%0A%0A%23%20Get%20interface%20that%20matches%20ip%20from%20node%20ip%20hint%20file%0A%23%20in%20case%20file%20not%20exists%20return%20nothing%20and%0A%23%20fallback%20to%20default%20interface%20search%20flow%0Aget_nodeip_hint_interface()%20%7B%0A%20%20local%20ip_hint%3D%22%22%0A%20%20local%20ip_hint_file%3D%22%241%22%0A%20%20local%20extra_bridge%3D%22%242%22%0A%20%20local%20iface%3D%22%22%0A%0A%20%20ip_hint%3D%24(get_ip_from_ip_hint_file%20%22%24%7Bip_hint_file%7D%22)%0A%20%20if%20%5B%5B%20-z%20%22%24%7Bip_hint%7D%22%20%20%5D%5D%3B%20then%0A%20%20%20%20return%0A%20%20fi%0A%0A%20%20iface%3D%24(ip%20-j%20addr%20%7C%20jq%20-r%20%22first(.%5B%5D%20%7C%20select(any(.addr_info%5B%5D%3B%20.local%3D%3D%5C%22%24%7Bip_hint%7D%5C%22)%20and%20.ifname!%3D%5C%22br-ex1%5C%22%20and%20.ifname!%3D%5C%22%24%7Bextra_bridge%7D%5C%22))%20%7C%20.ifname%22)%0A%20%20if%20%5B%5B%20-n%20%22%24%7Biface%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22%24%7Biface%7D%22%0A%20%20fi%0A%7D%0A%0A%23%20Accepts%20parameters%20%24bridge_interface%20(e.g.%20ovs-port-phys0)%0A%23%20Returns%20the%20physical%20interface%20name%20if%20%24bridge_interface%20exists%2C%20%22%22%20otherwise%0Aget_bridge_physical_interface()%20%7B%0A%20%20local%20bridge_interface%3D%22%241%22%0A%20%20local%20physical_interface%3D%22%22%0A%20%20physical_interface%3D%24(nmcli%20-g%20connection.interface-name%20conn%20show%20%22%24%7Bbridge_interface%7D%22%202%3E%2Fdev%2Fnull%20%7C%7C%20echo%20%22%22)%0A%20%20echo%20%22%24%7Bphysical_interface%7D%22%0A%7D%0A%0A%23%20Accepts%20parameters%20%24iface_default_hint_file%2C%20%24extra_bridge_file%2C%20%24ip_hint_file%2C%20%24default_bridge_file%0A%23%20Determines%20the%20interface%20to%20be%20used%20for%20br-ex.%20Order%20of%20priority%20is%3A%0A%23%201.%20Use%20the%20user%20specified%20interface%20if%20provided%20in%20the%20default%20bridge%20file%0A%23%202.%20Use%20the%20node%20IP%20hint%20interface%0A%23%203.%20Use%20the%20previously%20selected%20interface%0A%23%204.%20Use%20the%20interface%20detected%20as%20default%20gateway%0A%23%0A%23%20Read%20%24default_bridge_file%20and%20return%20the%20contained%20interface.%20Otherwise%2C%0A%23%20read%20%24ip_hint_file%20and%20return%20the%20interface%20that%20matches%20this%20ip.%20Otherwise%2C%0A%23%20if%20the%20default%20interface%20is%20br-ex%2C%20use%20that%20and%20return.%0A%23%20If%20the%20default%20interface%20is%20not%20br-ex%3A%0A%23%20Check%20if%20there%20is%20a%20valid%20hint%20inside%20%24iface_default_hint_file.%20If%20so%2C%20use%20that%20hint.%0A%23%20If%20there%20is%20no%20valid%20hint%2C%20use%20the%20default%20interface%20that%20we%20found%20during%20the%20step%0A%23%20earlier.%0A%23%20Never%20use%20the%20interface%20that%20is%20provided%20inside%20%24extra_bridge_file%20for%20br-ex1.%0A%23%20Never%20use%20br-ex1.%0A%23%20Write%20the%20default%20interface%20to%20%24iface_default_hint_file%0Aget_default_bridge_interface()%20%7B%0A%20%20local%20iface%3D%22%22%0A%20%20local%20counter%3D0%0A%20%20local%20iface_default_hint_file%3D%22%241%22%0A%20%20local%20extra_bridge_file%3D%22%242%22%0A%20%20local%20ip_hint_file%3D%22%243%22%0A%20%20local%20default_bridge_file%3D%22%244%22%0A%20%20local%20extra_bridge%3D%22%22%0A%0A%20%20if%20%5B%20-f%20%22%24%7Bextra_bridge_file%7D%22%20%5D%3B%20then%0A%20%20%20%20extra_bridge%3D%24(cat%20%24%7Bextra_bridge_file%7D)%0A%20%20fi%0A%0A%20%20%23%20try%20to%20use%20user%20specified%20file%20first%0A%20%20if%20%5B%20-f%20%22%24default_bridge_file%22%20%5D%3B%20then%0A%20%20%20%20iface%3D%24(cat%20%22%24%7Bdefault_bridge_file%7D%22)%0A%20%20%20%20if%20%5B%20-z%20%22%24iface%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22ERROR%3A%20User%20specified%20bridge%20file%20detected%20without%20any%20data%22%0A%20%20%20%20%20%20exit%201%0A%20%20%20%20fi%0A%20%20%20%20echo%20%22%24%7Biface%7D%22%0A%20%20%20%20return%0A%20%20fi%0A%0A%20%20%23%20if%20node%20ip%20was%20set%2C%20we%20should%20search%20for%20interface%20that%20matches%20it%0A%20%20iface%3D%24(get_nodeip_hint_interface%20%22%24%7Bip_hint_file%7D%22%20%22%24%7Bextra_bridge%7D%22)%0A%20%20if%20%5B%5B%20-n%20%22%24%7Biface%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22%24%7Biface%7D%22%0A%20%20%20%20return%0A%20%20fi%0A%0A%20%20%23%20find%20default%20interface%0A%20%20%23%20the%20default%20interface%20might%20be%20br-ex%2C%20so%20check%20this%20before%20looking%20at%20the%20hint%0A%20%20while%20%5B%20%24%7Bcounter%7D%20-lt%2012%20%5D%3B%20do%0A%20%20%20%20%23%20check%20ipv4%0A%20%20%20%20%23%20never%20use%20the%20interface%20that's%20specified%20in%20extra_bridge_file%0A%20%20%20%20%23%20never%20use%20br-ex1%0A%20%20%20%20if%20%5B%20%22%24%7Bextra_bridge%7D%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20iface%3D%24(ip%20route%20show%20default%20%7C%20grep%20-v%20%22br-ex1%22%20%7C%20grep%20-v%20%22%24%7Bextra_bridge%7D%22%20%7C%20awk%20'%7B%20if%20(%244%20%3D%3D%20%22dev%22)%20%7B%20print%20%245%3B%20exit%20%7D%20%7D')%0A%20%20%20%20else%0A%20%20%20%20%20%20iface%3D%24(ip%20route%20show%20default%20%7C%20grep%20-v%20%22br-ex1%22%20%7C%20awk%20'%7B%20if%20(%244%20%3D%3D%20%22dev%22)%20%7B%20print%20%245%3B%20exit%20%7D%20%7D')%0A%20%20%20%20fi%0A%20%20%20%20if%20%5B%5B%20-n%20%22%24%7Biface%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20%20%20%23%20check%20ipv6%0A%20%20%20%20%23%20never%20use%20the%20interface%20that's%20specified%20in%20extra_bridge_file%0A%20%20%20%20%23%20never%20use%20br-ex1%0A%20%20%20%20if%20%5B%20%22%24%7Bextra_bridge%7D%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20iface%3D%24(ip%20-6%20route%20show%20default%20%7C%20grep%20-v%20%22br-ex1%22%20%7C%20grep%20-v%20%22%24%7Bextra_bridge%7D%22%20%7C%20awk%20'%7B%20if%20(%244%20%3D%3D%20%22dev%22)%20%7B%20print%20%245%3B%20exit%20%7D%20%7D')%0A%20%20%20%20else%0A%20%20%20%20%20%20iface%3D%24(ip%20-6%20route%20show%20default%20%7C%20grep%20-v%20%22br-ex1%22%20%7C%20awk%20'%7B%20if%20(%244%20%3D%3D%20%22dev%22)%20%7B%20print%20%245%3B%20exit%20%7D%20%7D')%0A%20%20%20%20fi%0A%20%20%20%20if%20%5B%5B%20-n%20%22%24%7Biface%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20%20%20counter%3D%24((counter%2B1))%0A%20%20%20%20sleep%205%0A%20%20done%0A%0A%20%20%23%20if%20the%20default%20interface%20does%20not%20point%20out%20of%20br-ex%20or%20br-ex1%0A%20%20if%20%5B%20%22%24%7Biface%7D%22%20!%3D%20%22br-ex%22%20%5D%20%26%26%20%5B%20%22%24%7Biface%7D%22%20!%3D%20%22br-ex1%22%20%5D%3B%20then%0A%20%20%20%20%23%20determine%20if%20an%20interface%20default%20hint%20exists%20from%20a%20previous%20run%0A%20%20%20%20%23%20and%20if%20the%20interface%20has%20a%20valid%20default%20route%0A%20%20%20%20iface_default_hint%3D%24(get_iface_default_hint%20%22%24%7Biface_default_hint_file%7D%22)%0A%20%20%20%20if%20%5B%20%22%24%7Biface_default_hint%7D%22%20!%3D%20%22%22%20%5D%20%26%26%0A%20%20%20%20%20%20%20%20%5B%20%22%24%7Biface_default_hint%7D%22%20!%3D%20%22%24%7Biface%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%23%20start%20wherever%20count%20left%20off%20in%20the%20previous%20loop%0A%20%20%20%20%20%20%23%20allow%20this%20for%20one%20more%20iteration%20than%20the%20previous%20loop%0A%20%20%20%20%20%20while%20%5B%20%24%7Bcounter%7D%20-le%2012%20%5D%3B%20do%0A%20%20%20%20%20%20%20%20%23%20check%20ipv4%0A%20%20%20%20%20%20%20%20if%20%5B%20%22%24(ip%20route%20show%20default%20dev%20%22%24%7Biface_default_hint%7D%22)%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20iface%3D%22%24%7Biface_default_hint%7D%22%0A%20%20%20%20%20%20%20%20%20%20break%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20%23%20check%20ipv6%0A%20%20%20%20%20%20%20%20if%20%5B%20%22%24(ip%20-6%20route%20show%20default%20dev%20%22%24%7Biface_default_hint%7D%22)%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20iface%3D%22%24%7Biface_default_hint%7D%22%0A%20%20%20%20%20%20%20%20%20%20break%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20counter%3D%24((counter%2B1))%0A%20%20%20%20%20%20%20%20sleep%205%0A%20%20%20%20%20%20done%0A%20%20%20%20fi%0A%20%20%20%20%23%20store%20what%20was%20determined%20was%20the%20(new)%20default%20interface%20inside%0A%20%20%20%20%23%20the%20default%20hint%20file%20for%20future%20reference%0A%20%20%20%20if%20%5B%20%22%24%7Biface%7D%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20write_iface_default_hint%20%22%24%7Biface_default_hint_file%7D%22%20%22%24%7Biface%7D%22%0A%20%20%20%20fi%0A%20%20fi%0A%20%20echo%20%22%24%7Biface%7D%22%0A%7D%0A%0A%23%20Used%20to%20print%20network%20state%0Aprint_state()%20%7B%0A%20%20echo%20%22Current%20device%2C%20connection%2C%20interface%20and%20routing%20state%3A%22%0A%20%20nmcli%20-g%20all%20device%20%7C%20grep%20-v%20unmanaged%0A%20%20nmcli%20-g%20all%20connection%0A%20%20ip%20-d%20address%20show%0A%20%20ip%20route%20show%0A%20%20ip%20-6%20route%20show%0A%7D%0A%0A%23%20Setup%20an%20exit%20trap%20to%20rollback%20on%20error%0Ahandle_exit()%20%7B%0A%20%20e%3D%24%3F%0A%20%20tdir%3D%24(mktemp%20-u%20-d%20-t%20%22configure-ovs-%24(date%20%2B%25Y-%25m-%25d-%25H-%25M-%25S)-XXXXXXXXXX%22)%0A%20%20%0A%20%20if%20%5B%20%24e%20-eq%200%20%5D%3B%20then%0A%20%20%20%20print_state%0A%20%20%20%20%23%20remove%20previous%20troubleshooting%20information%0A%20%20%20%20rm%20-rf%20%22%24(dirname%20%22%24tdir%22)%2Fconfigure-ovs-*%22%0A%20%20%20%20exit%200%0A%20%20fi%0A%0A%20%20echo%20%22ERROR%3A%20configure-ovs%20exited%20with%20error%3A%20%24e%22%0A%20%20print_state%0A%0A%20%20%23%20remove%20previous%20troubleshooting%20information%20except%20the%20oldest%20one%0A%20%20mapfile%20-t%20tdirs%20%3C%20%3C(compgen%20-G%20%22%24(dirname%20%22%24tdir%22)%2Fconfigure-ovs-*%22)%0A%20%20unset%20-v%20%22tdirs%5B0%5D%22%0A%20%20for%20dir%20in%20%22%24%7Btdirs%5B%40%5D%7D%22%3B%20do%20rm%20-rf%20%22%24dir%22%3B%20done%0A%0A%20%20%23%20copy%20configuration%20to%20tmp%20for%20troubleshooting%0A%20%20mkdir%20-p%20%22%24tdir%22%0A%20%20update_nm_conn_run_files%20br-ex%20phys0%0A%20%20copy_nm_conn_files%20%22%24tdir%22%0A%20%20update_nm_conn_run_files%20br-ex1%20phys1%0A%20%20copy_nm_conn_files%20%22%24tdir%22%0A%20%20echo%20%22Copied%20OVS%20configuration%20to%20%24tdir%20for%20troubleshooting%22%0A%0A%20%20%23%20attempt%20to%20restore%20the%20previous%20network%20state%0A%20%20echo%20%22Attempting%20to%20restore%20previous%20configuration...%22%0A%20%20rollback_nm%0A%20%20print_state%0A%0A%20%20exit%20%24e%0A%7D%0A%0A%23%20Setup%20a%20signal%20trap%20to%20rollback%0Ahandle_termination()%20%7B%0A%20%20echo%20%22WARNING%3A%20configure-ovs%20has%20been%20requested%20to%20terminate%2C%20quitting...%22%0A%20%20%0A%20%20%23%20by%20exiting%20with%20an%20error%20we%20will%20cleanup%20after%20ourselves%20in%20a%0A%20%20%23%20subsequent%20call%20to%20handle_exit%0A%20%20exit%201%0A%7D%0A%0A%23%20main%20function%0Aconfigure_ovs()%20%7B%0A%20%20set%20-eu%0A%0A%20%20%23%20setup%20traps%20to%20handle%20signals%20and%20other%20abnormal%20exits%0A%20%20trap%20'handle_termination'%20TERM%20INT%0A%20%20trap%20'handle_exit'%20EXIT%0A%0A%20%20%23%20this%20flag%20tracks%20if%20any%20config%20change%20was%20made%0A%20%20nm_config_changed%3D0%0A%0A%20%20%23%20Check%20that%20we%20are%20provided%20a%20valid%20NM%20connection%20path%0A%20%20if%20%5B%20%22%24NM_CONN_SET_PATH%22%20!%3D%20%22%24NM_CONN_CONF_PATH%22%20%5D%20%26%26%20%5B%20%22%24NM_CONN_SET_PATH%22%20!%3D%20%22%24NM_CONN_RUN_PATH%22%20%5D%3B%20then%0A%20%20%20%20echo%20%22Error%3A%20Incorrect%20NM%20connection%20path%3A%20%24NM_CONN_SET_PATH%20is%20not%20%24NM_CONN_CONF_PATH%20nor%20%24NM_CONN_RUN_PATH%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%0A%20%20%23%20Clean%20up%20old%20config%20on%20behalf%20of%20mtu-migration%0A%20%20if%20!%20systemctl%20-q%20is-enabled%20mtu-migration%3B%20then%0A%20%20%20%20echo%20%22Cleaning%20up%20left%20over%20mtu%20migration%20configuration%22%0A%20%20%20%20rm%20-rf%20%2Fetc%2Fcno%2Fmtu-migration%0A%20%20fi%0A%0A%20%20if%20!%20rpm%20-qa%20%7C%20grep%20-q%20openvswitch%3B%20then%0A%20%20%20%20echo%20%22WARNING%3A%20Openvswitch%20package%20is%20not%20installed!%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%0A%20%20%23%20print%20initial%20state%0A%20%20print_state%0A%0A%20%20if%20%5B%20%22%241%22%20%3D%3D%20%22OVNKubernetes%22%20%5D%3B%20then%0A%20%20%20%20%23%20Configures%20NICs%20onto%20OVS%20bridge%20%22br-ex%22%0A%20%20%20%20%23%20Configuration%20is%20either%20auto-detected%20or%20provided%20through%20a%20config%20file%20written%20already%20in%20Network%20Manager%0A%20%20%20%20%23%20key%20files%20under%20%2Fetc%2FNetworkManager%2Fsystem-connections%2F%0A%20%20%20%20%23%20Managing%20key%20files%20is%20outside%20of%20the%20scope%20of%20this%20script%0A%0A%20%20%20%20%23%20if%20the%20interface%20is%20of%20type%20vmxnet3%20add%20multicast%20capability%20for%20that%20driver%0A%20%20%20%20%23%20History%3A%20BZ%3A1854355%0A%20%20%20%20function%20configure_driver_options%20%7B%0A%20%20%20%20%20%20intf%3D%241%0A%20%20%20%20%20%20if%20%5B%20!%20-f%20%22%2Fsys%2Fclass%2Fnet%2F%24%7Bintf%7D%2Fdevice%2Fuevent%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22Device%20file%20doesn't%20exist%2C%20skipping%20setting%20multicast%20mode%22%0A%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20driver%3D%24(cat%20%22%2Fsys%2Fclass%2Fnet%2F%24%7Bintf%7D%2Fdevice%2Fuevent%22%20%7C%20grep%20DRIVER%20%7C%20awk%20-F%20%22%3D%22%20'%7Bprint%20%242%7D')%0A%20%20%20%20%20%20%20%20echo%20%22Driver%20name%20is%22%20%24driver%0A%20%20%20%20%20%20%20%20if%20%5B%20%22%24driver%22%20%3D%20%22vmxnet3%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20ip%20link%20set%20dev%20%22%24%7Bintf%7D%22%20allmulticast%20on%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20fi%0A%20%20%20%20%7D%0A%0A%20%20%20%20ovnk_config_dir%3D'%2Fetc%2Fovnk'%0A%20%20%20%20ovnk_var_dir%3D'%2Fvar%2Flib%2Fovnk'%0A%20%20%20%20extra_bridge_file%3D%22%24%7Bovnk_config_dir%7D%2Fextra_bridge%22%0A%20%20%20%20iface_default_hint_file%3D%22%24%7Bovnk_var_dir%7D%2Fiface_default_hint%22%0A%20%20%20%20ip_hint_file%3D%22%2Frun%2Fnodeip-configuration%2Fprimary-ip%22%0A%20%20%20%20%23%20explicitly%20specify%20which%20interface%20should%20be%20used%20with%20the%20default%20bridge%0A%20%20%20%20default_bridge_file%3D%22%24%7Bovnk_config_dir%7D%2Fdefault_bridge%22%0A%0A%20%20%20%20%23%20make%20sure%20to%20create%20ovnk_config_dir%20if%20it%20does%20not%20exist%2C%20yet%0A%20%20%20%20mkdir%20-p%20%22%24%7Bovnk_config_dir%7D%22%0A%20%20%20%20%23%20make%20sure%20to%20create%20ovnk_var_dir%20if%20it%20does%20not%20exist%2C%20yet%0A%20%20%20%20mkdir%20-p%20%22%24%7Bovnk_var_dir%7D%22%0A%0A%20%20%20%20%23%20For%20upgrade%20scenarios%2C%20make%20sure%20that%20we%20stabilize%20what%20we%20already%20configured%0A%20%20%20%20%23%20before.%20If%20we%20do%20not%20have%20a%20valid%20interface%20hint%2C%20find%20the%20physical%20interface%0A%20%20%20%20%23%20that's%20attached%20to%20ovs-if-phys0.%0A%20%20%20%20%23%20If%20we%20find%20such%20an%20interface%2C%20write%20it%20to%20the%20hint%20file.%0A%20%20%20%20iface_default_hint%3D%24(get_iface_default_hint%20%22%24%7Biface_default_hint_file%7D%22)%0A%20%20%20%20if%20%5B%20%22%24%7Biface_default_hint%7D%22%20%3D%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20current_interface%3D%24(get_bridge_physical_interface%20ovs-if-phys0)%0A%20%20%20%20%20%20if%20%5B%20%22%24%7Bcurrent_interface%7D%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20write_iface_default_hint%20%22%24%7Biface_default_hint_file%7D%22%20%22%24%7Bcurrent_interface%7D%22%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20delete%20iface_default_hint_file%20if%20it%20has%20the%20same%20content%20as%20extra_bridge_file%0A%20%20%20%20%23%20in%20that%20case%2C%20we%20must%20also%20force%20a%20reconfiguration%20of%20our%20network%20interfaces%0A%20%20%20%20%23%20to%20make%20sure%20that%20we%20reconcile%20this%20conflict%0A%20%20%20%20if%20%5B%20-f%20%22%24%7Biface_default_hint_file%7D%22%20%5D%20%26%26%0A%20%20%20%20%20%20%5B%20-f%20%22%24%7Bextra_bridge_file%7D%22%20%5D%20%26%26%0A%20%20%20%20%20%20%5B%20%22%24(cat%20%22%24%7Biface_default_hint_file%7D%22)%22%20%3D%3D%20%22%24(cat%20%22%24%7Bextra_bridge_file%7D%22)%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22%24%7Biface_default_hint_file%7D%20and%20%24%7Bextra_bridge_file%7D%20share%20the%20same%20content%22%0A%20%20%20%20%20%20echo%20%22Deleting%20file%20%24%7Biface_default_hint_file%7D%20to%20choose%20a%20different%20interface%22%0A%20%20%20%20%20%20rm%20-f%20%22%24%7Biface_default_hint_file%7D%22%0A%20%20%20%20%20%20rm%20-f%20%2Frun%2Fconfigure-ovs-boot-done%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20on%20every%20boot%20we%20rollback%20and%20generate%20the%20configuration%20again%2C%20to%20take%0A%20%20%20%20%23%20in%20any%20changes%20that%20have%20possibly%20been%20applied%20in%20the%20standard%0A%20%20%20%20%23%20configuration%20sources%0A%20%20%20%20if%20%5B%20!%20-f%20%2Frun%2Fconfigure-ovs-boot-done%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22Running%20on%20boot%2C%20restoring%20previous%20configuration%20before%20proceeding...%22%0A%20%20%20%20%20%20rollback_nm%0A%20%20%20%20%20%20print_state%0A%20%20%20%20fi%0A%20%20%20%20touch%20%2Frun%2Fconfigure-ovs-boot-done%0A%0A%20%20%20%20iface%3D%24(get_default_bridge_interface%20%22%24%7Biface_default_hint_file%7D%22%20%22%24%7Bextra_bridge_file%7D%22%20%22%24%7Bip_hint_file%7D%22%20%22%24%7Bdefault_bridge_file%7D%22)%0A%0A%20%20%20%20if%20%5B%20%22%24iface%22%20!%3D%20%22br-ex%22%20%5D%3B%20then%0A%20%20%20%20%20%20%23%20Specified%20interface%20is%20not%20br-ex.%0A%20%20%20%20%20%20%23%20Some%20deployments%20use%20a%20temporary%20solution%20where%20br-ex%20is%20moved%20out%20from%20the%20default%20gateway%20interface%0A%20%20%20%20%20%20%23%20and%20bound%20to%20a%20different%20nic%20(https%3A%2F%2Fgithub.com%2Ftrozet%2Fopenshift-ovn-migration).%0A%20%20%20%20%20%20%23%20This%20is%20now%20supported%20through%20an%20extra%20bridge%20if%20requested.%20If%20that%20is%20the%20case%2C%20we%20rollback.%0A%20%20%20%20%20%20%23%20We%20also%20rollback%20if%20it%20looks%20like%20we%20need%20to%20configure%20things%2C%20just%20in%20case%20there%20are%20any%20leftovers%0A%20%20%20%20%20%20%23%20from%20previous%20attempts.%0A%20%20%20%20%20%20if%20%5B%20-f%20%22%24extra_bridge_file%22%20%5D%20%7C%7C%20%5B%20-z%20%22%24(nmcli%20connection%20show%20--active%20br-ex%202%3E%20%2Fdev%2Fnull)%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22Bridge%20br-ex%20is%20not%20active%2C%20restoring%20previous%20configuration%20before%20proceeding...%22%0A%20%20%20%20%20%20%20%20rollback_nm%0A%20%20%20%20%20%20%20%20print_state%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20convert_to_bridge%20%22%24iface%22%20%22br-ex%22%20%22phys0%22%20%22%24%7BBRIDGE_METRIC%7D%22%0A%0A%20%20%20%20%23%20Check%20if%20we%20need%20to%20configure%20the%20second%20bridge%0A%20%20%20%20if%20%5B%20-f%20%22%24extra_bridge_file%22%20%5D%20%26%26%20(!%20nmcli%20connection%20show%20br-ex1%20%26%3E%20%2Fdev%2Fnull%20%7C%7C%20!%20nmcli%20connection%20show%20ovs-if-phys1%20%26%3E%20%2Fdev%2Fnull)%3B%20then%0A%20%20%20%20%20%20interface%3D%24(head%20-n%201%20%24extra_bridge_file)%0A%20%20%20%20%20%20convert_to_bridge%20%22%24interface%22%20%22br-ex1%22%20%22phys1%22%20%22%24%7BBRIDGE1_METRIC%7D%22%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Check%20if%20we%20need%20to%20remove%20the%20second%20bridge%0A%20%20%20%20if%20%5B%20!%20-f%20%22%24extra_bridge_file%22%20%5D%20%26%26%20(nmcli%20connection%20show%20br-ex1%20%26%3E%20%2Fdev%2Fnull%20%7C%7C%20nmcli%20connection%20show%20ovs-if-phys1%20%26%3E%20%2Fdev%2Fnull)%3B%20then%0A%20%20%20%20%20%20remove_ovn_bridges%20br-ex1%20phys1%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Remove%20bridges%20created%20by%20openshift-sdn%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-br%20br0%0A%0A%20%20%20%20%23%20Make%20sure%20everything%20is%20activated.%20Do%20it%20in%20a%20specific%20order%3A%0A%20%20%20%20%23%20-%20activate%20br-ex%20first%2C%20due%20to%20autoconnect-slaves%20this%20will%20also%0A%20%20%20%20%23%20%20%20activate%20ovs-port-br-ex%2C%20ovs-port-phys0%20and%20ovs-if-phys0.%20It%20is%0A%20%20%20%20%23%20%20%20important%20that%20ovs-if-phys0%20activates%20with%20br-ex%20to%20avoid%20the%0A%20%20%20%20%23%20%20%20ovs-if-phys0%20profile%20being%20overridden%20with%20a%20profile%20generated%20from%0A%20%20%20%20%23%20%20%20kargs.%20The%20activation%20of%20ovs-if-phys0%2C%20if%20a%20bond%2C%20might%20cause%20the%0A%20%20%20%20%23%20%20%20slaves%20to%20re-activate%2C%20but%20it%20should%20be%20with%20our%20profiles%20since%20they%0A%20%20%20%20%23%20%20%20have%20higher%20priority%0A%20%20%20%20%23%20-%20make%20sure%20that%20ovs-if-phys0%20and%20its%20slaves%2C%20if%20any%2C%20are%20activated.%0A%20%20%20%20%23%20-%20finally%20activate%20ovs-if-br-ex%20which%20holds%20the%20IP%20configuration.%0A%20%20%20%20connections%3D(br-ex%20ovs-if-phys0)%0A%20%20%20%20if%20%5B%20-f%20%22%24extra_bridge_file%22%20%5D%3B%20then%0A%20%20%20%20%20%20connections%2B%3D(br-ex1%20ovs-if-phys1)%0A%20%20%20%20fi%0A%20%20%20%20while%20IFS%3D%20read%20-r%20connection%3B%20do%0A%20%20%20%20%20%20if%20%5B%5B%20%24connection%20%3D%3D%20*%22%24MANAGED_NM_CONN_SUFFIX%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20connections%2B%3D(%22%24connection%22)%0A%20%20%20%20%20%20fi%0A%20%20%20%20done%20%3C%20%3C(nmcli%20-g%20NAME%20c)%0A%20%20%20%20connections%2B%3D(ovs-if-br-ex)%0A%20%20%20%20if%20%5B%20-f%20%22%24extra_bridge_file%22%20%5D%3B%20then%0A%20%20%20%20%20%20connections%2B%3D(ovs-if-br-ex1)%0A%20%20%20%20fi%0A%20%20%20%20activate_nm_connections%20%22%24%7Bconnections%5B%40%5D%7D%22%0A%20%20%20%20try_to_bind_ipv6_address%0A%20%20%20%20set_nm_conn_files%0A%20%20elif%20%5B%20%22%241%22%20%3D%3D%20%22OpenShiftSDN%22%20%5D%3B%20then%0A%20%20%20%20%23%20Revert%20changes%20made%20by%20%2Fusr%2Flocal%2Fbin%2Fconfigure-ovs.sh%20during%20SDN%20migration.%0A%20%20%20%20rollback_nm%0A%20%20%20%20%0A%20%20%20%20%23%20Remove%20bridges%20created%20by%20ovn-kubernetes%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-br%20br-int%20--%20--if-exists%20del-br%20br-local%0A%20%20fi%0A%7D%0A%0A%23%20Retry%20configure_ovs%20until%20it%20succeeds.%0A%23%20By%20default%2C%20retry%20every%2015%20minutes%20to%20give%20enough%20time%20to%20gather%0A%23%20troubleshooting%20information%20in%20between.%20Note%20that%20configure_ovs%20has%20other%0A%23%20internal%20retry%20mechanisms.%20This%20retry%20is%20intended%20to%20give%20some%0A%23%20self-healing%20capabilities%20to%20temporary%20but%20not%20necessarily%20short-lived%0A%23%20infrastructure%20problems.%0ARETRY%3D%22%24%7BRETRY-15m%7D%22%0Awhile%20true%3B%20do%0A%0A%20%20%23%20Disable%20retries%20if%20termination%20signal%20is%20received.%20Note%20that%20systemd%0A%20%20%23%20sends%20the%20signals%20to%20all%20processes%20in%20the%20group%20by%20default%20so%20we%20expect%0A%20%20%23%20configure_ovs%20to%20get%20its%20own%20signals.%0A%20%20trap%20'echo%20%22WARNING%3A%20termination%20requested%2C%20disabling%20retries%22%3B%20RETRY%3D%22%22'%20INT%20TERM%0A%20%20%0A%20%20%23%20Run%20configure_ovs%20in%20a%20sub-shell.%20%0A%20%20(%20configure_ovs%20%22%24%40%22%20)%0A%20%20e%3D%24%3F%0A%0A%20%20%23%20Handle%20signals%20while%20we%20sleep%0A%20%20trap%20'handle_termination'%20INT%20TERM%0A%20%20%0A%20%20%23%20Exit%20if%20succesful%20and%20not%20configured%20to%20retry%0A%20%20%5B%20%22%24e%22%20-eq%200%20%5D%20%7C%7C%20%5B%20-z%20%22%24RETRY%22%20%5D%20%26%26%20exit%20%22%24e%22%0A%20%20%0A%20%20echo%20%22configure-ovs%20failed%2C%20will%20retry%20after%20%24RETRY%22%0A%20%20%23%20flag%20that%20a%20retry%20has%20happened%0A%20%20touch%20%2Ftmp%2Fconfigure-ovs-retry%0A%20%20sleep%20%22%24RETRY%22%0A%0Adone%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/configure-ovs.sh
        - contents:
            source: data:,%23%20This%20file%20is%20generated%20by%20the%20Machine%20Config%20Operator's%20containerruntimeconfig%20controller.%0A%23%0A%23%20storage.conf%20is%20the%20configuration%20file%20for%20all%20tools%0A%23%20that%20share%20the%20containers%2Fstorage%20libraries%0A%23%20See%20man%205%20containers-storage.conf%20for%20more%20information%0A%23%20The%20%22container%20storage%22%20table%20contains%20all%20of%20the%20server%20options.%0A%5Bstorage%5D%0A%0A%23%20Default%20storage%20driver%2C%20must%20be%20set%20for%20proper%20operation.%0Adriver%20%3D%20%22overlay%22%0A%0A%23%20Temporary%20storage%20location%0Arunroot%20%3D%20%22%2Frun%2Fcontainers%2Fstorage%22%0A%0A%23%20Primary%20Read%2FWrite%20location%20of%20container%20storage%0Agraphroot%20%3D%20%22%2Fvar%2Flib%2Fcontainers%2Fstorage%22%0A%0A%5Bstorage.options%5D%0A%23%20Storage%20options%20to%20be%20passed%20to%20underlying%20storage%20drivers%0A%0A%23%20AdditionalImageStores%20is%20used%20to%20pass%20paths%20to%20additional%20Read%2FOnly%20image%20stores%0A%23%20Must%20be%20comma%20separated%20list.%0Aadditionalimagestores%20%3D%20%5B%0A%5D%0A%0A%23%20Remap-UIDs%2FGIDs%20is%20the%20mapping%20from%20UIDs%2FGIDs%20as%20they%20should%20appear%20inside%20of%0A%23%20a%20container%2C%20to%20UIDs%2FGIDs%20as%20they%20should%20appear%20outside%20of%20the%20container%2C%20and%0A%23%20the%20length%20of%20the%20range%20of%20UIDs%2FGIDs.%20%20Additional%20mapped%20sets%20can%20be%20listed%0A%23%20and%20will%20be%20heeded%20by%20libraries%2C%20but%20there%20are%20limits%20to%20the%20number%20of%0A%23%20mappings%20which%20the%20kernel%20will%20allow%20when%20you%20later%20attempt%20to%20run%20a%0A%23%20container.%0A%23%0A%23%20remap-uids%20%3D%200%3A1668442479%3A65536%0A%23%20remap-gids%20%3D%200%3A1668442479%3A65536%0A%0A%23%20Remap-User%2FGroup%20is%20a%20name%20which%20can%20be%20used%20to%20look%20up%20one%20or%20more%20UID%2FGID%0A%23%20ranges%20in%20the%20%2Fetc%2Fsubuid%20or%20%2Fetc%2Fsubgid%20file.%20%20Mappings%20are%20set%20up%20starting%0A%23%20with%20an%20in-container%20ID%20of%200%20and%20the%20a%20host-level%20ID%20taken%20from%20the%20lowest%0A%23%20range%20that%20matches%20the%20specified%20name%2C%20and%20using%20the%20length%20of%20that%20range.%0A%23%20Additional%20ranges%20are%20then%20assigned%2C%20using%20the%20ranges%20which%20specify%20the%0A%23%20lowest%20host-level%20IDs%20first%2C%20to%20the%20lowest%20not-yet-mapped%20container-level%20ID%2C%0A%23%20until%20all%20of%20the%20entries%20have%20been%20used%20for%20maps.%20This%20setting%20overrides%20the%0A%23%20Remap-UIDs%2FGIDs%20setting.%0A%23%0A%23%20remap-user%20%3D%20%22storage%22%0A%23%20remap-group%20%3D%20%22storage%22%0A%0A%5Bstorage.options.pull_options%5D%0A%23%20Options%20controlling%20how%20storage%20is%20populated%20when%20pulling%20images.%0A%0A%23%20Enable%20the%20%22zstd%3Achunked%22%20feature%2C%20which%20allows%20partial%20pulls%2C%20reusing%0A%23%20content%20that%20already%20exists%20on%20the%20system.%20This%20is%20disabled%20by%20default%2C%0A%23%20and%20must%20be%20explicitly%20enabled%20to%20be%20used.%20For%20more%20on%20zstd%3Achunked%2C%20see%0A%23%20https%3A%2F%2Fgithub.com%2Fcontainers%2Fstorage%2Fblob%2Fmain%2Fdocs%2Fcontainers-storage-zstd-chunked.md%0Aenable_partial_images%20%3D%20%22false%22%0A%0A%23%20Tells%20containers%2Fstorage%20to%20use%20hard%20links%20rather%20then%20create%20new%20files%20in%0A%23%20the%20image%2C%20if%20an%20identical%20file%20already%20existed%20in%20storage.%0Ause_hard_links%20%3D%20%22false%22%0A%0A%23%20Path%20to%20an%20ostree%20repository%20that%20might%20have%0A%23%20previously%20pulled%20content%20which%20can%20be%20used%20when%20attempting%20to%20avoid%0A%23%20pulling%20content%20from%20the%20container%20registry.%0Aostree_repos%20%3D%20%22%22%0A%0A%5Bstorage.options.overlay%5D%0A%23%20Storage%20Options%20for%20overlay%0A%0A%23%20Do%20not%20create%20a%20PRIVATE%20bind%20mount%20on%20the%20home%20directory.%0Askip_mount_home%20%3D%20%22true%22%0A%0A%23%20Size%20is%20used%20to%20set%20a%20maximum%20size%20of%20the%20container%20image.%20%20Only%20supported%20by%0A%23%20certain%20container%20storage%20drivers.%0Asize%20%3D%20%22%22%0A
          mode: 420
          overwrite: true
          path: /etc/containers/storage.conf
        - contents:
            source: data:,.%20%7B%0A%20%20%20%20errors%0A%20%20%20%20bufsize%20512%0A%20%20%20%20health%20%3A18080%0A%20%20%20%20forward%20.%20%7B%7B-%20range%20%24upstream%20%3A%3D%20.DNSUpstreams%7D%7D%20%7B%7B%24upstream%7D%7D%7B%7B-%20end%7D%7D%20%7B%0A%20%20%20%20%20%20%20%20policy%20sequential%0A%20%20%20%20%7D%0A%20%20%20%20cache%2030%0A%20%20%20%20reload%0A%20%20%20%20template%20IN%20%7B%7B%20.Cluster.IngressVIPRecordType%20%7D%7D%20comp-poc-rh01.rhpoc.int%20%7B%0A%20%20%20%20%20%20%20%20match%20.*%5B.%5Dapps.comp-poc-rh01.rhpoc.int%0A%20%20%20%20%20%20%20%20answer%20%22%7B%7B%22%7B%7B%20.Name%20%7D%7D%22%7D%7D%2060%20in%20%7B%7B%22%7B%7B%20.Type%20%7D%7D%22%7D%7D%2010.100.0.51%22%0A%20%20%20%20%20%20%20%20fallthrough%0A%20%20%20%20%7D%0A%20%20%20%20template%20IN%20%7B%7B%20.Cluster.IngressVIPEmptyType%20%7D%7D%20comp-poc-rh01.rhpoc.int%20%7B%0A%20%20%20%20%20%20%20%20match%20.*%5B.%5Dapps.comp-poc-rh01.rhpoc.int%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20fallthrough%0A%20%20%20%20%7D%0A%20%20%20%20template%20IN%20%7B%7B%20.Cluster.APIVIPRecordType%20%7D%7D%20comp-poc-rh01.rhpoc.int%20%7B%0A%20%20%20%20%20%20%20%20match%20%5Eapi.comp-poc-rh01.rhpoc.int%0A%20%20%20%20%20%20%20%20answer%20%22%7B%7B%22%7B%7B%20.Name%20%7D%7D%22%7D%7D%2060%20in%20%7B%7B%22%7B%7B%20.Type%20%7D%7D%22%7D%7D%2010.100.0.50%22%0A%20%20%20%20%20%20%20%20fallthrough%0A%20%20%20%20%7D%0A%20%20%20%20template%20IN%20%7B%7B%20.Cluster.APIVIPEmptyType%20%7D%7D%20comp-poc-rh01.rhpoc.int%20%7B%0A%20%20%20%20%20%20%20%20match%20%5Eapi.comp-poc-rh01.rhpoc.int%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20fallthrough%0A%20%20%20%20%7D%0A%20%20%20%20template%20IN%20%7B%7B%20.Cluster.APIVIPRecordType%20%7D%7D%20comp-poc-rh01.rhpoc.int%20%7B%0A%20%20%20%20%20%20%20%20match%20%5Eapi-int.comp-poc-rh01.rhpoc.int%0A%20%20%20%20%20%20%20%20answer%20%22%7B%7B%22%7B%7B%20.Name%20%7D%7D%22%7D%7D%2060%20in%20%7B%7B%22%7B%7B%20.Type%20%7D%7D%22%7D%7D%2010.100.0.50%22%0A%20%20%20%20%20%20%20%20fallthrough%0A%20%20%20%20%7D%0A%20%20%20%20template%20IN%20%7B%7B%20.Cluster.APIVIPEmptyType%20%7D%7D%20comp-poc-rh01.rhpoc.int%20%7B%0A%20%20%20%20%20%20%20%20match%20%5Eapi-int.comp-poc-rh01.rhpoc.int%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20fallthrough%0A%20%20%20%20%7D%0A%20%20%20%20hosts%20%7B%0A%20%20%20%20%20%20%20%20%7B%7B-%20range%20.Cluster.NodeAddresses%20%7D%7D%0A%20%20%20%20%20%20%20%20%7B%7B%20.Address%20%7D%7D%20%7B%7B%20.Name%20%7D%7D%20%7B%7B%20.Name%20%7D%7D.%7B%7B%20%24.Cluster.Name%20%7D%7D.%7B%7B%20%24.Cluster.Domain%20%7D%7D%0A%20%20%20%20%20%20%20%20%7B%7B-%20end%20%7D%7D%0A%20%20%20%20%20%20%20%20fallthrough%0A%20%20%20%20%7D%0A%7D%0A
          mode: 420
          overwrite: true
          path: /etc/kubernetes/static-pod-resources/coredns/Corefile.tmpl
        - contents:
            source: data:,kind%3A%20Pod%0AapiVersion%3A%20v1%0Ametadata%3A%0A%20%20name%3A%20coredns%0A%20%20namespace%3A%20openshift-kni-infra%0A%20%20creationTimestamp%3A%0A%20%20deletionGracePeriodSeconds%3A%2065%0A%20%20labels%3A%0A%20%20%20%20app%3A%20kni-infra-coredns%0A%20%20annotations%3A%0A%20%20%20%20target.workload.openshift.io%2Fmanagement%3A%20'%7B%22effect%22%3A%20%22PreferredDuringScheduling%22%7D'%0A%20%20%20%20openshift.io%2Frequired-scc%3A%20privileged%0Aspec%3A%0A%20%20volumes%3A%0A%20%20-%20name%3A%20resource-dir%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fetc%2Fkubernetes%2Fstatic-pod-resources%2Fcoredns%22%0A%20%20-%20name%3A%20kubeconfig%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20-%20name%3A%20conf-dir%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fetc%2Fcoredns%22%0A%20%20-%20name%3A%20nm-resolv%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fvar%2Frun%2FNetworkManager%22%0A%20%20-%20name%3A%20nodeip-configuration%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Frun%2Fnodeip-configuration%22%0A%20%20initContainers%3A%0A%20%20-%20name%3A%20render-config-coredns%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A93e7b8c870261726d44bddc7ba0a702d3720d1838141dac837fb8c3be7c6e1a1%0A%20%20%20%20command%3A%0A%20%20%20%20-%20runtimecfg%0A%20%20%20%20-%20render%0A%20%20%20%20-%20%22%2Fvar%2Flib%2Fkubelet%2Fkubeconfig%22%0A%20%20%20%20-%20%22--api-vips%22%0A%20%20%20%20-%20%2210.100.0.50%22%0A%20%20%20%20-%20%22--ingress-vips%22%0A%20%20%20%20-%20%2210.100.0.51%22%0A%20%20%20%20-%20%22%2Fconfig%22%0A%20%20%20%20-%20%22--out-dir%22%0A%20%20%20%20-%20%22%2Fetc%2Fcoredns%22%0A%20%20%20%20-%20%22--resolvconf-path%22%0A%20%20%20%20-%20%22%2Fvar%2Frun%2FNetworkManager%2Fresolv.conf%22%0A%20%20%20%20resources%3A%20%7B%7D%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20kubeconfig%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20resource-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fconfig%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20conf-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fcoredns%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20nm-resolv%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Frun%2FNetworkManager%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20nodeip-configuration%0A%20%20%20%20%20%20mountPath%3A%20%22%2Frun%2Fnodeip-configuration%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20imagePullPolicy%3A%20IfNotPresent%0A%20%20containers%3A%0A%20%20-%20name%3A%20coredns%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A4f6294ed30ab476019aaaa77874157facc77413988f82ffc46f94d3a98d2e4f1%0A%20%20%20%20args%3A%0A%20%20%20%20-%20%22--conf%22%0A%20%20%20%20-%20%22%2Fetc%2Fcoredns%2FCorefile%22%0A%20%20%20%20resources%3A%0A%20%20%20%20%20%20requests%3A%0A%20%20%20%20%20%20%20%20cpu%3A%20100m%0A%20%20%20%20%20%20%20%20memory%3A%20200Mi%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20conf-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fcoredns%22%0A%20%20%20%20-%20name%3A%20nodeip-configuration%0A%20%20%20%20%20%20mountPath%3A%20%22%2Frun%2Fnodeip-configuration%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20livenessProbe%3A%0A%20%20%20%20%20%20httpGet%3A%0A%20%20%20%20%20%20%20%20path%3A%20%2Fhealth%0A%20%20%20%20%20%20%20%20port%3A%2018080%0A%20%20%20%20%20%20%20%20scheme%3A%20HTTP%0A%20%20%20%20%20%20initialDelaySeconds%3A%2060%0A%20%20%20%20%20%20timeoutSeconds%3A%205%0A%20%20%20%20%20%20successThreshold%3A%201%0A%20%20%20%20%20%20failureThreshold%3A%205%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20imagePullPolicy%3A%20IfNotPresent%0A%20%20-%20name%3A%20coredns-monitor%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A93e7b8c870261726d44bddc7ba0a702d3720d1838141dac837fb8c3be7c6e1a1%0A%20%20%20%20command%3A%0A%20%20%20%20-%20corednsmonitor%0A%20%20%20%20-%20%22%2Fvar%2Flib%2Fkubelet%2Fkubeconfig%22%0A%20%20%20%20-%20%22%2Fconfig%2FCorefile.tmpl%22%0A%20%20%20%20-%20%22%2Fetc%2Fcoredns%2FCorefile%22%0A%20%20%20%20-%20%22--api-vips%22%0A%20%20%20%20-%20%2210.100.0.50%22%0A%20%20%20%20-%20%22--ingress-vips%22%0A%20%20%20%20-%20%2210.100.0.51%22%0A%20%20%20%20resources%3A%0A%20%20%20%20%20%20requests%3A%0A%20%20%20%20%20%20%20%20cpu%3A%20100m%0A%20%20%20%20%20%20%20%20memory%3A%20200Mi%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20kubeconfig%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20resource-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fconfig%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20conf-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fcoredns%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20nm-resolv%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Frun%2FNetworkManager%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20nodeip-configuration%0A%20%20%20%20%20%20mountPath%3A%20%22%2Frun%2Fnodeip-configuration%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20imagePullPolicy%3A%20IfNotPresent%0A%20%20hostNetwork%3A%20true%0A%20%20tolerations%3A%0A%20%20-%20operator%3A%20Exists%0A%20%20priorityClassName%3A%20system-node-critical%0Astatus%3A%20%7B%7D%0A
          mode: 420
          overwrite: true
          path: /etc/kubernetes/manifests/coredns.yaml
        - contents:
            source: data:,Initial%20Creation%0A
          mode: 384
          overwrite: true
          path: /etc/docker/certs.d/.create
        - contents:
            source: data:,%23%20Proxy%20environment%20variables%20will%20be%20populated%20in%20this%20file.%20Properly%0A%23%20url%20encoded%20passwords%20with%20special%20characters%20will%20use%20'%25%3CHEX%3E%3CHEX%3E'.%0A%23%20Systemd%20requires%20that%20any%20%25%20used%20in%20a%20password%20be%20represented%20as%0A%23%20%25%25%20in%20a%20unit%20file%20since%20%25%20is%20a%20prefix%20for%20macros%3B%20this%20restriction%20does%20not%0A%23%20apply%20for%20environment%20files.%20Templates%20that%20need%20the%20proxy%20set%20should%20use%0A%23%20'EnvironmentFile%3D%2Fetc%2Fmco%2Fproxy.env'.%0A
          mode: 420
          overwrite: true
          path: /etc/mco/proxy.env
        - contents:
            source: data:,%5BManager%5D%0ADefaultEnvironment%3DGODEBUG%3Dx509ignoreCN%3D0%0A
          mode: 420
          overwrite: true
          path: /etc/systemd/system.conf.d/10-default-env-godebug.conf
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%23%20Workaround%3A%0A%23%20https%3A%2F%2Fissues.redhat.com%2Fbrowse%2FOCPBUGS-38779%0A%0Adriver%3D%24(nmcli%20-t%20-m%20tabular%20-f%20general.driver%20dev%20show%20%22%24%7BDEVICE_IFACE%7D%22)%0A%0Aif%20%5B%5B%20%22%242%22%20%3D%3D%20%22up%22%20%26%26%20%22%24%7Bdriver%7D%22%20%3D%3D%20%22idpf%22%20%5D%5D%3B%20then%0A%20%20ethtool%20-K%20%24%7BDEVICE_IFACE%7D%20tx-checksumming%20off%0Afi
          mode: 484
          overwrite: true
          path: /etc/NetworkManager/dispatcher.d/99-gcp-disable-idpf-tx-checksum-off
        - contents:
            source: data:,global%0A%20%20stats%20socket%20%2Fvar%2Flib%2Fhaproxy%2Frun%2Fhaproxy.sock%20%20mode%20600%20level%20admin%20expose-fd%20listeners%0Adefaults%0A%20%20maxconn%2040000%0A%20%20mode%20%20%20%20tcp%0A%20%20log%20%20%20%20%20%2Fvar%2Frun%2Fhaproxy%2Fhaproxy-log.sock%20local0%20notice%20alert%0A%20%20log-format%20%22%25ci%3A%25cp%20-%3E%20%25fi%3A%25fp%20%5B%25t%5D%20%25ft%20%25b%2F%25s%20%25Tw%2F%25Tc%2F%25Tt%20%25B%20%25ts%20%25ac%2F%25fc%2F%25bc%2F%25sc%2F%25rc%20%25sq%2F%25bq%22%0A%20%20option%20%20dontlognull%0A%20%20retries%203%0A%20%20timeout%20http-request%2030s%0A%20%20timeout%20queue%20%20%20%20%20%20%20%201m%0A%20%20timeout%20connect%20%20%20%20%20%2010s%0A%20%20timeout%20client%20%20%20%20%20%20%2086400s%0A%20%20timeout%20server%20%20%20%20%20%20%2086400s%0A%20%20timeout%20tunnel%20%20%20%20%20%20%2086400s%0A%7B%7B-%20if%20gt%20(len%20.LBConfig.Backends)%200%20%7D%7D%0Afrontend%20%20main%0A%20%20bind%20%3A%3A%3A%7B%7B%20.LBConfig.LbPort%20%7D%7D%20v4v6%0A%20%20default_backend%20masters%0Alisten%20health_check_http_url%0A%20%20bind%20%3A%3A%3A9444%20v4v6%0A%20%20mode%20http%0A%20%20monitor-uri%20%2Fhaproxy_ready%0A%20%20option%20dontlognull%0A%7B%7B-%20end%20%7D%7D%0Alisten%20stats%0A%20%20bind%20localhost%3A%7B%7B%20.LBConfig.StatPort%20%7D%7D%0A%20%20mode%20http%0A%20%20stats%20enable%0A%20%20stats%20hide-version%0A%20%20stats%20uri%20%2Fhaproxy_stats%0A%20%20stats%20refresh%2030s%0A%20%20stats%20auth%20Username%3APassword%0Abackend%20masters%0A%20%20%20timeout%20check%2010s%0A%20%20%20option%20%20httpchk%20GET%20%2Freadyz%20HTTP%2F1.0%0A%20%20%20balance%20roundrobin%0A%7B%7B-%20range%20.LBConfig.Backends%20%7D%7D%0A%20%20%20server%20%7B%7B%20.Host%20%7D%7D%20%7B%7B%20.Address%20%7D%7D%3A%7B%7B%20.Port%20%7D%7D%20weight%201%20verify%20none%20check%20check-ssl%20inter%205s%20fall%203%20rise%201%0A%7B%7B-%20end%20%7D%7D%0A
          mode: 420
          overwrite: true
          path: /etc/kubernetes/static-pod-resources/haproxy/haproxy.cfg.tmpl
        - contents:
            source: data:,kind%3A%20Pod%0AapiVersion%3A%20v1%0Ametadata%3A%0A%20%20name%3A%20haproxy%0A%20%20namespace%3A%20openshift-kni-infra%0A%20%20creationTimestamp%3A%0A%20%20deletionGracePeriodSeconds%3A%2065%0A%20%20labels%3A%0A%20%20%20%20app%3A%20kni-infra-api-lb%0A%20%20annotations%3A%0A%20%20%20%20target.workload.openshift.io%2Fmanagement%3A%20'%7B%22effect%22%3A%20%22PreferredDuringScheduling%22%7D'%0A%20%20%20%20openshift.io%2Frequired-scc%3A%20privileged%0Aspec%3A%0A%20%20volumes%3A%0A%20%20-%20name%3A%20resource-dir%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fetc%2Fkubernetes%2Fstatic-pod-resources%2Fhaproxy%22%0A%20%20-%20name%3A%20kubeconfigvarlib%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20-%20name%3A%20run-dir%0A%20%20%20%20empty-dir%3A%20%7B%7D%0A%20%20-%20name%3A%20conf-dir%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fetc%2Fhaproxy%22%0A%20%20-%20name%3A%20chroot-host%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2F%22%0A%20%20initContainers%3A%0A%20%20-%20name%3A%20verify-api-int-resolvable%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A93e7b8c870261726d44bddc7ba0a702d3720d1838141dac837fb8c3be7c6e1a1%0A%20%20%20%20command%3A%0A%20%20%20%20-%20%22%2Fbin%2Fbash%22%0A%20%20%20%20-%20%22-c%22%0A%20%20%20%20-%20%7C%0A%20%20%20%20%20%20%2Fusr%2Fbin%2Fcurl%20-o%20%2Fdev%2Fnull%20-kLfs%20https%3A%2F%2Fapi-int.comp-poc-rh01.rhpoc.int%3A6443%2Fhealthz%0A%20%20%20%20resources%3A%20%7B%7D%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20chroot-host%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fhost%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20kubeconfigvarlib%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20imagePullPolicy%3A%20IfNotPresent%0A%20%20containers%3A%0A%20%20-%20name%3A%20haproxy%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3Ae1eb49c0c126c193cd035f844746edd98c6c674fdfa6b822d078d4a491b4834d%0A%20%20%20%20env%3A%0A%20%20%20%20%20%20-%20name%3A%20OLD_HAPROXY_PS_FORCE_DEL_TIMEOUT%0A%20%20%20%20%20%20%20%20value%3A%20%22120%22%0A%20%20%20%20command%3A%0A%20%20%20%20-%20%22%2Fbin%2Fbash%22%0A%20%20%20%20-%20%22-c%22%0A%20%20%20%20-%20%7C%0A%20%20%20%20%20%20%23%2Fbin%2Fbash%0A%20%20%20%20%20%20verify_old_haproxy_ps_being_deleted()%0A%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20local%20prev_pids%0A%0A%20%20%20%20%20%20%20%20prev_pids%3D%22%241%22%0A%20%20%20%20%20%20%20%20sleep%20%24OLD_HAPROXY_PS_FORCE_DEL_TIMEOUT%0A%20%20%20%20%20%20%20%20cur_pids%3D%24(pidof%20haproxy)%0A%0A%20%20%20%20%20%20%20%20for%20val%20in%20%24prev_pids%3B%20do%0A%20%20%20%20%20%20%20%20%20%20%20%20if%20%5B%5B%20%24cur_pids%20%3D~%20(%5E%7C%5B%5B%3Aspace%3A%5D%5D)%22%24val%22(%24%7C%5B%5B%3Aspace%3A%5D%5D)%20%5D%5D%20%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20kill%20%24val%0A%20%20%20%20%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20done%0A%20%20%20%20%20%20%7D%0A%0A%20%20%20%20%20%20reload_haproxy()%0A%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20old_pids%3D%24(pidof%20haproxy)%0A%20%20%20%20%20%20%20%20if%20%5B%20-n%20%22%24old_pids%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%2Fusr%2Fsbin%2Fhaproxy%20-W%20-db%20-f%20%2Fetc%2Fhaproxy%2Fhaproxy.cfg%20%20-p%20%2Fvar%2Flib%2Fhaproxy%2Frun%2Fhaproxy.pid%20-x%20%2Fvar%2Flib%2Fhaproxy%2Frun%2Fhaproxy.sock%20-sf%20%24old_pids%20%26%0A%20%20%20%20%20%20%20%20%20%20%20%20%23There%20seems%20to%20be%20some%20cases%20where%20HAProxy%20doesn't%20drain%20properly.%0A%20%20%20%20%20%20%20%20%20%20%20%20%23To%20handle%20that%20case%2C%20SIGTERM%20signal%20being%20sent%20to%20old%20HAProxy%20processes%20which%20haven't%20terminated.%0A%20%20%20%20%20%20%20%20%20%20%20%20verify_old_haproxy_ps_being_deleted%20%22%24old_pids%22%20%20%26%0A%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20%2Fusr%2Fsbin%2Fhaproxy%20-W%20-db%20-f%20%2Fetc%2Fhaproxy%2Fhaproxy.cfg%20%20-p%20%2Fvar%2Flib%2Fhaproxy%2Frun%2Fhaproxy.pid%20%26%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%7D%0A%0A%20%20%20%20%20%20msg_handler()%0A%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20while%20read%20-r%20line%3B%20do%0A%20%20%20%20%20%20%20%20%20%20echo%20%22The%20client%20send%3A%20%24line%22%20%20%3E%262%0A%20%20%20%20%20%20%20%20%20%20%23%20currently%20only%20'reload'%20msg%20is%20supported%0A%20%20%20%20%20%20%20%20%20%20if%20%5B%20%22%24line%22%20%3D%20reload%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20reload_haproxy%0A%20%20%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20done%0A%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20set%20-ex%0A%20%20%20%20%20%20declare%20-r%20haproxy_sock%3D%22%2Fvar%2Frun%2Fhaproxy%2Fhaproxy-master.sock%22%0A%20%20%20%20%20%20declare%20-r%20haproxy_log_sock%3D%22%2Fvar%2Frun%2Fhaproxy%2Fhaproxy-log.sock%22%0A%20%20%20%20%20%20export%20-f%20msg_handler%0A%20%20%20%20%20%20export%20-f%20reload_haproxy%0A%20%20%20%20%20%20export%20-f%20verify_old_haproxy_ps_being_deleted%0A%20%20%20%20%20%20rm%20-f%20%22%24haproxy_sock%22%20%22%24haproxy_log_sock%22%0A%20%20%20%20%20%20socat%20UNIX-RECV%3A%24%7Bhaproxy_log_sock%7D%20STDOUT%20%26%0A%20%20%20%20%20%20if%20%5B%20-s%20%22%2Fetc%2Fhaproxy%2Fhaproxy.cfg%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%2Fusr%2Fsbin%2Fhaproxy%20-W%20-db%20-f%20%2Fetc%2Fhaproxy%2Fhaproxy.cfg%20%20-p%20%2Fvar%2Flib%2Fhaproxy%2Frun%2Fhaproxy.pid%20%26%0A%20%20%20%20%20%20fi%0A%20%20%20%20%20%20socat%20UNIX-LISTEN%3A%24%7Bhaproxy_sock%7D%2Cfork%20system%3A'bash%20-c%20msg_handler'%0A%20%20%20%20resources%3A%0A%20%20%20%20%20%20requests%3A%0A%20%20%20%20%20%20%20%20cpu%3A%20100m%0A%20%20%20%20%20%20%20%20memory%3A%20200Mi%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20conf-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fhaproxy%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20run-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Frun%2Fhaproxy%22%0A%20%20%20%20livenessProbe%3A%0A%20%20%20%20%20%20initialDelaySeconds%3A%2050%0A%20%20%20%20%20%20httpGet%3A%0A%20%20%20%20%20%20%20%20path%3A%20%2Fhaproxy_ready%0A%20%20%20%20%20%20%20%20port%3A%209444%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20imagePullPolicy%3A%20IfNotPresent%0A%20%20-%20name%3A%20haproxy-monitor%0A%20%20%20%20securityContext%3A%0A%20%20%20%20%20%20capabilities%3A%0A%20%20%20%20%20%20%20%20add%3A%20%5B%22NET_ADMIN%22%2C%20%22SYS_CHROOT%22%5D%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A93e7b8c870261726d44bddc7ba0a702d3720d1838141dac837fb8c3be7c6e1a1%0A%20%20%20%20command%3A%0A%20%20%20%20-%20monitor%0A%20%20%20%20-%20%22%2Fvar%2Flib%2Fkubelet%2Fkubeconfig%22%0A%20%20%20%20-%20%22%2Fconfig%2Fhaproxy.cfg.tmpl%22%0A%20%20%20%20-%20%22%2Fetc%2Fhaproxy%2Fhaproxy.cfg%22%0A%20%20%20%20-%20%22--api-vips%22%0A%20%20%20%20-%20%2210.100.0.50%22%0A%20%20%20%20resources%3A%0A%20%20%20%20%20%20requests%3A%0A%20%20%20%20%20%20%20%20cpu%3A%20100m%0A%20%20%20%20%20%20%20%20memory%3A%20200Mi%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20conf-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fhaproxy%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20run-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Frun%2Fhaproxy%22%0A%20%20%20%20-%20name%3A%20resource-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fconfig%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20chroot-host%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fhost%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20kubeconfigvarlib%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20imagePullPolicy%3A%20IfNotPresent%0A%20%20hostNetwork%3A%20true%0A%20%20tolerations%3A%0A%20%20-%20operator%3A%20Exists%0A%20%20priorityClassName%3A%20system-node-critical%0Astatus%3A%20%7B%7D%0A
          mode: 420
          overwrite: true
          path: /etc/kubernetes/manifests/haproxy.yaml
        - contents:
            source: data:,%23%20Force-load%20legacy%20iptables%20so%20it%20is%20usable%20from%20pod%20network%20namespaces%0Aip_tables%0A
          mode: 420
          overwrite: true
          path: /etc/modules-load.d/iptables.conf
        - contents:
            source: data:,global_defs%20%7B%0A%20%20%20%20enable_script_security%0A%20%20%20%20script_user%20root%0A%20%20%20%20max_auto_priority%20-1%0A%20%20%20%20vrrp_garp_master_refresh%2060%0A%7D%0A%0A%23%20These%20are%20separate%20checks%20to%20provide%20the%20following%20behavior%3A%0A%23%20If%20the%20loadbalancer%20is%20healthy%20then%20all%20is%20well%20regardless%0A%23%20of%20what%20the%20local%20API%20status%20is.%20Both%20checks%20will%20return%20success%20and%0A%23%20we'll%20have%20the%20maximum%20priority.%20This%20means%20as%20long%20as%20there%20is%20a%20node%0A%23%20with%20a%20functional%20loadbalancer%20it%20will%20get%20the%20VIP.%0A%23%20If%20all%20of%20the%20loadbalancers%20go%20down%20but%20the%20local%20API%20is%20still%20running%2C%0A%23%20the%20_both%20check%20will%20still%20succeed%20and%20allow%20any%20node%20with%20a%20functional%0A%23%20API%20to%20take%20the%20VIP.%20This%20isn't%20preferred%20because%20it%20means%20all%20API%0A%23%20traffic%20will%20go%20through%20one%20node%2C%20but%20at%20least%20it%20keeps%20the%20API%20available.%0Avrrp_script%20chk_ocp_lb%20%7B%0A%20%20%20%20script%20%22%2Fusr%2Fbin%2Ftimeout%201.9%20%2Fetc%2Fkeepalived%2Fchk_ocp_script.sh%22%0A%20%20%20%20interval%202%0A%20%20%20%20weight%2020%0A%20%20%20%20rise%203%0A%20%20%20%20fall%203%0A%7D%0A%0Avrrp_script%20chk_ocp_both%20%7B%0A%20%20%20%20script%20%22%2Fusr%2Fbin%2Ftimeout%201.9%20%2Fetc%2Fkeepalived%2Fchk_ocp_script_both.sh%22%0A%20%20%20%20interval%202%0A%20%20%20%20%23%20Use%20a%20smaller%20weight%20for%20this%20check%20so%20it%20won't%20trigger%20the%20move%20from%0A%20%20%20%20%23%20bootstrap%20to%20master%20by%20itself.%0A%20%20%20%20weight%205%0A%20%20%20%20rise%203%0A%20%20%20%20fall%203%0A%7D%0A%0Avrrp_script%20chk_mcs%20%7B%0A%20%20%20%20script%20%22%2Fusr%2Fbin%2Ftimeout%201.9%20%2Fetc%2Fkeepalived%2Fchk_mcs_script.sh%22%0A%20%20%20%20interval%202%0A%20%20%20%20weight%203%0A%20%20%20%20rise%203%0A%20%20%20%20fall%203%0A%7D%0A%0A%23%20TODO%3A%20Improve%20this%20check.%20The%20port%20is%20assumed%20to%20be%20alive.%0A%23%20Need%20to%20assess%20what%20is%20the%20ramification%20if%20the%20port%20is%20not%20there.%0Avrrp_script%20chk_ingress_ready%20%7B%0A%20%20%20%20script%20%22%2Fusr%2Fbin%2Ftimeout%200.9%20%2Fusr%2Fbin%2Fcurl%20-o%20%2Fdev%2Fnull%20-Lfs%20http%3A%2F%2Flocalhost%3A1936%2Fhealthz%2Fready%22%0A%20%20%20%20interval%201%0A%20%20%20%20weight%2010%0A%20%20%20%20rise%203%0A%20%20%20%20fall%202%0A%7D%0A%0Avrrp_script%20chk_ingress%20%7B%0A%20%20%20%20script%20%22%2Fusr%2Fbin%2Ftimeout%200.9%20%2Fusr%2Fbin%2Fcurl%20-o%20%2Fdev%2Fnull%20-Lfs%20http%3A%2F%2Flocalhost%3A1936%2Fhealthz%22%0A%20%20%20%20interval%201%0A%20%20%20%20rise%203%0A%20%20%20%20fall%202%0A%7D%0A%0Avrrp_script%20chk_default_ingress%20%7B%0A%20%20%20%20script%20%22%2Fusr%2Fbin%2Ftimeout%204.9%20%2Fetc%2Fkeepalived%2Fchk_default_ingress.sh%22%0A%20%20%20%20interval%205%0A%20%20%20%20weight%2050%0A%20%20%20%20rise%203%0A%20%20%20%20fall%202%0A%7D%0A%0A%7B%7B%20range%20%24i%2C%20%24config%20%3A%3D%20.Configs%20%7D%7D%0A%7B%7B%24nonVirtualIP%20%3A%3D%20.NonVirtualIP%7D%7D%0A%0A%7B%7B%24participateInAPIVRPP%20%3A%3D%20not%20.EnableUnicast%7D%7D%0A%7B%7B-%20if%20.EnableUnicast%7D%7D%0A%7B%7B-%20range%20.LBConfig.Backends%7D%7D%0A%7B%7B-%20if%20eq%20%24nonVirtualIP%20.Address%7D%7D%0A%7B%7B%24participateInAPIVRPP%20%3D%20true%7D%7D%0A%7B%7B-%20end%7D%7D%0A%7B%7B-%20end%7D%7D%0A%7B%7B-%20end%7D%7D%0A%0A%7B%7Bif%20%24participateInAPIVRPP%7D%7D%0Avrrp_instance%20%7B%7B%20.Cluster.Name%20%7D%7D_API_%7B%7B%24i%7D%7D%20%7B%0A%20%20%20%20state%20BACKUP%0A%20%20%20%20interface%20%7B%7B%20.VRRPInterface%20%7D%7D%0A%20%20%20%20virtual_router_id%20%7B%7B%20.Cluster.APIVirtualRouterID%20%7D%7D%0A%20%20%20%20priority%2040%0A%20%20%20%20advert_int%201%0A%20%20%20%20%7B%7Bif%20.EnableUnicast%7D%7D%0A%20%20%20%20unicast_src_ip%20%7B%7B.NonVirtualIP%7D%7D%0A%20%20%20%20unicast_peer%20%7B%0A%20%20%20%20%20%20%20%20%7B%7B-%20range%20.LBConfig.Backends%20-%7D%7D%0A%20%20%20%20%20%20%20%20%7B%7B-%20if%20ne%20%24nonVirtualIP%20.Address%7D%7D%0A%20%20%20%20%20%20%20%20%7B%7B.Address%7D%7D%0A%20%20%20%20%20%20%20%20%7B%7B-%20end%7D%7D%0A%20%20%20%20%20%20%20%20%7B%7B-%20end%7D%7D%0A%20%20%20%20%7D%0A%20%20%20%20%7B%7Bend%7D%7D%0A%20%20%20%20authentication%20%7B%0A%20%20%20%20%20%20%20%20auth_type%20PASS%0A%20%20%20%20%20%20%20%20auth_pass%20%7B%7B%20.Cluster.Name%20%7D%7D_api_vip%0A%20%20%20%20%7D%0A%20%20%20%20virtual_ipaddress%20%7B%0A%20%20%20%20%20%20%20%20%7B%7B%20.Cluster.APIVIP%20%7D%7D%2F%7B%7B%20.Cluster.VIPNetmask%20%7D%7D%20label%20vip%0A%20%20%20%20%7D%0A%20%20%20%20track_script%20%7B%0A%20%20%20%20%20%20%20%20chk_ocp_lb%0A%20%20%20%20%20%20%20%20chk_ocp_both%0A%20%20%20%20%20%20%20%20chk_mcs%0A%20%20%20%20%7D%0A%7D%0A%7B%7Bend%7D%7D%0A%0A%7B%7B%24participateInIngressVRPP%20%3A%3D%20not%20.EnableUnicast%7D%7D%0A%7B%7B-%20if%20.EnableUnicast%7D%7D%0A%7B%7B-%20range%20.IngressConfig.Peers%7D%7D%0A%7B%7B-%20if%20eq%20%24nonVirtualIP%20.%7D%7D%0A%7B%7B%24participateInIngressVRPP%20%3D%20true%7D%7D%0A%7B%7B-%20end%7D%7D%0A%7B%7B-%20end%7D%7D%0A%7B%7B-%20end%7D%7D%0A%0A%7B%7Bif%20%24participateInIngressVRPP%7D%7D%0Avrrp_instance%20%7B%7B%20.Cluster.Name%20%7D%7D_INGRESS_%7B%7B%24i%7D%7D%20%7B%0A%20%20%20%20state%20BACKUP%0A%20%20%20%20interface%20%7B%7B%20.VRRPInterface%20%7D%7D%0A%20%20%20%20virtual_router_id%20%7B%7B%20.Cluster.IngressVirtualRouterID%20%7D%7D%0A%20%20%20%20priority%2020%0A%20%20%20%20advert_int%201%0A%20%20%20%20%7B%7Bif%20.EnableUnicast%7D%7D%0A%20%20%20%20unicast_src_ip%20%7B%7B.NonVirtualIP%7D%7D%0A%20%20%20%20unicast_peer%20%7B%0A%20%20%20%20%20%20%20%20%7B%7B-%20range%20.IngressConfig.Peers%7D%7D%0A%20%20%20%20%20%20%20%20%7B%7B-%20if%20ne%20%24nonVirtualIP%20.%7D%7D%0A%20%20%20%20%20%20%20%20%7B%7B.%7D%7D%0A%20%20%20%20%20%20%20%20%7B%7B-%20end%7D%7D%0A%20%20%20%20%20%20%20%20%7B%7B-%20end%7D%7D%0A%20%20%20%20%7D%0A%20%20%20%20%7B%7Bend%7D%7D%0A%20%20%20%20authentication%20%7B%0A%20%20%20%20%20%20%20%20auth_type%20PASS%0A%20%20%20%20%20%20%20%20auth_pass%20%7B%7B%20.Cluster.Name%20%7D%7D_ingress_vip%0A%20%20%20%20%7D%0A%20%20%20%20virtual_ipaddress%20%7B%0A%20%20%20%20%20%20%20%20%7B%7B%20.Cluster.IngressVIP%20%7D%7D%2F%7B%7B%20.Cluster.VIPNetmask%20%7D%7D%20label%20vip%0A%20%20%20%20%7D%0A%20%20%20%20track_script%20%7B%0A%20%20%20%20%20%20%20%20chk_ingress%0A%20%20%20%20%20%20%20%20chk_ingress_ready%0A%20%20%20%20%20%20%20%20chk_default_ingress%0A%20%20%20%20%7D%0A%7D%0A%7B%7B%20end%20%7D%7D%0A%7B%7B%20end%20%7D%7D%0A
          mode: 420
          overwrite: true
          path: /etc/kubernetes/static-pod-resources/keepalived/keepalived.conf.tmpl
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Achroot%20%2Fhost%20%2Fbin%2Fcrictl%20ps%20--state%20running%20%7C%20grep%20-qE%20'%5Csmachine-config-server%5Cs'%0A
          mode: 493
          overwrite: true
          path: /etc/kubernetes/static-pod-resources/keepalived/scripts/chk_mcs_script.sh.tmpl
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%2Fusr%2Fbin%2Fcurl%20-o%20%2Fdev%2Fnull%20-kLfs%20http%3A%2F%2Flocalhost%3A9444%2Fhaproxy_ready%20%26%26%20%5B%20-e%20%2Fvar%2Frun%2Fkeepalived%2Fiptables-rule-exists%20%5D%20%7C%7C%20%2Fusr%2Fbin%2Fcurl%20-kLfs%20https%3A%2F%2Flocalhost%3A%7B%7B%20.LBConfig.ApiPort%20%7D%7D%2Freadyz%0A
          mode: 493
          overwrite: true
          path: /etc/kubernetes/static-pod-resources/keepalived/scripts/chk_ocp_script_both.sh.tmpl
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Achroot%20%2Fhost%20%2Fbin%2Fcrictl%20pods%20--namespace%20openshift-ingress%20--state%20Ready%20%7C%20grep%20-qE%20'router-default-%5B%5B%3Aalnum%3A%5D%5D%7B5%2C%7D-%5B%5B%3Aalnum%3A%5D%5D%7B5%2C%7D'%0A
          mode: 493
          overwrite: true
          path: /etc/kubernetes/static-pod-resources/keepalived/scripts/chk_default_ingress.sh.tmpl
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%2Fusr%2Fbin%2Fcurl%20-o%20%2Fdev%2Fnull%20-kLfs%20http%3A%2F%2Flocalhost%3A9444%2Fhaproxy_ready%20%26%26%20%5B%20-e%20%2Fvar%2Frun%2Fkeepalived%2Fiptables-rule-exists%20%5D%0A
          mode: 493
          overwrite: true
          path: /etc/kubernetes/static-pod-resources/keepalived/scripts/chk_ocp_script.sh.tmpl
        - contents:
            source: data:,kind%3A%20Pod%0AapiVersion%3A%20v1%0Ametadata%3A%0A%20%20name%3A%20keepalived%0A%20%20namespace%3A%20openshift-kni-infra%0A%20%20creationTimestamp%3A%0A%20%20deletionGracePeriodSeconds%3A%2065%0A%20%20labels%3A%0A%20%20%20%20app%3A%20kni-infra-vrrp%0A%20%20annotations%3A%0A%20%20%20%20target.workload.openshift.io%2Fmanagement%3A%20'%7B%22effect%22%3A%20%22PreferredDuringScheduling%22%7D'%0A%20%20%20%20openshift.io%2Frequired-scc%3A%20privileged%0Aspec%3A%0A%20%20volumes%3A%0A%20%20-%20name%3A%20resource-dir%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fetc%2Fkubernetes%2Fstatic-pod-resources%2Fkeepalived%22%0A%20%20-%20name%3A%20script-dir%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fetc%2Fkubernetes%2Fstatic-pod-resources%2Fkeepalived%2Fscripts%22%0A%20%20-%20name%3A%20kubeconfig%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fetc%2Fkubernetes%22%0A%20%20-%20name%3A%20kubeconfigvarlib%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20-%20name%3A%20conf-dir%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fetc%2Fkeepalived%22%0A%20%20-%20name%3A%20run-dir%0A%20%20%20%20empty-dir%3A%20%7B%7D%0A%20%20-%20name%3A%20chroot-host%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2F%22%0A%20%20-%20name%3A%20nodeip-configuration%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Frun%2Fnodeip-configuration%22%0A%20%20initContainers%3A%0A%20%20-%20name%3A%20render-config-keepalived%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A93e7b8c870261726d44bddc7ba0a702d3720d1838141dac837fb8c3be7c6e1a1%0A%20%20%20%20command%3A%0A%20%20%20%20-%20runtimecfg%0A%20%20%20%20-%20render%0A%20%20%20%20-%20%22%2Fetc%2Fkubernetes%2Fkubeconfig%22%0A%20%20%20%20-%20%22--api-vips%22%0A%20%20%20%20-%20%2210.100.0.50%22%0A%20%20%20%20-%20%22--ingress-vips%22%0A%20%20%20%20-%20%2210.100.0.51%22%0A%20%20%20%20-%20%22%2Fconfig%22%0A%20%20%20%20-%20%22--out-dir%22%0A%20%20%20%20-%20%22%2Fetc%2Fkeepalived%22%0A%20%20%20%20resources%3A%20%7B%7D%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20kubeconfig%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fkubernetes%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20script-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fconfig%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20conf-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fkeepalived%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20nodeip-configuration%0A%20%20%20%20%20%20mountPath%3A%20%22%2Frun%2Fnodeip-configuration%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20imagePullPolicy%3A%20IfNotPresent%0A%20%20containers%3A%0A%20%20-%20name%3A%20keepalived%0A%20%20%20%20securityContext%3A%0A%20%20%20%20%20%20capabilities%3A%0A%20%20%20%20%20%20%20%20add%3A%20%5B%22NET_ADMIN%22%2C%20%22NET_RAW%22%2C%20%22SYS_CHROOT%22%5D%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A3b0561a80561d95854d5f364f8cd6c3458d27cfb798bf93e09ffcfab97609216%0A%20%20%20%20env%3A%0A%20%20%20%20%20%20-%20name%3A%20NSS_SDB_USE_CACHE%0A%20%20%20%20%20%20%20%20value%3A%20%22no%22%0A%20%20%20%20command%3A%0A%20%20%20%20-%20%2Fbin%2Fbash%0A%20%20%20%20-%20-c%0A%20%20%20%20-%20%7C%0A%20%20%20%20%20%20%23%2Fbin%2Fbash%0A%20%20%20%20%20%20sigterm_handler()%0A%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20if%20pid%3D%24(pgrep%20-o%20keepalived)%3B%20then%0A%20%20%20%20%20%20%20%20%20%20kill%20-s%20SIGTERM%20%22%24pid%22%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%7D%0A%0A%20%20%20%20%20%20reload_keepalived()%0A%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20if%20pid%3D%24(pgrep%20-o%20keepalived)%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20kill%20-s%20SIGHUP%20%22%24pid%22%0A%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20%2Fusr%2Fsbin%2Fkeepalived%20-f%20%2Fetc%2Fkeepalived%2Fkeepalived.conf%20--dont-fork%20--vrrp%20--log-detail%20--log-console%20%26%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%7D%0A%0A%20%20%20%20%20%20msg_handler()%0A%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20while%20read%20-r%20line%3B%20do%0A%20%20%20%20%20%20%20%20%20%20echo%20%22The%20client%20sent%3A%20%24line%22%20%3E%262%0A%20%20%20%20%20%20%20%20%20%20%23%20currently%20only%20'reload'%20msg%20is%20supported%0A%20%20%20%20%20%20%20%20%20%20if%20%5B%20%22%24line%22%20%3D%20reload%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20reload_keepalived%0A%20%20%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20done%0A%20%20%20%20%20%20%7D%0A%0A%20%20%20%20%20%20remove_vip()%0A%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20address%3D%241%0A%20%20%20%20%20%20%20%20interface%3D%24(ip%20-o%20a%20%7C%20awk%20%22%2F%5Cs%24%7Baddress%7D%5C%2F%2F%20%7Bprint%20%5C%242%7D%22)%0A%20%20%20%20%20%20%20%20cidr%3D%24(ip%20-o%20a%20%7C%20awk%20%22%2F%5Cs%24%7Baddress%7D%5C%2F%2F%20%7Bprint%20%5C%244%7D%22)%0A%20%20%20%20%20%20%20%20if%20%5B%20-n%20%22%24interface%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20ip%20a%20del%20%24cidr%20dev%20%24interface%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%7D%0A%0A%20%20%20%20%20%20set%20-ex%0A%20%20%20%20%20%20%23%20Ensure%20that%20we%20don't%20have%20stale%20VIPs%20configured%0A%20%20%20%20%20%20%23%20See%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1931505%0A%20%20%20%20%20%20remove_vip%20%2210.100.0.50%22%0A%20%20%20%20%20%20remove_vip%20%2210.100.0.51%22%0A%20%20%20%20%20%20declare%20-r%20keepalived_sock%3D%22%2Fvar%2Frun%2Fkeepalived%2Fkeepalived.sock%22%0A%20%20%20%20%20%20export%20-f%20msg_handler%0A%20%20%20%20%20%20export%20-f%20reload_keepalived%0A%20%20%20%20%20%20export%20-f%20sigterm_handler%0A%0A%20%20%20%20%20%20%23%20in%20remote%20worker%20case%20sleep%20forever%0A%20%20%20%20%20%20if%20%5B%20-f%20%22%2Frun%2Fnodeip-configuration%2Fremote-worker%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20sleep%20infinity%0A%20%20%20%20%20%20%20%20%20exit%200%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20trap%20sigterm_handler%20SIGTERM%0A%20%20%20%20%20%20if%20%5B%20-s%20%22%2Fetc%2Fkeepalived%2Fkeepalived.conf%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%2Fusr%2Fsbin%2Fkeepalived%20-f%20%2Fetc%2Fkeepalived%2Fkeepalived.conf%20--dont-fork%20--vrrp%20--log-detail%20--log-console%20%26%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20rm%20-f%20%22%24keepalived_sock%22%0A%20%20%20%20%20%20socat%20UNIX-LISTEN%3A%24%7Bkeepalived_sock%7D%2Cfork%20system%3A'bash%20-c%20msg_handler'%0A%20%20%20%20resources%3A%0A%20%20%20%20%20%20requests%3A%0A%20%20%20%20%20%20%20%20cpu%3A%20100m%0A%20%20%20%20%20%20%20%20memory%3A%20200Mi%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20conf-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fkeepalived%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20run-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Frun%2Fkeepalived%22%0A%20%20%20%20-%20name%3A%20chroot-host%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fhost%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20kubeconfigvarlib%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20nodeip-configuration%0A%20%20%20%20%20%20mountPath%3A%20%22%2Frun%2Fnodeip-configuration%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20livenessProbe%3A%0A%20%20%20%20%20%20exec%3A%0A%20%20%20%20%20%20%20%20command%3A%0A%20%20%20%20%20%20%20%20-%20%2Fbin%2Fbash%0A%20%20%20%20%20%20%20%20-%20-c%0A%20%20%20%20%20%20%20%20-%20%7C%0A%20%20%20%20%20%20%20%20%20%20%5B%20!%20-s%20%22%2Fetc%2Fkeepalived%2Fkeepalived.conf%22%20%5D%20%7C%7C%20(echo%20%22%22%20%3E%20%2Ftmp%2Fkeepalived.data%20%26%26%20kill%20-s%20SIGUSR1%20%22%24(pgrep%20-o%20keepalived)%22%20%26%26%20for%20i%20in%20%24(seq%205)%3B%20do%20grep%20-q%20%22VRRP%20Instance%22%20%2Ftmp%2Fkeepalived.data%20%26%26%20exit%200%20%7C%7C%20sleep%201%3B%20done%20%26%26%20exit%201)%0A%20%20%20%20%20%20initialDelaySeconds%3A%2020%0A%20%20%20%20%20%20timeoutSeconds%3A%205%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20imagePullPolicy%3A%20IfNotPresent%0A%20%20-%20name%3A%20keepalived-monitor%0A%20%20%20%20securityContext%3A%0A%20%20%20%20%20%20capabilities%3A%0A%20%20%20%20%20%20%20%20add%3A%20%5B%22NET_ADMIN%22%2C%20%22SYS_CHROOT%22%5D%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A93e7b8c870261726d44bddc7ba0a702d3720d1838141dac837fb8c3be7c6e1a1%0A%20%20%20%20env%3A%0A%20%20%20%20%20%20-%20name%3A%20ENABLE_UNICAST%0A%20%20%20%20%20%20%20%20value%3A%20%22yes%22%0A%20%20%20%20%20%20-%20name%3A%20IS_BOOTSTRAP%0A%20%20%20%20%20%20%20%20value%3A%20%22no%22%0A%20%20%20%20%20%20-%20name%3A%20POD_NAMESPACE%0A%20%20%20%20%20%20%20%20valueFrom%3A%0A%20%20%20%20%20%20%20%20%20%20fieldRef%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20fieldPath%3A%20metadata.namespace%0A%20%20%20%20command%3A%0A%20%20%20%20-%20%2Fbin%2Fbash%0A%20%20%20%20-%20-c%0A%20%20%20%20-%20%7C%0A%20%20%20%20%20%20%23%2Fbin%2Fbash%0A%20%20%20%20%20%20%23%20in%20remote%20worker%20case%20sleep%20forever%0A%20%20%20%20%20%20if%20%5B%20-f%20%22%2Frun%2Fnodeip-configuration%2Fremote-worker%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20sleep%20infinity%0A%20%20%20%20%20%20%20%20%20%20exit%200%0A%20%20%20%20%20%20fi%0A%20%20%20%20%20%20api_vips%3D10.100.0.50%0A%20%20%20%20%20%20ingress_vips%3D10.100.0.51%0A%20%20%20%20%20%20dynkeepalived%20%2Fvar%2Flib%2Fkubelet%2Fkubeconfig%20%2Fconfig%2Fkeepalived.conf.tmpl%20%2Fetc%2Fkeepalived%2Fkeepalived.conf%20--api-vips%20%22%24%7Bapi_vips%7D%22%20--ingress-vips%20%22%24%7Bingress_vips%7D%22%0A%20%20%20%20resources%3A%0A%20%20%20%20%20%20requests%3A%0A%20%20%20%20%20%20%20%20cpu%3A%20100m%0A%20%20%20%20%20%20%20%20memory%3A%20200Mi%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20resource-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fconfig%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20kubeconfigvarlib%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20conf-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fkeepalived%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20run-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Frun%2Fkeepalived%22%0A%20%20%20%20-%20name%3A%20chroot-host%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fhost%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20nodeip-configuration%0A%20%20%20%20%20%20mountPath%3A%20%22%2Frun%2Fnodeip-configuration%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20imagePullPolicy%3A%20IfNotPresent%0A%20%20hostNetwork%3A%20true%0A%20%20tolerations%3A%0A%20%20-%20operator%3A%20Exists%0A%20%20priorityClassName%3A%20system-node-critical%0Astatus%3A%20%7B%7D%0A
          mode: 420
          overwrite: true
          path: /etc/kubernetes/manifests/keepalived.yaml
        - contents:
            source: data:,NODE_SIZING_ENABLED%3Dfalse%0ASYSTEM_RESERVED_MEMORY%3D1Gi%0ASYSTEM_RESERVED_CPU%3D500m%0ASYSTEM_RESERVED_ES%3D1Gi
          mode: 420
          overwrite: true
          path: /etc/node-sizing-enabled.env
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-e%0ANODE_SIZES_ENV%3D%24%7BNODE_SIZES_ENV%3A-%2Fetc%2Fnode-sizing.env%7D%0AVERSION_1%3D1%0AVERSION_2%3D2%0ANODE_AUTO_SIZING_VERSION%3D%24%7BNODE_AUTO_SIZING_VERSION%3A-%24VERSION_2%7D%0ANODE_AUTO_SIZING_VERSION_FILE%3D%24%7BNODE_AUTO_SIZING_VERSION_FILE%3A-%2Fetc%2Fnode-sizing-version.json%7D%0Afunction%20dynamic_memory_sizing%20%7B%0A%20%20%20%20total_memory%3D%24(free%20-g%7Cawk%20'%2F%5EMem%3A%2F%7Bprint%20%242%7D')%0A%20%20%20%20%23%20total_memory%3D8%20test%20the%20recommended%20values%20by%20modifying%20this%20value%0A%20%20%20%20recommended_systemreserved_memory%3D0%0A%20%20%20%20if%20((%24total_memory%20%3C%3D%204))%3B%20then%20%23%2025%25%20of%20the%20first%204GB%20of%20memory%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24total_memory%200.25%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D0%0A%20%20%20%20else%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D1%0A%20%20%20%20%20%20%20%20total_memory%3D%24((total_memory-4))%0A%20%20%20%20fi%0A%20%20%20%20if%20((%24total_memory%20%3C%3D%204))%3B%20then%20%23%2020%25%20of%20the%20next%204GB%20of%20memory%20(up%20to%208GB)%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%20%24(echo%20%24total_memory%200.20%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D0%0A%20%20%20%20else%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%200.80%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D%24((total_memory-4))%0A%20%20%20%20fi%0A%20%20%20%20if%20((%24total_memory%20%3C%3D%208))%3B%20then%20%23%2010%25%20of%20the%20next%208GB%20of%20memory%20(up%20to%2016GB)%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%20%24(echo%20%24total_memory%200.10%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D0%0A%20%20%20%20else%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%200.80%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D%24((total_memory-8))%0A%20%20%20%20fi%0A%20%20%20%20if%20((%24total_memory%20%3C%3D%20112))%3B%20then%20%23%206%25%20of%20the%20next%20112GB%20of%20memory%20(up%20to%20128GB)%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%20%24(echo%20%24total_memory%200.06%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D0%0A%20%20%20%20else%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%206.72%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D%24((total_memory-112))%0A%20%20%20%20fi%0A%20%20%20%20if%20((%24total_memory%20%3E%3D%200))%3B%20then%20%23%202%25%20of%20any%20memory%20above%20128GB%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%20%24(echo%20%24total_memory%200.02%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20fi%0A%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%20%7C%20awk%20'%7Bprintf(%22%25d%5Cn%22%2C%241%20%2B%200.5)%7D')%20%23%20Round%20off%20so%20we%20avoid%20float%20conversions%0A%20%20%20%20echo%20%22SYSTEM_RESERVED_MEMORY%3D%24%7Brecommended_systemreserved_memory%7DGi%22%3E%3E%20%24%7BNODE_SIZES_ENV%7D%0A%7D%0Afunction%20dynamic_cpu_sizing%20%7B%0A%20%20%20%20total_cpu%3D%24(getconf%20_NPROCESSORS_ONLN)%0A%20%20%20%20if%20%5B%20%22%241%22%20-eq%20%22%24VERSION_1%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D0%0A%20%20%20%20%20%20%20%20if%20((%24total_cpu%20%3C%3D%201))%3B%20then%20%23%206%25%20of%20the%20first%20core%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24total_cpu%200.06%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D0%0A%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D0.06%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D%24((total_cpu-1))%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20if%20((%24total_cpu%20%3C%3D%201))%3B%20then%20%23%201%25%20of%20the%20next%20core%20(up%20to%202%20cores)%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24recommended_systemreserved_cpu%20%24(echo%20%24total_cpu%200.01%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D0%0A%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24recommended_systemreserved_cpu%200.01%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D%24((total_cpu-1))%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20if%20((%24total_cpu%20%3C%3D%202))%3B%20then%20%23%200.5%25%20of%20the%20next%202%20cores%20(up%20to%204%20cores)%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24recommended_systemreserved_cpu%20%24(echo%20%24total_cpu%200.005%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D0%0A%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24recommended_systemreserved_cpu%200.01%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D%24((total_cpu-2))%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20if%20((%24total_cpu%20%3E%3D%200))%3B%20then%20%23%200.25%25%20of%20any%20cores%20above%204%20cores%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24recommended_systemreserved_cpu%20%24(echo%20%24total_cpu%200.0025%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20else%0A%20%20%20%20%20%20%20%20%23%20Base%20allocation%20for%201%20CPU%20in%20fractions%20of%20a%20core%20(60%20millicores%20%3D%200.06%20CPU%20core)%0A%20%20%20%20%20%20%20%20base_allocation_fraction%3D0.06%0A%20%20%20%20%20%20%20%20%23%20Increment%20per%20additional%20CPU%20in%20fractions%20of%20a%20core%20(12%20millicores%20%3D%200.012%20CPU%20core)%0A%20%20%20%20%20%20%20%20increment_per_cpu_fraction%3D0.012%0A%20%20%20%20%20%20%20%20if%20((total_cpu%20%3E%201))%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Calculate%20the%20total%20system-reserved%20CPU%20in%20fractions%2C%20starting%20with%20the%20base%20allocation%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20and%20adding%20the%20incremental%20fraction%20for%20each%20additional%20CPU%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(awk%20-v%20base%3D%22%24base_allocation_fraction%22%20-v%20increment%3D%22%24increment_per_cpu_fraction%22%20-v%20cpus%3D%22%24total_cpu%22%20'BEGIN%20%7Bprintf%20%22%25.2f%5Cn%22%2C%20base%20%2B%20increment%20*%20(cpus%20-%201)%7D')%0A%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20For%20a%20single%20CPU%2C%20use%20the%20base%20allocation%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24base_allocation_fraction%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Enforce%20minimum%20threshold%20of%200.5%20CPU%0A%20%20%20%20recommended_systemreserved_cpu%3D%24(awk%20-v%20val%3D%22%24recommended_systemreserved_cpu%22%20'BEGIN%20%7Bif%20(val%20%3C%200.5)%20print%200.5%3B%20else%20print%20val%7D')%0A%0A%20%20%20%20echo%20%22SYSTEM_RESERVED_CPU%3D%24%7Brecommended_systemreserved_cpu%7D%22%3E%3E%20%24%7BNODE_SIZES_ENV%7D%0A%7D%0Afunction%20dynamic_ephemeral_sizing%20%7B%0A%20%20%20%20echo%20%22Not%20implemented%20yet%22%0A%7D%0Afunction%20dynamic_pid_sizing%20%7B%0A%20%20%20%20echo%20%22Not%20implemented%20yet%22%0A%7D%0Afunction%20set_memory%20%7B%0A%20%20%20%20SYSTEM_RESERVED_MEMORY%3D%241%0A%20%20%20%20if%20%5B%20-z%20%22%24%7BSYSTEM_RESERVED_MEMORY%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20SYSTEM_RESERVED_MEMORY%3D%221Gi%22%0A%20%20%20%20fi%0A%20%20%20%20echo%20%22SYSTEM_RESERVED_MEMORY%3D%24%7BSYSTEM_RESERVED_MEMORY%7D%22%20%3E%3E%20%24%7BNODE_SIZES_ENV%7D%0A%7D%0Afunction%20set_cpu%20%7B%0A%20%20%20%20SYSTEM_RESERVED_CPU%3D%241%0A%20%20%20%20if%20%5B%20-z%20%22%24%7BSYSTEM_RESERVED_CPU%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20SYSTEM_RESERVED_CPU%3D%22500m%22%0A%20%20%20%20fi%0A%20%20%20%20echo%20%22SYSTEM_RESERVED_CPU%3D%24%7BSYSTEM_RESERVED_CPU%7D%22%20%3E%3E%20%24%7BNODE_SIZES_ENV%7D%0A%7D%0Afunction%20set_es%20%7B%0A%20%20%20%20SYSTEM_RESERVED_ES%3D%241%0A%20%20%20%20if%20%5B%20-z%20%22%24%7BSYSTEM_RESERVED_ES%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20SYSTEM_RESERVED_ES%3D%221Gi%22%0A%20%20%20%20fi%0A%20%20%20%20echo%20%22SYSTEM_RESERVED_ES%3D%24%7BSYSTEM_RESERVED_ES%7D%22%20%3E%3E%20%24%7BNODE_SIZES_ENV%7D%0A%7D%0Afunction%20dynamic_node_sizing%20%7B%0A%20%20%20%20rm%20-f%20%24%7BNODE_SIZES_ENV%7D%0A%20%20%20%20dynamic_memory_sizing%0A%20%20%20%20dynamic_cpu_sizing%20%241%0A%20%20%20%20set_es%20%242%0A%20%20%20%20%23dynamic_ephemeral_sizing%0A%20%20%20%20%23dynamic_pid_sizing%0A%7D%0Afunction%20static_node_sizing%20%7B%0A%20%20%20%20rm%20-f%20%24%7BNODE_SIZES_ENV%7D%0A%20%20%20%20set_memory%20%241%0A%20%20%20%20set_cpu%20%242%0A%20%20%20%20set_es%20%243%0A%7D%0Afunction%20create_version_file%20%7B%0A%20%20%20%20echo%20%22%7B%5C%22version%5C%22%3A%20%241%7D%22%20%3E%20%242%0A%7D%0Aif%20!%20%5B%20-f%20%24NODE_AUTO_SIZING_VERSION_FILE%20%5D%3B%20then%0A%20%20%20%20create_version_file%20%24NODE_AUTO_SIZING_VERSION%20%24NODE_AUTO_SIZING_VERSION_FILE%0Afi%0Anew_version%3D%24(jq%20.version%20%24NODE_AUTO_SIZING_VERSION_FILE)%0Aif%20%5B%20%241%20%3D%3D%20%22true%22%20%5D%3B%20then%0A%20%20%20%20dynamic_node_sizing%20%24new_version%20%244%0Aelif%20%5B%20%241%20%3D%3D%20%22false%22%20%5D%3B%20then%0A%20%20%20%20static_node_sizing%20%242%20%243%20%244%0Aelse%0A%20%20%20%20echo%20%22Unrecognized%20command%20line%20option.%20Valid%20options%20are%20%5C%22true%5C%22%20or%20%5C%22false%5C%22%22%0Afi%0A
          mode: 493
          overwrite: true
          path: /usr/local/sbin/dynamic-system-reserved-calc.sh
        - contents:
            source: data:,%23%20Turning%20on%20Accounting%20helps%20track%20down%20performance%20issues.%0A%5BManager%5D%0ADefaultCPUAccounting%3Dyes%0ADefaultMemoryAccounting%3Dyes%0ADefaultBlockIOAccounting%3Dyes%0A
          mode: 420
          overwrite: true
          path: /etc/systemd/system.conf.d/kubelet-cgroups.conf
        - contents:
            source: data:,%5BService%5D%0AEnvironment%3D%22KUBELET_LOG_LEVEL%3D2%22%0A
          mode: 420
          overwrite: true
          path: /etc/systemd/system/kubelet.service.d/20-logging.conf
        - contents:
            source: data:,%23%20ignore%20known%20SDN-managed%20devices%0A%5Bdevice%5D%0Amatch-device%3Dinterface-name%3Abr-int%3Binterface-name%3Abr-local%3Binterface-name%3Abr-nexthop%3Binterface-name%3Aovn-k8s-*%3Binterface-name%3Ak8s-*%3Binterface-name%3Atun0%3Binterface-name%3Abr0%3Binterface-name%3Apatch-br-*%3Binterface-name%3Abr-ext%3Binterface-name%3Aext-vxlan%3Binterface-name%3Aext%3Binterface-name%3Aint%3Binterface-name%3Avxlan_sys_*%3Binterface-name%3Agenev_sys_*%3Bdriver%3Aveth%0Amanaged%3D0%0A
          mode: 420
          overwrite: true
          path: /etc/NetworkManager/conf.d/sdn.conf
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-eux%0A%0A%23%20Clean%20up%20old%20config%20on%20behalf%20of%20mtu-migration%0Aif%20!%20systemctl%20-q%20is-enabled%20mtu-migration%3B%20then%0A%20%20echo%20%22Cleaning%20up%20left%20over%20mtu%20migration%20configuration%22%0A%20%20rm%20-rf%20%2Fetc%2Fcno%2Fmtu-migration%0Afi%0A%0Aif%20%5B%20-e%20%2Fetc%2Fnmstate%2Fopenshift%2Fapplied%20%5D%3B%20then%0A%20%20echo%20%22Configuration%20already%20applied%2C%20exiting%22%0A%20%20exit%200%0Afi%0A%0Asrc_path%3D%22%2Fetc%2Fnmstate%2Fopenshift%22%0Adst_path%3D%22%2Fetc%2Fnmstate%22%0Ahostname%3D%24(hostname%20-s)%0Ahost_file%3D%22%24%7Bhostname%7D.yml%22%0Acluster_file%3D%22cluster.yml%22%0Aconfig_file%3D%22%22%0Aif%20%5B%20-s%20%22%24src_path%2F%24host_file%22%20%5D%3B%20then%0A%20%20config_file%3D%24host_file%0Aelif%20%5B%20-s%20%22%24src_path%2F%24cluster_file%22%20%5D%3B%20then%0A%20%20config_file%3D%24cluster_file%0Aelse%0A%20%20echo%20%22No%20configuration%20found%20at%20%24src_path%2F%24host_file%20or%20%24src_path%2F%24cluster_file%22%0A%20%20exit%200%0Afi%0A%0Aif%20%5B%20-e%20%22%24dst_path%2F%24config_file%22%20%5D%3B%20then%0A%20%20echo%20%22ERROR%3A%20File%20%24dst_path%2F%24config_file%20exists.%20Refusing%20to%20overwrite.%22%0A%20%20exit%201%0Afi%0A%0A%23%20Handle%20the%20case%20where%20we're%20migrating%20from%20configure-ovs%0Aovs-vsctl%20--timeout%3D30%20--if-exists%20del-br%20br-ex%0A%0A%23%20Handle%20the%20case%20where%20we're%20migrating%20from%20OpenShift%20SDN%0Aovs-vsctl%20--timeout%3D30%20--if-exists%20del-br%20br0%0A%0Acp%20%22%24src_path%2F%24config_file%22%20%2Fetc%2Fnmstate%0Atouch%20%2Fetc%2Fnmstate%2Fopenshift%2Fapplied%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/nmstate-configuration.sh
        - contents:
            source: data:,%5Bservice%5D%0Akeep_state_file_after_apply%20%3D%20true%0A
          mode: 420
          overwrite: true
          path: /etc/nmstate/nmstate.conf
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%23%20Set%20interface%20ofport_request%20to%20guarantee%20stable%20ofport%20numbers.%20This%20is%20important%20for%20flow%20matches.%0A%23%20Otherwise%2C%20another%20ofport%20number%20is%20assigned%20to%20the%20interface%20on%20every%20restart%20of%20NetworkManager.%0A%23%20This%20script%20will%20build%20an%20associative%20array%20INTERFACE_NAME-%3Eofport_request%20and%20will%20save%20it%20to%20file%20CONFIGURATION_FILE.%0A%23%20When%20an%20interface%20is%20brought%20up%2C%20this%20will%20reuse%20the%20value%20from%20the%20associative%20array%20if%20such%20a%20value%20exists.%0A%23%20Otherwise%2C%20this%20will%20try%20to%20use%20the%20current%20ofport%20value.%20If%20the%20ofport%20value%20is%20already%20reserved%2C%20then%0A%23%20this%20uses%20the%20lowest%20available%20numerical%20value%2C%20instead.%0Aset%20-eux%20-o%20pipefail%0Aif%20%5B%5B%20%22OVNKubernetes%22%20!%3D%20%22OVNKubernetes%22%20%5D%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0AINTERFACE_NAME%3D%241%0AOPERATION%3D%242%0A%0A%23%20Only%20execute%20this%20on%20pre-up%0Aif%20%5B%20%22%24%7BOPERATION%7D%22%20!%3D%20%22pre-up%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20interface's%20NM%20uuid%0AINTERFACE_CONNECTION_UUID%3D%24(nmcli%20-t%20-f%20device%2Ctype%2Cuuid%20conn%20%7C%20awk%20-F%20'%3A'%20'%7Bif(%241%3D%3D%22'%24%7BINTERFACE_NAME%7D'%22%20%26%26%20%242!~%2F%5Eovs*%2F)%20print%20%24NF%7D')%0Aif%20%5B%20%22%24%7BINTERFACE_CONNECTION_UUID%7D%22%20%3D%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20interface's%20slave-type.%20If%20this%20is%20not%20an%20ovs-port%2C%20then%20exit%0AINTERFACE_OVS_SLAVE_TYPE%3D%24(nmcli%20-t%20-f%20connection.slave-type%20conn%20show%20%22%24%7BINTERFACE_CONNECTION_UUID%7D%22%20%7C%20awk%20-F%20'%3A'%20'%7Bprint%20%24NF%7D')%0Aif%20%5B%20%22%24%7BINTERFACE_OVS_SLAVE_TYPE%7D%22%20!%3D%20%22ovs-port%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20This%20is%20not%20necessarily%20a%20UUID%20(can%20be%20a%20name%20in%20case%20of%20bonds)%20but%20this%20should%20be%20unique%0APORT%3D%24(nmcli%20-t%20-f%20connection.master%20conn%20show%20%22%24%7BINTERFACE_CONNECTION_UUID%7D%22%20%7C%20awk%20-F%20'%3A'%20'%7Bprint%20%24NF%7D')%0Aif%20%5B%20%22%24%7BPORT%7D%22%20%3D%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20interface's%20NM%20uuid%0APORT_CONNECTION_UUID%3D%24(nmcli%20-t%20-f%20device%2Ctype%2Cuuid%20conn%20%7C%20awk%20-F%20'%3A'%20'%7Bif(%20(%241%3D%3D%22'%24%7BPORT%7D'%22%20%7C%7C%20%243%3D%3D%22'%24%7BPORT%7D'%22)%20%26%26%20%242~%2F%5Eovs*%2F)%20print%20%24NF%7D')%0Aif%20%5B%20%22%24%7BPORT_CONNECTION_UUID%7D%22%20%3D%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20port's%20slave-type.%20If%20this%20is%20not%20an%20ovs-bridge%2C%20then%20exit%0APORT_OVS_SLAVE_TYPE%3D%24(nmcli%20-t%20-f%20connection.slave-type%20conn%20show%20%22%24%7BPORT_CONNECTION_UUID%7D%22%20%7C%20awk%20-F%20'%3A'%20'%7Bprint%20%24NF%7D')%0Aif%20%5B%20%22%24%7BPORT_OVS_SLAVE_TYPE%7D%22%20!%3D%20%22ovs-bridge%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20port's%20master.%20If%20it%20doesn't%20have%20any%2C%20assume%20it's%20not%20our%20bridge%0ABRIDGE_ID%3D%24(nmcli%20-t%20-f%20connection.master%20conn%20show%20%22%24%7BPORT_CONNECTION_UUID%7D%22%20%7C%20awk%20-F%20'%3A'%20'%7Bprint%20%24NF%7D')%0Aif%20%5B%20%22%24%7BBRIDGE_ID%7D%22%20%3D%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20bridge%20name%0ABRIDGE_NAME%3D%24(nmcli%20-t%20-f%20connection.interface-name%20conn%20show%20%22%24%7BBRIDGE_ID%7D%22%20%7C%20awk%20-F%20'%3A'%20'%7Bprint%20%24NF%7D')%0A%23%20Limit%20this%20to%20br-ex%20and%20br-ex1%20only.%20If%20one%20wanted%20to%20enable%20this%20for%20all%20OVS%20bridges%2C%0A%23%20the%20condition%20would%20be%3A%20if%20%5B%20%22%24BRIDGE_NAME%22%20%3D%3D%20%22%22%20%5D%3B%20then%0Aif%20%5B%20%22%24%7BBRIDGE_NAME%7D%22%20!%3D%20%22br-ex%22%20%5D%20%26%26%20%5B%20%22%24%7BBRIDGE_NAME%7D%22%20!%3D%20%22br-ex1%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Make%20sure%20that%20the%20interface%20is%20plugged%20into%20OVS%0A%23%20This%20should%20always%20be%20the%20case%20given%20that%20we%20are%20in%20pre-up%2C%20but%20exit%20gracefully%20in%20the%20odd%20case%20that%20it's%20not%0Aif%20!%20ovs-vsctl%20list%20interface%20%22%24%7BINTERFACE_NAME%7D%22%20%3E%2Fdev%2Fnull%202%3E%261%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0ACONFIGURATION_FILE%3D%22%2Frun%2Fofport_requests.%24%7BBRIDGE_NAME%7D%22%0A%0A%23%20Declare%20a%20new%20associative%20array.%20If%20CONFIGURATION_FILE%20exists%2C%20source%20entries%20from%20there%0Adeclare%20-A%20INTERFACES%0Aif%20%5B%20-f%20%22%24%7BCONFIGURATION_FILE%7D%22%20%5D%3B%20then%0A%20%20%20%20echo%20%22Sourcing%20configuration%20file%20'%24%7BCONFIGURATION_FILE%7D'%20with%20contents%3A%22%0A%20%20%20%20cat%20%22%24%7BCONFIGURATION_FILE%7D%22%0A%20%20%20%20source%20%22%24%7BCONFIGURATION_FILE%7D%22%0Afi%0A%0A%23%20get_interface_ofport_request%20will%20return%0A%23%20*%20either%3A%20the%20current%20ofport%20assignment%20for%20the%20port%20if%20no%20interface%20has%20claimed%20this%20ofport%20number%2C%20yet%0A%23%20*%20or%3A%20%20%20%20%20the%20lowest%20available%20free%20ofport%20number%0Afunction%20get_interface_ofport_request()%20%7B%0A%20%20%20%20%23%20Build%20an%20array%20that%20only%20contains%20the%20currently%20reserved%20ofport_requests%0A%20%20%20%20declare%20-A%20ofport_requests%0A%20%20%20%20for%20interface_name%20in%20%22%24%7B!INTERFACES%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20%20%20%20%20ofport_requests%5B%24%7BINTERFACES%5B%24interface_name%5D%7D%5D%3D%24%7BINTERFACES%5B%24interface_name%5D%7D%0A%20%20%20%20done%0A%0A%20%20%20%20%23%20Get%20the%20current%20ofport%20number%20assignment%0A%20%20%20%20local%20current_ofport%3D%24(ovs-vsctl%20get%20Interface%20%22%24%7BINTERFACE_NAME%7D%22%20ofport)%0A%0A%20%20%20%20%23%20If%20the%20current%20ofport%20number%20is%20still%20free%2C%20use%20it%0A%20%20%20%20if%20!%20%5B%20%22%24%7Bofport_requests%5B%24current_ofport%5D%2Ba%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%24current_ofport%0A%20%20%20%20%20%20%20%20return%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20If%20the%20current%20ofport%20number%20is%20not%20free%2C%20return%20the%20lowest%20free%20entry%0A%20%20%20%20i%3D0%0A%20%20%20%20for%20i%20in%20%7B1..65000%7D%3B%20do%0A%20%20%20%20%20%20%20%20if%20!%20%5B%20%22%24%7Bofport_requests%5B%24i%5D%2Ba%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20echo%20%24i%0A%20%20%20%20%20%20%20%20%20%20%20%20return%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20done%0A%0A%20%20%20%20%23%20if%20we%20still%20cannot%20find%20an%20ID%2C%20exit%20with%20an%20error%0A%20%20%20%20echo%20%22Impossible%20to%20find%20an%20ofport%20ID%20for%20interface%20%24%7BINTERFACE_NAME%7D%22%20%3E%262%0A%20%20%20%20exit%201%0A%7D%0A%0A%23%20If%20INTERFACES%5BINTERFACE_NAME%5D%20exists%2C%20use%20that%20value%0A%23%20If%20INTERFACES%5BINTERFACE_NAME%5D%20does%20not%20exists%2C%20use%20the%20value%20from%20get_interface_ofport_request%0Aif%20!%20%5B%20%22%24%7BINTERFACES%5B%24INTERFACE_NAME%5D%2Ba%7D%22%20%5D%3B%20then%0A%20%20%20%20INTERFACES%5B%24INTERFACE_NAME%5D%3D%24(get_interface_ofport_request)%0Afi%0A%23%20Set%20ofport_request%20according%20to%20INTERFACES%5BINTERFACE_NAME%5D%0Aovs-vsctl%20set%20Interface%20%22%24%7BINTERFACE_NAME%7D%22%20ofport_request%3D%24%7BINTERFACES%5B%24INTERFACE_NAME%5D%7D%0A%0A%23%20Save%20current%20state%20of%20INTERFACES%20to%20CONFIGURATION_FILE%0Adeclare%20-p%20INTERFACES%20%3E%7C%20%22%24%7BCONFIGURATION_FILE%7D%22%0A
          mode: 493
          overwrite: true
          path: /etc/NetworkManager/dispatcher.d/pre-up.d/10-ofport-request.sh
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%0A%23%20Extract%20Podman%20version%20and%20determine%20the%20signature%20policy%0A%2Fusr%2Fbin%2Fpodman%20-v%20%7C%20%2Fbin%2Fawk%20'%7B%0A%20%20%20%20split(%243%2C%20version%2C%20%22-%22)%3B%0A%20%20%20%20clean_version%20%3D%20version%5B1%5D%3B%0A%0A%20%20%20%20split(clean_version%2C%20current%2C%20%2F%5C.%2F)%3B%0A%20%20%20%20split(%224.4.1%22%2C%20target%2C%20%2F%5C.%2F)%3B%0A%0A%20%20%20%20for%20(i%20%3D%201%3B%20i%20%3C%3D%203%3B%20i%2B%2B)%20%7B%0A%20%20%20%20%20%20%20%20if%20((current%5Bi%5D%20%2B%200)%20%3C%20(target%5Bi%5D%20%2B%200))%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20print%20%22--signature-policy%20%2Fetc%2Fmachine-config-daemon%2Fpolicy-for-old-podman.json%22%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20exit%3B%0A%20%20%20%20%20%20%20%20%7D%20else%20if%20((current%5Bi%5D%20%2B%200)%20%3E%20(target%5Bi%5D%20%2B%200))%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20exit%3B%0A%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%7D%0A%7D'%20%3E%20%2Ftmp%2Fpodman_policy_args%0A
          mode: 493
          overwrite: true
          path: /etc/machine-config-daemon/generate_podman_policy_args.sh
        - contents:
            source: data:,%7B%22auths%22%3A%7B%22cloud.openshift.com%22%3A%7B%22auth%22%3A%22b3BlbnNoaWZ0LXJlbGVhc2UtZGV2K29jbV9hY2Nlc3NfOTRmZDViZTMwOTM3NGU5NDlkM2Q5NzhmOTQzZGFlYTI6TDc0UlozWjNEUUM1U0RFMjBUUUU3UDRZR1RNSDRIRUdMUkMySzk3MjJMSE1PMlBPVUNaUDJFVVo0UDc1N1RLQw%3D%3D%22%2C%22email%22%3A%22jgoldberg%40allcovered.com%22%7D%2C%22quay.io%22%3A%7B%22auth%22%3A%22b3BlbnNoaWZ0LXJlbGVhc2UtZGV2K29jbV9hY2Nlc3NfOTRmZDViZTMwOTM3NGU5NDlkM2Q5NzhmOTQzZGFlYTI6TDc0UlozWjNEUUM1U0RFMjBUUUU3UDRZR1RNSDRIRUdMUkMySzk3MjJMSE1PMlBPVUNaUDJFVVo0UDc1N1RLQw%3D%3D%22%2C%22email%22%3A%22jgoldberg%40allcovered.com%22%7D%2C%22registry.connect.redhat.com%22%3A%7B%22auth%22%3A%22fHVoYy1wb29sLTljZTJiZWU4LTUwYWQtNDVlNC04NDExLTNkNjQ1NWNkODI1NjpleUpoYkdjaU9pSlNVelV4TWlKOS5leUp6ZFdJaU9pSTNaakppTldOallXWXhZVEEwWXpZMVlUSTFaRGN6TjJSa05UVXlNbVJqWWlKOS5NZHFkUUgzenYyMHFzQ0dfR2hGYy1WSzFRNGRsOW05TFhqcmhQNjNjUDh0dDVGX25Wc1U5NGxlcmVVSEQ4R1FXRUxDZlIzeE5HQ2dOSXFPNWUyNC02U3NGOFNTQV9RSnZIODVzLTBBWXlWMHY2QnJxV21CRHNLSWdnSzE2SFhWUzd4cTlSZ05hN200RFRMdUF2RUdtVkRSQ05VUVNFN1FMTWMxaUVhSVI4RVdrT0pPUklQd3hQM3YyUDlsTHpSRWtKYl82WVRjUWRjQUR3T0d1OWkzUHIwMWRHX1d4QU90NkFxcFZBX0JSaHRhNFRjWTFwSHk1bXBlWWVIVnE3Q3hzZWFRV3FzR01Oc0lObkFFNGdjV0MyekVXVl9NZHpIQXVad203WWsxMjg5VVhfYnhVMWhDUkVzdG5zdGdCSERheFRpSTFjalZSZkJ4X05hb0RMU01GVXBzNmlDVXhTTUxzVmc3Mi04LVJHal9nVmMxRDZPNjJkODJoakdaaW5HekJsendzMkZLYlFnNDRjb1VWcWpDdUMwdktCdVJRbDhkX0taVGZTWFVSTS0wOE91YjBNdDRIMjVjZmx6bjNERWdDcUtlSVlUYVdMS3ZranRKVy1MaGdLRjlDUHFqWmozUjhwN2xja2ZkR0lPbHRvY0hZY0xXVlM3QURjdmRNaWVLa3p5STRHb2RPamp2NU5OVF9UWDdjRHBRRVdWUnlENkxkOElXODA4SHVoSmtfa2R0MWVDSkxSTTVUdFBSRHVxZ3UwODlqcWM4WXRVWFhfcm9KcFhoSE5iMUlnekZTdFJqZktTSVJ6YTdlV2g4VWxvRmNwNXJZOV9VeDFTaFVnZ3JlQXFmQ1Y4NXF5Wjlya2RibVNZUE5PRVdzTmtUeGJoY0Q4YWpkYlJrWkFCRQ%3D%3D%22%2C%22email%22%3A%22jgoldberg%40allcovered.com%22%7D%2C%22registry.redhat.io%22%3A%7B%22auth%22%3A%22fHVoYy1wb29sLTljZTJiZWU4LTUwYWQtNDVlNC04NDExLTNkNjQ1NWNkODI1NjpleUpoYkdjaU9pSlNVelV4TWlKOS5leUp6ZFdJaU9pSTNaakppTldOallXWXhZVEEwWXpZMVlUSTFaRGN6TjJSa05UVXlNbVJqWWlKOS5NZHFkUUgzenYyMHFzQ0dfR2hGYy1WSzFRNGRsOW05TFhqcmhQNjNjUDh0dDVGX25Wc1U5NGxlcmVVSEQ4R1FXRUxDZlIzeE5HQ2dOSXFPNWUyNC02U3NGOFNTQV9RSnZIODVzLTBBWXlWMHY2QnJxV21CRHNLSWdnSzE2SFhWUzd4cTlSZ05hN200RFRMdUF2RUdtVkRSQ05VUVNFN1FMTWMxaUVhSVI4RVdrT0pPUklQd3hQM3YyUDlsTHpSRWtKYl82WVRjUWRjQUR3T0d1OWkzUHIwMWRHX1d4QU90NkFxcFZBX0JSaHRhNFRjWTFwSHk1bXBlWWVIVnE3Q3hzZWFRV3FzR01Oc0lObkFFNGdjV0MyekVXVl9NZHpIQXVad203WWsxMjg5VVhfYnhVMWhDUkVzdG5zdGdCSERheFRpSTFjalZSZkJ4X05hb0RMU01GVXBzNmlDVXhTTUxzVmc3Mi04LVJHal9nVmMxRDZPNjJkODJoakdaaW5HekJsendzMkZLYlFnNDRjb1VWcWpDdUMwdktCdVJRbDhkX0taVGZTWFVSTS0wOE91YjBNdDRIMjVjZmx6bjNERWdDcUtlSVlUYVdMS3ZranRKVy1MaGdLRjlDUHFqWmozUjhwN2xja2ZkR0lPbHRvY0hZY0xXVlM3QURjdmRNaWVLa3p5STRHb2RPamp2NU5OVF9UWDdjRHBRRVdWUnlENkxkOElXODA4SHVoSmtfa2R0MWVDSkxSTTVUdFBSRHVxZ3UwODlqcWM4WXRVWFhfcm9KcFhoSE5iMUlnekZTdFJqZktTSVJ6YTdlV2g4VWxvRmNwNXJZOV9VeDFTaFVnZ3JlQXFmQ1Y4NXF5Wjlya2RibVNZUE5PRVdzTmtUeGJoY0Q4YWpkYlJrWkFCRQ%3D%3D%22%2C%22email%22%3A%22jgoldberg%40allcovered.com%22%7D%7D%7D%0A
          mode: 384
          overwrite: true
          path: /var/lib/kubelet/config.json
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-eo%20pipefail%0A%0Afunction%20pull_baremetal_runtime_cfg_image%20%7B%0A%20%20%20%20%23%20By%20default%20podman%20retries%20to%20pull%20an%20image%203%20times%20with%201%20second%20back-off.%20It%20is%20not%20configurable.%20For%20this%0A%20%20%20%20%23%20reason%20we%20are%20implementing%20our%20own%20logic%20of%20pulling%20image%20and%20retrying%20indefinitely.%0A%20%20%20%20%23%20Ref.%3A%20https%3A%2F%2Fgithub.com%2Fcontainers%2Fcommon%2Fblob%2Fe028741ef77fdfa3ae261b9d23cdd50253d586c4%2Flibimage%2Fcopier.go%23L27-L30%0A%0A%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Checking%20if%20baremetal%20runtime%20cfg%20image%20already%20exists%22%0A%20%20%20%20if%20!%20%2Fusr%2Fbin%2Fpodman%20image%20exists%20%22quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A93e7b8c870261726d44bddc7ba0a702d3720d1838141dac837fb8c3be7c6e1a1%22%3B%20then%0A%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Starting%20download%20of%20baremetal%20runtime%20cfg%20image%22%0A%20%20%20%20%20%20while%20!%20%2Fusr%2Fbin%2Fpodman%20pull%20--authfile%20%2Fvar%2Flib%2Fkubelet%2Fconfig.json%20%22quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A93e7b8c870261726d44bddc7ba0a702d3720d1838141dac837fb8c3be7c6e1a1%22%3B%20do%20sleep%201%3B%20done%0A%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Download%20of%20baremetal%20runtime%20cfg%20image%20completed%22%0A%20%20%20%20else%0A%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Image%20exists%2C%20no%20need%20to%20download%22%0A%20%20%20%20fi%0A%7D%0A%0Afunction%20resolv_prepender%20%7B%0A%20%20%20%20%20%20%20%20%23%20In%20DHCP%20connections%2C%20the%20resolv.conf%20content%20may%20be%20late%2C%20thus%20we%20wait%20for%20nameservers%0A%20%20%20%20%20%20%20%20while%20!%20grep%20nameserver%20%2Fvar%2Frun%2FNetworkManager%2Fresolv.conf%3B%20do%0A%20%20%20%20%20%20%20%20%20%20%20%20%3E%262%20echo%20%20%22NM%20resolv-prepender%3A%20NM%20resolv.conf%20still%20empty%20of%20nameserver%22%0A%20%20%20%20%20%20%20%20%20%20%20%20sleep%200.5%0A%20%20%20%20%20%20%20%20done%0A%0A%20%20%20%20%20%20%20%20%23%20Ensure%20resolv.conf%20exists%20and%20contains%20nameservers%20before%20we%20try%20to%20pull%20image%20or%20run%20podman%0A%20%20%20%20%20%20%20%20if%20%5B%5B%20!%20-e%20%2Fetc%2Fresolv.conf%20%5D%5D%20%7C%7C%20!%20grep%20-q%20nameserver%20%2Fetc%2Fresolv.conf%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20cp%20%2Fvar%2Frun%2FNetworkManager%2Fresolv.conf%20%2Fetc%2Fresolv.conf%0A%20%20%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20%20%20%23%20Ensure%20baremetalRuntimeCfgImage%20is%20pulled%20in%20a%20reliable%20way%20before%20trying%20to%20use%20it%0A%20%20%20%20%20%20%20%20%23%20in%20the%20subsequent%20code%0A%20%20%20%20%20%20%20%20pull_baremetal_runtime_cfg_image%0A%0A%20%20%20%20%20%20%20%20NAMESERVER_IP%3D%22%24(%2Fusr%2Fbin%2Fpodman%20run%20--rm%20%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20--authfile%20%2Fvar%2Flib%2Fkubelet%2Fconfig.json%20%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20--net%3Dhost%20%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A93e7b8c870261726d44bddc7ba0a702d3720d1838141dac837fb8c3be7c6e1a1%20%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20node-ip%20%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20show%20%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%2210.100.0.50%22%20%20%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%2210.100.0.51%22%20)%22%0A%20%20%20%20%20%20%20%20DOMAINS%3D%22%24%7BIP4_DOMAINS%3A-%7D%20%24%7BIP6_DOMAINS%3A-%7D%20comp-poc-rh01.rhpoc.int%22%0A%20%20%20%20%20%20%20%20if%20%5B%5B%20-n%20%22%24NAMESERVER_IP%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20KNICONFDONEPATH%3D%22%2Frun%2Fresolv-prepender-kni-conf-done%22%0A%20%20%20%20%20%20%20%20%20%20%20%20if%20systemctl%20-q%20is-enabled%20systemd-resolved%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Configure%20for%20OKD%20domain%20and%20local%20IP%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20mkdir%20-p%20%2Fetc%2Fsystemd%2Fresolved.conf.d%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20KNICONFTMPPATH%3D%22%24(mktemp)%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20KNICONFPATH%3D%22%2Fetc%2Fsystemd%2Fresolved.conf.d%2F60-kni.conf%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20echo%20%22%5BResolve%5D%22%20%3E%20%22%24%7BKNICONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20echo%20%22DNS%3D%24NAMESERVER_IP%22%20%3E%3E%20%22%24%7BKNICONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20echo%20%22Domains%3D%24%7BDOMAINS%7D%22%20%3E%3E%20%22%24%7BKNICONFTMPPATH%7D%22%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20If%20KNI%20conf%20is%20not%20created%20or%20doesn't%20match%20what%20is%20generated%20or%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20if%20we%20haven't%20completed%20a%20full%20update%20-%20create%20or%20update%20it%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20%5B%5B%20!%20-f%20%22%24%7BKNICONFPATH%7D%22%20%5D%5D%20%7C%7C%20%5B%5B%20!%20-f%20%22%24%7BKNICONFDONEPATH%7D%22%20%5D%5D%20%7C%7C%20!%20cmp%20--silent%20%22%24%7BKNICONFPATH%7D%22%20%22%24%7BKNICONFTMPPATH%7D%22%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Creating%2Fupdating%20%2Fetc%2Fsystemd%2Fresolved.conf.d%2F60-kni.conf%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Remove%20the%20done%20file%20flag%20before%20writing%20the%20config%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20This%20would%20guard%20against%20interruptions%20and%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20prevent%20double%20restart%20of%20systemd-resolved%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20rm%20-f%20%22%24%7BKNICONFDONEPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Copy%20tmp%20file%20contents%20to%20preserve%20permissions%20and%20SELinux%20label%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20cat%20%22%24%7BKNICONFTMPPATH%7D%22%20%3E%20%22%24%7BKNICONFPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20%5B%5B%20!%20-f%20%22%24%7BKNICONFDONEPATH%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20systemctl%20-q%20is-active%20systemd-resolved%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Restarting%20systemd-resolved%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20systemctl%20restart%20systemd-resolved%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20touch%20%22%24%7BKNICONFDONEPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20rm%20-rf%20%22%24%7BKNICONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Prepending%20'nameserver%20%24NAMESERVER_IP'%20to%20%2Fetc%2Fresolv.conf%20(other%20nameservers%20from%20%2Fvar%2Frun%2FNetworkManager%2Fresolv.conf)%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20RESOLVCONFTMPPATH%3D%22%24(mktemp)%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20sed%20-e%20%22%2FGenerated%20by%2Fc%23%20Generated%20by%20KNI%20resolv%20prepender%20NM%20dispatcher%20script%22%20%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%2Fvar%2Frun%2FNetworkManager%2Fresolv.conf%20%3E%20%22%24%7BRESOLVCONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20sed%20-i%20%220%2C%2F%5Enameserver.*%2Fs%2F%2Fnameserver%20%24NAMESERVER_IP%5Cn%5C0%2F%22%20%22%24%7BRESOLVCONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20!%20grep%20-q%20search%20%22%24%7BRESOLVCONFTMPPATH%7D%22%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Make%20sure%20we%20have%20a%20search%20entry%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20echo%20%22search%20comp-poc-rh01.rhpoc.int%22%20%3E%3E%20%22%24%7BRESOLVCONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Make%20sure%20cluster%20domain%20is%20first%20in%20the%20search%20list%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20sed%20-i%20%22s%2F%5Esearch%20%5C(.*%5C)%2Fsearch%20comp-poc-rh01.rhpoc.int%20%5C1%2F%22%20%22%24%7BRESOLVCONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Remove%20duplicate%20cluster%20domain%20entries%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20sed%20-i%20%22s%2F%5C(search%20comp-poc-rh01.rhpoc.int.*%5C)%20comp-poc-rh01.rhpoc.int%5C(%20.*%5C%7C%24%5C)%2F%5C1%5C2%2F%22%20%22%24%7BRESOLVCONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Only%20leave%20the%20first%203%20nameservers%20in%20%2Fetc%2Fresolv.conf%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20sed%20-i%20'%3Aa%20%24!%7BN%3B%20ba%7D%3B%20s%2F%5C(%5E%5C%7C%5Cn%5C)nameserver%2F%5Cn%23%20nameserver%2F4g'%20%22%24%7BRESOLVCONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Only%20touch%20existing%20resolv.conf%20if%20files%20actually%20differ%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20!%20cmp%20-s%20%22%24%7BRESOLVCONFTMPPATH%7D%22%20%2Fetc%2Fresolv.conf%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20chmod%20644%20%22%24%7BRESOLVCONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20mv%20-Zf%20%22%24%7BRESOLVCONFTMPPATH%7D%22%20%2Fetc%2Fresolv.conf%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Workaround%20for%20bz%201929160.%20Reload%20NetworkManager%20to%20force%20it%20to%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20re-run%20the%20lookup%20of%20the%20hostname%20now%20that%20we%20know%20we%20have%20DNS%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20servers%20configured%20correctly%20in%20resolv.conf.%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20nmcli%20general%20reload%20dns-rc%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20touch%20%22%24%7BKNICONFDONEPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20rm%20-rf%20%22%24%7BRESOLVCONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20fi%0A%7D%0A%0Aresolv_prepender%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/resolv-prepender.sh
        - contents:
            source: data:,%23%20Needed%20by%20the%20OpenShift%20SDN.%20See%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1758552%0Anet.ipv4.conf.all.arp_announce%20%3D%202%0A
          mode: 420
          overwrite: true
          path: /etc/sysctl.d/arp.conf
        - contents:
            source: data:,%23%20See%3A%20rhbz%231384746%2C%20OCPBUGS-24012%0Anet.ipv4.neigh.default.gc_thresh1%3D8192%0Anet.ipv4.neigh.default.gc_thresh2%3D32768%0Anet.ipv4.neigh.default.gc_thresh3%3D65536%0Anet.ipv6.neigh.default.gc_thresh1%3D8192%0Anet.ipv6.neigh.default.gc_thresh2%3D32768%0Anet.ipv6.neigh.default.gc_thresh3%3D65536%0A
          mode: 420
          overwrite: true
          path: /etc/sysctl.d/gc-thresh.conf
        - contents:
            source: data:,%0Afs.inotify.max_user_watches%20%3D%2065536%0Afs.inotify.max_user_instances%20%3D%208192%0A
          mode: 420
          overwrite: true
          path: /etc/sysctl.d/inotify.conf
        - contents:
            source: data:,vm.unprivileged_userfaultfd%20%3D%201
          mode: 420
          overwrite: true
          path: /etc/sysctl.d/enable-userfaultfd.conf
        - contents:
            source: data:,%23%20Needed%20for%20OpenShift%20Logging%20(ElasticSearch).%20See%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1793714%0Avm.max_map_count%20%3D%20262144%0A
          mode: 420
          overwrite: true
          path: /etc/sysctl.d/vm-max-map.conf
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-euo%20pipefail%0A%0A%23%20First%2C%20we%20need%20to%20wait%20until%20DHCP%20finishes%20and%20the%20node%20has%20a%20non-%60localhost%60%0A%23%20hostname%20before%20%60kubelet.service%60%20starts.%0A%23%20That's%20the%20%60--wait%60%20argument%20as%20used%20by%20%60node-valid-hostname.service%60.%0A%23%0A%23%20Second%2C%20on%20GCP%20specifically%20we%20truncate%20the%20hostname%20if%20it's%20%3E63%20characters.%0A%23%20That's%20%60gcp-hostname.service%60.%0A%0A%23%20Block%20indefinitely%20until%20the%20host%20gets%20a%20non-localhost%20name.%0A%23%20Note%20node-valid-hostname.service%20uses%20systemd%20to%20abort%20if%20this%20takes%20too%20long.%0Await_localhost()%20%7B%0A%20%20%20%20echo%20%22waiting%20for%20non-localhost%20hostname%20to%20be%20assigned%22%0A%20%20%20%20while%20%5B%5B%20%22%24(%3C%20%2Fproc%2Fsys%2Fkernel%2Fhostname)%22%20%3D~%20(localhost%7Clocalhost.localdomain)%20%5D%5D%3B%0A%20%20%20%20do%0A%20%20%20%20%20%20%20%20sleep%201%0A%20%20%20%20done%0A%20%20%20%20echo%20%22node%20identified%20as%20%24(%3C%2Fproc%2Fsys%2Fkernel%2Fhostname)%22%0A%20%20%20%20echo%20%22saving%20hostname%20to%20prevent%20NetworkManager%20from%20ever%20unsetting%20it%22%0A%20%20%20%20hostnamectl%20set-hostname%20--static%20--transient%20%24(%3C%2Fproc%2Fsys%2Fkernel%2Fhostname)%0A%20%20%20%20exit%200%0A%7D%0A%0Aset_gcp_hostname()%20%7B%0A%20%20%20%20%2Fusr%2Fbin%2Fafterburn%20--provider%20gcp%20--hostname%3D%2Frun%2Fafterburn.hostname%0A%0A%20%20%20%20local%20host_name%3D%24(cat%20%2Frun%2Fafterburn.hostname)%0A%20%20%20%20local%20type_arg%3D%22transient%22%0A%0A%20%20%20%20%23%20%2Fetc%2Fhostname%20is%20used%20for%20static%20hostnames%20and%20is%20authoritative.%0A%20%20%20%20%23%20This%20will%20check%20to%20make%20sure%20that%20the%20static%20hostname%20is%20the%0A%20%20%20%20%23%20less%20than%20or%20equal%20to%2063%20characters%20in%20length.%0A%20%20%20%20if%20%5B%20-f%20%2Fetc%2Fhostname%20%5D%20%26%26%20%5B%20%22%24(cat%20%2Fetc%2Fhostname%20%7C%20wc%20-m)%22%20-gt%200%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20etc_name%3D%22%24(%3C%20%2Fetc%2Fhostname)%22%0A%20%20%20%20%20%20%20%20type_arg%3D%22static%22%0A%20%20%20%20%20%20%20%20if%20%5B%20%22%24%7Betc_name%7D%22%20!%3D%20%22%24%7Bhost_name%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20echo%20%22%2Fetc%2Fhostname%20is%20set%20to%20%24%7Betc_name%7D%20but%20does%20not%20match%20%24%7Bhost_name%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20echo%20%22using%20%2Fetc%2Fhostname%20as%20the%20authoritative%20name%22%0A%20%20%20%20%20%20%20%20%20%20%20%20host_name%3D%22%24%7Betc_name%7D%22%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Only%20mutate%20the%20hostname%20if%20the%20length%20is%20longer%20than%2063%20characters.%20The%0A%20%20%20%20%23%20hostname%20will%20be%20the%20lesser%20of%2063%20characters%20after%20the%20first%20dot%20in%20the%0A%20%20%20%20%23%20FQDN.%20%20This%20algorithm%20is%20only%20known%20to%20work%20in%20GCP%2C%20and%20hence%20is%20only%0A%20%20%20%20%23%20executed%20in%20GCP.%0A%20%20%20%20if%20%5B%20%22%24%7B%23host_name%7D%22%20-gt%2063%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20alt_name%3D%24(printf%20%22%24%7Bhost_name%7D%22%20%7C%20cut%20-f1%20-d'.'%20%7C%20cut%20-c%20-63)%0A%20%20%20%20%20%20%20%20echo%20%22%24%7Bhost_name%7D%20is%20longer%20than%2063%20characters%2C%20using%20truncated%20hostname%22%0A%20%20%20%20%20%20%20%20host_name%3D%22%24%7Balt_name%7D%22%0A%20%20%20%20fi%0A%20%20%20%20echo%20%22setting%20%24%7Btype_arg%7D%20hostname%20to%20%24%7Bhost_name%7D%22%0A%20%20%20%20%2Fbin%2Fhostnamectl%20%22--%24%7Btype_arg%7D%22%20set-hostname%20%22%24%7Bhost_name%7D%22%0A%20%20%20%20exit%200%0A%7D%0A%0Aset_openstack_hostname()%20%7B%0A%20%20%20%20%23%20Read%20metadata%20written%20by%20afterburn%20service%0A%20%20%20%20.%20%2Frun%2Fmetadata%2Fafterburn%0A%0A%20%20%20%20%23%20node-valid-hostname%20sets%20persistent%20hostname%20from%20%2Fproc%2Fsys%2Fkernel%2Fhostname%0A%20%20%20%20echo%20%22%24AFTERBURN_OPENSTACK_HOSTNAME%22%20%3E%20%2Fproc%2Fsys%2Fkernel%2Fhostname%0A%7D%0A%0Aset_powervs_hostname()%20%7B%0A%20%20%20%20%23%20Read%20metadata%20written%20by%20afterburn%20service%0A%20%20%20%20.%20%2Frun%2Fmetadata%2Fafterburn%0A%0A%20%20%20%20%23%20node-valid-hostname%20sets%20persistent%20hostname%20from%20%2Fproc%2Fsys%2Fkernel%2Fhostname%0A%20%20%20%20echo%20%22%24AFTERBURN_POWERVS_LOCAL_HOSTNAME%22%20%3E%20%2Fproc%2Fsys%2Fkernel%2Fhostname%0A%7D%0A%0Aarg%3D%24%7B1%7D%3B%20shift%3B%0Acase%20%22%24%7Barg%7D%22%20in%0A%20%20%20%20--wait)%20wait_localhost%3B%3B%0A%20%20%20%20--gcp)%20set_gcp_hostname%3B%3B%0A%20%20%20%20--openstack)%20set_openstack_hostname%3B%3B%0A%20%20%20%20--powervs)%20set_powervs_hostname%3B%3B%0A%20%20%20%20*)%20echo%20%22Unhandled%20arg%20%24arg%22%3B%20exit%201%0Aesac%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/mco-hostname
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%0Aset%20-eou%20pipefail%0A%0A%23%20context%0Aintapi%3D%24(oc%20get%20infrastructures.config.openshift.io%20cluster%20-o%20%22jsonpath%3D%7B.status.apiServerInternalURI%7D%22)%0Acontext%3D%22%24(oc%20config%20current-context)%22%0A%23%20cluster%0Acluster%3D%22%24(oc%20config%20view%20-o%20%22jsonpath%3D%7B.contexts%5B%3F(%40.name%3D%3D%5C%22%24context%5C%22)%5D.context.cluster%7D%22)%22%0Aserver%3D%22%24(oc%20config%20view%20-o%20%22jsonpath%3D%7B.clusters%5B%3F(%40.name%3D%3D%5C%22%24cluster%5C%22)%5D.cluster.server%7D%22)%22%0A%23%20token%0Aca_crt_data%3D%22%24(oc%20get%20secret%20-n%20openshift-machine-config-operator%20node-bootstrapper-token%20-o%20%22jsonpath%3D%7B.data.ca%5C.crt%7D%22%20%7C%20base64%20--decode)%22%0Anamespace%3D%22%24(oc%20get%20secret%20-n%20openshift-machine-config-operator%20node-bootstrapper-token%20%20-o%20%22jsonpath%3D%7B.data.namespace%7D%22%20%7C%20base64%20--decode)%22%0Atoken%3D%22%24(oc%20get%20secret%20-n%20openshift-machine-config-operator%20node-bootstrapper-token%20-o%20%22jsonpath%3D%7B.data.token%7D%22%20%7C%20base64%20--decode)%22%0A%0Aexport%20KUBECONFIG%3D%22%24(mktemp)%22%0Akubectl%20config%20set-credentials%20%22kubelet%22%20--token%3D%22%24token%22%20%3E%2Fdev%2Fnull%0Aca_crt%3D%22%24(mktemp)%22%3B%20echo%20%22%24ca_crt_data%22%20%3E%20%24ca_crt%0Akubectl%20config%20set-cluster%20%24cluster%20--server%3D%22%24intapi%22%20--certificate-authority%3D%22%24ca_crt%22%20--embed-certs%20%3E%2Fdev%2Fnull%0Akubectl%20config%20set-context%20kubelet%20--cluster%3D%22%24cluster%22%20--user%3D%22kubelet%22%20%3E%2Fdev%2Fnull%0Akubectl%20config%20use-context%20kubelet%20%3E%2Fdev%2Fnull%0Acat%20%22%24KUBECONFIG%22%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/recover-kubeconfig.sh
        - contents:
            source: data:,
          mode: 493
          overwrite: true
          path: /etc/kubernetes/kubelet-plugins/volume/exec/.dummy
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%23%20Workaround%3A%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1941714%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1935539%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1987108%0A%0Adriver%3D%24(nmcli%20-t%20-m%20tabular%20-f%20general.driver%20dev%20show%20%22%24%7BDEVICE_IFACE%7D%22)%0A%0Aif%20%5B%5B%20%22%242%22%20%3D%3D%20%22up%22%20%26%26%20%22%24%7Bdriver%7D%22%20%3D%3D%20%22vmxnet3%22%20%5D%5D%3B%20then%0A%20%20logger%20-s%20%2299-vsphere-disable-tx-udp-tnl%20triggered%20by%20%24%7B2%7D%20on%20device%20%24%7BDEVICE_IFACE%7D.%22%0A%20%20ethtool%20-K%20%24%7BDEVICE_IFACE%7D%20tx-udp_tnl-segmentation%20off%0A%20%20ethtool%20-K%20%24%7BDEVICE_IFACE%7D%20tx-udp_tnl-csum-segmentation%20off%0A%20%20ethtool%20-K%20%24%7BDEVICE_IFACE%7D%20tx-checksum-ip-generic%20off%0Afi%0A
          mode: 484
          overwrite: true
          path: /etc/NetworkManager/dispatcher.d/99-vsphere-disable-tx-udp-tnl
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%0Auntil%20%5B%20-e%20%2Frun%2Fnodeip-configuration%2Fbr-ex-up%20%5D%0Ado%0A%20%20sleep%201%0Adone%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/wait-for-br-ex-up.sh
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-x%0A%0Aif%20%5B%20!%20-e%20%22%2Fetc%2Fipsec.d%2Fopenshift.conf%22%20%5D%3B%20then%0A%20%20exit%200%0Afi%0A%0A%23%20Modify%20existing%20IPsec%20connection%20entries%20with%20%22auto%3Dstart%22%0A%23%20option%20and%20restart%20ipsec%20systemd%20service.%20This%20helps%20to%0A%23%20establish%20IKE%20SAs%20for%20the%20existing%20IPsec%20connections%20with%0A%23%20peer%20nodes.%20This%20option%20will%20be%20deleted%20from%20connections%0A%23%20once%20ovs-monitor-ipsec%20process%20spinned%20up%20on%20the%20node%20by%0A%23%20ovn-ipsec-host%20pod%2C%20but%20still%20it%20won't%20reestablish%20IKE%20SAs%0A%23%20again%20with%20peer%20nodes%2C%20so%20it%20shouldn't%20be%20a%20problem.%0Aif%20!%20grep%20-q%20%22auto%3Dstart%22%20%2Fetc%2Fipsec.d%2Fopenshift.conf%3B%20then%0A%20%20sed%20-i%20'%2F%5E.*conn%20ovn.*%24%2Fa%5C%20%20%20%20auto%3Dstart'%20%2Fetc%2Fipsec.d%2Fopenshift.conf%0Afi%0Achroot%20%2Fproc%2F1%2Froot%20ipsec%20restart%0A%0A%23%20Wait%20for%20upto%2060s%20to%20get%20IPsec%20SAs%20to%20establish%20with%20peer%20nodes.%0Atimeout%3D60%0Aelapsed%3D0%0Adesiredconn%3D%22%22%0Aestablishedsa%3D%22%22%0Awhile%20%5B%5B%20%24elapsed%20-lt%20%24timeout%20%5D%5D%3B%20do%0A%20%20desiredconn%3D%24(grep%20-E%20'%5E%5Cs*conn%5Cs%2B'%20%2Fetc%2Fipsec.d%2Fopenshift.conf%20%7C%20grep%20-v%20'%25default'%20%7C%20awk%20'%7Bprint%20%242%7D'%20%7C%20tr%20'%20'%20'%5Cn'%20%7C%20sort%20%7C%20tr%20'%5Cn'%20'%20')%0A%20%20establishedsa%3D%24(ipsec%20showstates%20%7C%20grep%20STATE_V2_ESTABLISHED_CHILD_SA%20%7C%20grep%20-o%20'%22%5B%5E%22%5D*%22'%20%7C%20sed%20's%2F%22%2F%2Fg'%20%7C%20tr%20'%20'%20'%5Cn'%20%7C%20sort%20%7C%20uniq%20%7C%20tr%20'%5Cn'%20'%20')%0A%20%20if%20%5B%20%22%24desiredconn%22%20%3D%3D%20%22%24establishedsa%22%20%5D%3B%20then%0A%20%20%20%20echo%20%22IPsec%20SAs%20are%20established%20for%20desired%20connections%20after%20%24%7Belapsed%7Ds%22%0A%20%20%20%20break%0A%20%20else%0A%20%20%20%20echo%20%22IPsec%20SAs%20are%20not%20established%20yet%2C%20total%20waited%20time%20%24%7Belapsed%7Ds%22%0A%20%20%20%20sleep%202s%0A%20%20fi%0A%20%20elapsed%3D%24((elapsed%20%2B%202))%0Adone%0A%0Aif%20%5B%5B%20%24elapsed%20-ge%20%24timeout%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22Timed%20out%20waiting%2C%20some%20connections%20are%20not%20established%2C%20desired%20conns%20%24desiredconn%2C%20established%20conns%20%24establishedsa%22%0Afi%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/ipsec-connect-wait.sh
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-eux%0A%0Aif%20%5B%20!%20-e%20%2Fetc%2Fnmstate%2Fopenshift%2Fapplied%20%5D%3B%20then%0A%20%20%23%20No%20need%20to%20do%20this%20if%20no%20NMState%20configuration%20was%20applied%0A%20%20exit%200%0Afi%0A%0A%23%20This%20logic%20is%20borrowed%20from%20configure-ovs.sh%0A%23%20TODO%3A%20Find%20a%20platform-agnostic%20way%20to%20do%20this.%20It%20won't%20work%20on%20platforms%20where%0A%23%20nodeip-configuration%20is%20not%20used.%0Aip%3D%24(cat%20%2Frun%2Fnodeip-configuration%2Fprimary-ip)%0Aif%20%5B%5B%20%22%24%7Bip%7D%22%20%3D%3D%20%22%22%20%5D%5D%3B%20then%0A%20%20echo%20%22No%20ip%20to%20bind%20was%20found%22%0A%20%20exit%201%0Afi%0Awhile%20%3A%0Ado%0A%20%20random_port%3D%24(shuf%20-i%2050000-60000%20-n%201)%0A%20%20echo%20%22Trying%20to%20bind%20%24%7Bip%7D%20on%20port%20%24%7Brandom_port%7D%22%0A%20%20exit_code%3D%24(timeout%202s%20nc%20-l%20%22%24%7Bip%7D%22%20%24%7Brandom_port%7D%3B%20echo%20%24%3F)%0A%20%20if%20%5B%5B%20exit_code%20-eq%20124%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22Address%20bound%20successfully%22%0A%20%20%20%20exit%200%0A%20%20fi%0A%20%20sleep%2010%0Adone%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/wait-for-primary-ip.sh
        - contents:
            source: data:,unqualified-search-registries%20%3D%20%5B'registry.access.redhat.com'%2C%20'docker.io'%5D%0A
          mode: 420
          overwrite: true
          path: /etc/containers/registries.conf
        - contents:
            source: data:,%5Bcrio%5D%0Ainternal_wipe%20%3D%20true%0Ainternal_repair%20%3D%20true%0A%0A%5Bcrio.api%5D%0Astream_address%20%3D%20%22127.0.0.1%22%0Astream_port%20%3D%20%220%22%0A%0A%5Bcrio.runtime%5D%0Aselinux%20%3D%20true%0Aconmon%20%3D%20%22%22%0Aconmon_cgroup%20%3D%20%22pod%22%0Adefault_env%20%3D%20%5B%0A%20%20%20%20%22NSS_SDB_USE_CACHE%3Dno%22%2C%0A%5D%0Adefault_runtime%20%3D%20%22crun%22%0Alog_level%20%3D%20%22info%22%0Acgroup_manager%20%3D%20%22systemd%22%0Adefault_sysctls%20%3D%20%5B%0A%20%20%20%20%22net.ipv4.ping_group_range%3D0%202147483647%22%2C%0A%5D%0Ahooks_dir%20%3D%20%5B%0A%20%20%20%20%22%2Fetc%2Fcontainers%2Foci%2Fhooks.d%22%2C%0A%20%20%20%20%22%2Frun%2Fcontainers%2Foci%2Fhooks.d%22%2C%0A%20%20%20%20%22%2Fusr%2Fshare%2Fcontainers%2Foci%2Fhooks.d%22%2C%0A%5D%0Amanage_ns_lifecycle%20%3D%20true%0Aabsent_mount_sources_to_reject%20%3D%20%5B%0A%20%20%20%20%22%2Fetc%2Fhostname%22%2C%0A%5D%0Adrop_infra_ctr%20%3D%20true%0A%0A%5Bcrio.runtime.runtimes.runc%5D%0Aruntime_root%20%3D%20%22%2Frun%2Frunc%22%0Aallowed_annotations%20%3D%20%5B%0A%20%20%20%20%22io.containers.trace-syscall%22%2C%0A%20%20%20%20%22io.kubernetes.cri-o.Devices%22%2C%0A%20%20%20%20%22io.kubernetes.cri-o.LinkLogs%22%2C%0A%5D%0A%0A%5Bcrio.runtime.runtimes.crun%5D%0Aruntime_root%20%3D%20%22%2Frun%2Fcrun%22%0Aallowed_annotations%20%3D%20%5B%0A%20%20%20%20%22io.containers.trace-syscall%22%2C%0A%20%20%20%20%22io.kubernetes.cri-o.Devices%22%2C%0A%20%20%20%20%22io.kubernetes.cri-o.LinkLogs%22%2C%0A%5D%0A%23%20Based%20on%20https%3A%2F%2Fgithub.com%2Fcontainers%2Fcrun%2Fblob%2F27d7dd3a0%2FREADME.md%3Fplain%3D1%23L48%0Acontainer_min_memory%20%3D%20%22512KiB%22%0Adefault_annotations%20%3D%20%7B%22run.oci.systemd.subgroup%22%20%3D%20%22%22%7D%0A%0A%5Bcrio.runtime.workloads.openshift-builder%5D%0Aactivation_annotation%20%3D%20%22io.openshift.builder%22%0Aallowed_annotations%20%3D%20%5B%0A%20%20%22io.kubernetes.cri-o.userns-mode%22%2C%0A%20%20%22io.kubernetes.cri-o.Devices%22%0A%5D%0A%5Bcrio.runtime.workloads.openshift-builder.resources%5D%0A%0A%5Bcrio.image%5D%0Aglobal_auth_file%20%3D%20%22%2Fvar%2Flib%2Fkubelet%2Fconfig.json%22%0Apause_image%20%3D%20%22quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A2f61599219ee63c77391e05d2e02a8a5baae1c463d0ef965c49a5c470546db90%22%0Apause_image_auth_file%20%3D%20%22%2Fvar%2Flib%2Fkubelet%2Fconfig.json%22%0Apause_command%20%3D%20%22%2Fusr%2Fbin%2Fpod%22%0A%0A%5Bcrio.network%5D%0Anetwork_dir%20%3D%20%22%2Fetc%2Fkubernetes%2Fcni%2Fnet.d%2F%22%0Aplugin_dirs%20%3D%20%5B%0A%20%20%20%20%22%2Fvar%2Flib%2Fcni%2Fbin%22%2C%0A%20%20%20%20%22%2Fusr%2Flibexec%2Fcni%22%2C%0A%5D%0A%0A%5Bcrio.metrics%5D%0Aenable_metrics%20%3D%20true%0Ametrics_host%20%3D%20%22127.0.0.1%22%0Ametrics_port%20%3D%209537%0Ametrics_collectors%20%3D%20%5B%0A%20%20%22operations%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22operations_total%22%0A%20%20%22operations_latency_microseconds_total%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22operations_latency_seconds_total%22%0A%20%20%22operations_latency_microseconds%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22operations_latency_seconds%22%0A%20%20%22operations_errors%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22operations_errors_total%22%0A%20%20%22image_pulls_layer_size%22%2C%0A%20%20%22containers_oom_total%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22containers_oom_count_total%22%0A%20%20%22containers_oom%22%2C%0A%20%20%23%20Drop%20metrics%20with%20excessive%20label%20cardinality.%0A%20%20%23%20%22image_pulls_by_digest%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_pulls_bytes_total%22%0A%20%20%23%20%22image_pulls_by_name%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_pulls_bytes_total%22%0A%20%20%23%20%22image_pulls_by_name_skipped%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_pulls_skipped_bytes_total%22%0A%20%20%23%20%22image_pulls_failures%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_pulls_failure_total%22%0A%20%20%23%20%22image_pulls_successes%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_pulls_success_total%22%0A%20%20%23%20%22image_layer_reuse%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_layer_reuse_total%22%0A%20%20%22operations_total%22%2C%0A%20%20%22operations_latency_seconds_total%22%2C%0A%20%20%22operations_latency_seconds%22%2C%0A%20%20%22operations_errors_total%22%2C%0A%20%20%22image_pulls_bytes_total%22%2C%0A%20%20%22image_pulls_skipped_bytes_total%22%2C%0A%20%20%22image_pulls_success_total%22%2C%0A%20%20%22image_pulls_failure_total%22%2C%0A%20%20%22image_layer_reuse_total%22%2C%0A%20%20%22containers_oom_count_total%22%2C%0A%20%20%22processes_defunct%22%0A%5D%0A
          mode: 420
          overwrite: true
          path: /etc/crio/crio.conf.d/00-default
        - contents:
            source: data:,%7B%0A%20%20%20%20%22default%22%3A%20%5B%0A%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%22type%22%3A%20%22insecureAcceptAnything%22%0A%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%5D%2C%0A%20%20%20%20%22transports%22%3A%0A%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%22docker-daemon%22%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22%22%3A%20%5B%7B%22type%22%3A%22insecureAcceptAnything%22%7D%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20%20%20%7D%0A%7D%0A
          mode: 420
          overwrite: true
          path: /etc/machine-config-daemon/policy-for-old-podman.json
        - contents:
            source: data:,%7B%0A%20%20%20%20%22default%22%3A%20%5B%0A%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%22type%22%3A%20%22insecureAcceptAnything%22%0A%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%5D%2C%0A%20%20%20%20%22transports%22%3A%0A%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%22docker-daemon%22%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22%22%3A%20%5B%7B%22type%22%3A%22insecureAcceptAnything%22%7D%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20%20%20%7D%0A%7D
          mode: 420
          overwrite: true
          path: /etc/containers/policy.json
        - contents:
            source: data:,
          mode: 420
          overwrite: true
          path: /etc/kubernetes/cloud.conf
        - contents:
            source: data:,authorization%3A%0A%20%20static%3A%0A%20%20%20%20-%20resourceRequest%3A%20false%0A%20%20%20%20%20%20path%3A%20%2Fmetrics%0A%20%20%20%20%20%20verb%3A%20get%0A%20%20%20%20%20%20user%3A%0A%20%20%20%20%20%20%20%20name%3A%20system%3Aserviceaccount%3Aopenshift-monitoring%3Aprometheus-k8s
          mode: 420
          overwrite: true
          path: /etc/kubernetes/crio-metrics-proxy.cfg
        - contents:
            source: data:,apiVersion%3A%20v1%0Akind%3A%20Pod%0Ametadata%3A%0A%20%20name%3A%20kube-rbac-proxy-crio%0A%20%20namespace%3A%20openshift-machine-config-operator%0A%20%20annotations%3A%0A%20%20%20%20target.workload.openshift.io%2Fmanagement%3A%20'%7B%22effect%22%3A%20%22PreferredDuringScheduling%22%7D'%0A%20%20%20%20openshift.io%2Frequired-scc%3A%20privileged%0Aspec%3A%0A%20%20volumes%3A%0A%20%20-%20name%3A%20etc-kube%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fetc%2Fkubernetes%22%0A%20%20-%20name%3A%20var-lib-kubelet%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20hostNetwork%3A%20true%0A%20%20priorityClassName%3A%20system-cluster-critical%0A%20%20initContainers%3A%0A%20%20-%20name%3A%20setup%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3Ab6413e64e7d5885315b3cabc65c2af82135ee649b1664976b3d300884d302414%0A%20%20%20%20imagePullPolicy%3A%20IfNotPresent%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20var-lib-kubelet%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20command%3A%20%5B'%2Fbin%2Fbash'%2C%20'-ec'%5D%0A%20%20%20%20args%3A%0A%20%20%20%20-%20%7C%0A%20%20%20%20%20%20echo%20-n%20%22Waiting%20for%20kubelet%20key%20and%20certificate%20to%20be%20available%22%0A%20%20%20%20%20%20while%20%5B%20-n%20%22%24(test%20-e%20%2Fvar%2Flib%2Fkubelet%2Fpki%2Fkubelet-server-current.pem)%22%20%5D%20%3B%20do%0A%20%20%20%20%20%20%20%20echo%20-n%20%22.%22%0A%20%20%20%20%20%20%20%20sleep%201%0A%20%20%20%20%20%20%20%20((%20tries%20%2B%3D%201%20))%0A%20%20%20%20%20%20%20%20if%20%5B%5B%20%22%24%7Btries%7D%22%20-gt%2010%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20echo%20%22Timed%20out%20waiting%20for%20kubelet%20key%20and%20cert.%22%0A%20%20%20%20%20%20%20%20%20%20exit%201%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20done%0A%20%20%20%20securityContext%3A%0A%20%20%20%20%20%20privileged%3A%20true%0A%20%20%20%20resources%3A%0A%20%20%20%20%20%20requests%3A%0A%20%20%20%20%20%20%20%20memory%3A%2050Mi%0A%20%20%20%20%20%20%20%20cpu%3A%205m%0A%20%20containers%3A%0A%20%20-%20name%3A%20kube-rbac-proxy-crio%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3Ab6413e64e7d5885315b3cabc65c2af82135ee649b1664976b3d300884d302414%0A%20%20%20%20securityContext%3A%0A%20%20%20%20%20%20privileged%3A%20true%0A%20%20%20%20ports%3A%0A%20%20%20%20-%20containerPort%3A%209637%0A%20%20%20%20args%3A%0A%20%20%20%20-%20--secure-listen-address%3D%3A9637%0A%20%20%20%20-%20--config-file%3D%2Fetc%2Fkubernetes%2Fcrio-metrics-proxy.cfg%0A%20%20%20%20-%20--client-ca-file%3D%2Fetc%2Fkubernetes%2Fkubelet-ca.crt%0A%20%20%20%20-%20--logtostderr%3Dtrue%0A%20%20%20%20-%20--kubeconfig%3D%2Fvar%2Flib%2Fkubelet%2Fkubeconfig%0A%20%20%20%20-%20--tls-cipher-suites%3DTLS_AES_128_GCM_SHA256%2CTLS_AES_256_GCM_SHA384%2CTLS_CHACHA20_POLY1305_SHA256%2CTLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256%2CTLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256%2CTLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384%2CTLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384%2CTLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256%2CTLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256%20%0A%20%20%20%20-%20--tls-min-version%3DVersionTLS12%0A%20%20%20%20-%20--upstream%3Dhttp%3A%2F%2F127.0.0.1%3A9537%0A%20%20%20%20-%20--tls-cert-file%3D%2Fvar%2Flib%2Fkubelet%2Fpki%2Fkubelet-server-current.pem%0A%20%20%20%20-%20--tls-private-key-file%3D%2Fvar%2Flib%2Fkubelet%2Fpki%2Fkubelet-server-current.pem%0A%20%20%20%20resources%3A%0A%20%20%20%20%20%20requests%3A%0A%20%20%20%20%20%20%20%20cpu%3A%2020m%0A%20%20%20%20%20%20%20%20memory%3A%2050Mi%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20etc-kube%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fkubernetes%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20%20%20readOnly%3A%20true%0A%20%20%20%20-%20name%3A%20var-lib-kubelet%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20%20%20readOnly%3A%20true
          mode: 420
          overwrite: true
          path: /etc/kubernetes/manifests/criometricsproxy.yaml
        - contents:
            compression: ""
            source: data:text/plain;charset=utf-8;base64,YXBpVmVyc2lvbjoga3ViZWxldC5jb25maWcuazhzLmlvL3YxYmV0YTEKYXV0aGVudGljYXRpb246CiAgYW5vbnltb3VzOgogICAgZW5hYmxlZDogZmFsc2UKICB3ZWJob29rOgogICAgY2FjaGVUVEw6IDBzCiAgeDUwOToKICAgIGNsaWVudENBRmlsZTogL2V0Yy9rdWJlcm5ldGVzL2t1YmVsZXQtY2EuY3J0CmF1dGhvcml6YXRpb246CiAgd2ViaG9vazoKICAgIGNhY2hlQXV0aG9yaXplZFRUTDogMHMKICAgIGNhY2hlVW5hdXRob3JpemVkVFRMOiAwcwpjZ3JvdXBEcml2ZXI6IHN5c3RlbWQKY2dyb3VwUm9vdDogLwpjbHVzdGVyRE5TOgotIDE3Mi4zMC4wLjEwCmNsdXN0ZXJEb21haW46IGNsdXN0ZXIubG9jYWwKY29udGFpbmVyTG9nTWF4U2l6ZTogNTBNaQpjb250YWluZXJSdW50aW1lRW5kcG9pbnQ6ICIiCmNwdU1hbmFnZXJSZWNvbmNpbGVQZXJpb2Q6IDBzCmVuYWJsZVN5c3RlbUxvZ1F1ZXJ5OiB0cnVlCmV2aWN0aW9uUHJlc3N1cmVUcmFuc2l0aW9uUGVyaW9kOiAwcwpmZWF0dXJlR2F0ZXM6CiAgQVdTQ2x1c3Rlckhvc3RlZEROUzogZmFsc2UKICBBV1NFRlNEcml2ZXJWb2x1bWVNZXRyaWNzOiB0cnVlCiAgQWRkaXRpb25hbFJvdXRpbmdDYXBhYmlsaXRpZXM6IGZhbHNlCiAgQWRtaW5OZXR3b3JrUG9saWN5OiB0cnVlCiAgQWxpYmFiYVBsYXRmb3JtOiB0cnVlCiAgQXV0b21hdGVkRXRjZEJhY2t1cDogZmFsc2UKICBBenVyZVdvcmtsb2FkSWRlbnRpdHk6IHRydWUKICBCYXJlTWV0YWxMb2FkQmFsYW5jZXI6IHRydWUKICBCb290Y05vZGVNYW5hZ2VtZW50OiBmYWxzZQogIEJ1aWxkQ1NJVm9sdW1lczogdHJ1ZQogIENTSURyaXZlclNoYXJlZFJlc291cmNlOiBmYWxzZQogIENodW5rU2l6ZU1pQjogdHJ1ZQogIENsb3VkRHVhbFN0YWNrTm9kZUlQczogdHJ1ZQogIENsdXN0ZXJBUElJbnN0YWxsOiBmYWxzZQogIENsdXN0ZXJBUElJbnN0YWxsSUJNQ2xvdWQ6IGZhbHNlCiAgQ2x1c3Rlck1vbml0b3JpbmdDb25maWc6IGZhbHNlCiAgQ29uc29sZVBsdWdpbkNvbnRlbnRTZWN1cml0eVBvbGljeTogZmFsc2UKICBETlNOYW1lUmVzb2x2ZXI6IGZhbHNlCiAgRGlzYWJsZUt1YmVsZXRDbG91ZENyZWRlbnRpYWxQcm92aWRlcnM6IHRydWUKICBEeW5hbWljUmVzb3VyY2VBbGxvY2F0aW9uOiBmYWxzZQogIEV0Y2RCYWNrZW5kUXVvdGE6IGZhbHNlCiAgRXZlbnRlZFBMRUc6IGZhbHNlCiAgRXhhbXBsZTogZmFsc2UKICBFeHRlcm5hbE9JREM6IGZhbHNlCiAgRXh0ZXJuYWxPSURDV2l0aFVJREFuZEV4dHJhQ2xhaW1NYXBwaW5nczogZmFsc2UKICBHQ1BDbHVzdGVySG9zdGVkRE5TOiBmYWxzZQogIEdDUExhYmVsc1RhZ3M6IHRydWUKICBHYXRld2F5QVBJOiBmYWxzZQogIEhhcmR3YXJlU3BlZWQ6IHRydWUKICBJbWFnZVN0cmVhbUltcG9ydE1vZGU6IGZhbHNlCiAgSW5ncmVzc0NvbnRyb2xsZXJEeW5hbWljQ29uZmlndXJhdGlvbk1hbmFnZXI6IGZhbHNlCiAgSW5ncmVzc0NvbnRyb2xsZXJMQlN1Ym5ldHNBV1M6IHRydWUKICBJbnNpZ2h0c0NvbmZpZzogZmFsc2UKICBJbnNpZ2h0c0NvbmZpZ0FQSTogZmFsc2UKICBJbnNpZ2h0c09uRGVtYW5kRGF0YUdhdGhlcjogZmFsc2UKICBJbnNpZ2h0c1J1bnRpbWVFeHRyYWN0b3I6IGZhbHNlCiAgS01TdjE6IHRydWUKICBNYWNoaW5lQVBJTWlncmF0aW9uOiBmYWxzZQogIE1hY2hpbmVBUElPcGVyYXRvckRpc2FibGVNYWNoaW5lSGVhbHRoQ2hlY2tDb250cm9sbGVyOiBmYWxzZQogIE1hY2hpbmVBUElQcm92aWRlck9wZW5TdGFjazogZmFsc2UKICBNYWNoaW5lQ29uZmlnTm9kZXM6IGZhbHNlCiAgTWFuYWdlZEJvb3RJbWFnZXM6IHRydWUKICBNYW5hZ2VkQm9vdEltYWdlc0FXUzogdHJ1ZQogIE1heFVuYXZhaWxhYmxlU3RhdGVmdWxTZXQ6IGZhbHNlCiAgTWV0cmljc0NvbGxlY3Rpb25Qcm9maWxlczogZmFsc2UKICBNaW5pbXVtS3ViZWxldFZlcnNpb246IGZhbHNlCiAgTWl4ZWRDUFVzQWxsb2NhdGlvbjogZmFsc2UKICBNdWx0aUFyY2hJbnN0YWxsQVdTOiB0cnVlCiAgTXVsdGlBcmNoSW5zdGFsbEF6dXJlOiBmYWxzZQogIE11bHRpQXJjaEluc3RhbGxHQ1A6IHRydWUKICBOZXR3b3JrRGlhZ25vc3RpY3NDb25maWc6IHRydWUKICBOZXR3b3JrTGl2ZU1pZ3JhdGlvbjogdHJ1ZQogIE5ldHdvcmtTZWdtZW50YXRpb246IHRydWUKICBOZXdPTE06IHRydWUKICBOb2RlRGlzcnVwdGlvblBvbGljeTogdHJ1ZQogIE5vZGVTd2FwOiBmYWxzZQogIE51dGFuaXhNdWx0aVN1Ym5ldHM6IGZhbHNlCiAgT1ZOT2JzZXJ2YWJpbGl0eTogZmFsc2UKICBPbkNsdXN0ZXJCdWlsZDogdHJ1ZQogIE9wZW5TaGlmdFBvZFNlY3VyaXR5QWRtaXNzaW9uOiBmYWxzZQogIFBlcnNpc3RlbnRJUHNGb3JWaXJ0dWFsaXphdGlvbjogdHJ1ZQogIFBpbm5lZEltYWdlczogZmFsc2UKICBQbGF0Zm9ybU9wZXJhdG9yczogZmFsc2UKICBQcml2YXRlSG9zdGVkWm9uZUFXUzogdHJ1ZQogIFByb2NNb3VudFR5cGU6IGZhbHNlCiAgUm91dGVBZHZlcnRpc2VtZW50czogZmFsc2UKICBSb3V0ZUV4dGVybmFsQ2VydGlmaWNhdGU6IGZhbHNlCiAgU2VydmljZUFjY291bnRUb2tlbk5vZGVCaW5kaW5nOiBmYWxzZQogIFNldEVJUEZvck5MQkluZ3Jlc3NDb250cm9sbGVyOiB0cnVlCiAgU2lnbmF0dXJlU3RvcmVzOiBmYWxzZQogIFNpZ3N0b3JlSW1hZ2VWZXJpZmljYXRpb246IGZhbHNlCiAgVHJhbnNsYXRlU3RyZWFtQ2xvc2VXZWJzb2NrZXRSZXF1ZXN0czogZmFsc2UKICBVcGdyYWRlU3RhdHVzOiBmYWxzZQogIFVzZXJOYW1lc3BhY2VzUG9kU2VjdXJpdHlTdGFuZGFyZHM6IGZhbHNlCiAgVXNlck5hbWVzcGFjZXNTdXBwb3J0OiBmYWxzZQogIFZTcGhlcmVDb250cm9sUGxhbmVNYWNoaW5lU2V0OiB0cnVlCiAgVlNwaGVyZURyaXZlckNvbmZpZ3VyYXRpb246IHRydWUKICBWU3BoZXJlTXVsdGlOZXR3b3JrczogZmFsc2UKICBWU3BoZXJlTXVsdGlWQ2VudGVyczogdHJ1ZQogIFZTcGhlcmVTdGF0aWNJUHM6IHRydWUKICBWYWxpZGF0aW5nQWRtaXNzaW9uUG9saWN5OiB0cnVlCiAgVm9sdW1lQXR0cmlidXRlc0NsYXNzOiBmYWxzZQogIFZvbHVtZUdyb3VwU25hcHNob3Q6IGZhbHNlCmZpbGVDaGVja0ZyZXF1ZW5jeTogMHMKaHR0cENoZWNrRnJlcXVlbmN5OiAwcwppbWFnZU1heGltdW1HQ0FnZTogMHMKaW1hZ2VNaW5pbXVtR0NBZ2U6IDBzCmtpbmQ6IEt1YmVsZXRDb25maWd1cmF0aW9uCmt1YmVBUElCdXJzdDogMTAwCmt1YmVBUElRUFM6IDUwCmxvZ2dpbmc6CiAgZmx1c2hGcmVxdWVuY3k6IDAKICBvcHRpb25zOgogICAganNvbjoKICAgICAgaW5mb0J1ZmZlclNpemU6ICIwIgogICAgdGV4dDoKICAgICAgaW5mb0J1ZmZlclNpemU6ICIwIgogIHZlcmJvc2l0eTogMAptYXhQb2RzOiAyNTAKbWVtb3J5U3dhcDoge30Kbm9kZVN0YXR1c1JlcG9ydEZyZXF1ZW5jeTogNW0wcwpub2RlU3RhdHVzVXBkYXRlRnJlcXVlbmN5OiAxMHMKcG9kUGlkc0xpbWl0OiA0MDk2CnByb3RlY3RLZXJuZWxEZWZhdWx0czogdHJ1ZQpyb3RhdGVDZXJ0aWZpY2F0ZXM6IHRydWUKcnVudGltZVJlcXVlc3RUaW1lb3V0OiAwcwpzZXJpYWxpemVJbWFnZVB1bGxzOiBmYWxzZQpzZXJ2ZXJUTFNCb290c3RyYXA6IHRydWUKc2h1dGRvd25HcmFjZVBlcmlvZDogMHMKc2h1dGRvd25HcmFjZVBlcmlvZENyaXRpY2FsUG9kczogMHMKc3RhdGljUG9kUGF0aDogL2V0Yy9rdWJlcm5ldGVzL21hbmlmZXN0cwpzdHJlYW1pbmdDb25uZWN0aW9uSWRsZVRpbWVvdXQ6IDBzCnN5bmNGcmVxdWVuY3k6IDBzCnN5c3RlbUNncm91cHM6IC9zeXN0ZW0uc2xpY2UKdGxzQ2lwaGVyU3VpdGVzOgotIFRMU19BRVNfMTI4X0dDTV9TSEEyNTYKLSBUTFNfQUVTXzI1Nl9HQ01fU0hBMzg0Ci0gVExTX0NIQUNIQTIwX1BPTFkxMzA1X1NIQTI1NgotIFRMU19FQ0RIRV9FQ0RTQV9XSVRIX0FFU18xMjhfR0NNX1NIQTI1NgotIFRMU19FQ0RIRV9SU0FfV0lUSF9BRVNfMTI4X0dDTV9TSEEyNTYKLSBUTFNfRUNESEVfRUNEU0FfV0lUSF9BRVNfMjU2X0dDTV9TSEEzODQKLSBUTFNfRUNESEVfUlNBX1dJVEhfQUVTXzI1Nl9HQ01fU0hBMzg0Ci0gVExTX0VDREhFX0VDRFNBX1dJVEhfQ0hBQ0hBMjBfUE9MWTEzMDVfU0hBMjU2Ci0gVExTX0VDREhFX1JTQV9XSVRIX0NIQUNIQTIwX1BPTFkxMzA1X1NIQTI1Ngp0bHNNaW5WZXJzaW9uOiBWZXJzaW9uVExTMTIKdm9sdW1lU3RhdHNBZ2dQZXJpb2Q6IDBzCg==
          mode: 420
          overwrite: true
          path: /etc/kubernetes/kubelet.conf
        - contents:
            source: data:,%23!%2Fbin%2Fsh%0Aif%20%5B%20-x%20%2Fusr%2Fbin%2Fkubensenter%20%5D%3B%20then%0A%20%20exec%20%2Fusr%2Fbin%2Fkubensenter%20%22%24%40%22%0Aelse%0A%20%20exec%20%22%24%40%22%0Afi%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/kubenswrapper
        - contents:
            source: data:text/plain;charset=utf-8;base64,CnBvb2wgMC5yaGVsLnBvb2wubnRwLm9yZyBpYnVyc3QKZHJpZnRmaWxlIC92YXIvbGliL2Nocm9ueS9kcmlmdAptYWtlc3RlcCAxLjAgMwpydGNzeW5jCmxvZ2RpciAvdmFyL2xvZy9jaHJvbnkKc2VydmVyIDc0LjIwOC4yNS40NiBpYnVyc3QKc2VydmVyIHRpbWUubG10bGFicy5jb20gaWJ1cnN0CnNlcnZlciBsaXRoaXVtLmNvbnN0YW50LmNvbSBpYnVyc3QKc2VydmVyIDY5LjE3Ni44NC4zOCBpYnVyc3QKc2VydmVyIGFybTEubWF4aG9zdC5pbyBpYnVyc3QKc2VydmVyIG50cDEubGF4LnVzLmhvam1hcmsubmV0IGlidXJzdApzZXJ2ZXIgbnRwMTEua2VybmZ1c2lvbi5hdCBpYnVyc3QKc2VydmVyIHRyaWFuZ2xlLmthbnNhcy5uZXQgaWJ1cnN0
          mode: 420
          overwrite: true
          path: /etc/chrony.conf
      systemd:
        units:
        - contents: |
            [Unit]
            Description=Cleans NetworkManager state generated by dracut
            # Removal of this file signals firstboot completion
            ConditionPathExists=!/etc/ignition-machine-config-encapsulated.json
            # This is opt-in for some deployment types, and opt-out for others.
            ConditionPathExists=/var/lib/mco/nm-clean-initrd-state
            Wants=network-pre.target
            Before=network-pre.target

            [Service]
            Type=oneshot
            # Remove any existing state possibly generated NM run by dracut. We want NM to
            # consider all profiles autoconnect priority when it starts instead of
            # remembering which profile was a device activated with when NM is run by
            # dracut.
            ExecStart=/usr/local/bin/nm-clean-initrd-state.sh
            StandardOutput=journal+console
            StandardError=journal+console

            [Install]
            WantedBy=network-online.target
          enabled: true
          name: NetworkManager-clean-initrd-state.service
        - dropins:
          - contents: |
              # vim:set ft=systemd :
              #
              # This drop-in will enable any service built with this
              # github.com/containers/kubemntns library to properly join the mount namespace
              # managed by kubens.service
              #

              [Unit]
              After=kubens.service

              [Service]
              EnvironmentFile=-/run/kubens/env
            name: 01-kubens.conf
          - contents: ""
            name: 10-mco-default-env.conf
          - contents: |
              [Service]
              Environment="ENABLE_PROFILE_UNIX_SOCKET=true"
            name: 10-mco-profile-unix-socket.conf
          - contents: |
              [Unit]
              After=kubelet-dependencies.target
              Requires=kubelet-dependencies.target
            name: 05-mco-ordering.conf
          - contents: |
              [Service]
              Environment="GODEBUG=x509ignoreCN=0,madvdontneed=1"
            name: 10-mco-default-madv.conf
          name: crio.service
        - dropins:
          - contents: |
              [Unit]
              ConditionPathExists=/enoent
            name: mco-disabled.conf
          name: docker.socket
        - contents: |
            [Unit]
            Description=The firstboot OS update has completed
            Documentation=https://github.com/openshift/machine-config-operator/
            Requires=basic.target

            [Install]
            WantedBy=default.target
          enabled: true
          name: firstboot-osupdate.target
        - dropins:
          - contents: |
              [Unit]
              After=ovs-configuration.service
              Before=crio.service
            name: 01-after-configure-ovs.conf
          name: ipsec.service
        - contents: |
            [Unit]
            Description=Dynamically sets the system reserved for the kubelet
            Wants=network-online.target
            After=network-online.target firstboot-osupdate.target
            Before=kubelet-dependencies.target

            [Service]
            # Need oneshot to delay kubelet
            Type=oneshot
            RemainAfterExit=yes
            EnvironmentFile=/etc/node-sizing-enabled.env
            ExecStart=/bin/bash /usr/local/sbin/dynamic-system-reserved-calc.sh ${NODE_SIZING_ENABLED} ${SYSTEM_RESERVED_MEMORY} ${SYSTEM_RESERVED_CPU} ${SYSTEM_RESERVED_ES}
            [Install]
            RequiredBy=kubelet-dependencies.target
          enabled: true
          name: kubelet-auto-node-size.service
        - contents: |
            [Unit]
            Description=Dependencies necessary to run kubelet
            Documentation=https://github.com/openshift/machine-config-operator/
            Requires=basic.target network-online.target
            Wants=NetworkManager-wait-online.service crio-wipe.service
            Wants=rpc-statd.service chrony-wait.service
          name: kubelet-dependencies.target
        - contents: |
            [Unit]
            Description=Kubernetes Kubelet
            Requires=crio.service kubelet-dependencies.target
            After=kubelet-dependencies.target
            After=ostree-finalize-staged.service

            [Service]
            Type=notify
            ExecStartPre=/bin/mkdir --parents /etc/kubernetes/manifests
            ExecStartPre=-/usr/sbin/restorecon -ri /var/lib/kubelet/pod-resources /usr/local/bin/kubenswrapper /usr/bin/kubensenter
            Environment="KUBELET_NODE_IP=0.0.0.0"
            EnvironmentFile=/etc/os-release
            EnvironmentFile=-/etc/kubernetes/kubelet-workaround
            EnvironmentFile=-/etc/kubernetes/kubelet-env
            EnvironmentFile=/etc/node-sizing.env

            ExecStart=/usr/local/bin/kubenswrapper \
                /usr/bin/kubelet \
                  --config=/etc/kubernetes/kubelet.conf \
                  --bootstrap-kubeconfig=/etc/kubernetes/kubeconfig \
                  --kubeconfig=/var/lib/kubelet/kubeconfig \
                  --container-runtime-endpoint=/var/run/crio/crio.sock \
                  --runtime-cgroups=/system.slice/crio.service \
                  --node-labels=node-role.kubernetes.io/control-plane,node-role.kubernetes.io/master,node.openshift.io/os_id=${ID} \
                  --node-ip=${KUBELET_NODE_IP} \
                  --address=${KUBELET_NODE_IP} \
                  --minimum-container-ttl-duration=6m0s \
                  --cloud-provider= \
                  --volume-plugin-dir=/etc/kubernetes/kubelet-plugins/volume/exec \
                  --hostname-override=${KUBELET_NODE_NAME} \
                  --register-with-taints=node-role.kubernetes.io/master=:NoSchedule \
                  --pod-infra-container-image=quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:2f61599219ee63c77391e05d2e02a8a5baae1c463d0ef965c49a5c470546db90 \
                  --system-reserved=cpu=${SYSTEM_RESERVED_CPU},memory=${SYSTEM_RESERVED_MEMORY},ephemeral-storage=${SYSTEM_RESERVED_ES} \
                  --v=${KUBELET_LOG_LEVEL}

            Restart=always
            RestartSec=10

            [Install]
            WantedBy=multi-user.target
          dropins:
          - contents: |
              # vim:set ft=systemd :
              #
              # This drop-in will enable any service built with this
              # github.com/containers/kubemntns library to properly join the mount namespace
              # managed by kubens.service
              #

              [Unit]
              After=kubens.service

              [Service]
              EnvironmentFile=-/run/kubens/env
            name: 01-kubens.conf
          - contents: ""
            name: 10-mco-default-env.conf
          - contents: |
              [Service]
              # Wait for resolv-prepender to configure nameservers, exit 255 otherwise
              # to mark the unit as failed and retry later
              ExecCondition=/bin/bash -c '[ -f /run/resolv-prepender-kni-conf-done ] || { echo "NM resolv-prepender failed"; exit 255; }'
            name: 10-mco-on-prem-wait-resolv.conf
          - contents: |
              [Service]
              Environment="GODEBUG=x509ignoreCN=0,madvdontneed=1"
            name: 10-mco-default-madv.conf
          enabled: true
          name: kubelet.service
        - contents: |
            [Unit]
            Description=Manages a mount namespace for kubernetes-specific mounts

            [Service]
            Type=oneshot
            RemainAfterExit=yes
            RuntimeDirectory=kubens
            Environment=RUNTIME_DIRECTORY=%t/kubens
            Environment=BIND_POINT=%t/kubens/mnt
            Environment=ENVFILE=%t/kubens/env

            # Set up the runtime directory as an unbindable mountpoint
            ExecStartPre=bash -c "findmnt ${RUNTIME_DIRECTORY} || mount --make-unbindable --bind ${RUNTIME_DIRECTORY} ${RUNTIME_DIRECTORY}"
            # Ensure the bind point exists
            ExecStartPre=touch ${BIND_POINT}
            # Use 'unshare' to create the new mountpoint, then 'mount --make-rshared' so it cascades internally
            ExecStart=unshare --mount=${BIND_POINT} --propagation slave mount --make-rshared /
            # Finally, set an env pointer for ease-of-use
            ExecStartPost=bash -c 'echo "KUBENSMNT=${BIND_POINT}" > "${ENVFILE}"'

            # On stop, a recursive unmount cleans up the namespace and bind-mounted unbindable parent directory
            ExecStop=umount -R ${RUNTIME_DIRECTORY}

            [Install]
            WantedBy=multi-user.target
          enabled: false
          name: kubens.service
        - contents: |
            [Unit]
            Description=Machine Config Daemon Firstboot
            # Make sure it runs only on OSTree booted system
            ConditionPathExists=/run/ostree-booted
            # Removal of this file signals firstboot completion
            ConditionPathExists=/etc/ignition-machine-config-encapsulated.json
            After=machine-config-daemon-pull.service
            Before=kubelet-dependencies.target

            [Service]
            Type=oneshot
            RemainAfterExit=yes
            # Disable existing repos (if any) so that OS extensions would use embedded RPMs only
            ExecStartPre=-/usr/bin/sh -c "sed -i 's/enabled=1/enabled=0/' /etc/yum.repos.d/*.repo"
            # Run this via podman because we want to use the nmstatectl binary in our container
            ExecStart=/usr/bin/podman run --rm --privileged --net=host -v /:/rootfs  --entrypoint machine-config-daemon 'quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:94bac6c3782cf6579032c7c9dabca74146753d9a44591125acd30d606d7d340c' firstboot-complete-machineconfig --persist-nics
            ExecStart=/usr/bin/podman run --rm --privileged --pid=host --net=host -v /:/rootfs  --entrypoint machine-config-daemon 'quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:94bac6c3782cf6579032c7c9dabca74146753d9a44591125acd30d606d7d340c' firstboot-complete-machineconfig
            [Install]
            RequiredBy=firstboot-osupdate.target
          enabled: true
          name: machine-config-daemon-firstboot.service
        - contents: |
            [Unit]
            Description=Machine Config Daemon Pull
            # Make sure it runs only on OSTree booted system
            ConditionPathExists=/run/ostree-booted
            # This "stamp file" is unlinked when we complete
            # machine-config-daemon-firstboot.service
            ConditionPathExists=/etc/ignition-machine-config-encapsulated.json
            # Run after crio-wipe so the pulled MCD image is protected against a corrupted storage from a forced shutdown
            Wants=crio-wipe.service NetworkManager-wait-online.service
            After=crio-wipe.service NetworkManager-wait-online.service network.service

            [Service]
            Type=oneshot
            RemainAfterExit=yes
            ExecStartPre=/etc/machine-config-daemon/generate_podman_policy_args.sh
            ExecStart=/bin/sh -c "while ! /usr/bin/podman pull $(cat /tmp/podman_policy_args) --authfile=/var/lib/kubelet/config.json 'quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:94bac6c3782cf6579032c7c9dabca74146753d9a44591125acd30d606d7d340c'; do sleep 1; done"

            [Install]
            RequiredBy=machine-config-daemon-firstboot.service
          enabled: true
          name: machine-config-daemon-pull.service
        - contents: |
            [Unit]
            Description=Applies per-node NMState network configuration
            Requires=openvswitch.service
            Wants=NetworkManager-wait-online.service
            After=NetworkManager-wait-online.service openvswitch.service network.service nodeip-configuration.service
            Before=nmstate.service kubelet-dependencies.target ovs-configuration.service node-valid-hostname.service

            [Service]
            Type=oneshot
            # Would prefer to do Restart=on-failure instead of this bash retry loop, but
            # the version of systemd we have right now doesn't support it. It should be
            # available in systemd v244 and higher.
            ExecStart=/usr/local/bin/nmstate-configuration.sh
            StandardOutput=journal+console
            StandardError=journal+console

            [Install]
            WantedBy=network-online.target
          enabled: true
          name: nmstate-configuration.service
        - contents: |
            [Unit]
            Description=Apply nmstate on-disk state
            Documentation=man:nmstate.service(8) https://www.nmstate.io
            After=NetworkManager-wait-online.service
            Before=network-online.target
            Wants=NetworkManager-wait-online.service
            Requires=NetworkManager.service

            [Service]
            Type=oneshot
            ExecStart=/usr/bin/nmstatectl service
            RemainAfterExit=yes

            [Install]
            WantedBy=NetworkManager.service
          enabled: true
          name: nmstate.service
        - contents: |
            [Unit]
            Description=Wait for a non-localhost hostname
            Before=kubelet-dependencies.target

            [Service]
            Type=oneshot
            RemainAfterExit=yes
            User=root
            ExecStart=/usr/local/bin/mco-hostname --wait

            # Wait up to 5min for the node to get a non-localhost name
            TimeoutSec=300

            [Install]
            # TODO: Change this to RequiredBy after we fix https://github.com/openshift/machine-config-operator/pull/3865#issuecomment-1746963115
            WantedBy=kubelet-dependencies.target
          enabled: true
          name: node-valid-hostname.service
        - contents: |
            [Unit]
            Description=Writes IP address configuration so that kubelet and crio services select a valid node IP
            # This only applies to VIP managing environments where the kubelet and crio IP
            # address picking logic is flawed and may end up selecting an address from a
            # different subnet or a deprecated address
            Wants=NetworkManager-wait-online.service
            After=NetworkManager-wait-online.service firstboot-osupdate.target
            Before=kubelet-dependencies.target ovs-configuration.service

            [Service]
            # Need oneshot to delay kubelet
            Type=oneshot
            # Would prefer to do Restart=on-failure instead of this bash retry loop, but
            # the version of systemd we have right now doesn't support it. It should be
            # available in systemd v244 and higher.
            ExecStart=/bin/bash -c " \
              until \
              /usr/bin/podman run --rm \
              --authfile /var/lib/kubelet/config.json \
              --net=host \
              --security-opt label=disable \
              --volume /etc/systemd/system:/etc/systemd/system \
              --volume /run/nodeip-configuration:/run/nodeip-configuration \
              quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:93e7b8c870261726d44bddc7ba0a702d3720d1838141dac837fb8c3be7c6e1a1 \
              node-ip \
              set \
              --platform BareMetal \
              --retry-on-failure \
              ${NODEIP_HINT:-} \
              10.100.0.50  \
              10.100.0.51 ; \
              do \
              sleep 5; \
              done"
            ExecStart=/bin/systemctl daemon-reload
            ExecStartPre=/bin/mkdir -p /run/nodeip-configuration
            ExecStartPost=+/usr/local/bin/configure-ip-forwarding.sh
            StandardOutput=journal+console
            StandardError=journal+console
            EnvironmentFile=-/etc/default/nodeip-configuration

            [Install]
            RequiredBy=kubelet-dependencies.target
          enabled: true
          name: nodeip-configuration.service
        - contents: |
            [Unit]
            Description=Watches for changes in /var/run/NetworkManager/resolv.conf according to on-prem IPI needs
            [Path]
            PathModified=/var/run/NetworkManager/resolv.conf
            PathModified=/run/resolv-prepender/env
            Unit=on-prem-resolv-prepender.service
            [Install]
            WantedBy=multi-user.target
          enabled: true
          name: on-prem-resolv-prepender.path
        - contents: |
            [Unit]
            Description=Populates resolv.conf according to on-prem IPI needs
            # Per https://issues.redhat.com/browse/OCPBUGS-27162 there is a problem if this is started before crio-wipe
            After=crio-wipe.service
            StartLimitIntervalSec=0
            [Service]
            Type=oneshot
            # Would prefer to do Restart=on-failure instead of this bash retry loop, but
            # the version of systemd we have right now doesn't support it. It should be
            # available in systemd v244 and higher.
            ExecStart=/bin/bash -c " \
              until \
              /usr/local/bin/resolv-prepender.sh; \
              do \
              sleep 10; \
              done"
            EnvironmentFile=-/run/resolv-prepender/env
          enabled: false
          name: on-prem-resolv-prepender.service
        - enabled: true
          name: openvswitch.service
        - contents: |
            [Unit]
            # Kdump will generate it's initramfs based on the running state when kdump.service run
            # If OVS has already run, the kdump fails to gather a working network config,
            # which prevent network log exports, sush as SSH.
            # See https://issues.redhat.com/browse/OCPBUGS-28239
            After=kdump.service
            Description=Configures OVS with proper host networking configuration
            # This service is used to move a physical NIC into OVS and reconfigure OVS to use the host IP
            Requires=openvswitch.service
            Wants=NetworkManager-wait-online.service
            After=firstboot-osupdate.target
            After=NetworkManager-wait-online.service openvswitch.service network.service nodeip-configuration.service nmstate.service
            Before=kubelet-dependencies.target node-valid-hostname.service

            [Service]
            # Need oneshot to delay kubelet
            Type=oneshot
            ExecStart=/usr/local/bin/configure-ovs.sh OVNKubernetes
            StandardOutput=journal+console
            StandardError=journal+console

            [Install]
            RequiredBy=kubelet-dependencies.target
          enabled: true
          name: ovs-configuration.service
        - dropins:
          - contents: |
              [Service]
              Restart=always
              ExecStartPre=-/bin/sh -c '/usr/bin/chown -R :$${OVS_USER_ID##*:} /var/lib/openvswitch'
              ExecStartPre=-/bin/sh -c '/usr/bin/chown -R :$${OVS_USER_ID##*:} /etc/openvswitch'
              ExecStartPre=-/bin/sh -c '/usr/bin/chown -R :$${OVS_USER_ID##*:} /run/openvswitch'
              ExecStartPost=-/usr/bin/ovs-appctl vlog/set syslog:info
              ExecReload=-/usr/bin/ovs-appctl vlog/set syslog:info
            name: 10-ovs-vswitchd-restart.conf
          name: ovs-vswitchd.service
        - dropins:
          - contents: |
              [Service]
              Restart=always
            name: 10-ovsdb-restart.conf
          enabled: true
          name: ovsdb-server.service
        - dropins:
          - contents: ""
            name: 10-mco-default-env.conf
          - contents: |
              # See https://github.com/openshift/machine-config-operator/issues/1897
              [Service]
              Nice=10
              IOSchedulingClass=best-effort
              IOSchedulingPriority=6
            name: mco-controlplane-nice.conf
          name: rpm-ostreed.service
        - contents: |
            [Unit]
            Description=Wait for br-ex up event from NetworkManager
            Wants=ovs-configuration.service
            After=ovs-configuration.service
            Before=node-valid-hostname.service

            [Service]
            Type=oneshot
            ExecStart=/usr/local/bin/wait-for-br-ex-up.sh

            [Install]
            RequiredBy=node-valid-hostname.service
          enabled: true
          name: wait-for-br-ex-up.service
        - contents: |
            [Unit]
            Description=Ensure IKE SA established for existing IPsec connections.
            After=ipsec.service
            Before=kubelet-dependencies.target node-valid-hostname.service

            [Service]
            Type=oneshot
            ExecStart=/usr/local/bin/ipsec-connect-wait.sh
            StandardOutput=journal+console
            StandardError=journal+console

            [Install]
            WantedBy=ipsec.service
          enabled: true
          name: wait-for-ipsec-connect.service
        - contents: |
            [Unit]
            Description=Ensure primary IP is assigned and usable
            Requires=nmstate.service
            After=nmstate.service
            Before=kubelet-dependencies.target

            [Service]
            Type=oneshot
            # Would prefer to do Restart=on-failure instead of this bash retry loop, but
            # the version of systemd we have right now doesn't support it. It should be
            # available in systemd v244 and higher.
            ExecStart=/bin/bash -c " \
              until \
              /usr/local/bin/wait-for-primary-ip.sh; \
              do \
              sleep 10; \
              done"
            StandardOutput=journal+console
            StandardError=journal+console

            [Install]
            WantedBy=network-online.target
          enabled: true
          name: wait-for-primary-ip.service
        - dropins:
          - contents: |
              [Unit]
              ConditionPathExists=/enoent
            name: mco-disabled.conf
          name: zincati.service
        - contents: |
            [Unit]
            Description=Kubernetes Kubelet After Reboot Cleanup
            Before=kubelet.service

            [Service]
            Type=oneshot
            ExecStart=/bin/rm -f /var/lib/kubelet/cpu_manager_state
            ExecStart=/bin/rm -f /var/lib/kubelet/memory_manager_state
            ExecStart=-/bin/rm -f /var/lib/kubelet/dra_manager_state

            [Install]
            WantedBy=multi-user.target
          enabled: true
          name: kubelet-cleanup.service
    extensions: []
    fips: false
    kernelArguments:
    - schedstats=enable
    - systemd.unified_cgroup_hierarchy=1
    - cgroup_no_v1="all"
    - psi=0
    kernelType: default
    osImageURL: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4e309dd906392e783a404b92dfd4fa4c32d74e2804ee37d1fb8a00c9355d5978
- apiVersion: machineconfiguration.openshift.io/v1
  kind: MachineConfig
  metadata:
    annotations:
      machineconfiguration.openshift.io/generated-by-controller-version: fcf8f254943cbcba1400ba55f3978cc292b6460b
      machineconfiguration.openshift.io/release-image-version: 4.18.26
    creationTimestamp: "2025-11-04T16:32:12Z"
    generation: 1
    name: rendered-worker-9add496aafbac739d3d79a9705bfa73f
    ownerReferences:
    - apiVersion: machineconfiguration.openshift.io/v1
      blockOwnerDeletion: true
      controller: true
      kind: MachineConfigPool
      name: worker
      uid: 7ac2da7a-3f0d-4ad8-974e-12dd34c8fded
    resourceVersion: "43348"
    uid: 3655a77b-a3b6-40c0-9fdc-f849a88035f1
  spec:
    baseOSExtensionsContainerImage: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:7033f46996eddcbad8c8b8aeb18e601bdeef3d04bd7f79cd194db5e6346a7fc4
    config:
      ignition:
        version: 3.4.0
      passwd:
        users:
        - name: core
          sshAuthorizedKeys:
          - ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQDaG45aoa4HpJ+V029gSYKSv5IenhVmZcJvicGrs+D0PgzzwNIGG52iK4r3YOoEYJn4nX80OHf4ob23avJ1ruDPR9inD1c+oiAk5BLRE7CNdU1mllWE0l6pYRHfpIuCOXC6iWpX1kXbVPJZk3ytVZOgff7LkaIIzbAjDjJ+N1MQSUmKvnioh8c6WtFfQNAZ2gFBCRWPLxcjHdyTYvy+oB0qR10WpQYHrGVB0LawtudQrO/8zHcfZJpI0uFwSAvYqspgiO3hPfuT0Fx8xzAb66AK/2vF/WrMOH3AbBu5S954B+xZI4apPJN/Yy5ENRVIoL7w9V5pV5FENtsSvQ+fpFat9yoVewvy5CMo8qJHrvAqlBJ9JriVX2mnigJRkshG0F+Z7BLZUjMcueSIIzasQ2igc8nbpfElSnTmoyweiMbFIXNJJwaV/tKbFkF3J7A3fz1qbfSQ7AIHAigoUf/CnCr+j+BQs1ZZMoWGQOPwFo00OBDICnP0Pc6wBr4iN6gnDFs=
            jnakamura@JNakamura-22
      storage:
        files:
        - contents:
            source: data:,%23%20This%20file%20signals%20NetworkManager-clean-initrd-state%20service%20to%20run%20on%0A%23%20boot.%20This%20service%20is%20used%20to%20clean%20up%20the%20network%20activation%20state%0A%23%20generated%20by%20dracut%20so%20that%20other%20network%20configuration%20deployed%20by%20the%0A%23%20user%20can%20be%20activated.%20This%20only%20happens%20if%20dracut%20activated%20a%20default%0A%23%20network%20configuration%20and%20there%20is%20an%20alternate%20configuration%20available%20in%0A%23%20the%20root%20filesystem.%20Otherwise%2C%20it%20is%20assumed%20that%20the%20network%0A%23%20configuration%20activated%20by%20dracut%20is%20the%20one%20that%20is%20intended%20to%20be%20used%0A%23%20throughout%20the%20life%20of%20the%20system.%0A%23%20Opt-out%20for%20baremetal%20IPI%20deplyments%2C%20opt-in%20otherwise.%0A
          mode: 493
          overwrite: true
          path: /var/lib/mco/nm-clean-initrd-state
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-ex%20-o%20pipefail%0A%0ANM_DEVICES_DIR%3D%2Frun%2FNetworkManager%2Fdevices%0ANM_RUN_CONN_DIR%3D%2Frun%2FNetworkManager%2Fsystem-connections%0ANM_ETC_CONN_DIR%3D%2Fetc%2FNetworkManager%2Fsystem-connections%0A%0Alogger%20-t%20nm-clean-initrd-state%20%22Cleaning%20network%20activation%20state%20generated%20by%20dracut...%22%0Alogger%20-t%20nm-clean-initrd-state%20%22To%20disable%2C%20remove%20%2Fvar%2Flib%2Fmco%2Fnm-clean-initrd-state%22%0A%0Aif%20%5B%20!%20-e%20%22%24NM_DEVICES_DIR%22%20%5D%20%7C%7C%20%5B%20!%20-e%20%22%24NM_RUN_CONN_DIR%22%20%5D%20%7C%7C%20%5B%20!%20-e%20%22%24NM_ETC_CONN_DIR%22%20%5D%3B%20then%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22There%20is%20no%20network%20activation%20state%20to%20clean%22%0A%20%20exit%0Afi%0A%0A%23%20Some%20deployments%20require%20an%20active%20network%20early%20in%20the%20boot%20process.%20To%0A%23%20achieve%20this%2C%20dracut%20runs%20specific%20NetworkManager%20modules.%20This%20results%20in%0A%23%20NetworkManager%20keyfiles%20being%20generated%20(either%20default%20or%20from%20ip%20kernel%0A%23%20arguments)%20and%20activated.%20This%20activation%20generates%20state%20that%20makes%20those%0A%23%20profiles%20to%20be%20re-activated%20by%20the%20NetworkManager%20service%20later%20in%20the%0A%23%20boot%20process.%20And%20this%20has%20the%20effect%20that%20other%20profiles%20deployed%20by%20the%0A%23%20user%20for%20the%20same%20set%20of%20devices%20are%20ignored.%0A%0A%23%20Most%20of%20the%20time%20this%20is%20the%20desired%20behavior.%20The%20exception%20to%20this%20rule%0A%23%20is%20when%20the%20user%20wants%20to%20run%20the%20boot%20process%20with%20a%20different%20network%0A%23%20setup%20than%20the%20real%20root%20which%20is%20usually%20related%20to%20the%20fact%20that%0A%23%20generating%20images%20with%20customized%20kernel%20arguments%20is%20a%20complication%20in%0A%23%20the%20deployment%20pipeline.%0A%0A%23%20This%20need%20has%20been%20exacerbated%20by%20past%20NetworkManager%20bugs%20that%20activated%0A%23%20the%20network%20on%20boot%20when%20it%20was%20not%20really%20needed.%20Most%20notably%20when%20ip%0A%23%20kernel%20argument%20is%20present%2C%20something%20that%20the%20baremetal%20installer%20adds%20by%0A%23%20default.%0A%0A%23%20The%20intention%20here%20is%20to%20remove%20the%20state%20that%20was%20generated%20with%20the%0A%23%20activation%20of%20those%20profiles%20during%20dracut%20execution.%20Then%20when%0A%23%20NetworkManager%20service%20runs%2C%20the%20profiles%20generated%20by%20dracut%2C%20along%20with%0A%23%20other%20profiles%20configured%20by%20the%20user%2C%20are%20evaluated%20towards%20finding%20the%0A%23%20most%20appropriate%20profile%20to%20connect%20a%20device%20with.%20As%20a%20precaution%2C%20clean%0A%23%20state%20only%20for%20devices%20that%3A%0A%23%20-%20have%20been%20activated%20with%20a%20default%20profile%20(assume%20that%20a%20non-default%0A%23%20%20%20configuration%20expresses%20intention%20by%20user%20to%20run%20with%20it%20permanently)%0A%23%20-%20have%20a%20specific%20configured%20profile%20set%20to%20auto-connect%20(if%20there%20is%20no%0A%23%20%20%20alternate%20configured%20profile%20for%20a%20device%20it%20makes%20no%20sense%20to%0A%23%20%20%20de-activate%20anything)%0A%23%0A%23%20Although%20this%20can%20theoretically%20happen%20on%20any%20deployment%20type%2C%20need%20has%0A%23%20mostly%20come%20from%20IPI%20bare%20metal%20deployments.%20For%20the%20time%20being%2C%20this%0A%23%20should%20be%20opt-in%20in%20any%20other%20deploment%20type.%0A%23%0A%23%20There%20is%20an%20RFE%20filed%20against%20NM%20that%20once%20implemented%20would%20make%20this%0A%23%20script%20unnecessary%3A%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D2089707%0A%0Afor%20device%20in%20%22%24%7BNM_DEVICES_DIR%7D%22%2F*%3B%20do%0A%20%20if%20%5B%20!%20-e%20%22%24device%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20the%20device%20file%20name%20is%20the%20ifindex%0A%20%20ifindex%3D%24(basename%20%22%24device%22)%0A%20%20%0A%20%20%23%20get%20the%20interface%20name%20by%20ifindex%0A%20%20ifname%3D%24(ip%20-j%20link%20show%20%7C%20jq%20-r%20%22.%5B%5D%20%7C%20select(.ifindex%20%3D%3D%20%24%7Bifindex%7D)%20%7C%20.ifname%20%2F%2F%20empty%22)%0A%0A%20%20%23%20no%20interface%20name%20found%2C%20ignore%0A%20%20if%20%5B%20-z%20%22%24ifname%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20get%20the%20uuid%20of%20the%20profile%20the%20device%20has%20been%20activated%20with%0A%20%20active_profile_uuid%3D%24(sed%20-nr%20'%2F%5E%5C%5Bdevice%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Econnection-uuid%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24device%22)%0A%0A%20%20%23%20the%20device%20was%20not%20activated%20with%20any%20profile%2C%20ignore%0A%20%20if%20%5B%20-z%20%22%24active_profile_uuid%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20find%20the%20generated%20profile%20by%20uuid%0A%20%20for%20profile%20in%20%22%24%7BNM_RUN_CONN_DIR%7D%22%2F*%3B%20do%0A%20%20%20%20generated_profile_uuid%3D%24(sed%20-nr%20'%2F%5E%5C%5Bconnection%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Euuid%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20%20%20if%20%5B%20%22%24active_profile_uuid%22%20%3D%20%22%24generated_profile_uuid%22%20%5D%3B%20then%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20done%0A%0A%20%20%23%20generated%20profile%20not%20found%2C%20ignore%0A%20%20if%20%5B%20%22%24active_profile_uuid%22%20!%3D%20%22%24generated_profile_uuid%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20check%20that%20it%20is%20not%20specific%20for%20the%20device%2C%20otherwise%20ignore%0A%20%20profile_ifname%3D%24(sed%20-nr%20'%2F%5E%5C%5Bconnection%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Einterface-name%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20if%20%5B%20-n%20%22%24profile_ifname%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20profile%20not%20generated%20by%20nm-initrd-generator%2C%20ignore%0A%20%20%23%20only%20check%20it%20if%20the%20key%20is%20set%20(from%20NM%201.32.4)%0A%20%20origin%3D%24(sed%20-nr%20'%2F%5E%5C%5Buser%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Eorg.freedesktop.NetworkManager.origin%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20if%20%5B%20-n%20%22%24origin%22%20%5D%20%26%26%20%5B%20%22%24origin%22%20!%3D%20%22nm-initrd-generator%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20find%20the%20configured%20profile%20by%20name%20with%20auto-connect%20set%0A%20%20for%20profile%20in%20%22%24%7BNM_ETC_CONN_DIR%7D%22%2F*%3B%20do%0A%20%20%20%20profile_ifname%3D%24(sed%20-nr%20'%2F%5E%5C%5Bconnection%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Einterface-name%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20%20%20autoconnect%3D%24(sed%20-nr%20'%2F%5E%5C%5Bconnection%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Eautoconnect%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20%20%20if%20%5B%20%22%24profile_ifname%22%20%3D%20%22%24ifname%22%20%5D%20%26%26%20%5B%20%22%24autoconnect%22%20!%3D%20%22false%22%20%5D%3B%20then%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20done%0A%0A%20%20%23%20configured%20profile%20not%20found%2C%20ignore%0A%20%20if%20%5B%20%22%24profile_ifname%22%20!%3D%20%22%24ifname%22%20%5D%20%7C%7C%20%5B%20%22%24autoconnect%22%20%3D%20%22false%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20configured_profile_uuid%3D%24(sed%20-nr%20'%2F%5E%5C%5Bconnection%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Euuid%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22%24ifname%20activated%20with%20default%20generated%20profile%20%24generated_profile_uuid%22%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22%24ifname%20has%20different%20configured%20specific%20profile%20%24configured_profile_uuid%22%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22%24ifname%3A%20removing%20state...%22%0A%20%20%0A%20%20%23%20NM%20can%20still%20generate%20internal%20profiles%20from%20the%20IP%20address%0A%20%20%23%20configuration%20of%20devices%2C%20so%20flush%20addresses%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22Flushing%20IP%20addresses%20from%20%24ifname%22%0A%20%20ip%20addr%20flush%20%22%24ifname%22%0A%20%20ip%20-6%20addr%20flush%20%22%24ifname%22%0A%0A%20%20%23%20remove%20device%20state%20file%20to%20prevent%20NM%20to%20unilaterally%20connect%20with%20the%0A%20%20%23%20latest%20activated%20profile%20without%20evaluating%20other%20profiles%20%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22Removing%20%24device%22%0A%20%20rm%20-f%20--%20%22%24device%22%0A%0Adone%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/nm-clean-initrd-state.sh
        - contents:
            source: data:,%5Bconnection%5D%0Aipv6.dhcp-duid%3Dll%0Aipv6.dhcp-iaid%3Dmac%0A
          mode: 420
          overwrite: true
          path: /etc/NetworkManager/conf.d/01-ipv6.conf
        - contents:
            source: data:,%5Bmain%5D%0Aplugins%3Dkeyfile%2Cifcfg-rh%0A%5Bkeyfile%5D%0Apath%3D%2Fetc%2FNetworkManager%2Fsystem-connections%0A
          mode: 420
          overwrite: true
          path: /etc/NetworkManager/conf.d/20-keyfiles.conf
        - contents:
            source: data:,%5Bmain%5D%0Arc-manager%3Dunmanaged%0A
          mode: 420
          overwrite: true
          path: /etc/NetworkManager/conf.d/99-kni.conf
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-eo%20pipefail%0AIFACE%3D%241%0ASTATUS%3D%242%0A%0Afunction%20resolv_prepender%20%7B%0A%20%20mkdir%20-p%20%2Frun%2Fresolv-prepender%0A%20%20echo%20%22IP4_DOMAINS%3D%24IP4_DOMAINS%22%20%3E%20%2Frun%2Fresolv-prepender%2Fenv.new%0A%20%20echo%20%22IP6_DOMAINS%3D%24IP6_DOMAINS%22%20%3E%3E%20%2Frun%2Fresolv-prepender%2Fenv.new%0A%0A%20%20if%20!%20diff%20-q%20%2Frun%2Fresolv-prepender%2Fenv%20%2Frun%2Fresolv-prepender%2Fenv.new%3B%20then%0A%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Environment%20variable(s)%20changed.%20Systemd%20path%20unit%20will%20pick%20the%20change.%22%0A%20%20%20%20mv%20-f%20%2Frun%2Fresolv-prepender%2Fenv.new%20%2Frun%2Fresolv-prepender%2Fenv%0A%20%20fi%0A%7D%0A%0Aexport%20IP4_DOMAINS%20IP6_DOMAINS%0Aexport%20-f%20resolv_prepender%0A%0A%23%20For%20RHEL8%20with%20NetworkManager%20%3E%3D%201.36%20and%20RHEL9%20with%20NetworkManager%20%3E%3D1.42%20we%20can%20use%20simplified%20logic%0A%23%20of%20observing%20only%20a%20single%20%22dns-change%22%20event.%20Older%20version%20of%20NetworkManager%20require%20however%20that%20we%0A%23%20react%20on%20a%20set%20of%20multiple%20events.%20Once%20dns-change%20event%20is%20detected%20we%20create%20a%20flag%20file%20to%20ignore%0A%23%20subsequent%20up%26co.%20events%20as%20undesired.%0A%23%0A%23%20Given%20an%20overall%20Network%20Manager%20dispatcher%20timeout%20of%2090%20seconds%2C%20we%20are%20enforcing%20a%20slightly%20shorter%0A%23%20timeout%20for%20the%20observed%20events.%20It%20is%20not%20really%20required%20because%20all%20we%20do%20in%20this%20function%20is%20to%20write%20a%20file.%0A%23%20We%20could%20get%20rid%20of%20this%20timeout%20completely%2C%20but%20it%20also%20does%20not%20cost%20much%20to%20keep%20it.%0Acase%20%22%24STATUS%22%20in%0A%20%20dns-change)%0A%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%20triggered%20by%20%24%7BIFACE%7D%20%24%7BSTATUS%7D.%22%0A%20%20%20%20if%20%5B%20!%20-f%20%22%2Frun%2Fnetworkmanager-dns-event-detected%22%20%5D%3B%20then%0A%20%20%20%20%20%20touch%20%2Frun%2Fnetworkmanager-dns-event-detected%0A%20%20%20%20fi%0A%20%20%20%20if%20!%20timeout%2060s%20bash%20-c%20resolv_prepender%3B%20then%0A%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Timeout%20occurred%22%0A%20%20%20%20%20%20exit%201%0A%20%20%20%20fi%0A%20%20%3B%3B%0A%0A%20%20up%7Cdhcp4-change%7Cdhcp6-change%7Creapply)%0A%20%20%20%20if%20%5B%20!%20-f%20%22%2Frun%2Fnetworkmanager-dns-event-detected%22%20%5D%3B%20then%0A%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%20triggered%20by%20%24%7BIFACE%7D%20%24%7BSTATUS%7D.%22%0A%20%20%20%20%20%20if%20!%20timeout%2030s%20bash%20-c%20resolv_prepender%3B%20then%0A%20%20%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Timeout%20occurred%22%0A%20%20%20%20%20%20%20%20exit%201%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20If%20%24DHCP6_FQDN_FQDN%20is%20not%20empty%20and%20is%20not%20localhost.localdomain%20and%20static%20hostname%20was%20not%20already%20set%0A%20%20%20%20if%20%5B%5B%20-n%20%22%24DHCP6_FQDN_FQDN%22%20%26%26%20%22%24DHCP6_FQDN_FQDN%22%20!%3D%20%22localhost.localdomain%22%20%26%26%20%22%24DHCP6_FQDN_FQDN%22%20%3D~%20%22.%22%20%5D%5D%20%3B%20then%0A%20%20%20%20%20%20%20STATIC_HOSTNAME%3D%22%24(test%20!%20-e%20%2Fetc%2Fhostname%20%26%26%20echo%20-n%20%7C%7C%20cat%20%2Fetc%2Fhostname%20%7C%20xargs)%22%0A%0A%20%20%20%20%20%20%20if%20%5B%5B%20-z%20%22%24STATIC_HOSTNAME%22%20%7C%7C%20%22%24STATIC_HOSTNAME%22%20%3D%3D%20%22localhost.localdomain%22%20%5D%5D%20%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%23%20run%20with%20systemd-run%20to%20avoid%20selinux%20problems%0A%20%20%20%20%20%20%20%20%20%20systemd-run%20--property%3DType%3Doneshot%20--unit%20resolve-prepender-hostnamectl%20-Pq%20%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20hostnamectl%20set-hostname%20--static%20--transient%20%24DHCP6_FQDN_FQDN%0A%20%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20if%20%5B%5B%20%22%24STATUS%22%20%3D%3D%20%22up%22%20%5D%5D%20%26%26%20%5B%5B%20%24IFACE%20%3D%3D%20%22br-ex%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20%2Fbin%2Fmkdir%20-p%20%2Frun%2Fnodeip-configuration%0A%20%20%20%20%20%20%20%20touch%20%2Frun%2Fnodeip-configuration%2Fbr-ex-up%0A%20%20%20%20fi%0A%20%20%3B%3B%0A%20%20*)%0A%20%20%3B%3B%0Aesac%0A
          mode: 493
          overwrite: true
          path: /etc/NetworkManager/dispatcher.d/30-resolv-prepender
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-ex%20-o%20pipefail%0A%0Aif%20%5B%5B%20%22OVNKubernetes%22%20%3D%3D%20%22OVNKubernetes%22%20%26%26%20%22%24CONNECTION_ID%22%20%3D%3D%20%22Wired%20Connection%22%20%5D%5D%0Athen%0A%20%20%20%20%3E%262%20echo%20%22Refusing%20to%20modify%20default%20connection.%22%0A%20%20%20%20exit%200%0Afi%0A%0Aif%20%5B%20-z%20%24%7BDHCP4_IP_ADDRESS%3A-%7D%20%5D%0Athen%0A%20%20%20%20%3E%262%20echo%20%22Not%20a%20DHCP4%20address.%20Ignoring.%22%0A%20%20%20%20exit%200%0Afi%0A%0Aif%20%5B%20%24%7BDHCP4_DHCP_LEASE_TIME%3A-0%7D%20-lt%204294967295%20%5D%0Athen%0A%20%20%20%20%3E%262%20echo%20%22Not%20an%20infinite%20DHCP4%20lease.%20Ignoring.%22%0A%20%20%20%20exit%200%0Afi%0A%0AIPS%3D(%24IP4_ADDRESS_0)%0ACIDR%3D%24%7BIPS%5B0%5D%7D%0AGATEWAY%3D%24%7BIPS%5B1%5D%7D%0A%0ATYPE%3D%24(nmcli%20--get-values%20connection.type%20connection%20show%20%22%24CONNECTION_ID%22)%0A%0A%23%20Modifying%20the%20default%20connection%20id%20directly%20doesn't%20do%20what%20we%20want.%0A%23%20If%20we%20see%20that%2C%20then%20we%20need%20to%20create%20a%20new%20connection.%0Aif%20%5B%20%22%24CONNECTION_ID%22%20%3D%3D%20%22Wired%20Connection%22%20%5D%0Athen%0A%20%20%20%20if%20!%20nmcli%20con%20show%20inf-lease-to-static%0A%20%20%20%20then%0A%20%20%20%20%20%20%20%20nmcli%20con%20add%20type%20%22%24TYPE%22%20con-name%20inf-lease-to-static%0A%20%20%20%20fi%0A%20%20%20%20STATIC_INT_NAME%3Dinf-lease-to-static%0Aelse%0A%20%20%20%20STATIC_INT_NAME%3D%22%24CONNECTION_ID%22%0Afi%0Anmcli%20con%20mod%20%22%24STATIC_INT_NAME%22%20%5C%0A%20%20conn.interface%20%22%241%22%20%5C%0A%20%20connection.autoconnect%20yes%20%5C%0A%20%20ipv4.addresses%20%22%24CIDR%22%20%5C%0A%20%20ipv4.method%20manual%20%5C%0A%20%20ipv4.gateway%20%22%24GATEWAY%22%20%5C%0A%20%20ipv4.dns%20%22%24IP4_NAMESERVERS%22%0A%0Aif%20%5B%20-n%20%22%24IP4_DOMAINS%22%20%5D%3B%20then%0A%20%20%20%20nmcli%20con%20mod%20%22%24STATIC_INT_NAME%22%20ipv4.dns-search%20%22%24IP4_DOMAINS%22%0Afi%0Aplus%3D''%0Afor%20i%20in%20%24(seq%200%20%24((%24IP4_NUM_ROUTES-1))%20)%0Ado%0A%20%20%20%20varname%3D%22IP4_ROUTE_%24i%22%0A%20%20%20%20nmcli%20con%20mod%20%22%24STATIC_INT_NAME%22%20%24%7Bplus%7Dipv4.routes%20%22%24%7B!varname%7D%22%0A%20%20%20%20plus%3D'%2B'%0Adone%0A%0Anmcli%20con%20up%20%22%24STATIC_INT_NAME%22%0A%0Aif%20%5B%20-n%20%22%24%7BDHCP4_HOST_NAME%3A-%7D%22%20%5D%0Athen%0A%20%20%20%20systemd-run%20--property%3DType%3Doneshot%20--unit%20static-dhcp-hostnamectl%20-Pq%20%5C%0A%20%20%20%20%20%20hostnamectl%20set-hostname%20--static%20--transient%20%22%24DHCP4_HOST_NAME%22%0Afi%0A
          mode: 493
          overwrite: true
          path: /etc/NetworkManager/dispatcher.d/30-static-dhcp
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-ex%20-o%20pipefail%0A%0Aif%20%5B%20-z%20%22%24DHCP6_IP6_ADDRESS%22%20%5D%0Athen%0A%20%20%20%20%3E%262%20echo%20%22Not%20a%20DHCP6%20address.%20Ignoring.%22%0A%20%20%20%20exit%200%0Afi%0A%0ALEASE_TIME%3D%24(ip%20-j%20-6%20a%20show%20%22%24DEVICE_IFACE%22%20%7C%20jq%20-r%20%22.%5B%5D.addr_info%5B%5D%20%7C%20select(.scope%3D%3D%5C%22global%5C%22)%20%7C%20select(.deprecated!%3Dtrue)%20%7C%20select(.local%3D%3D%5C%22%24DHCP6_IP6_ADDRESS%5C%22)%20%7C%20.preferred_life_time%22)%0APREFIX_LEN%3D%24(ip%20-j%20-6%20a%20show%20%22%24DEVICE_IFACE%22%20%7C%20jq%20-r%20%22.%5B%5D.addr_info%5B%5D%20%7C%20select(.scope%3D%3D%5C%22global%5C%22)%20%7C%20select(.deprecated!%3Dtrue)%20%7C%20select(.local%3D%3D%5C%22%24DHCP6_IP6_ADDRESS%5C%22)%20%7C%20.prefixlen%22)%0A%0Aif%20%5B%20%24%7BLEASE_TIME%3A-0%7D%20-lt%204294967295%20%5D%0Athen%0A%20%20%20%20%3E%262%20echo%20%22Not%20an%20infinite%20DHCP6%20lease.%20Ignoring.%22%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20We%20don't%20want%20this%20to%20run%20before%20OVNKubernetes%20creates%20its%20bridge.%20If%20we%0A%23%20see%20the%20default%20CONNECTION_ID%20we%20know%20to%20wait.%0Aif%20%5B%20%22%24CONNECTION_ID%22%20%3D%3D%20%22Wired%20Connection%22%20%5D%0Athen%0A%20%20%20%20%3E%262%20echo%20%22Refusing%20to%20modify%20default%20connection.%22%0A%20%20%20%20exit%200%0Afi%0A%0ACIDR%3D%22%24DHCP6_IP6_ADDRESS%2F%24PREFIX_LEN%22%0Anmcli%20con%20mod%20%22%24CONNECTION_ID%22%20ipv6.addresses%20%22%24CIDR%22%0Anmcli%20con%20mod%20%22%24CONNECTION_ID%22%20connection.autoconnect%20%22yes%22%0Anmcli%20con%20mod%20%22%24CONNECTION_ID%22%20ipv6.method%20%22manual%22%0Anmcli%20con%20mod%20%22%24CONNECTION_ID%22%20ipv6.gateway%20%22%24IP6_GATEWAY%22%0Anmcli%20con%20mod%20%22%24CONNECTION_ID%22%20ipv6.dns%20%22%24IP6_NAMESERVERS%22%0ASEARCH_DOMAIN%3D%22%24%7BDHCP6_FQDN_FQDN%23*.%7D%22%0Aif%20%5B%20-n%20%22%24SEARCH_DOMAIN%22%20%5D%3B%20then%0A%20%20%20%20nmcli%20con%20mod%20%22%24CONNECTION_ID%22%20ipv6.dns-search%20%22%24SEARCH_DOMAIN%22%0Afi%0Aplus%3D''%0Afor%20i%20in%20%24(seq%200%20%24((%24IP6_NUM_ROUTES-1))%20)%0Ado%0A%20%20%20%20varname%3D%22IP6_ROUTE_%24i%22%0A%20%20%20%20nmcli%20con%20mod%20%22%24CONNECTION_ID%22%20%24%7Bplus%7Dipv6.routes%20%22%24%7B!varname%7D%22%0A%20%20%20%20plus%3D'%2B'%0Adone%0A%0A%23%20Copy%20it%20from%20the%20OverlayFS%20mount%20to%20the%20persistent%20lowerdir%0Acp%20%22%24CONNECTION_FILENAME%22%20%2Fetc%2FNetworkManager%2Fsystem-connections%0A
          mode: 493
          overwrite: true
          path: /etc/NetworkManager/dispatcher.d/30-static-dhcpv6
        - contents:
            source: data:,
          mode: 384
          overwrite: true
          path: /etc/pki/ca-trust/source/anchors/openshift-config-user-ca-bundle.crt
        - contents:
            source: data:,KUBERNETES_SERVICE_HOST%3D'api-int.comp-poc-rh01.rhpoc.int'%0AKUBERNETES_SERVICE_PORT%3D'6443'%0A
          mode: 420
          overwrite: true
          path: /etc/kubernetes/apiserver-url.env
        - contents:
            source: data:,%23%20This%20file%20is%20managed%20by%20machine-config-operator.%0A%23%20Suppress%20audit%20rules%20which%20always%20trigger%20for%20container%0A%23%20workloads%2C%20as%20they%20spam%20the%20audit%20log.%20%20Workloads%20are%20expected%0A%23%20to%20be%20dynamic%2C%20and%20the%20networking%20stack%20uses%20iptables.%0A-a%20exclude%2Calways%20-F%20msgtype%3DNETFILTER_CFG%0A%23%20The%20default%20bridged%20networking%20enables%20promiscuous%20on%20the%20veth%0A%23%20device.%20%20Ideally%2C%20we'd%20teach%20audit%20to%20ignore%20only%20veth%20devices%2C%0A%23%20since%20one%20might%20legitimately%20care%20about%20promiscuous%20on%20real%20physical%0A%23%20devices.%20%20But%20we%20can't%20currently%20differentiate.%0A-a%20exclude%2Calways%20-F%20msgtype%3DANOM_PROMISCUOUS%0A
          mode: 420
          overwrite: true
          path: /etc/audit/rules.d/mco-audit-quiet-containers.rules
        - contents:
            source: data:,mode%3A%20unicast%0A
          mode: 420
          overwrite: true
          path: /etc/keepalived/monitor.conf
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%0A%23%20ESP%20offload%2C%20either%20in%20actual%20hardware%20or%20as%20part%20as%20GRO%20(generic%0A%23%20recieve%20offload)%20does%20not%20work%20for%20interfaces%20attached%20to%20an%20OVS%20bridge%0A%23%20so%20turn%20it%20off%20for%20the%20time%20being.%0A%23%20https%3A%2F%2Fissues.redhat.com%2Fbrowse%2FRHEL-58811%0A%0A%23%20Depends%20on%20ipsec%20service%20drop-in%20to%20start%20it%20after%20configure-ovs%20to%20make%0A%23%20sure%20offloads%20are%20disabled%20before%20ipsec%20starts.%0A%0Aif%20%5B%5B%20%22%242%22%20!%3D%20%22up%22%20%5D%5D%3B%20then%0A%20%20exit%0Afi%0A%0Adevice%3D%24DEVICE_IFACE%0Akind_slave%3D%24(ip%20-j%20-d%20link%20show%20%22%24device%22%20%7C%20jq%20-r%20'.%5B0%5D%20%7C%20.linkinfo.info_slave_kind%20%2F%2F%20empty')%0A%0Aif%20%5B%20%22%24kind_slave%22%20%3D%20%22openvswitch%22%20%5D%3B%20then%0A%20%20for%20feature%20in%20tx-esp-segmentation%20esp-hw-offload%20esp-tx-csum-hw-offload%3B%20do%0A%20%20%20%20if%20ethtool%20-k%20%22%24device%22%20%7C%20grep%20-qE%20%22%5E%24%7Bfeature%7D%3A%20off%22%3B%20then%0A%20%20%20%20%20%20%23%20already%20disabled%2C%20nothing%20to%20do%0A%20%20%20%20%20%20continue%0A%20%20%20%20fi%0A%20%20%20%20%0A%20%20%20%20logger%20-t%2099-esp-offload%20-s%20%22Setting%20%24feature%20off%20for%20%24device%3A%20unsupported%20when%20attached%20to%20Open%20vSwitch%20bridge%22%0A%20%20%20%20ethtool%20-K%20%22%24device%22%20%22%24feature%22%20off%0A%20%20done%0Afi%0A
          mode: 484
          overwrite: true
          path: /etc/NetworkManager/dispatcher.d/99-esp-offload
        - contents:
            source: data:,r%20%2Fetc%2Fkubernetes%2Fcni%2Fnet.d%2F80-openshift-network.conf%0Ar%20%2Fetc%2Fkubernetes%2Fcni%2Fnet.d%2F10-ovn-kubernetes.conf%0Ad%20%2Frun%2Fmultus%2Fcni%2Fnet.d%2F%200755%20root%20root%20-%20-%0AD%20%2Fvar%2Flib%2Fcni%2Fnetworks%2Fopenshift-sdn%2F%200755%20root%20root%20-%20-%0A
          mode: 420
          overwrite: true
          path: /etc/tmpfiles.d/cleanup-cni.conf
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-ex%0A%0A%23%20Used%20for%20on-prem%20deployments%20to%20enable%20ip%20forwarding%20as%20part%20of%20nodeip-configuration%20service.%0A%23%20IP%20forwarding%20is%20required%20on%20the%20node%20IP%20(k8s%20API)%20interface%20in%20order%20for%20keepalived%20to%20function.%0A%0Aecho%20%22Configuring%20IP%20Forwarding...%22%0Aovnk_config_dir%3D'%2Fetc%2Fovnk'%0Aip_hint_file%3D%22%2Frun%2Fnodeip-configuration%2Fprimary-ip%22%0A%0Aget_ip_from_ip_hint_file()%20%7B%0A%20%20local%20ip_hint_file%3D%22%241%22%0A%20%20if%20%5B%5B%20!%20-f%20%22%24%7Bip_hint_file%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22error%3A%20unable%20to%20enable%20IP%20forwarding.%20IP%20hint%20file%3A%20%24%7Bip_hint_file%7D%20does%20not%20exist!%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%20%20ip_hint%3D%24(cat%20%22%24%7Bip_hint_file%7D%22)%0A%20%20echo%20%22%24%7Bip_hint%7D%22%0A%7D%0A%0Aget_nodeip_hint_interface()%20%7B%0A%20%20local%20ip_hint%3D%22%22%0A%20%20local%20ip_hint_file%3D%22%241%22%0A%20%20local%20iface%3D%22%22%0A%0A%20%20ip_hint%3D%24(get_ip_from_ip_hint_file%20%22%24%7Bip_hint_file%7D%22)%0A%20%20if%20%5B%5B%20-z%20%22%24%7Bip_hint%7D%22%20%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22error%3A%20unable%20to%20enable%20IP%20forwarding.%20IP%20hint%20file%3A%20%24%7Bip_hint_file%7D%20is%20empty!%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%0A%20%20iface%3D%24(ip%20-j%20addr%20%7C%20jq%20-r%20%22first(.%5B%5D%20%7C%20select(any(.addr_info%5B%5D%3B%20.local%3D%3D%5C%22%24%7Bip_hint%7D%5C%22)))%20%7C%20.ifname%22)%0A%20%20if%20%5B%5B%20-z%20%22%24%7Biface%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22error%3A%20unable%20to%20enable%20IP%20forwarding.%20Cannot%20detect%20valid%20interface%20within%20file%3A%20%24%7Bip_hint_file%7D%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%20%20echo%20%22%24%7Biface%7D%22%0A%7D%0A%0Aiface%3D%24(get_nodeip_hint_interface%20%22%24%7Bip_hint_file%7D%22)%0A%0Aecho%20%22Node%20IP%20interface%20determined%20as%3A%20%24%7Biface%7D.%20Enabling%20IP%20forwarding...%22%0Afile_paths%3D(%22%2Fproc%2Fsys%2Fnet%2Fipv4%2Fconf%2F%24%7Biface%7D%2Fforwarding%22%20%22%2Fproc%2Fsys%2Fnet%2Fipv6%2Fconf%2F%24%7Biface%7D%2Fforwarding%22)%0Afor%20file_path%20in%20%22%24%7Bfile_paths%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20if%20%5B%20-f%20%22%24%7Bfile_path%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%221%22%20%3E%20%22%24%7Bfile_path%7D%22%0A%20%20%20%20fi%0Adone%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/configure-ip-forwarding.sh
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-x%0A%0Aif%20%5B%20-e%20%2Fetc%2Fnmstate%2Fopenshift%2Fapplied%20%5D%3B%20then%0A%20%20echo%20%22Skipping%20configure-ovs%20due%20to%20manual%20network%20configuration%22%0A%20%20exit%200%0Afi%0A%0A%23%20This%20file%20is%20not%20needed%20anymore%20in%204.7%2B%2C%20but%20when%20rolling%20back%20to%204.6%0A%23%20the%20ovs%20pod%20needs%20it%20to%20know%20ovs%20is%20running%20on%20the%20host.%0Atouch%20%2Fvar%2Frun%2Fovs-config-executed%0A%0A%23%20These%20are%20well%20knwon%20NM%20default%20paths%0ANM_CONN_ETC_PATH%3D%22%2Fetc%2FNetworkManager%2Fsystem-connections%22%0ANM_CONN_RUN_PATH%3D%22%2Frun%2FNetworkManager%2Fsystem-connections%22%0A%0A%23%20This%20is%20the%20path%20where%20NM%20is%20known%20to%20be%20configured%20to%20store%20user%20keyfiles%20%0ANM_CONN_CONF_PATH%3D%22%24NM_CONN_ETC_PATH%22%0A%0A%23%20This%20is%20where%20we%20want%20our%20keyfiles%20to%20finally%20reside.%20configure-ovs%0A%23%20operates%20with%20temporary%20keyfiles%20in%20NM_CONN_RUN_PATH%20and%20then%20as%20a%20last%0A%23%20step%20moves%20those%20keyfiles%20to%20NM_CONN_SET_PATH%20if%20it%20is%20a%20different%20path%0A%23%20(not%20by%20default).%20This%20mitigates%20hard%20interruptions%20(SIGKILL%2C%20hard%20reboot)%0A%23%20of%20configure-ovs%20leaving%20the%20machine%20with%20a%20half-baked%20set%20of%20keyfiles%0A%23%20that%20might%20prevent%20machine%20networking%20from%20working%20correctly.%0ANM_CONN_SET_PATH%3D%22%24%7BNM_CONN_SET_PATH%3A-%24NM_CONN_RUN_PATH%7D%22%0A%0AMANAGED_NM_CONN_SUFFIX%3D%22-slave-ovs-clone%22%0A%23%20Workaround%20to%20ensure%20OVS%20is%20installed%20due%20to%20bug%20in%20systemd%20Requires%3A%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1888017%0Acopy_nm_conn_files()%20%7B%0A%20%20local%20dst_path%3D%22%241%22%0A%20%20for%20src%20in%20%22%24%7BMANAGED_NM_CONN_FILES%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20src_path%3D%24(dirname%20%22%24src%22)%0A%20%20%20%20file%3D%24(basename%20%22%24src%22)%0A%20%20%20%20if%20%5B%20-f%20%22%24src_path%2F%24file%22%20%5D%3B%20then%0A%20%20%20%20%20%20if%20%5B%20!%20-f%20%22%24dst_path%2F%24file%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22Copying%20configuration%20%24file%22%0A%20%20%20%20%20%20%20%20cp%20%22%24src_path%2F%24file%22%20%22%24dst_path%2F%24file%22%0A%20%20%20%20%20%20elif%20!%20cmp%20--silent%20%22%24src_path%2F%24file%22%20%22%24dst_path%2F%24file%22%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22Copying%20updated%20configuration%20%24file%22%0A%20%20%20%20%20%20%20%20cp%20-f%20%22%24src_path%2F%24file%22%20%22%24dst_path%2F%24file%22%0A%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20echo%20%22Skipping%20%24file%20since%20it's%20equal%20at%20destination%22%0A%20%20%20%20%20%20fi%0A%20%20%20%20else%0A%20%20%20%20%20%20echo%20%22Skipping%20%24file%20since%20it%20does%20not%20exist%20at%20source%22%0A%20%20%20%20fi%0A%20%20done%0A%7D%0A%0Aupdate_nm_conn_files_base()%20%7B%0A%20%20base_path%3D%24%7B1%7D%0A%20%20bridge_name%3D%24%7B2%7D%0A%20%20port_name%3D%24%7B3%7D%0A%20%20ovs_port%3D%22ovs-port-%24%7Bbridge_name%7D%22%0A%20%20ovs_interface%3D%22ovs-if-%24%7Bbridge_name%7D%22%0A%20%20default_port_name%3D%22ovs-port-%24%7Bport_name%7D%22%20%23%20ovs-port-phys0%0A%20%20bridge_interface_name%3D%22ovs-if-%24%7Bport_name%7D%22%20%23%20ovs-if-phys0%0A%20%20%23%20In%20RHEL7%20files%20in%20%2F%7Betc%2Crun%7D%2FNetworkManager%2Fsystem-connections%20end%20without%20the%20suffix%20'.nmconnection'%2C%20whereas%20in%20RHCOS%20they%20end%20with%20the%20suffix.%0A%20%20MANAGED_NM_CONN_FILES%3D(%24(echo%20%22%24%7Bbase_path%7D%22%2F%7B%22%24bridge_name%22%2C%22%24ovs_interface%22%2C%22%24ovs_port%22%2C%22%24bridge_interface_name%22%2C%22%24default_port_name%22%7D%7B%2C.nmconnection%7D))%0A%20%20shopt%20-s%20nullglob%0A%20%20MANAGED_NM_CONN_FILES%2B%3D(%24%7Bbase_path%7D%2F*%24%7BMANAGED_NM_CONN_SUFFIX%7D.nmconnection%20%24%7Bbase_path%7D%2F*%24%7BMANAGED_NM_CONN_SUFFIX%7D)%0A%20%20shopt%20-u%20nullglob%0A%7D%0A%0Aupdate_nm_conn_run_files()%20%7B%0A%20%20update_nm_conn_files_base%20%22%24%7BNM_CONN_RUN_PATH%7D%22%20%22%24%7B1%7D%22%20%22%24%7B2%7D%22%0A%7D%0A%0Aupdate_nm_conn_set_files()%20%7B%0A%20%20update_nm_conn_files_base%20%22%24%7BNM_CONN_SET_PATH%7D%22%20%22%24%7B1%7D%22%20%22%24%7B2%7D%22%0A%7D%0A%0Aupdate_nm_conn_etc_files()%20%7B%0A%20%20update_nm_conn_files_base%20%22%24%7BNM_CONN_ETC_PATH%7D%22%20%22%24%7B1%7D%22%20%22%24%7B2%7D%22%0A%7D%0A%0A%23%20Move%20and%20reload%20keyfiles%20at%20their%20final%20destination%0Aset_nm_conn_files()%20%7B%0A%20%20if%20%5B%20%22%24NM_CONN_RUN_PATH%22%20!%3D%20%22%24NM_CONN_SET_PATH%22%20%5D%3B%20then%0A%20%20%20%20update_nm_conn_run_files%20br-ex%20phys0%0A%20%20%20%20copy_nm_conn_files%20%22%24NM_CONN_SET_PATH%22%0A%20%20%20%20rm_nm_conn_files%0A%20%20%20%20update_nm_conn_run_files%20br-ex1%20phys1%0A%20%20%20%20copy_nm_conn_files%20%22%24NM_CONN_SET_PATH%22%0A%20%20%20%20rm_nm_conn_files%0A%0A%20%20%20%20%23%20reload%20keyfiles%0A%20%20%20%20nmcli%20connection%20reload%0A%20%20fi%0A%7D%0A%0A%23%20Used%20to%20remove%20files%20managed%20by%20configure-ovs%20and%20temporary%20leftover%20files%20from%20network%20manager%0Arm_nm_conn_files()%20%7B%0A%20%20for%20file%20in%20%22%24%7BMANAGED_NM_CONN_FILES%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20if%20%5B%20-f%20%22%24file%22%20%5D%3B%20then%0A%20%20%20%20%20%20rm%20-f%20%22%24file%22%0A%20%20%20%20%20%20echo%20%22Removed%20nmconnection%20file%20%24file%22%0A%20%20%20%20%20%20nm_config_changed%3D1%0A%20%20%20%20fi%0A%20%20done%0A%20%20for%20file%20in%20%22%24%7BMANAGED_NM_CONN_FILES%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20for%20temp%20in%20%24(compgen%20-G%20%22%24%7Bfile%7D.*%22)%3B%20do%0A%20%20%20%20%20%20rm%20-f%20%22%24temp%22%0A%20%20%20%20%20%20echo%20%22Removed%20nmconnection%20temporary%20file%20%24temp%22%0A%20%20%20%20%20%20nm_config_changed%3D1%0A%20%20%20%20done%0A%20%20done%0A%7D%0A%0A%23%20Used%20to%20clone%20a%20slave%20connection%20by%20uuid%2C%20returns%20new%20name%0Aclone_slave_connection()%20%7B%0A%20%20local%20uuid%3D%22%241%22%0A%20%20local%20old_name%0A%20%20old_name%3D%22%24(nmcli%20-g%20connection.id%20connection%20show%20uuid%20%22%24uuid%22)%22%0A%20%20local%20new_name%3D%22%24%7Bold_name%7D%24%7BMANAGED_NM_CONN_SUFFIX%7D%22%0A%20%20if%20nmcli%20connection%20show%20id%20%22%24%7Bnew_name%7D%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20echo%20%22WARNING%3A%20existing%20ovs%20slave%20%24%7Bnew_name%7D%20connection%20profile%20file%20found%2C%20overwriting...%22%20%3E%262%0A%20%20%20%20nmcli%20connection%20delete%20id%20%22%24%7Bnew_name%7D%22%20%26%3E%20%2Fdev%2Fnull%0A%20%20fi%0A%20%20clone_nm_conn%20%24uuid%20%22%24%7Bnew_name%7D%22%0A%20%20echo%20%22%24%7Bnew_name%7D%22%0A%7D%0A%0A%23%20Used%20to%20replace%20an%20old%20master%20connection%20uuid%20with%20a%20new%20one%20on%20all%20connections%0Areplace_connection_master()%20%7B%0A%20%20local%20old%3D%22%241%22%0A%20%20local%20new%3D%22%242%22%0A%20%20for%20conn_uuid%20in%20%24(nmcli%20-g%20UUID%20connection%20show)%20%3B%20do%0A%20%20%20%20if%20%5B%20%22%24(nmcli%20-g%20connection.master%20connection%20show%20uuid%20%22%24conn_uuid%22)%22%20!%3D%20%22%24old%22%20%5D%3B%20then%0A%20%20%20%20%20%20continue%0A%20%20%20%20fi%0A%0A%20%20%20%20local%20active_state%3D%24(nmcli%20-g%20GENERAL.STATE%20connection%20show%20%22%24conn_uuid%22)%0A%20%20%20%20local%20autoconnect%3D%24(nmcli%20-g%20connection.autoconnect%20connection%20show%20%22%24conn_uuid%22)%0A%20%20%20%20if%20%5B%20%22%24active_state%22%20!%3D%20%22activated%22%20%5D%20%26%26%20%5B%20%22%24autoconnect%22%20!%3D%20%22yes%22%20%5D%3B%20then%0A%20%20%20%20%20%20%23%20Assume%20that%20slave%20profiles%20intended%20to%20be%20used%20are%20those%20that%20are%3A%0A%20%20%20%20%20%20%23%20-%20active%0A%20%20%20%20%20%20%23%20-%20or%20inactive%20(which%20might%20be%20due%20to%20link%20being%20down)%20but%20to%20be%20autoconnected.%0A%20%20%20%20%20%20%23%20Otherwise%2C%20ignore%20them.%0A%20%20%20%20%20%20continue%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20make%20changes%20for%20slave%20profiles%20in%20a%20new%20clone%0A%20%20%20%20local%20new_name%0A%20%20%20%20new_name%3D%24(clone_slave_connection%20%24conn_uuid)%0A%0A%20%20%20%20mod_nm_conn%20%22%24new_name%22%20connection.master%20%22%24new%22%20connection.autoconnect-priority%20100%20connection.autoconnect%20no%20%0A%20%20%20%20echo%20%22Replaced%20master%20%24old%20with%20%24new%20for%20slave%20profile%20%24new_name%22%0A%20%20done%0A%7D%0A%0A%23%20when%20creating%20the%20bridge%2C%20we%20use%20a%20value%20lower%20than%20NM's%20ethernet%20device%20default%20route%20metric%0A%23%20(we%20pick%2048%20and%2049%20to%20be%20lower%20than%20anything%20that%20NM%20chooses%20by%20default)%0ABRIDGE_METRIC%3D%2248%22%0ABRIDGE1_METRIC%3D%2249%22%0A%23%20Given%20an%20interface%2C%20generates%20NM%20configuration%20to%20add%20to%20an%20OVS%20bridge%0Aconvert_to_bridge()%20%7B%0A%20%20local%20iface%3D%24%7B1%7D%0A%20%20local%20bridge_name%3D%24%7B2%7D%0A%20%20local%20port_name%3D%24%7B3%7D%0A%20%20local%20bridge_metric%3D%24%7B4%7D%0A%20%20local%20ovs_port%3D%22ovs-port-%24%7Bbridge_name%7D%22%0A%20%20local%20ovs_interface%3D%22ovs-if-%24%7Bbridge_name%7D%22%0A%20%20local%20default_port_name%3D%22ovs-port-%24%7Bport_name%7D%22%20%23%20ovs-port-phys0%0A%20%20local%20bridge_interface_name%3D%22ovs-if-%24%7Bport_name%7D%22%20%23%20ovs-if-phys0%0A%0A%20%20if%20%5B%20%22%24iface%22%20%3D%20%22%24bridge_name%22%20%5D%3B%20then%0A%20%20%20%20%23%20handle%20vlans%20and%20bonds%20etc%20if%20they%20have%20already%20been%0A%20%20%20%20%23%20configured%20via%20nm%20key%20files%20and%20br-ex%20is%20already%20up%0A%20%20%20%20ifaces%3D%24(ovs-vsctl%20list-ifaces%20%24%7Biface%7D)%0A%20%20%20%20for%20intf%20in%20%24ifaces%3B%20do%20configure_driver_options%20%24intf%3B%20done%0A%20%20%20%20echo%20%22Networking%20already%20configured%20and%20up%20for%20%24%7Bbridge-name%7D!%22%0A%20%20%20%20return%0A%20%20fi%0A%0A%20%20%23%20flag%20to%20reload%20NM%20to%20account%20for%20all%20the%20configuration%20changes%0A%20%20%23%20going%20forward%0A%20%20nm_config_changed%3D1%0A%0A%20%20if%20%5B%20-z%20%22%24iface%22%20%5D%3B%20then%0A%20%20%20%20echo%20%22ERROR%3A%20Unable%20to%20find%20default%20gateway%20interface%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%20%20%23%20find%20the%20MAC%20from%20OVS%20config%20or%20the%20default%20interface%20to%20use%20for%20OVS%20internal%20port%0A%20%20%23%20this%20prevents%20us%20from%20getting%20a%20different%20DHCP%20lease%20and%20dropping%20connection%0A%20%20if%20!%20iface_mac%3D%24(%3C%22%2Fsys%2Fclass%2Fnet%2F%24%7Biface%7D%2Faddress%22)%3B%20then%0A%20%20%20%20echo%20%22Unable%20to%20determine%20default%20interface%20MAC%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%0A%20%20echo%20%22MAC%20address%20found%20for%20iface%3A%20%24%7Biface%7D%3A%20%24%7Biface_mac%7D%22%0A%0A%20%20%23%20find%20MTU%20from%20original%20iface%0A%20%20iface_mtu%3D%24(ip%20link%20show%20%22%24iface%22%20%7C%20awk%20'%7Bprint%20%245%3B%20exit%7D')%0A%20%20if%20%5B%5B%20-z%20%22%24iface_mtu%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22Unable%20to%20determine%20default%20interface%20MTU%2C%20defaulting%20to%201500%22%0A%20%20%20%20iface_mtu%3D1500%0A%20%20else%0A%20%20%20%20echo%20%22MTU%20found%20for%20iface%3A%20%24%7Biface%7D%3A%20%24%7Biface_mtu%7D%22%0A%20%20fi%0A%0A%20%20%23%20store%20old%20conn%20for%20later%0A%20%20old_conn%3D%24(nmcli%20--fields%20UUID%2CDEVICE%20conn%20show%20--active%20%7C%20awk%20%22%2F%5Cs%24%7Biface%7D%5Cs*%5C%24%2F%20%7Bprint%20%5C%241%7D%22)%0A%0A%20%20if%20%5B%5B%20-z%20%22%24old_conn%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22ERROR%3A%20cannot%20find%20connection%20for%20interface%3A%20%24%7Biface%7D%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%0A%20%20%23%20create%20bridge%0A%20%20if%20!%20nmcli%20connection%20show%20%22%24bridge_name%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-br%20%22%24bridge_name%22%0A%20%20%20%20add_nm_conn%20%22%24bridge_name%22%20type%20ovs-bridge%20conn.interface%20%22%24bridge_name%22%20802-3-ethernet.mtu%20%24%7Biface_mtu%7D%20%5C%0A%20%20%20%20connection.autoconnect-slaves%201%0A%20%20fi%0A%0A%20%20%23%20find%20default%20port%20to%20add%20to%20bridge%0A%20%20if%20!%20nmcli%20connection%20show%20%22%24default_port_name%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-port%20%22%24bridge_name%22%20%24%7Biface%7D%0A%20%20%20%20add_nm_conn%20%22%24default_port_name%22%20type%20ovs-port%20conn.interface%20%24%7Biface%7D%20slave-type%20ovs-bridge%20master%20%22%24bridge_name%22%20%5C%0A%20%20%20%20connection.autoconnect-slaves%201%0A%20%20fi%0A%0A%20%20if%20!%20nmcli%20connection%20show%20%22%24ovs_port%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-port%20%22%24bridge_name%22%20%22%24bridge_name%22%0A%20%20%20%20add_nm_conn%20%22%24ovs_port%22%20type%20ovs-port%20conn.interface%20%22%24bridge_name%22%20slave-type%20ovs-bridge%20master%20%22%24bridge_name%22%0A%20%20fi%0A%0A%20%20extra_phys_args%3D()%0A%20%20%23%20check%20if%20this%20interface%20is%20a%20vlan%2C%20bond%2C%20team%2C%20or%20ethernet%20type%0A%20%20if%20%5B%20%22%24(nmcli%20--get-values%20connection.type%20conn%20show%20%24%7Bold_conn%7D)%22%20%3D%3D%20%22vlan%22%20%5D%3B%20then%0A%20%20%20%20iface_type%3Dvlan%0A%20%20%20%20vlan_id%3D%24(nmcli%20--get-values%20vlan.id%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20if%20%5B%20-z%20%22%24vlan_id%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22ERROR%3A%20unable%20to%20determine%20vlan_id%20for%20vlan%20connection%3A%20%24%7Bold_conn%7D%22%0A%20%20%20%20%20%20exit%201%0A%20%20%20%20fi%0A%20%20%20%20vlan_parent%3D%24(nmcli%20--get-values%20vlan.parent%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20if%20%5B%20-z%20%22%24vlan_parent%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22ERROR%3A%20unable%20to%20determine%20vlan_parent%20for%20vlan%20connection%3A%20%24%7Bold_conn%7D%22%0A%20%20%20%20%20%20exit%201%0A%20%20%20%20fi%0A%0A%20%20%20%20if%20nmcli%20connection%20show%20uuid%20%22%24vlan_parent%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20%20%20%23%20if%20the%20VLAN%20connection%20is%20configured%20with%20a%20connection%20UUID%20as%20parent%2C%20we%20need%20to%20find%20the%20underlying%20device%0A%20%20%20%20%20%20%23%20and%20create%20the%20bridge%20against%20it%2C%20as%20the%20parent%20connection%20can%20be%20replaced%20by%20another%20bridge.%0A%20%20%20%20%20%20vlan_parent%3D%24(nmcli%20--get-values%20GENERAL.DEVICES%20conn%20show%20uuid%20%24%7Bvlan_parent%7D)%0A%20%20%20%20fi%0A%0A%20%20%20%20extra_phys_args%3D(%20dev%20%22%24%7Bvlan_parent%7D%22%20id%20%22%24%7Bvlan_id%7D%22%20)%0A%20%20elif%20%5B%20%22%24(nmcli%20--get-values%20connection.type%20conn%20show%20%24%7Bold_conn%7D)%22%20%3D%3D%20%22bond%22%20%5D%3B%20then%0A%20%20%20%20iface_type%3Dbond%0A%20%20%20%20%23%20check%20bond%20options%0A%20%20%20%20bond_opts%3D%24(nmcli%20--get-values%20bond.options%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20if%20%5B%20-n%20%22%24bond_opts%22%20%5D%3B%20then%0A%20%20%20%20%20%20extra_phys_args%2B%3D(%20bond.options%20%22%24%7Bbond_opts%7D%22%20)%0A%20%20%20%20%20%20MODE_REGEX%3D%22(%5E%7C%2C)mode%3Dactive-backup(%2C%7C%24)%22%0A%20%20%20%20%20%20MAC_REGEX%3D%22(%5E%7C%2C)fail_over_mac%3D(1%7Cactive%7C2%7Cfollow)(%2C%7C%24)%22%0A%20%20%20%20%20%20if%20%5B%5B%20%24bond_opts%20%3D~%20%24MODE_REGEX%20%5D%5D%20%26%26%20%5B%5B%20%24bond_opts%20%3D~%20%24MAC_REGEX%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20clone_mac%3D0%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%20%20elif%20%5B%20%22%24(nmcli%20--get-values%20connection.type%20conn%20show%20%24%7Bold_conn%7D)%22%20%3D%3D%20%22team%22%20%5D%3B%20then%0A%20%20%20%20iface_type%3Dteam%0A%20%20%20%20%23%20check%20team%20config%20options%0A%20%20%20%20team_config_opts%3D%24(nmcli%20--get-values%20team.config%20-e%20no%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20if%20%5B%20-n%20%22%24team_config_opts%22%20%5D%3B%20then%0A%20%20%20%20%20%20%23%20team.config%20is%20json%2C%20remove%20spaces%20to%20avoid%20problems%20later%20on%0A%20%20%20%20%20%20extra_phys_args%2B%3D(%20team.config%20%22%24%7Bteam_config_opts%2F%2F%5B%5B%3Aspace%3A%5D%5D%2F%7D%22%20)%0A%20%20%20%20%20%20team_mode%3D%24(echo%20%22%24%7Bteam_config_opts%7D%22%20%7C%20jq%20-r%20%22.runner.name%20%2F%2F%20empty%22)%0A%20%20%20%20%20%20team_mac_policy%3D%24(echo%20%22%24%7Bteam_config_opts%7D%22%20%7C%20jq%20-r%20%22.runner.hwaddr_policy%20%2F%2F%20empty%22)%0A%20%20%20%20%20%20MAC_REGEX%3D%22(by_active%7Conly_active)%22%0A%20%20%20%20%20%20if%20%5B%20%22%24team_mode%22%20%3D%20%22activebackup%22%20%5D%20%26%26%20%5B%5B%20%22%24team_mac_policy%22%20%3D~%20%24MAC_REGEX%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20clone_mac%3D0%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%20%20elif%20%5B%20%22%24(nmcli%20--get-values%20connection.type%20conn%20show%20%24%7Bold_conn%7D)%22%20%3D%3D%20%22tun%22%20%5D%3B%20then%0A%20%20%20%20iface_type%3Dtun%0A%20%20%20%20tun_mode%3D%24(nmcli%20--get-values%20tun.mode%20-e%20no%20connection%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20extra_phys_args%2B%3D(%20tun.mode%20%22%24%7Btun_mode%7D%22%20)%0A%20%20elif%20%5B%20%22%24(nmcli%20--get-values%20connection.type%20conn%20show%20%24%7Bold_conn%7D)%22%20%3D%3D%20%22bridge%22%20%5D%3B%20then%0A%20%20%20%20iface_type%3Dbridge%0A%20%20else%0A%20%20%20%20iface_type%3D802-3-ethernet%0A%20%20fi%0A%0A%20%20if%20%5B%20!%20%22%24%7Bclone_mac%3A-%7D%22%20%3D%20%220%22%20%5D%3B%20then%0A%20%20%20%20%23%20In%20active-backup%20link%20aggregation%2C%20with%20fail_over_mac%20mode%20enabled%2C%0A%20%20%20%20%23%20cloning%20the%20mac%20address%20is%20not%20supported.%20It%20is%20possible%20then%20that%0A%20%20%20%20%23%20br-ex%20has%20a%20different%20mac%20address%20than%20the%20bond%20which%20might%20be%0A%20%20%20%20%23%20troublesome%20on%20some%20platforms%20where%20the%20nic%20won't%20accept%20packets%20with%0A%20%20%20%20%23%20a%20different%20destination%20mac.%20But%20nobody%20has%20complained%20so%20far%20so%20go%20on%0A%20%20%20%20%23%20with%20what%20we%20got.%20%0A%20%20%20%20%0A%20%20%20%20%23%20Do%20set%20it%20though%20for%20other%20link%20aggregation%20configurations%20where%20the%0A%20%20%20%20%23%20mac%20address%20would%20otherwise%20depend%20on%20enslave%20order%20for%20which%20we%20have%0A%20%20%20%20%23%20no%20control%20going%20forward.%0A%20%20%20%20extra_phys_args%2B%3D(%20802-3-ethernet.cloned-mac-address%20%22%24%7Biface_mac%7D%22%20)%0A%20%20fi%0A%0A%20%20%23%20use%20%24%7Bextra_phys_args%5B%40%5D%2B%22%24%7Bextra_phys_args%5B%40%5D%7D%22%7D%20instead%20of%20%24%7Bextra_phys_args%5B%40%5D%7D%20to%20be%20compatible%20with%20bash%204.2%20in%20RHEL7.9%0A%20%20if%20!%20nmcli%20connection%20show%20%22%24bridge_interface_name%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20destroy%20interface%20%24%7Biface%7D%0A%20%20%20%20ovs_default_port_conn%3D%24(nmcli%20-g%20connection.uuid%20conn%20show%20%22%24default_port_name%22)%0A%20%20%20%20add_nm_conn%20%22%24bridge_interface_name%22%20type%20%24%7Biface_type%7D%20conn.interface%20%24%7Biface%7D%20master%20%22%24ovs_default_port_conn%22%20%5C%0A%20%20%20%20%20%20slave-type%20ovs-port%20connection.autoconnect-priority%20100%20connection.autoconnect-slaves%201%20802-3-ethernet.mtu%20%24%7Biface_mtu%7D%20%5C%0A%20%20%20%20%20%20%24%7Bextra_phys_args%5B%40%5D%2B%22%24%7Bextra_phys_args%5B%40%5D%7D%22%7D%0A%20%20fi%0A%0A%20%20%23%20Get%20the%20new%20connection%20uuids%0A%20%20new_conn%3D%24(nmcli%20-g%20connection.uuid%20conn%20show%20%22%24bridge_interface_name%22)%0A%20%20ovs_port_conn%3D%24(nmcli%20-g%20connection.uuid%20conn%20show%20%22%24ovs_port%22)%0A%0A%20%20%23%20Update%20connections%20with%20master%20property%20set%20to%20use%20the%20new%20connection%0A%20%20replace_connection_master%20%24old_conn%20%24new_conn%0A%20%20replace_connection_master%20%24iface%20%24new_conn%0A%0A%20%20ipv4_method%3D%24(nmcli%20-g%20ipv4.method%20conn%20show%20%22%24old_conn%22)%0A%20%20ipv6_method%3D%24(nmcli%20-g%20ipv6.method%20conn%20show%20%22%24old_conn%22)%0A%0A%20%20ipv4_addresses%3D%24(nmcli%20-g%20ipv4.addresses%20conn%20show%20%22%24old_conn%22)%0A%20%20ipv6_addresses%3D%24(nmcli%20-g%20ipv6.addresses%20conn%20show%20%22%24old_conn%22)%0A%0A%20%20%23%20Warn%20about%20an%20invalid%20MTU%20that%20will%20most%20likely%20fail%20in%20one%20way%20or%0A%20%20%23%20another%0A%20%20if%20%5B%20%24%7Biface_mtu%7D%20-lt%201280%20%5D%20%26%26%20%5B%20%22%24%7Bipv6_method%7D%22%20!%3D%20%22disabled%22%20%5D%3B%20then%0A%20%20%20%20echo%20%22WARNING%3A%20MTU%20%24%7Biface_mtu%7D%20is%20lower%20than%20the%20minimum%20required%20of%201280%20for%20IPv6%22%0A%20%20fi%0A%0A%20%20if%20!%20nmcli%20connection%20show%20%22%24ovs_interface%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20destroy%20interface%20%22%24bridge_name%22%0A%20%20%20%20%23%20Clone%20the%20connection%20in%20case%20the%20method%20is%20manual%20or%20in%20case%20the%20an%20address%20is%20set%20(DHCP%20%2B%20static%20IP)%0A%20%20%20%20if%20%5B%20%22%24%7Bipv4_method%7D%22%20%3D%20%22manual%22%20%5D%20%7C%7C%20%5B%20%22%24%7Bipv4_addresses%7D%22%20!%3D%20%22%22%20%5D%20%7C%7C%20%5B%20%22%24%7Bipv6_method%7D%22%20%3D%20%22manual%22%20%5D%20%7C%7C%20%5B%20%22%24%7Bipv6_addresses%7D%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22Static%20IP%20addressing%20detected%20on%20default%20gateway%20connection%3A%20%24%7Bold_conn%7D%22%0A%20%20%20%20%20%20%23%20clone%20the%20old%20connection%20to%20get%20the%20address%20settings%0A%20%20%20%20%20%20%23%20prefer%20cloning%20vs%20copying%20the%20connection%20file%20to%20avoid%20problems%20with%20selinux%0A%20%20%20%20%20%20clone_nm_conn%20%22%24%7Bold_conn%7D%22%20%22%24%7Bovs_interface%7D%22%0A%20%20%20%20%20%20shopt%20-s%20nullglob%0A%20%20%20%20%20%20new_conn_files%3D(%24%7BNM_CONN_RUN_PATH%7D%2F%22%24%7Bovs_interface%7D%22*)%0A%20%20%20%20%20%20shopt%20-u%20nullglob%0A%20%20%20%20%20%20if%20%5B%20%24%7B%23new_conn_files%5B%40%5D%7D%20-ne%201%20%5D%20%7C%7C%20%5B%20!%20-f%20%22%24%7Bnew_conn_files%5B0%5D%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22ERROR%3A%20could%20not%20find%20%24%7Bovs_interface%7D%20conn%20file%20after%20cloning%20from%20%24%7Bold_conn%7D%22%0A%20%20%20%20%20%20%20%20exit%201%0A%20%20%20%20%20%20fi%0A%20%20%20%20%20%20new_conn_file%3D%22%24%7Bnew_conn_files%5B0%5D%7D%22%0A%0A%20%20%20%20%20%20%23%20modify%20the%20connection%20type%20directly%20because%20it%20can't%20be%20modified%0A%20%20%20%20%20%20%23%20through%20nmcli%0A%20%20%20%20%20%20sed%20-i%20'%2F%5E%5C%5Bconnection%5C%5D%24%2F%2C%2F%5E%5C%5B%2F%20s%2F%5Etype%3D.*%24%2Ftype%3Dovs-interface%2F'%20%24%7Bnew_conn_file%7D%0A%0A%20%20%20%20%20%20%23%20modify%20some%20more%20settings%20through%20nmcli%0A%20%20%20%20%20%20mod_nm_conn%20%22%24%7Bovs_interface%7D%22%20conn.interface%20%22%24bridge_name%22%20%5C%0A%20%20%20%20%20%20%20%20connection.multi-connect%20%22%22%20connection.autoconnect%20no%20%5C%0A%20%20%20%20%20%20%20%20connection.master%20%22%24ovs_port_conn%22%20connection.slave-type%20ovs-port%20%5C%0A%20%20%20%20%20%20%20%20ovs-interface.type%20internal%20%5C%0A%20%20%20%20%20%20%20%20802-3-ethernet.mtu%20%24%7Biface_mtu%7D%20802-3-ethernet.cloned-mac-address%20%24%7Biface_mac%7D%20%5C%0A%20%20%20%20%20%20%20%20ipv4.route-metric%20%22%24%7Bbridge_metric%7D%22%20ipv6.route-metric%20%22%24%7Bbridge_metric%7D%22%0A%0A%20%20%20%20%20%20echo%20%22Loaded%20new%20%24ovs_interface%20connection%20file%3A%20%24%7Bnew_conn_file%7D%22%0A%20%20%20%20else%0A%20%20%20%20%20%20extra_if_brex_args%3D%22%22%0A%20%20%20%20%20%20%23%20check%20if%20interface%20had%20ipv4%2Fipv6%20addresses%20assigned%0A%20%20%20%20%20%20num_ipv4_addrs%3D%24(ip%20-j%20a%20show%20dev%20%24%7Biface%7D%20%7C%20jq%20%22.%5B0%5D.addr_info%20%7C%20map(.%20%7C%20select(.family%20%3D%3D%20%5C%22inet%5C%22))%20%7C%20length%22)%0A%20%20%20%20%20%20if%20%5B%20%22%24num_ipv4_addrs%22%20-gt%200%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20extra_if_brex_args%2B%3D%22ipv4.may-fail%20no%20%22%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20%23%20IPV6%20should%20have%20at%20least%20a%20link%20local%20address.%20Check%20for%20more%20than%201%20to%20see%20if%20there%20is%20an%0A%20%20%20%20%20%20%23%20assigned%20address.%0A%20%20%20%20%20%20num_ip6_addrs%3D%24(ip%20-j%20a%20show%20dev%20%24%7Biface%7D%20%7C%20jq%20%22.%5B0%5D.addr_info%20%7C%20map(.%20%7C%20select(.family%20%3D%3D%20%5C%22inet6%5C%22%20and%20.scope%20!%3D%20%5C%22link%5C%22))%20%7C%20length%22)%0A%20%20%20%20%20%20if%20%5B%20%22%24num_ip6_addrs%22%20-gt%200%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20extra_if_brex_args%2B%3D%22ipv6.may-fail%20no%20%22%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20%23%20check%20for%20dhcp%20client%20ids%0A%20%20%20%20%20%20dhcp_client_id%3D%24(nmcli%20--get-values%20ipv4.dhcp-client-id%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20%20%20if%20%5B%20-n%20%22%24dhcp_client_id%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20extra_if_brex_args%2B%3D%22ipv4.dhcp-client-id%20%24%7Bdhcp_client_id%7D%20%22%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20dhcp6_client_id%3D%24(nmcli%20--get-values%20ipv6.dhcp-duid%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20%20%20if%20%5B%20-n%20%22%24dhcp6_client_id%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20extra_if_brex_args%2B%3D%22ipv6.dhcp-duid%20%24%7Bdhcp6_client_id%7D%20%22%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20ipv6_addr_gen_mode%3D%24(nmcli%20--get-values%20ipv6.addr-gen-mode%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20%20%20if%20%5B%20-n%20%22%24ipv6_addr_gen_mode%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20extra_if_brex_args%2B%3D%22ipv6.addr-gen-mode%20%24%7Bipv6_addr_gen_mode%7D%20%22%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20add_nm_conn%20%22%24ovs_interface%22%20type%20ovs-interface%20slave-type%20ovs-port%20conn.interface%20%22%24bridge_name%22%20master%20%22%24ovs_port_conn%22%20%5C%0A%20%20%20%20%20%20%20%20802-3-ethernet.mtu%20%24%7Biface_mtu%7D%20802-3-ethernet.cloned-mac-address%20%24%7Biface_mac%7D%20%5C%0A%20%20%20%20%20%20%20%20ipv4.method%20%22%24%7Bipv4_method%7D%22%20ipv4.route-metric%20%22%24%7Bbridge_metric%7D%22%20%5C%0A%20%20%20%20%20%20%20%20ipv6.method%20%22%24%7Bipv6_method%7D%22%20ipv6.route-metric%20%22%24%7Bbridge_metric%7D%22%20%5C%0A%20%20%20%20%20%20%20%20%24%7Bextra_if_brex_args%7D%0A%20%20%20%20fi%0A%20%20fi%0A%0A%20%20configure_driver_options%20%22%24%7Biface%7D%22%0A%7D%0A%0A%23%20Used%20to%20remove%20a%20bridge%0Aremove_ovn_bridges()%20%7B%0A%20%20bridge_name%3D%24%7B1%7D%0A%20%20port_name%3D%24%7B2%7D%0A%0A%20%20%23%20Remove%20the%20keyfiles%20from%20known%20configuration%20paths%0A%20%20update_nm_conn_run_files%20%24%7Bbridge_name%7D%20%24%7Bport_name%7D%0A%20%20rm_nm_conn_files%0A%20%20update_nm_conn_set_files%20%24%7Bbridge_name%7D%20%24%7Bport_name%7D%0A%20%20rm_nm_conn_files%0A%20%20%23%20Shouldn't%20be%20necessary%2C%20workaround%20for%20https%3A%2F%2Fissues.redhat.com%2Fbrowse%2FOCPBUGS-41489%0A%20%20update_nm_conn_etc_files%20%24%7Bbridge_name%7D%20%24%7Bport_name%7D%0A%20%20rm_nm_conn_files%0A%0A%20%20%23%20NetworkManager%20will%20not%20remove%20%24%7Bbridge_name%7D%20if%20it%20has%20the%20patch%20port%20created%20by%20ovn-kubernetes%0A%20%20%23%20so%20remove%20explicitly%0A%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-br%20%24%7Bbridge_name%7D%0A%7D%0A%0A%23%20Removes%20any%20previous%20ovs%20configuration%0Aremove_all_ovn_bridges()%20%7B%0A%20%20echo%20%22Reverting%20any%20previous%20OVS%20configuration%22%0A%20%20%0A%20%20remove_ovn_bridges%20br-ex%20phys0%0A%20%20remove_ovn_bridges%20br-ex1%20phys1%0A%20%20%0A%20%20echo%20%22OVS%20configuration%20successfully%20reverted%22%0A%7D%0A%0A%23%20Reloads%20NM%20NetworkManager%20profiles%20if%20any%20configuration%20change%20was%20done.%0A%23%20Accepts%20a%20list%20of%20devices%20that%20should%20be%20re-connect%20after%20reload.%0Areload_profiles_nm()%20%7B%0A%20%20if%20%5B%20%24%7Bnm_config_changed%3A-0%7D%20-eq%200%20%5D%3B%20then%0A%20%20%20%20%23%20no%20config%20was%20changed%2C%20no%20need%20to%20reload%0A%20%20%20%20return%0A%20%20fi%0A%0A%20%20%23%20reload%20profiles%0A%20%20nmcli%20connection%20reload%0A%0A%20%20%23%20precautionary%20sleep%20of%2010s%20(default%20timeout%20of%20NM%20to%20bring%20down%20devices)%0A%20%20sleep%2010%0A%0A%20%20%23%20After%20reload%2C%20devices%20that%20were%20already%20connected%20should%20connect%20again%0A%20%20%23%20if%20any%20profile%20is%20available.%20If%20no%20profile%20is%20available%2C%20a%20device%20can%0A%20%20%23%20remain%20disconnected%20and%20we%20have%20to%20explicitly%20connect%20it%20so%20that%20a%0A%20%20%23%20profile%20is%20generated.%20This%20can%20happen%20for%20physical%20devices%20but%20should%0A%20%20%23%20not%20happen%20for%20software%20devices%20as%20those%20always%20require%20a%20profile.%0A%20%20for%20dev%20in%20%24%40%3B%20do%0A%20%20%20%20%23%20Only%20attempt%20to%20connect%20a%20disconnected%20device%0A%20%20%20%20local%20connected_state%3D%24(nmcli%20-g%20GENERAL.STATE%20device%20show%20%22%24dev%22%20%7C%7C%20echo%20%22%22)%0A%20%20%20%20if%20%5B%5B%20%22%24connected_state%22%20%3D~%20%22disconnected%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%23%20keep%20track%20if%20a%20profile%20by%20the%20same%20name%20as%20the%20device%20existed%20%0A%20%20%20%20%20%20%23%20before%20we%20attempt%20activation%0A%20%20%20%20%20%20local%20named_profile_existed%3D%24(%5B%20-f%20%22%24%7BNM_CONN_CONF_PATH%7D%2F%24%7Bdev%7D%22%20%5D%20%7C%7C%20%5B%20-f%20%22%24%7BNM_CONN_CONF_PATH%7D%2F%24%7Bdev%7D.nmconnection%22%20%5D%20%26%26%20echo%20%22yes%22)%0A%20%20%20%20%20%20%0A%20%20%20%20%20%20for%20i%20in%20%7B1..10%7D%3B%20do%0A%20%20%20%20%20%20%20%20%20%20echo%20%22Attempt%20%24i%20to%20connect%20device%20%24dev%22%0A%20%20%20%20%20%20%20%20%20%20nmcli%20device%20connect%20%22%24dev%22%20%26%26%20break%0A%20%20%20%20%20%20%20%20%20%20sleep%205%0A%20%20%20%20%20%20done%0A%0A%20%20%20%20%20%20%23%20if%20a%20profile%20did%20not%20exist%20before%20but%20does%20now%2C%20it%20was%20generated%0A%20%20%20%20%20%20%23%20but%20we%20want%20it%20to%20be%20ephemeral%2C%20so%20move%20it%20back%20to%20%2Frun%0A%20%20%20%20%20%20if%20%5B%20!%20%22%24named_profile_existed%22%20%3D%20%22yes%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20MANAGED_NM_CONN_FILES%3D(%22%24%7BNM_CONN_CONF_PATH%7D%2F%24%7Bdev%7D%22%20%22%24%7BNM_CONN_CONF_PATH%7D%2F%24%7Bdev%7D.nmconnection%22)%0A%20%20%20%20%20%20%20%20copy_nm_conn_files%20%22%24%7BNM_CONN_RUN_PATH%7D%22%0A%20%20%20%20%20%20%20%20rm_nm_conn_files%0A%20%20%20%20%20%20%20%20%23%20reload%20profiles%20so%20that%20NM%20notices%20that%20some%20might%20have%20been%20moved%0A%20%20%20%20%20%20%20%20nmcli%20connection%20reload%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20echo%20%22Waiting%20for%20interface%20%24dev%20to%20activate...%22%0A%20%20%20%20if%20!%20timeout%2060%20bash%20-c%20%22while%20!%20nmcli%20-g%20DEVICE%2CSTATE%20c%20%7C%20grep%20%22'%22'%22%24dev%22%3Aactivated'%22'%22%3B%20do%20sleep%205%3B%20done%22%3B%20then%0A%20%20%20%20%20%20echo%20%22WARNING%3A%20%24dev%20did%20not%20activate%22%0A%20%20%20%20fi%0A%20%20done%0A%0A%20%20nm_config_changed%3D0%0A%7D%0A%0A%23%20Removes%20all%20configuration%20and%20reloads%20NM%20if%20necessary%0Arollback_nm()%20%7B%0A%20%20phys0%3D%24(get_bridge_physical_interface%20ovs-if-phys0)%0A%20%20phys1%3D%24(get_bridge_physical_interface%20ovs-if-phys1)%0A%20%20%0A%20%20%23%20Revert%20changes%20made%20by%20%2Fusr%2Flocal%2Fbin%2Fconfigure-ovs.sh%20during%20SDN%20migration.%0A%20%20remove_all_ovn_bridges%0A%20%20%0A%20%20%23%20reload%20profiles%20so%20that%20NM%20notices%20that%20some%20were%20removed%0A%20%20reload_profiles_nm%20%22%24phys0%22%20%22%24phys1%22%0A%7D%0A%0A%23%20Add%20a%20temporary%20deactivated%20connection%20profile%20%0A%23%20First%20argument%20is%20the%20connection%20name%20folowed%20by%20arguments%20passed%20to%0A%23%20%60nmcli%20connection%20add%60%0Aadd_nm_conn()%20%7B%0A%20%20%23%20Use%20%60save%20no%60%20to%20add%20a%20temporary%20profile%0A%20%20nmcli%20c%20add%20save%20no%20con-name%20%22%24%40%22%20connection.autoconnect%20no%0A%7D%0A%0A%23%20Modify%20a%20temporary%20connection%20profile%20%0A%23%20First%20argument%20is%20the%20connection%20name%20followed%20by%20arguments%20passed%20to%0A%23%20%60nmcli%20connection%20modify%60%0Amod_nm_conn()%20%7B%0A%20%20%23%20the%20easiest%20thing%20to%20do%20here%20would%20be%20to%20use%20%60nmcli%20c%20mod%20--temporary%60%0A%20%20%23%20but%20there%20is%20a%20bug%20in%20selinux%20profiles%20that%20denies%20NM%20from%20performing%0A%20%20%23%20the%20operation%0A%20%20local%20dst_path%3D%24%7BNM_CONN_RUN_PATH%7D%2F%241.nmconnection%0A%20%20local%20src_path%0A%20%20src_path%3D%24(mktemp)%0A%20%20shift%0A%20%20cat%20%22%24dst_path%22%20%3E%20%22%24src_path%22%0A%20%20rm%20-f%20%22%24dst_path%22%0A%20%20nmcli%20--offline%20c%20mod%20%22%24%40%22%20%3C%20%22%24src_path%22%20%3E%20%22%24dst_path%22%0A%20%20rm%20-f%20%22%24src_path%22%0A%20%20chmod%20600%20%22%24dst_path%22%0A%20%20nmcli%20c%20load%20%22%24dst_path%22%0A%7D%0A%0A%23%20Clone%20to%20a%20temporary%20connection%20profile%20%0A%23%20First%20argument%20is%20the%20connection%20to%20clone%2C%20second%20argument%20is%20the%20clone%20name%0Aclone_nm_conn()%20%7B%0A%20%20%23%20clone%20as%20temporary%20so%20that%20it%20is%20generated%20in%20NM_CONN_RUN_PATH%0A%20%20nmcli%20connection%20clone%20--temporary%20%22%241%22%20%22%242%22%20%26%3E%20%2Fdev%2Fnull%0A%7D%0A%0A%23%20Activates%20an%20ordered%20set%20of%20NM%20connection%20profiles%0Aactivate_nm_connections()%20%7B%0A%20%20local%20connections%3D(%22%24%40%22)%0A%0A%20%20%23%20We%20want%20autoconnect%20set%20for%20our%20cloned%20slave%20profiles%20so%20that%20they%20are%0A%20%20%23%20used%20over%20the%20original%20profiles%20if%20implicitly%20re-activated%20with%20other%0A%20%20%23%20dependant%20profiles.%20Otherwise%20if%20a%20slave%20activates%20with%20an%20old%20profile%2C%0A%20%20%23%20the%20old%20master%20profile%20might%20activate%20as%20well%2C%20interfering%20and%20causing%0A%20%20%23%20further%20activations%20to%20fail.%0A%20%20%23%20Slave%20interfaces%20should%20already%20be%20active%20so%20setting%20autoconnect%20here%0A%20%20%23%20won't%20implicitly%20activate%20them%20but%20there%20is%20an%20edge%20case%20where%20a%20slave%0A%20%20%23%20might%20be%20inactive%20(link%20down%20for%20example)%20and%20in%20that%20case%20setting%0A%20%20%23%20autoconnect%20will%20cause%20an%20implicit%20activation.%20This%20is%20not%20necessarily%20a%0A%20%20%23%20problem%20and%20hopefully%20we%20can%20make%20sure%20everything%20is%20activated%20as%20we%0A%20%20%23%20want%20next.%0A%20%20for%20conn%20in%20%22%24%7Bconnections%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20local%20slave_type%3D%24(nmcli%20-g%20connection.slave-type%20connection%20show%20%22%24conn%22)%0A%20%20%20%20if%20%5B%20%22%24slave_type%22%20%3D%20%22team%22%20%5D%20%7C%7C%20%5B%20%22%24slave_type%22%20%3D%20%22bond%22%20%5D%3B%20then%0A%20%20%20%20%20%20mod_nm_conn%20%22%24conn%22%20connection.autoconnect%20yes%0A%20%20%20%20fi%0A%20%20done%0A%0A%20%20%23%20Activate%20all%20connections%20and%20fail%20if%20activation%20fails%0A%20%20%23%20For%20slave%20connections%20-%20for%20as%20long%20as%20at%20least%20one%20slave%20that%20belongs%20to%20a%20bond%2Fteam%0A%20%20%23%20comes%20up%2C%20we%20should%20not%20fail%0A%20%20declare%20-A%20master_interfaces%0A%20%20for%20conn%20in%20%22%24%7Bconnections%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20%23%20Get%20the%20slave%20type%0A%20%20%20%20local%20slave_type%3D%24(nmcli%20-g%20connection.slave-type%20connection%20show%20%22%24conn%22)%0A%20%20%20%20local%20is_slave%3Dfalse%0A%20%20%20%20if%20%5B%20%22%24slave_type%22%20%3D%20%22team%22%20%5D%20%7C%7C%20%5B%20%22%24slave_type%22%20%3D%20%22bond%22%20%5D%3B%20then%0A%20%20%20%20%20%20is_slave%3Dtrue%0A%20%20%20%20fi%20%0A%0A%20%20%20%20%23%20For%20slave%20interfaces%2C%20initialize%20the%20master%20interface%20to%20false%20if%20the%20key%20is%20not%20yet%20in%20the%20array%0A%20%20%20%20local%20master_interface%0A%20%20%20%20if%20%24is_slave%3B%20then%0A%20%20%20%20%20%20master_interface%3D%24(nmcli%20-g%20connection.master%20connection%20show%20%22%24conn%22)%0A%20%20%20%20%20%20if%20!%20%5B%5B%20-v%20%22master_interfaces%5B%24master_interface%5D%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20master_interfaces%5B%22%24master_interface%22%5D%3Dfalse%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20slaves%20should%20implicitly%20activate%2C%20give%20them%20a%20chance%20to%20do%20so%0A%20%20%20%20if%20%24is_slave%3B%20then%0A%20%20%20%20%20%20if%20!%20timeout%205%20bash%20-c%20%22while%20!%20nmcli%20-g%20GENERAL.STATE%20conn%20show%20%22%24conn%22%20%7C%20grep%20activated%3B%20do%20sleep%201%3B%20done%22%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22WARNING%3A%20slave%20%24conn%20did%20not%20implicitly%20activate%20in%205s%2C%20activating%20explicitly.%22%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Do%20not%20activate%20interfaces%20that%20are%20already%20active%0A%20%20%20%20%23%20But%20set%20the%20entry%20in%20master_interfaces%20to%20true%20if%20this%20is%20a%20slave%0A%20%20%20%20%23%20Also%20set%20autoconnect%20to%20yes%0A%20%20%20%20local%20active_state%3D%24(nmcli%20-g%20GENERAL.STATE%20conn%20show%20%22%24conn%22)%0A%20%20%20%20if%20%5B%20%22%24active_state%22%20%3D%3D%20%22activated%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22Connection%20%24conn%20already%20activated%22%0A%20%20%20%20%20%20if%20%24is_slave%3B%20then%0A%20%20%20%20%20%20%20%20master_interfaces%5B%24master_interface%5D%3Dtrue%0A%20%20%20%20%20%20fi%0A%20%20%20%20%20%20mod_nm_conn%20%22%24conn%22%20connection.autoconnect%20yes%0A%20%20%20%20%20%20continue%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Activate%20all%20interfaces%20that%20are%20not%20yet%20active%0A%20%20%20%20for%20i%20in%20%7B1..10%7D%3B%20do%0A%20%20%20%20%20%20echo%20%22Attempt%20%24i%20to%20bring%20up%20connection%20%24conn%22%0A%20%20%20%20%20%20nmcli%20conn%20up%20%22%24conn%22%20%26%26%20s%3D0%20%26%26%20break%20%7C%7C%20s%3D%24%3F%0A%20%20%20%20%20%20sleep%205%0A%20%20%20%20done%0A%20%20%20%20if%20%5B%20%24s%20-eq%200%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22Brought%20up%20connection%20%24conn%20successfully%22%0A%20%20%20%20%20%20if%20%24is_slave%3B%20then%0A%20%20%20%20%20%20%20%20master_interfaces%5B%22%24master_interface%22%5D%3Dtrue%0A%20%20%20%20%20%20fi%0A%20%20%20%20elif%20!%20%24is_slave%3B%20then%0A%20%20%20%20%20%20echo%20%22ERROR%3A%20Cannot%20bring%20up%20connection%20%24conn%20after%20%24i%20attempts%22%0A%20%20%20%20%20%20return%20%24s%0A%20%20%20%20fi%0A%20%20%20%20mod_nm_conn%20%22%24conn%22%20connection.autoconnect%20yes%0A%20%20done%0A%20%20%23%20Check%20that%20all%20master%20interfaces%20report%20at%20least%20a%20single%20active%20slave%0A%20%20%23%20Note%3A%20associative%20arrays%20require%20an%20exclamation%20mark%20when%20looping%0A%20%20for%20i%20in%20%22%24%7B!master_interfaces%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20if%20!%20%24%7Bmaster_interfaces%5B%22%24i%22%5D%7D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22ERROR%3A%20Cannot%20bring%20up%20any%20slave%20interface%20for%20master%20interface%3A%20%24i%22%0A%20%20%20%20%20%20%20%20return%201%0A%20%20%20%20fi%0A%20%20done%0A%7D%0A%0A%23%20Accepts%20parameters%20%24iface_default_hint_file%2C%20%24iface%0A%23%20Writes%20content%20of%20%24iface%20into%20%24iface_default_hint_file%0Awrite_iface_default_hint()%20%7B%0A%20%20local%20iface_default_hint_file%3D%22%241%22%0A%20%20local%20iface%3D%22%242%22%0A%0A%20%20echo%20%22%24%7Biface%7D%22%20%3E%7C%20%22%24%7Biface_default_hint_file%7D%22%0A%7D%0A%0A%23%20Accepts%20parameters%20%24iface_default_hint_file%0A%23%20Returns%20the%20stored%20interface%20default%20hint%20if%20the%20hint%20is%20non-empty%2C%0A%23%20not%20br-ex%2C%20not%20br-ex1%20and%20if%20the%20interface%20can%20be%20found%20in%20%2Fsys%2Fclass%2Fnet%0Aget_iface_default_hint()%20%7B%0A%20%20local%20iface_default_hint_file%3D%241%0A%20%20if%20%5B%20-f%20%22%24%7Biface_default_hint_file%7D%22%20%5D%3B%20then%0A%20%20%20%20local%20iface_default_hint%3D%24(cat%20%22%24%7Biface_default_hint_file%7D%22)%0A%20%20%20%20if%20%5B%20%22%24%7Biface_default_hint%7D%22%20!%3D%20%22%22%20%5D%20%26%26%0A%20%20%20%20%20%20%20%20%5B%20%22%24%7Biface_default_hint%7D%22%20!%3D%20%22br-ex%22%20%5D%20%26%26%0A%20%20%20%20%20%20%20%20%5B%20%22%24%7Biface_default_hint%7D%22%20!%3D%20%22br-ex1%22%20%5D%20%26%26%0A%20%20%20%20%20%20%20%20%5B%20-d%20%22%2Fsys%2Fclass%2Fnet%2F%24%7Biface_default_hint%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22%24%7Biface_default_hint%7D%22%0A%20%20%20%20%20%20%20%20return%0A%20%20%20%20fi%0A%20%20fi%0A%20%20echo%20%22%22%0A%7D%0A%0Aget_ip_from_ip_hint_file()%20%7B%0A%20%20local%20ip_hint_file%3D%22%241%22%0A%20%20if%20%5B%5B%20!%20-f%20%22%24%7Bip_hint_file%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20return%0A%20%20fi%0A%20%20ip_hint%3D%24(cat%20%22%24%7Bip_hint_file%7D%22)%0A%20%20echo%20%22%24%7Bip_hint%7D%22%0A%7D%0A%0A%23%20This%20function%20waits%20for%20ip%20address%20of%20br-ex%20to%20be%20bindable%20only%20in%20case%20of%20ipv6%0A%23%20This%20is%20workaround%20for%20OCPBUGS-673%20as%20it%20will%20not%20allow%20starting%20crio%0A%23%20before%20address%20is%20bindable%0Atry_to_bind_ipv6_address()%20%7B%0A%20%20%23%20Retry%20for%201%20minute%0A%20%20retries%3D60%0A%20%20until%20%5B%5B%20%24%7Bretries%7D%20-eq%200%20%5D%5D%3B%20do%0A%20%20%20%20ip%3D%24(ip%20-6%20-j%20addr%20%7C%20jq%20-r%20%22first(.%5B%5D%20%7C%20select(.ifname%3D%3D%5C%22br-ex%5C%22)%20%7C%20.addr_info%5B%5D%20%7C%20select(.scope%3D%3D%5C%22global%5C%22)%20%7C%20.local)%22)%0A%20%20%20%20if%20%5B%5B%20%22%24%7Bip%7D%22%20%3D%3D%20%22%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22No%20ipv6%20ip%20to%20bind%20was%20found%22%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20%20%20random_port%3D%24(shuf%20-i%2050000-60000%20-n%201)%0A%20%20%20%20echo%20%22Trying%20to%20bind%20%24%7Bip%7D%20on%20port%20%24%7Brandom_port%7D%22%0A%20%20%20%20exit_code%3D%24(timeout%202s%20nc%20-l%20%22%24%7Bip%7D%22%20%24%7Brandom_port%7D%3B%20echo%20%24%3F)%0A%20%20%20%20if%20%5B%5B%20exit_code%20-eq%20124%20%5D%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22Address%20bound%20successfully%22%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20%20%20sleep%201%0A%20%20%20%20((%20retries--%20))%0A%20%20done%0A%20%20if%20%5B%5B%20%24%7Bretries%7D%20-eq%200%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22Failed%20to%20bind%20ip%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%7D%0A%0A%23%20Get%20interface%20that%20matches%20ip%20from%20node%20ip%20hint%20file%0A%23%20in%20case%20file%20not%20exists%20return%20nothing%20and%0A%23%20fallback%20to%20default%20interface%20search%20flow%0Aget_nodeip_hint_interface()%20%7B%0A%20%20local%20ip_hint%3D%22%22%0A%20%20local%20ip_hint_file%3D%22%241%22%0A%20%20local%20extra_bridge%3D%22%242%22%0A%20%20local%20iface%3D%22%22%0A%0A%20%20ip_hint%3D%24(get_ip_from_ip_hint_file%20%22%24%7Bip_hint_file%7D%22)%0A%20%20if%20%5B%5B%20-z%20%22%24%7Bip_hint%7D%22%20%20%5D%5D%3B%20then%0A%20%20%20%20return%0A%20%20fi%0A%0A%20%20iface%3D%24(ip%20-j%20addr%20%7C%20jq%20-r%20%22first(.%5B%5D%20%7C%20select(any(.addr_info%5B%5D%3B%20.local%3D%3D%5C%22%24%7Bip_hint%7D%5C%22)%20and%20.ifname!%3D%5C%22br-ex1%5C%22%20and%20.ifname!%3D%5C%22%24%7Bextra_bridge%7D%5C%22))%20%7C%20.ifname%22)%0A%20%20if%20%5B%5B%20-n%20%22%24%7Biface%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22%24%7Biface%7D%22%0A%20%20fi%0A%7D%0A%0A%23%20Accepts%20parameters%20%24bridge_interface%20(e.g.%20ovs-port-phys0)%0A%23%20Returns%20the%20physical%20interface%20name%20if%20%24bridge_interface%20exists%2C%20%22%22%20otherwise%0Aget_bridge_physical_interface()%20%7B%0A%20%20local%20bridge_interface%3D%22%241%22%0A%20%20local%20physical_interface%3D%22%22%0A%20%20physical_interface%3D%24(nmcli%20-g%20connection.interface-name%20conn%20show%20%22%24%7Bbridge_interface%7D%22%202%3E%2Fdev%2Fnull%20%7C%7C%20echo%20%22%22)%0A%20%20echo%20%22%24%7Bphysical_interface%7D%22%0A%7D%0A%0A%23%20Accepts%20parameters%20%24iface_default_hint_file%2C%20%24extra_bridge_file%2C%20%24ip_hint_file%2C%20%24default_bridge_file%0A%23%20Determines%20the%20interface%20to%20be%20used%20for%20br-ex.%20Order%20of%20priority%20is%3A%0A%23%201.%20Use%20the%20user%20specified%20interface%20if%20provided%20in%20the%20default%20bridge%20file%0A%23%202.%20Use%20the%20node%20IP%20hint%20interface%0A%23%203.%20Use%20the%20previously%20selected%20interface%0A%23%204.%20Use%20the%20interface%20detected%20as%20default%20gateway%0A%23%0A%23%20Read%20%24default_bridge_file%20and%20return%20the%20contained%20interface.%20Otherwise%2C%0A%23%20read%20%24ip_hint_file%20and%20return%20the%20interface%20that%20matches%20this%20ip.%20Otherwise%2C%0A%23%20if%20the%20default%20interface%20is%20br-ex%2C%20use%20that%20and%20return.%0A%23%20If%20the%20default%20interface%20is%20not%20br-ex%3A%0A%23%20Check%20if%20there%20is%20a%20valid%20hint%20inside%20%24iface_default_hint_file.%20If%20so%2C%20use%20that%20hint.%0A%23%20If%20there%20is%20no%20valid%20hint%2C%20use%20the%20default%20interface%20that%20we%20found%20during%20the%20step%0A%23%20earlier.%0A%23%20Never%20use%20the%20interface%20that%20is%20provided%20inside%20%24extra_bridge_file%20for%20br-ex1.%0A%23%20Never%20use%20br-ex1.%0A%23%20Write%20the%20default%20interface%20to%20%24iface_default_hint_file%0Aget_default_bridge_interface()%20%7B%0A%20%20local%20iface%3D%22%22%0A%20%20local%20counter%3D0%0A%20%20local%20iface_default_hint_file%3D%22%241%22%0A%20%20local%20extra_bridge_file%3D%22%242%22%0A%20%20local%20ip_hint_file%3D%22%243%22%0A%20%20local%20default_bridge_file%3D%22%244%22%0A%20%20local%20extra_bridge%3D%22%22%0A%0A%20%20if%20%5B%20-f%20%22%24%7Bextra_bridge_file%7D%22%20%5D%3B%20then%0A%20%20%20%20extra_bridge%3D%24(cat%20%24%7Bextra_bridge_file%7D)%0A%20%20fi%0A%0A%20%20%23%20try%20to%20use%20user%20specified%20file%20first%0A%20%20if%20%5B%20-f%20%22%24default_bridge_file%22%20%5D%3B%20then%0A%20%20%20%20iface%3D%24(cat%20%22%24%7Bdefault_bridge_file%7D%22)%0A%20%20%20%20if%20%5B%20-z%20%22%24iface%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22ERROR%3A%20User%20specified%20bridge%20file%20detected%20without%20any%20data%22%0A%20%20%20%20%20%20exit%201%0A%20%20%20%20fi%0A%20%20%20%20echo%20%22%24%7Biface%7D%22%0A%20%20%20%20return%0A%20%20fi%0A%0A%20%20%23%20if%20node%20ip%20was%20set%2C%20we%20should%20search%20for%20interface%20that%20matches%20it%0A%20%20iface%3D%24(get_nodeip_hint_interface%20%22%24%7Bip_hint_file%7D%22%20%22%24%7Bextra_bridge%7D%22)%0A%20%20if%20%5B%5B%20-n%20%22%24%7Biface%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22%24%7Biface%7D%22%0A%20%20%20%20return%0A%20%20fi%0A%0A%20%20%23%20find%20default%20interface%0A%20%20%23%20the%20default%20interface%20might%20be%20br-ex%2C%20so%20check%20this%20before%20looking%20at%20the%20hint%0A%20%20while%20%5B%20%24%7Bcounter%7D%20-lt%2012%20%5D%3B%20do%0A%20%20%20%20%23%20check%20ipv4%0A%20%20%20%20%23%20never%20use%20the%20interface%20that's%20specified%20in%20extra_bridge_file%0A%20%20%20%20%23%20never%20use%20br-ex1%0A%20%20%20%20if%20%5B%20%22%24%7Bextra_bridge%7D%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20iface%3D%24(ip%20route%20show%20default%20%7C%20grep%20-v%20%22br-ex1%22%20%7C%20grep%20-v%20%22%24%7Bextra_bridge%7D%22%20%7C%20awk%20'%7B%20if%20(%244%20%3D%3D%20%22dev%22)%20%7B%20print%20%245%3B%20exit%20%7D%20%7D')%0A%20%20%20%20else%0A%20%20%20%20%20%20iface%3D%24(ip%20route%20show%20default%20%7C%20grep%20-v%20%22br-ex1%22%20%7C%20awk%20'%7B%20if%20(%244%20%3D%3D%20%22dev%22)%20%7B%20print%20%245%3B%20exit%20%7D%20%7D')%0A%20%20%20%20fi%0A%20%20%20%20if%20%5B%5B%20-n%20%22%24%7Biface%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20%20%20%23%20check%20ipv6%0A%20%20%20%20%23%20never%20use%20the%20interface%20that's%20specified%20in%20extra_bridge_file%0A%20%20%20%20%23%20never%20use%20br-ex1%0A%20%20%20%20if%20%5B%20%22%24%7Bextra_bridge%7D%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20iface%3D%24(ip%20-6%20route%20show%20default%20%7C%20grep%20-v%20%22br-ex1%22%20%7C%20grep%20-v%20%22%24%7Bextra_bridge%7D%22%20%7C%20awk%20'%7B%20if%20(%244%20%3D%3D%20%22dev%22)%20%7B%20print%20%245%3B%20exit%20%7D%20%7D')%0A%20%20%20%20else%0A%20%20%20%20%20%20iface%3D%24(ip%20-6%20route%20show%20default%20%7C%20grep%20-v%20%22br-ex1%22%20%7C%20awk%20'%7B%20if%20(%244%20%3D%3D%20%22dev%22)%20%7B%20print%20%245%3B%20exit%20%7D%20%7D')%0A%20%20%20%20fi%0A%20%20%20%20if%20%5B%5B%20-n%20%22%24%7Biface%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20%20%20counter%3D%24((counter%2B1))%0A%20%20%20%20sleep%205%0A%20%20done%0A%0A%20%20%23%20if%20the%20default%20interface%20does%20not%20point%20out%20of%20br-ex%20or%20br-ex1%0A%20%20if%20%5B%20%22%24%7Biface%7D%22%20!%3D%20%22br-ex%22%20%5D%20%26%26%20%5B%20%22%24%7Biface%7D%22%20!%3D%20%22br-ex1%22%20%5D%3B%20then%0A%20%20%20%20%23%20determine%20if%20an%20interface%20default%20hint%20exists%20from%20a%20previous%20run%0A%20%20%20%20%23%20and%20if%20the%20interface%20has%20a%20valid%20default%20route%0A%20%20%20%20iface_default_hint%3D%24(get_iface_default_hint%20%22%24%7Biface_default_hint_file%7D%22)%0A%20%20%20%20if%20%5B%20%22%24%7Biface_default_hint%7D%22%20!%3D%20%22%22%20%5D%20%26%26%0A%20%20%20%20%20%20%20%20%5B%20%22%24%7Biface_default_hint%7D%22%20!%3D%20%22%24%7Biface%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%23%20start%20wherever%20count%20left%20off%20in%20the%20previous%20loop%0A%20%20%20%20%20%20%23%20allow%20this%20for%20one%20more%20iteration%20than%20the%20previous%20loop%0A%20%20%20%20%20%20while%20%5B%20%24%7Bcounter%7D%20-le%2012%20%5D%3B%20do%0A%20%20%20%20%20%20%20%20%23%20check%20ipv4%0A%20%20%20%20%20%20%20%20if%20%5B%20%22%24(ip%20route%20show%20default%20dev%20%22%24%7Biface_default_hint%7D%22)%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20iface%3D%22%24%7Biface_default_hint%7D%22%0A%20%20%20%20%20%20%20%20%20%20break%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20%23%20check%20ipv6%0A%20%20%20%20%20%20%20%20if%20%5B%20%22%24(ip%20-6%20route%20show%20default%20dev%20%22%24%7Biface_default_hint%7D%22)%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20iface%3D%22%24%7Biface_default_hint%7D%22%0A%20%20%20%20%20%20%20%20%20%20break%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20counter%3D%24((counter%2B1))%0A%20%20%20%20%20%20%20%20sleep%205%0A%20%20%20%20%20%20done%0A%20%20%20%20fi%0A%20%20%20%20%23%20store%20what%20was%20determined%20was%20the%20(new)%20default%20interface%20inside%0A%20%20%20%20%23%20the%20default%20hint%20file%20for%20future%20reference%0A%20%20%20%20if%20%5B%20%22%24%7Biface%7D%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20write_iface_default_hint%20%22%24%7Biface_default_hint_file%7D%22%20%22%24%7Biface%7D%22%0A%20%20%20%20fi%0A%20%20fi%0A%20%20echo%20%22%24%7Biface%7D%22%0A%7D%0A%0A%23%20Used%20to%20print%20network%20state%0Aprint_state()%20%7B%0A%20%20echo%20%22Current%20device%2C%20connection%2C%20interface%20and%20routing%20state%3A%22%0A%20%20nmcli%20-g%20all%20device%20%7C%20grep%20-v%20unmanaged%0A%20%20nmcli%20-g%20all%20connection%0A%20%20ip%20-d%20address%20show%0A%20%20ip%20route%20show%0A%20%20ip%20-6%20route%20show%0A%7D%0A%0A%23%20Setup%20an%20exit%20trap%20to%20rollback%20on%20error%0Ahandle_exit()%20%7B%0A%20%20e%3D%24%3F%0A%20%20tdir%3D%24(mktemp%20-u%20-d%20-t%20%22configure-ovs-%24(date%20%2B%25Y-%25m-%25d-%25H-%25M-%25S)-XXXXXXXXXX%22)%0A%20%20%0A%20%20if%20%5B%20%24e%20-eq%200%20%5D%3B%20then%0A%20%20%20%20print_state%0A%20%20%20%20%23%20remove%20previous%20troubleshooting%20information%0A%20%20%20%20rm%20-rf%20%22%24(dirname%20%22%24tdir%22)%2Fconfigure-ovs-*%22%0A%20%20%20%20exit%200%0A%20%20fi%0A%0A%20%20echo%20%22ERROR%3A%20configure-ovs%20exited%20with%20error%3A%20%24e%22%0A%20%20print_state%0A%0A%20%20%23%20remove%20previous%20troubleshooting%20information%20except%20the%20oldest%20one%0A%20%20mapfile%20-t%20tdirs%20%3C%20%3C(compgen%20-G%20%22%24(dirname%20%22%24tdir%22)%2Fconfigure-ovs-*%22)%0A%20%20unset%20-v%20%22tdirs%5B0%5D%22%0A%20%20for%20dir%20in%20%22%24%7Btdirs%5B%40%5D%7D%22%3B%20do%20rm%20-rf%20%22%24dir%22%3B%20done%0A%0A%20%20%23%20copy%20configuration%20to%20tmp%20for%20troubleshooting%0A%20%20mkdir%20-p%20%22%24tdir%22%0A%20%20update_nm_conn_run_files%20br-ex%20phys0%0A%20%20copy_nm_conn_files%20%22%24tdir%22%0A%20%20update_nm_conn_run_files%20br-ex1%20phys1%0A%20%20copy_nm_conn_files%20%22%24tdir%22%0A%20%20echo%20%22Copied%20OVS%20configuration%20to%20%24tdir%20for%20troubleshooting%22%0A%0A%20%20%23%20attempt%20to%20restore%20the%20previous%20network%20state%0A%20%20echo%20%22Attempting%20to%20restore%20previous%20configuration...%22%0A%20%20rollback_nm%0A%20%20print_state%0A%0A%20%20exit%20%24e%0A%7D%0A%0A%23%20Setup%20a%20signal%20trap%20to%20rollback%0Ahandle_termination()%20%7B%0A%20%20echo%20%22WARNING%3A%20configure-ovs%20has%20been%20requested%20to%20terminate%2C%20quitting...%22%0A%20%20%0A%20%20%23%20by%20exiting%20with%20an%20error%20we%20will%20cleanup%20after%20ourselves%20in%20a%0A%20%20%23%20subsequent%20call%20to%20handle_exit%0A%20%20exit%201%0A%7D%0A%0A%23%20main%20function%0Aconfigure_ovs()%20%7B%0A%20%20set%20-eu%0A%0A%20%20%23%20setup%20traps%20to%20handle%20signals%20and%20other%20abnormal%20exits%0A%20%20trap%20'handle_termination'%20TERM%20INT%0A%20%20trap%20'handle_exit'%20EXIT%0A%0A%20%20%23%20this%20flag%20tracks%20if%20any%20config%20change%20was%20made%0A%20%20nm_config_changed%3D0%0A%0A%20%20%23%20Check%20that%20we%20are%20provided%20a%20valid%20NM%20connection%20path%0A%20%20if%20%5B%20%22%24NM_CONN_SET_PATH%22%20!%3D%20%22%24NM_CONN_CONF_PATH%22%20%5D%20%26%26%20%5B%20%22%24NM_CONN_SET_PATH%22%20!%3D%20%22%24NM_CONN_RUN_PATH%22%20%5D%3B%20then%0A%20%20%20%20echo%20%22Error%3A%20Incorrect%20NM%20connection%20path%3A%20%24NM_CONN_SET_PATH%20is%20not%20%24NM_CONN_CONF_PATH%20nor%20%24NM_CONN_RUN_PATH%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%0A%20%20%23%20Clean%20up%20old%20config%20on%20behalf%20of%20mtu-migration%0A%20%20if%20!%20systemctl%20-q%20is-enabled%20mtu-migration%3B%20then%0A%20%20%20%20echo%20%22Cleaning%20up%20left%20over%20mtu%20migration%20configuration%22%0A%20%20%20%20rm%20-rf%20%2Fetc%2Fcno%2Fmtu-migration%0A%20%20fi%0A%0A%20%20if%20!%20rpm%20-qa%20%7C%20grep%20-q%20openvswitch%3B%20then%0A%20%20%20%20echo%20%22WARNING%3A%20Openvswitch%20package%20is%20not%20installed!%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%0A%20%20%23%20print%20initial%20state%0A%20%20print_state%0A%0A%20%20if%20%5B%20%22%241%22%20%3D%3D%20%22OVNKubernetes%22%20%5D%3B%20then%0A%20%20%20%20%23%20Configures%20NICs%20onto%20OVS%20bridge%20%22br-ex%22%0A%20%20%20%20%23%20Configuration%20is%20either%20auto-detected%20or%20provided%20through%20a%20config%20file%20written%20already%20in%20Network%20Manager%0A%20%20%20%20%23%20key%20files%20under%20%2Fetc%2FNetworkManager%2Fsystem-connections%2F%0A%20%20%20%20%23%20Managing%20key%20files%20is%20outside%20of%20the%20scope%20of%20this%20script%0A%0A%20%20%20%20%23%20if%20the%20interface%20is%20of%20type%20vmxnet3%20add%20multicast%20capability%20for%20that%20driver%0A%20%20%20%20%23%20History%3A%20BZ%3A1854355%0A%20%20%20%20function%20configure_driver_options%20%7B%0A%20%20%20%20%20%20intf%3D%241%0A%20%20%20%20%20%20if%20%5B%20!%20-f%20%22%2Fsys%2Fclass%2Fnet%2F%24%7Bintf%7D%2Fdevice%2Fuevent%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22Device%20file%20doesn't%20exist%2C%20skipping%20setting%20multicast%20mode%22%0A%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20driver%3D%24(cat%20%22%2Fsys%2Fclass%2Fnet%2F%24%7Bintf%7D%2Fdevice%2Fuevent%22%20%7C%20grep%20DRIVER%20%7C%20awk%20-F%20%22%3D%22%20'%7Bprint%20%242%7D')%0A%20%20%20%20%20%20%20%20echo%20%22Driver%20name%20is%22%20%24driver%0A%20%20%20%20%20%20%20%20if%20%5B%20%22%24driver%22%20%3D%20%22vmxnet3%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20ip%20link%20set%20dev%20%22%24%7Bintf%7D%22%20allmulticast%20on%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20fi%0A%20%20%20%20%7D%0A%0A%20%20%20%20ovnk_config_dir%3D'%2Fetc%2Fovnk'%0A%20%20%20%20ovnk_var_dir%3D'%2Fvar%2Flib%2Fovnk'%0A%20%20%20%20extra_bridge_file%3D%22%24%7Bovnk_config_dir%7D%2Fextra_bridge%22%0A%20%20%20%20iface_default_hint_file%3D%22%24%7Bovnk_var_dir%7D%2Fiface_default_hint%22%0A%20%20%20%20ip_hint_file%3D%22%2Frun%2Fnodeip-configuration%2Fprimary-ip%22%0A%20%20%20%20%23%20explicitly%20specify%20which%20interface%20should%20be%20used%20with%20the%20default%20bridge%0A%20%20%20%20default_bridge_file%3D%22%24%7Bovnk_config_dir%7D%2Fdefault_bridge%22%0A%0A%20%20%20%20%23%20make%20sure%20to%20create%20ovnk_config_dir%20if%20it%20does%20not%20exist%2C%20yet%0A%20%20%20%20mkdir%20-p%20%22%24%7Bovnk_config_dir%7D%22%0A%20%20%20%20%23%20make%20sure%20to%20create%20ovnk_var_dir%20if%20it%20does%20not%20exist%2C%20yet%0A%20%20%20%20mkdir%20-p%20%22%24%7Bovnk_var_dir%7D%22%0A%0A%20%20%20%20%23%20For%20upgrade%20scenarios%2C%20make%20sure%20that%20we%20stabilize%20what%20we%20already%20configured%0A%20%20%20%20%23%20before.%20If%20we%20do%20not%20have%20a%20valid%20interface%20hint%2C%20find%20the%20physical%20interface%0A%20%20%20%20%23%20that's%20attached%20to%20ovs-if-phys0.%0A%20%20%20%20%23%20If%20we%20find%20such%20an%20interface%2C%20write%20it%20to%20the%20hint%20file.%0A%20%20%20%20iface_default_hint%3D%24(get_iface_default_hint%20%22%24%7Biface_default_hint_file%7D%22)%0A%20%20%20%20if%20%5B%20%22%24%7Biface_default_hint%7D%22%20%3D%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20current_interface%3D%24(get_bridge_physical_interface%20ovs-if-phys0)%0A%20%20%20%20%20%20if%20%5B%20%22%24%7Bcurrent_interface%7D%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20write_iface_default_hint%20%22%24%7Biface_default_hint_file%7D%22%20%22%24%7Bcurrent_interface%7D%22%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20delete%20iface_default_hint_file%20if%20it%20has%20the%20same%20content%20as%20extra_bridge_file%0A%20%20%20%20%23%20in%20that%20case%2C%20we%20must%20also%20force%20a%20reconfiguration%20of%20our%20network%20interfaces%0A%20%20%20%20%23%20to%20make%20sure%20that%20we%20reconcile%20this%20conflict%0A%20%20%20%20if%20%5B%20-f%20%22%24%7Biface_default_hint_file%7D%22%20%5D%20%26%26%0A%20%20%20%20%20%20%5B%20-f%20%22%24%7Bextra_bridge_file%7D%22%20%5D%20%26%26%0A%20%20%20%20%20%20%5B%20%22%24(cat%20%22%24%7Biface_default_hint_file%7D%22)%22%20%3D%3D%20%22%24(cat%20%22%24%7Bextra_bridge_file%7D%22)%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22%24%7Biface_default_hint_file%7D%20and%20%24%7Bextra_bridge_file%7D%20share%20the%20same%20content%22%0A%20%20%20%20%20%20echo%20%22Deleting%20file%20%24%7Biface_default_hint_file%7D%20to%20choose%20a%20different%20interface%22%0A%20%20%20%20%20%20rm%20-f%20%22%24%7Biface_default_hint_file%7D%22%0A%20%20%20%20%20%20rm%20-f%20%2Frun%2Fconfigure-ovs-boot-done%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20on%20every%20boot%20we%20rollback%20and%20generate%20the%20configuration%20again%2C%20to%20take%0A%20%20%20%20%23%20in%20any%20changes%20that%20have%20possibly%20been%20applied%20in%20the%20standard%0A%20%20%20%20%23%20configuration%20sources%0A%20%20%20%20if%20%5B%20!%20-f%20%2Frun%2Fconfigure-ovs-boot-done%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22Running%20on%20boot%2C%20restoring%20previous%20configuration%20before%20proceeding...%22%0A%20%20%20%20%20%20rollback_nm%0A%20%20%20%20%20%20print_state%0A%20%20%20%20fi%0A%20%20%20%20touch%20%2Frun%2Fconfigure-ovs-boot-done%0A%0A%20%20%20%20iface%3D%24(get_default_bridge_interface%20%22%24%7Biface_default_hint_file%7D%22%20%22%24%7Bextra_bridge_file%7D%22%20%22%24%7Bip_hint_file%7D%22%20%22%24%7Bdefault_bridge_file%7D%22)%0A%0A%20%20%20%20if%20%5B%20%22%24iface%22%20!%3D%20%22br-ex%22%20%5D%3B%20then%0A%20%20%20%20%20%20%23%20Specified%20interface%20is%20not%20br-ex.%0A%20%20%20%20%20%20%23%20Some%20deployments%20use%20a%20temporary%20solution%20where%20br-ex%20is%20moved%20out%20from%20the%20default%20gateway%20interface%0A%20%20%20%20%20%20%23%20and%20bound%20to%20a%20different%20nic%20(https%3A%2F%2Fgithub.com%2Ftrozet%2Fopenshift-ovn-migration).%0A%20%20%20%20%20%20%23%20This%20is%20now%20supported%20through%20an%20extra%20bridge%20if%20requested.%20If%20that%20is%20the%20case%2C%20we%20rollback.%0A%20%20%20%20%20%20%23%20We%20also%20rollback%20if%20it%20looks%20like%20we%20need%20to%20configure%20things%2C%20just%20in%20case%20there%20are%20any%20leftovers%0A%20%20%20%20%20%20%23%20from%20previous%20attempts.%0A%20%20%20%20%20%20if%20%5B%20-f%20%22%24extra_bridge_file%22%20%5D%20%7C%7C%20%5B%20-z%20%22%24(nmcli%20connection%20show%20--active%20br-ex%202%3E%20%2Fdev%2Fnull)%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22Bridge%20br-ex%20is%20not%20active%2C%20restoring%20previous%20configuration%20before%20proceeding...%22%0A%20%20%20%20%20%20%20%20rollback_nm%0A%20%20%20%20%20%20%20%20print_state%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20convert_to_bridge%20%22%24iface%22%20%22br-ex%22%20%22phys0%22%20%22%24%7BBRIDGE_METRIC%7D%22%0A%0A%20%20%20%20%23%20Check%20if%20we%20need%20to%20configure%20the%20second%20bridge%0A%20%20%20%20if%20%5B%20-f%20%22%24extra_bridge_file%22%20%5D%20%26%26%20(!%20nmcli%20connection%20show%20br-ex1%20%26%3E%20%2Fdev%2Fnull%20%7C%7C%20!%20nmcli%20connection%20show%20ovs-if-phys1%20%26%3E%20%2Fdev%2Fnull)%3B%20then%0A%20%20%20%20%20%20interface%3D%24(head%20-n%201%20%24extra_bridge_file)%0A%20%20%20%20%20%20convert_to_bridge%20%22%24interface%22%20%22br-ex1%22%20%22phys1%22%20%22%24%7BBRIDGE1_METRIC%7D%22%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Check%20if%20we%20need%20to%20remove%20the%20second%20bridge%0A%20%20%20%20if%20%5B%20!%20-f%20%22%24extra_bridge_file%22%20%5D%20%26%26%20(nmcli%20connection%20show%20br-ex1%20%26%3E%20%2Fdev%2Fnull%20%7C%7C%20nmcli%20connection%20show%20ovs-if-phys1%20%26%3E%20%2Fdev%2Fnull)%3B%20then%0A%20%20%20%20%20%20remove_ovn_bridges%20br-ex1%20phys1%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Remove%20bridges%20created%20by%20openshift-sdn%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-br%20br0%0A%0A%20%20%20%20%23%20Make%20sure%20everything%20is%20activated.%20Do%20it%20in%20a%20specific%20order%3A%0A%20%20%20%20%23%20-%20activate%20br-ex%20first%2C%20due%20to%20autoconnect-slaves%20this%20will%20also%0A%20%20%20%20%23%20%20%20activate%20ovs-port-br-ex%2C%20ovs-port-phys0%20and%20ovs-if-phys0.%20It%20is%0A%20%20%20%20%23%20%20%20important%20that%20ovs-if-phys0%20activates%20with%20br-ex%20to%20avoid%20the%0A%20%20%20%20%23%20%20%20ovs-if-phys0%20profile%20being%20overridden%20with%20a%20profile%20generated%20from%0A%20%20%20%20%23%20%20%20kargs.%20The%20activation%20of%20ovs-if-phys0%2C%20if%20a%20bond%2C%20might%20cause%20the%0A%20%20%20%20%23%20%20%20slaves%20to%20re-activate%2C%20but%20it%20should%20be%20with%20our%20profiles%20since%20they%0A%20%20%20%20%23%20%20%20have%20higher%20priority%0A%20%20%20%20%23%20-%20make%20sure%20that%20ovs-if-phys0%20and%20its%20slaves%2C%20if%20any%2C%20are%20activated.%0A%20%20%20%20%23%20-%20finally%20activate%20ovs-if-br-ex%20which%20holds%20the%20IP%20configuration.%0A%20%20%20%20connections%3D(br-ex%20ovs-if-phys0)%0A%20%20%20%20if%20%5B%20-f%20%22%24extra_bridge_file%22%20%5D%3B%20then%0A%20%20%20%20%20%20connections%2B%3D(br-ex1%20ovs-if-phys1)%0A%20%20%20%20fi%0A%20%20%20%20while%20IFS%3D%20read%20-r%20connection%3B%20do%0A%20%20%20%20%20%20if%20%5B%5B%20%24connection%20%3D%3D%20*%22%24MANAGED_NM_CONN_SUFFIX%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20connections%2B%3D(%22%24connection%22)%0A%20%20%20%20%20%20fi%0A%20%20%20%20done%20%3C%20%3C(nmcli%20-g%20NAME%20c)%0A%20%20%20%20connections%2B%3D(ovs-if-br-ex)%0A%20%20%20%20if%20%5B%20-f%20%22%24extra_bridge_file%22%20%5D%3B%20then%0A%20%20%20%20%20%20connections%2B%3D(ovs-if-br-ex1)%0A%20%20%20%20fi%0A%20%20%20%20activate_nm_connections%20%22%24%7Bconnections%5B%40%5D%7D%22%0A%20%20%20%20try_to_bind_ipv6_address%0A%20%20%20%20set_nm_conn_files%0A%20%20elif%20%5B%20%22%241%22%20%3D%3D%20%22OpenShiftSDN%22%20%5D%3B%20then%0A%20%20%20%20%23%20Revert%20changes%20made%20by%20%2Fusr%2Flocal%2Fbin%2Fconfigure-ovs.sh%20during%20SDN%20migration.%0A%20%20%20%20rollback_nm%0A%20%20%20%20%0A%20%20%20%20%23%20Remove%20bridges%20created%20by%20ovn-kubernetes%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-br%20br-int%20--%20--if-exists%20del-br%20br-local%0A%20%20fi%0A%7D%0A%0A%23%20Retry%20configure_ovs%20until%20it%20succeeds.%0A%23%20By%20default%2C%20retry%20every%2015%20minutes%20to%20give%20enough%20time%20to%20gather%0A%23%20troubleshooting%20information%20in%20between.%20Note%20that%20configure_ovs%20has%20other%0A%23%20internal%20retry%20mechanisms.%20This%20retry%20is%20intended%20to%20give%20some%0A%23%20self-healing%20capabilities%20to%20temporary%20but%20not%20necessarily%20short-lived%0A%23%20infrastructure%20problems.%0ARETRY%3D%22%24%7BRETRY-15m%7D%22%0Awhile%20true%3B%20do%0A%0A%20%20%23%20Disable%20retries%20if%20termination%20signal%20is%20received.%20Note%20that%20systemd%0A%20%20%23%20sends%20the%20signals%20to%20all%20processes%20in%20the%20group%20by%20default%20so%20we%20expect%0A%20%20%23%20configure_ovs%20to%20get%20its%20own%20signals.%0A%20%20trap%20'echo%20%22WARNING%3A%20termination%20requested%2C%20disabling%20retries%22%3B%20RETRY%3D%22%22'%20INT%20TERM%0A%20%20%0A%20%20%23%20Run%20configure_ovs%20in%20a%20sub-shell.%20%0A%20%20(%20configure_ovs%20%22%24%40%22%20)%0A%20%20e%3D%24%3F%0A%0A%20%20%23%20Handle%20signals%20while%20we%20sleep%0A%20%20trap%20'handle_termination'%20INT%20TERM%0A%20%20%0A%20%20%23%20Exit%20if%20succesful%20and%20not%20configured%20to%20retry%0A%20%20%5B%20%22%24e%22%20-eq%200%20%5D%20%7C%7C%20%5B%20-z%20%22%24RETRY%22%20%5D%20%26%26%20exit%20%22%24e%22%0A%20%20%0A%20%20echo%20%22configure-ovs%20failed%2C%20will%20retry%20after%20%24RETRY%22%0A%20%20%23%20flag%20that%20a%20retry%20has%20happened%0A%20%20touch%20%2Ftmp%2Fconfigure-ovs-retry%0A%20%20sleep%20%22%24RETRY%22%0A%0Adone%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/configure-ovs.sh
        - contents:
            source: data:,%23%20This%20file%20is%20generated%20by%20the%20Machine%20Config%20Operator's%20containerruntimeconfig%20controller.%0A%23%0A%23%20storage.conf%20is%20the%20configuration%20file%20for%20all%20tools%0A%23%20that%20share%20the%20containers%2Fstorage%20libraries%0A%23%20See%20man%205%20containers-storage.conf%20for%20more%20information%0A%23%20The%20%22container%20storage%22%20table%20contains%20all%20of%20the%20server%20options.%0A%5Bstorage%5D%0A%0A%23%20Default%20storage%20driver%2C%20must%20be%20set%20for%20proper%20operation.%0Adriver%20%3D%20%22overlay%22%0A%0A%23%20Temporary%20storage%20location%0Arunroot%20%3D%20%22%2Frun%2Fcontainers%2Fstorage%22%0A%0A%23%20Primary%20Read%2FWrite%20location%20of%20container%20storage%0Agraphroot%20%3D%20%22%2Fvar%2Flib%2Fcontainers%2Fstorage%22%0A%0A%5Bstorage.options%5D%0A%23%20Storage%20options%20to%20be%20passed%20to%20underlying%20storage%20drivers%0A%0A%23%20AdditionalImageStores%20is%20used%20to%20pass%20paths%20to%20additional%20Read%2FOnly%20image%20stores%0A%23%20Must%20be%20comma%20separated%20list.%0Aadditionalimagestores%20%3D%20%5B%0A%5D%0A%0A%23%20Remap-UIDs%2FGIDs%20is%20the%20mapping%20from%20UIDs%2FGIDs%20as%20they%20should%20appear%20inside%20of%0A%23%20a%20container%2C%20to%20UIDs%2FGIDs%20as%20they%20should%20appear%20outside%20of%20the%20container%2C%20and%0A%23%20the%20length%20of%20the%20range%20of%20UIDs%2FGIDs.%20%20Additional%20mapped%20sets%20can%20be%20listed%0A%23%20and%20will%20be%20heeded%20by%20libraries%2C%20but%20there%20are%20limits%20to%20the%20number%20of%0A%23%20mappings%20which%20the%20kernel%20will%20allow%20when%20you%20later%20attempt%20to%20run%20a%0A%23%20container.%0A%23%0A%23%20remap-uids%20%3D%200%3A1668442479%3A65536%0A%23%20remap-gids%20%3D%200%3A1668442479%3A65536%0A%0A%23%20Remap-User%2FGroup%20is%20a%20name%20which%20can%20be%20used%20to%20look%20up%20one%20or%20more%20UID%2FGID%0A%23%20ranges%20in%20the%20%2Fetc%2Fsubuid%20or%20%2Fetc%2Fsubgid%20file.%20%20Mappings%20are%20set%20up%20starting%0A%23%20with%20an%20in-container%20ID%20of%200%20and%20the%20a%20host-level%20ID%20taken%20from%20the%20lowest%0A%23%20range%20that%20matches%20the%20specified%20name%2C%20and%20using%20the%20length%20of%20that%20range.%0A%23%20Additional%20ranges%20are%20then%20assigned%2C%20using%20the%20ranges%20which%20specify%20the%0A%23%20lowest%20host-level%20IDs%20first%2C%20to%20the%20lowest%20not-yet-mapped%20container-level%20ID%2C%0A%23%20until%20all%20of%20the%20entries%20have%20been%20used%20for%20maps.%20This%20setting%20overrides%20the%0A%23%20Remap-UIDs%2FGIDs%20setting.%0A%23%0A%23%20remap-user%20%3D%20%22storage%22%0A%23%20remap-group%20%3D%20%22storage%22%0A%0A%5Bstorage.options.pull_options%5D%0A%23%20Options%20controlling%20how%20storage%20is%20populated%20when%20pulling%20images.%0A%0A%23%20Enable%20the%20%22zstd%3Achunked%22%20feature%2C%20which%20allows%20partial%20pulls%2C%20reusing%0A%23%20content%20that%20already%20exists%20on%20the%20system.%20This%20is%20disabled%20by%20default%2C%0A%23%20and%20must%20be%20explicitly%20enabled%20to%20be%20used.%20For%20more%20on%20zstd%3Achunked%2C%20see%0A%23%20https%3A%2F%2Fgithub.com%2Fcontainers%2Fstorage%2Fblob%2Fmain%2Fdocs%2Fcontainers-storage-zstd-chunked.md%0Aenable_partial_images%20%3D%20%22false%22%0A%0A%23%20Tells%20containers%2Fstorage%20to%20use%20hard%20links%20rather%20then%20create%20new%20files%20in%0A%23%20the%20image%2C%20if%20an%20identical%20file%20already%20existed%20in%20storage.%0Ause_hard_links%20%3D%20%22false%22%0A%0A%23%20Path%20to%20an%20ostree%20repository%20that%20might%20have%0A%23%20previously%20pulled%20content%20which%20can%20be%20used%20when%20attempting%20to%20avoid%0A%23%20pulling%20content%20from%20the%20container%20registry.%0Aostree_repos%20%3D%20%22%22%0A%0A%5Bstorage.options.overlay%5D%0A%23%20Storage%20Options%20for%20overlay%0A%0A%23%20Do%20not%20create%20a%20PRIVATE%20bind%20mount%20on%20the%20home%20directory.%0Askip_mount_home%20%3D%20%22true%22%0A%0A%23%20Size%20is%20used%20to%20set%20a%20maximum%20size%20of%20the%20container%20image.%20%20Only%20supported%20by%0A%23%20certain%20container%20storage%20drivers.%0Asize%20%3D%20%22%22%0A
          mode: 420
          overwrite: true
          path: /etc/containers/storage.conf
        - contents:
            source: data:,.%20%7B%0A%20%20%20%20errors%0A%20%20%20%20bufsize%20512%0A%20%20%20%20health%20%3A18080%0A%20%20%20%20forward%20.%20%7B%7B-%20range%20%24upstream%20%3A%3D%20.DNSUpstreams%7D%7D%20%7B%7B%24upstream%7D%7D%7B%7B-%20end%7D%7D%20%7B%0A%20%20%20%20%20%20%20%20policy%20sequential%0A%20%20%20%20%7D%0A%20%20%20%20cache%2030%0A%20%20%20%20reload%0A%20%20%20%20template%20IN%20%7B%7B%20.Cluster.IngressVIPRecordType%20%7D%7D%20comp-poc-rh01.rhpoc.int%20%7B%0A%20%20%20%20%20%20%20%20match%20.*%5B.%5Dapps.comp-poc-rh01.rhpoc.int%0A%20%20%20%20%20%20%20%20answer%20%22%7B%7B%22%7B%7B%20.Name%20%7D%7D%22%7D%7D%2060%20in%20%7B%7B%22%7B%7B%20.Type%20%7D%7D%22%7D%7D%2010.100.0.51%22%0A%20%20%20%20%20%20%20%20fallthrough%0A%20%20%20%20%7D%0A%20%20%20%20template%20IN%20%7B%7B%20.Cluster.IngressVIPEmptyType%20%7D%7D%20comp-poc-rh01.rhpoc.int%20%7B%0A%20%20%20%20%20%20%20%20match%20.*%5B.%5Dapps.comp-poc-rh01.rhpoc.int%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20fallthrough%0A%20%20%20%20%7D%0A%20%20%20%20template%20IN%20%7B%7B%20.Cluster.APIVIPRecordType%20%7D%7D%20comp-poc-rh01.rhpoc.int%20%7B%0A%20%20%20%20%20%20%20%20match%20%5Eapi.comp-poc-rh01.rhpoc.int%0A%20%20%20%20%20%20%20%20answer%20%22%7B%7B%22%7B%7B%20.Name%20%7D%7D%22%7D%7D%2060%20in%20%7B%7B%22%7B%7B%20.Type%20%7D%7D%22%7D%7D%2010.100.0.50%22%0A%20%20%20%20%20%20%20%20fallthrough%0A%20%20%20%20%7D%0A%20%20%20%20template%20IN%20%7B%7B%20.Cluster.APIVIPEmptyType%20%7D%7D%20comp-poc-rh01.rhpoc.int%20%7B%0A%20%20%20%20%20%20%20%20match%20%5Eapi.comp-poc-rh01.rhpoc.int%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20fallthrough%0A%20%20%20%20%7D%0A%20%20%20%20template%20IN%20%7B%7B%20.Cluster.APIVIPRecordType%20%7D%7D%20comp-poc-rh01.rhpoc.int%20%7B%0A%20%20%20%20%20%20%20%20match%20%5Eapi-int.comp-poc-rh01.rhpoc.int%0A%20%20%20%20%20%20%20%20answer%20%22%7B%7B%22%7B%7B%20.Name%20%7D%7D%22%7D%7D%2060%20in%20%7B%7B%22%7B%7B%20.Type%20%7D%7D%22%7D%7D%2010.100.0.50%22%0A%20%20%20%20%20%20%20%20fallthrough%0A%20%20%20%20%7D%0A%20%20%20%20template%20IN%20%7B%7B%20.Cluster.APIVIPEmptyType%20%7D%7D%20comp-poc-rh01.rhpoc.int%20%7B%0A%20%20%20%20%20%20%20%20match%20%5Eapi-int.comp-poc-rh01.rhpoc.int%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20fallthrough%0A%20%20%20%20%7D%0A%20%20%20%20hosts%20%7B%0A%20%20%20%20%20%20%20%20%7B%7B-%20range%20.Cluster.NodeAddresses%20%7D%7D%0A%20%20%20%20%20%20%20%20%7B%7B%20.Address%20%7D%7D%20%7B%7B%20.Name%20%7D%7D%20%7B%7B%20.Name%20%7D%7D.%7B%7B%20%24.Cluster.Name%20%7D%7D.%7B%7B%20%24.Cluster.Domain%20%7D%7D%0A%20%20%20%20%20%20%20%20%7B%7B-%20end%20%7D%7D%0A%20%20%20%20%20%20%20%20fallthrough%0A%20%20%20%20%7D%0A%7D%0A
          mode: 420
          overwrite: true
          path: /etc/kubernetes/static-pod-resources/coredns/Corefile.tmpl
        - contents:
            source: data:,kind%3A%20Pod%0AapiVersion%3A%20v1%0Ametadata%3A%0A%20%20name%3A%20coredns%0A%20%20namespace%3A%20openshift-kni-infra%0A%20%20creationTimestamp%3A%0A%20%20deletionGracePeriodSeconds%3A%2065%0A%20%20labels%3A%0A%20%20%20%20app%3A%20kni-infra-coredns%0A%20%20annotations%3A%0A%20%20%20%20target.workload.openshift.io%2Fmanagement%3A%20'%7B%22effect%22%3A%20%22PreferredDuringScheduling%22%7D'%0A%20%20%20%20openshift.io%2Frequired-scc%3A%20privileged%0Aspec%3A%0A%20%20volumes%3A%0A%20%20-%20name%3A%20resource-dir%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fetc%2Fkubernetes%2Fstatic-pod-resources%2Fcoredns%22%0A%20%20-%20name%3A%20kubeconfig%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20-%20name%3A%20conf-dir%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fetc%2Fcoredns%22%0A%20%20-%20name%3A%20nm-resolv%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fvar%2Frun%2FNetworkManager%22%0A%20%20-%20name%3A%20nodeip-configuration%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Frun%2Fnodeip-configuration%22%0A%20%20initContainers%3A%0A%20%20-%20name%3A%20render-config-coredns%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A93e7b8c870261726d44bddc7ba0a702d3720d1838141dac837fb8c3be7c6e1a1%0A%20%20%20%20command%3A%0A%20%20%20%20-%20runtimecfg%0A%20%20%20%20-%20render%0A%20%20%20%20-%20%22%2Fvar%2Flib%2Fkubelet%2Fkubeconfig%22%0A%20%20%20%20-%20%22--api-vips%22%0A%20%20%20%20-%20%2210.100.0.50%22%0A%20%20%20%20-%20%22--ingress-vips%22%0A%20%20%20%20-%20%2210.100.0.51%22%0A%20%20%20%20-%20%22%2Fconfig%22%0A%20%20%20%20-%20%22--out-dir%22%0A%20%20%20%20-%20%22%2Fetc%2Fcoredns%22%0A%20%20%20%20-%20%22--resolvconf-path%22%0A%20%20%20%20-%20%22%2Fvar%2Frun%2FNetworkManager%2Fresolv.conf%22%0A%20%20%20%20resources%3A%20%7B%7D%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20kubeconfig%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20resource-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fconfig%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20conf-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fcoredns%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20nm-resolv%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Frun%2FNetworkManager%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20nodeip-configuration%0A%20%20%20%20%20%20mountPath%3A%20%22%2Frun%2Fnodeip-configuration%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20imagePullPolicy%3A%20IfNotPresent%0A%20%20containers%3A%0A%20%20-%20name%3A%20coredns%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A4f6294ed30ab476019aaaa77874157facc77413988f82ffc46f94d3a98d2e4f1%0A%20%20%20%20args%3A%0A%20%20%20%20-%20%22--conf%22%0A%20%20%20%20-%20%22%2Fetc%2Fcoredns%2FCorefile%22%0A%20%20%20%20resources%3A%0A%20%20%20%20%20%20requests%3A%0A%20%20%20%20%20%20%20%20cpu%3A%20100m%0A%20%20%20%20%20%20%20%20memory%3A%20200Mi%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20conf-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fcoredns%22%0A%20%20%20%20-%20name%3A%20nodeip-configuration%0A%20%20%20%20%20%20mountPath%3A%20%22%2Frun%2Fnodeip-configuration%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20livenessProbe%3A%0A%20%20%20%20%20%20httpGet%3A%0A%20%20%20%20%20%20%20%20path%3A%20%2Fhealth%0A%20%20%20%20%20%20%20%20port%3A%2018080%0A%20%20%20%20%20%20%20%20scheme%3A%20HTTP%0A%20%20%20%20%20%20initialDelaySeconds%3A%2060%0A%20%20%20%20%20%20timeoutSeconds%3A%205%0A%20%20%20%20%20%20successThreshold%3A%201%0A%20%20%20%20%20%20failureThreshold%3A%205%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20imagePullPolicy%3A%20IfNotPresent%0A%20%20-%20name%3A%20coredns-monitor%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A93e7b8c870261726d44bddc7ba0a702d3720d1838141dac837fb8c3be7c6e1a1%0A%20%20%20%20command%3A%0A%20%20%20%20-%20corednsmonitor%0A%20%20%20%20-%20%22%2Fvar%2Flib%2Fkubelet%2Fkubeconfig%22%0A%20%20%20%20-%20%22%2Fconfig%2FCorefile.tmpl%22%0A%20%20%20%20-%20%22%2Fetc%2Fcoredns%2FCorefile%22%0A%20%20%20%20-%20%22--api-vips%22%0A%20%20%20%20-%20%2210.100.0.50%22%0A%20%20%20%20-%20%22--ingress-vips%22%0A%20%20%20%20-%20%2210.100.0.51%22%0A%20%20%20%20resources%3A%0A%20%20%20%20%20%20requests%3A%0A%20%20%20%20%20%20%20%20cpu%3A%20100m%0A%20%20%20%20%20%20%20%20memory%3A%20200Mi%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20kubeconfig%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20resource-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fconfig%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20conf-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fcoredns%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20nm-resolv%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Frun%2FNetworkManager%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20nodeip-configuration%0A%20%20%20%20%20%20mountPath%3A%20%22%2Frun%2Fnodeip-configuration%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20imagePullPolicy%3A%20IfNotPresent%0A%20%20hostNetwork%3A%20true%0A%20%20tolerations%3A%0A%20%20-%20operator%3A%20Exists%0A%20%20priorityClassName%3A%20system-node-critical%0Astatus%3A%20%7B%7D%0A
          mode: 420
          overwrite: true
          path: /etc/kubernetes/manifests/coredns.yaml
        - contents:
            source: data:,Initial%20Creation%0A
          mode: 384
          overwrite: true
          path: /etc/docker/certs.d/.create
        - contents:
            source: data:,%23%20Proxy%20environment%20variables%20will%20be%20populated%20in%20this%20file.%20Properly%0A%23%20url%20encoded%20passwords%20with%20special%20characters%20will%20use%20'%25%3CHEX%3E%3CHEX%3E'.%0A%23%20Systemd%20requires%20that%20any%20%25%20used%20in%20a%20password%20be%20represented%20as%0A%23%20%25%25%20in%20a%20unit%20file%20since%20%25%20is%20a%20prefix%20for%20macros%3B%20this%20restriction%20does%20not%0A%23%20apply%20for%20environment%20files.%20Templates%20that%20need%20the%20proxy%20set%20should%20use%0A%23%20'EnvironmentFile%3D%2Fetc%2Fmco%2Fproxy.env'.%0A
          mode: 420
          overwrite: true
          path: /etc/mco/proxy.env
        - contents:
            source: data:,%5BManager%5D%0ADefaultEnvironment%3DGODEBUG%3Dx509ignoreCN%3D0%0A
          mode: 420
          overwrite: true
          path: /etc/systemd/system.conf.d/10-default-env-godebug.conf
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%23%20Workaround%3A%0A%23%20https%3A%2F%2Fissues.redhat.com%2Fbrowse%2FOCPBUGS-38779%0A%0Adriver%3D%24(nmcli%20-t%20-m%20tabular%20-f%20general.driver%20dev%20show%20%22%24%7BDEVICE_IFACE%7D%22)%0A%0Aif%20%5B%5B%20%22%242%22%20%3D%3D%20%22up%22%20%26%26%20%22%24%7Bdriver%7D%22%20%3D%3D%20%22idpf%22%20%5D%5D%3B%20then%0A%20%20ethtool%20-K%20%24%7BDEVICE_IFACE%7D%20tx-checksumming%20off%0Afi
          mode: 484
          overwrite: true
          path: /etc/NetworkManager/dispatcher.d/99-gcp-disable-idpf-tx-checksum-off
        - contents:
            source: data:,%23%20Force-load%20legacy%20iptables%20so%20it%20is%20usable%20from%20pod%20network%20namespaces%0Aip_tables%0A
          mode: 420
          overwrite: true
          path: /etc/modules-load.d/iptables.conf
        - contents:
            source: data:,global_defs%20%7B%0A%20%20%20%20enable_script_security%0A%20%20%20%20script_user%20root%0A%20%20%20%20max_auto_priority%20-1%0A%20%20%20%20vrrp_garp_master_refresh%2060%0A%7D%0A%0A%23%20TODO%3A%20Improve%20this%20check.%20The%20port%20is%20assumed%20to%20be%20alive.%0A%23%20Need%20to%20assess%20what%20is%20the%20ramification%20if%20the%20port%20is%20not%20there.%0Avrrp_script%20chk_ingress_ready%20%7B%0A%20%20%20%20script%20%22%2Fusr%2Fbin%2Ftimeout%200.9%20%2Fusr%2Fbin%2Fcurl%20-o%20%2Fdev%2Fnull%20-Lfs%20http%3A%2F%2Flocalhost%3A1936%2Fhealthz%2Fready%22%0A%20%20%20%20interval%201%0A%20%20%20%20weight%2010%0A%20%20%20%20rise%203%0A%20%20%20%20fall%202%0A%7D%0A%0Avrrp_script%20chk_ingress%20%7B%0A%20%20%20%20script%20%22%2Fusr%2Fbin%2Ftimeout%200.9%20%2Fusr%2Fbin%2Fcurl%20-o%20%2Fdev%2Fnull%20-Lfs%20http%3A%2F%2Flocalhost%3A1936%2Fhealthz%22%0A%20%20%20%20interval%201%0A%20%20%20%20rise%203%0A%20%20%20%20fall%202%0A%7D%0A%0Avrrp_script%20chk_default_ingress%20%7B%0A%20%20%20%20script%20%22%2Fusr%2Fbin%2Ftimeout%204.9%20%2Fetc%2Fkeepalived%2Fchk_default_ingress.sh%22%0A%20%20%20%20interval%205%0A%20%20%20%20weight%2050%0A%20%20%20%20rise%203%0A%20%20%20%20fall%202%0A%7D%0A%0A%7B%7B%20range%20%24i%2C%20%24config%20%3A%3D%20.Configs%20%7D%7D%0A%7B%7B%24nonVirtualIP%20%3A%3D%20.NonVirtualIP%7D%7D%0A%0A%7B%7B%24participateInIngressVRPP%20%3A%3D%20not%20.EnableUnicast%7D%7D%0A%7B%7B-%20if%20.EnableUnicast%7D%7D%0A%7B%7B-%20range%20.IngressConfig.Peers%7D%7D%0A%7B%7B-%20if%20eq%20%24nonVirtualIP%20.%7D%7D%0A%7B%7B%24participateInIngressVRPP%20%3D%20true%7D%7D%0A%7B%7B-%20end%7D%7D%0A%7B%7B-%20end%7D%7D%0A%7B%7B-%20end%7D%7D%0A%0A%7B%7Bif%20%24participateInIngressVRPP%7D%7D%0Avrrp_instance%20%7B%7B%20.Cluster.Name%20%7D%7D_INGRESS_%7B%7B%24i%7D%7D%20%7B%0A%20%20%20%20state%20BACKUP%0A%20%20%20%20interface%20%7B%7B%20.VRRPInterface%20%7D%7D%0A%20%20%20%20virtual_router_id%20%7B%7B%20.Cluster.IngressVirtualRouterID%20%7D%7D%0A%20%20%20%20priority%2020%0A%20%20%20%20advert_int%201%0A%20%20%20%20%7B%7Bif%20.EnableUnicast%7D%7D%0A%20%20%20%20unicast_src_ip%20%7B%7B.NonVirtualIP%7D%7D%0A%20%20%20%20unicast_peer%20%7B%0A%20%20%20%20%20%20%20%20%7B%7B-%20range%20.IngressConfig.Peers%7D%7D%0A%20%20%20%20%20%20%20%20%7B%7B-%20if%20ne%20%24nonVirtualIP%20.%7D%7D%0A%20%20%20%20%20%20%20%20%7B%7B.%7D%7D%0A%20%20%20%20%20%20%20%20%7B%7B-%20end%7D%7D%0A%20%20%20%20%20%20%20%20%7B%7B-%20end%7D%7D%0A%20%20%20%20%7D%0A%20%20%20%20%7B%7Bend%7D%7D%0A%20%20%20%20authentication%20%7B%0A%20%20%20%20%20%20%20%20auth_type%20PASS%0A%20%20%20%20%20%20%20%20auth_pass%20%7B%7B%20.Cluster.Name%20%7D%7D_ingress_vip%0A%20%20%20%20%7D%0A%20%20%20%20virtual_ipaddress%20%7B%0A%20%20%20%20%20%20%20%20%7B%7B%20.Cluster.IngressVIP%20%7D%7D%2F%7B%7B%20.Cluster.VIPNetmask%20%7D%7D%20label%20vip%0A%20%20%20%20%7D%0A%20%20%20%20track_script%20%7B%0A%20%20%20%20%20%20%20%20chk_ingress%0A%20%20%20%20%20%20%20%20chk_ingress_ready%0A%20%20%20%20%20%20%20%20chk_default_ingress%0A%20%20%20%20%7D%0A%7D%0A%7B%7B%20end%20%7D%7D%0A%7B%7B%20end%20%7D%7D%0A
          mode: 420
          overwrite: true
          path: /etc/kubernetes/static-pod-resources/keepalived/keepalived.conf.tmpl
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Achroot%20%2Fhost%20%2Fbin%2Fcrictl%20pods%20--namespace%20openshift-ingress%20--state%20Ready%20%7C%20grep%20-qE%20'router-default-%5B%5B%3Aalnum%3A%5D%5D%7B5%2C%7D-%5B%5B%3Aalnum%3A%5D%5D%7B5%2C%7D'%0A
          mode: 493
          overwrite: true
          path: /etc/kubernetes/static-pod-resources/keepalived/scripts/chk_default_ingress.sh.tmpl
        - contents:
            source: data:,kind%3A%20Pod%0AapiVersion%3A%20v1%0Ametadata%3A%0A%20%20name%3A%20keepalived%0A%20%20namespace%3A%20openshift-kni-infra%0A%20%20creationTimestamp%3A%0A%20%20deletionGracePeriodSeconds%3A%2065%0A%20%20labels%3A%0A%20%20%20%20app%3A%20kni-infra-vrrp%0A%20%20annotations%3A%0A%20%20%20%20target.workload.openshift.io%2Fmanagement%3A%20'%7B%22effect%22%3A%20%22PreferredDuringScheduling%22%7D'%0A%20%20%20%20openshift.io%2Frequired-scc%3A%20privileged%0Aspec%3A%0A%20%20volumes%3A%0A%20%20-%20name%3A%20resource-dir%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fetc%2Fkubernetes%2Fstatic-pod-resources%2Fkeepalived%22%0A%20%20-%20name%3A%20script-dir%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fetc%2Fkubernetes%2Fstatic-pod-resources%2Fkeepalived%2Fscripts%22%0A%20%20-%20name%3A%20kubeconfig%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fetc%2Fkubernetes%22%0A%20%20-%20name%3A%20kubeconfigvarlib%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20-%20name%3A%20conf-dir%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fetc%2Fkeepalived%22%0A%20%20-%20name%3A%20run-dir%0A%20%20%20%20empty-dir%3A%20%7B%7D%0A%20%20-%20name%3A%20chroot-host%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2F%22%0A%20%20-%20name%3A%20nodeip-configuration%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Frun%2Fnodeip-configuration%22%0A%20%20initContainers%3A%0A%20%20-%20name%3A%20render-config-keepalived%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A93e7b8c870261726d44bddc7ba0a702d3720d1838141dac837fb8c3be7c6e1a1%0A%20%20%20%20command%3A%0A%20%20%20%20-%20runtimecfg%0A%20%20%20%20-%20render%0A%20%20%20%20-%20%22%2Fetc%2Fkubernetes%2Fkubeconfig%22%0A%20%20%20%20-%20%22--api-vips%22%0A%20%20%20%20-%20%2210.100.0.50%22%0A%20%20%20%20-%20%22--ingress-vips%22%0A%20%20%20%20-%20%2210.100.0.51%22%0A%20%20%20%20-%20%22%2Fconfig%22%0A%20%20%20%20-%20%22--out-dir%22%0A%20%20%20%20-%20%22%2Fetc%2Fkeepalived%22%0A%20%20%20%20resources%3A%20%7B%7D%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20kubeconfig%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fkubernetes%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20script-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fconfig%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20conf-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fkeepalived%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20nodeip-configuration%0A%20%20%20%20%20%20mountPath%3A%20%22%2Frun%2Fnodeip-configuration%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20imagePullPolicy%3A%20IfNotPresent%0A%20%20containers%3A%0A%20%20-%20name%3A%20keepalived%0A%20%20%20%20securityContext%3A%0A%20%20%20%20%20%20capabilities%3A%0A%20%20%20%20%20%20%20%20add%3A%20%5B%22NET_ADMIN%22%2C%20%22NET_RAW%22%2C%20%22SYS_CHROOT%22%5D%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A3b0561a80561d95854d5f364f8cd6c3458d27cfb798bf93e09ffcfab97609216%0A%20%20%20%20env%3A%0A%20%20%20%20%20%20-%20name%3A%20NSS_SDB_USE_CACHE%0A%20%20%20%20%20%20%20%20value%3A%20%22no%22%0A%20%20%20%20command%3A%0A%20%20%20%20-%20%2Fbin%2Fbash%0A%20%20%20%20-%20-c%0A%20%20%20%20-%20%7C%0A%20%20%20%20%20%20%23%2Fbin%2Fbash%0A%20%20%20%20%20%20sigterm_handler()%0A%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20if%20pid%3D%24(pgrep%20-o%20keepalived)%3B%20then%0A%20%20%20%20%20%20%20%20%20%20kill%20-s%20SIGTERM%20%22%24pid%22%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%7D%0A%0A%20%20%20%20%20%20reload_keepalived()%0A%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20if%20pid%3D%24(pgrep%20-o%20keepalived)%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20kill%20-s%20SIGHUP%20%22%24pid%22%0A%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20%2Fusr%2Fsbin%2Fkeepalived%20-f%20%2Fetc%2Fkeepalived%2Fkeepalived.conf%20--dont-fork%20--vrrp%20--log-detail%20--log-console%20%26%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%7D%0A%0A%20%20%20%20%20%20msg_handler()%0A%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20while%20read%20-r%20line%3B%20do%0A%20%20%20%20%20%20%20%20%20%20echo%20%22The%20client%20sent%3A%20%24line%22%20%3E%262%0A%20%20%20%20%20%20%20%20%20%20%23%20currently%20only%20'reload'%20msg%20is%20supported%0A%20%20%20%20%20%20%20%20%20%20if%20%5B%20%22%24line%22%20%3D%20reload%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20reload_keepalived%0A%20%20%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20done%0A%20%20%20%20%20%20%7D%0A%0A%20%20%20%20%20%20remove_vip()%0A%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20address%3D%241%0A%20%20%20%20%20%20%20%20interface%3D%24(ip%20-o%20a%20%7C%20awk%20%22%2F%5Cs%24%7Baddress%7D%5C%2F%2F%20%7Bprint%20%5C%242%7D%22)%0A%20%20%20%20%20%20%20%20cidr%3D%24(ip%20-o%20a%20%7C%20awk%20%22%2F%5Cs%24%7Baddress%7D%5C%2F%2F%20%7Bprint%20%5C%244%7D%22)%0A%20%20%20%20%20%20%20%20if%20%5B%20-n%20%22%24interface%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20ip%20a%20del%20%24cidr%20dev%20%24interface%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%7D%0A%0A%20%20%20%20%20%20set%20-ex%0A%20%20%20%20%20%20%23%20Ensure%20that%20we%20don't%20have%20stale%20VIPs%20configured%0A%20%20%20%20%20%20%23%20See%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1931505%0A%20%20%20%20%20%20remove_vip%20%2210.100.0.50%22%0A%20%20%20%20%20%20remove_vip%20%2210.100.0.51%22%0A%20%20%20%20%20%20declare%20-r%20keepalived_sock%3D%22%2Fvar%2Frun%2Fkeepalived%2Fkeepalived.sock%22%0A%20%20%20%20%20%20export%20-f%20msg_handler%0A%20%20%20%20%20%20export%20-f%20reload_keepalived%0A%20%20%20%20%20%20export%20-f%20sigterm_handler%0A%0A%20%20%20%20%20%20%23%20in%20remote%20worker%20case%20sleep%20forever%0A%20%20%20%20%20%20if%20%5B%20-f%20%22%2Frun%2Fnodeip-configuration%2Fremote-worker%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20sleep%20infinity%0A%20%20%20%20%20%20%20%20%20exit%200%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20trap%20sigterm_handler%20SIGTERM%0A%20%20%20%20%20%20if%20%5B%20-s%20%22%2Fetc%2Fkeepalived%2Fkeepalived.conf%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%2Fusr%2Fsbin%2Fkeepalived%20-f%20%2Fetc%2Fkeepalived%2Fkeepalived.conf%20--dont-fork%20--vrrp%20--log-detail%20--log-console%20%26%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20rm%20-f%20%22%24keepalived_sock%22%0A%20%20%20%20%20%20socat%20UNIX-LISTEN%3A%24%7Bkeepalived_sock%7D%2Cfork%20system%3A'bash%20-c%20msg_handler'%0A%20%20%20%20resources%3A%0A%20%20%20%20%20%20requests%3A%0A%20%20%20%20%20%20%20%20cpu%3A%20100m%0A%20%20%20%20%20%20%20%20memory%3A%20200Mi%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20conf-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fkeepalived%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20run-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Frun%2Fkeepalived%22%0A%20%20%20%20-%20name%3A%20chroot-host%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fhost%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20kubeconfigvarlib%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20nodeip-configuration%0A%20%20%20%20%20%20mountPath%3A%20%22%2Frun%2Fnodeip-configuration%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20livenessProbe%3A%0A%20%20%20%20%20%20exec%3A%0A%20%20%20%20%20%20%20%20command%3A%0A%20%20%20%20%20%20%20%20-%20%2Fbin%2Fbash%0A%20%20%20%20%20%20%20%20-%20-c%0A%20%20%20%20%20%20%20%20-%20%7C%0A%20%20%20%20%20%20%20%20%20%20%5B%20!%20-s%20%22%2Fetc%2Fkeepalived%2Fkeepalived.conf%22%20%5D%20%7C%7C%20(echo%20%22%22%20%3E%20%2Ftmp%2Fkeepalived.data%20%26%26%20kill%20-s%20SIGUSR1%20%22%24(pgrep%20-o%20keepalived)%22%20%26%26%20for%20i%20in%20%24(seq%205)%3B%20do%20grep%20-q%20%22VRRP%20Instance%22%20%2Ftmp%2Fkeepalived.data%20%26%26%20exit%200%20%7C%7C%20sleep%201%3B%20done%20%26%26%20exit%201)%0A%20%20%20%20%20%20initialDelaySeconds%3A%2020%0A%20%20%20%20%20%20timeoutSeconds%3A%205%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20imagePullPolicy%3A%20IfNotPresent%0A%20%20-%20name%3A%20keepalived-monitor%0A%20%20%20%20securityContext%3A%0A%20%20%20%20%20%20capabilities%3A%0A%20%20%20%20%20%20%20%20add%3A%20%5B%22NET_ADMIN%22%2C%20%22SYS_CHROOT%22%5D%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A93e7b8c870261726d44bddc7ba0a702d3720d1838141dac837fb8c3be7c6e1a1%0A%20%20%20%20env%3A%0A%20%20%20%20%20%20-%20name%3A%20ENABLE_UNICAST%0A%20%20%20%20%20%20%20%20value%3A%20%22yes%22%0A%20%20%20%20%20%20-%20name%3A%20IS_BOOTSTRAP%0A%20%20%20%20%20%20%20%20value%3A%20%22no%22%0A%20%20%20%20%20%20-%20name%3A%20POD_NAMESPACE%0A%20%20%20%20%20%20%20%20valueFrom%3A%0A%20%20%20%20%20%20%20%20%20%20fieldRef%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20fieldPath%3A%20metadata.namespace%0A%20%20%20%20command%3A%0A%20%20%20%20-%20%2Fbin%2Fbash%0A%20%20%20%20-%20-c%0A%20%20%20%20-%20%7C%0A%20%20%20%20%20%20%23%2Fbin%2Fbash%0A%20%20%20%20%20%20%23%20in%20remote%20worker%20case%20sleep%20forever%0A%20%20%20%20%20%20if%20%5B%20-f%20%22%2Frun%2Fnodeip-configuration%2Fremote-worker%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20sleep%20infinity%0A%20%20%20%20%20%20%20%20%20%20exit%200%0A%20%20%20%20%20%20fi%0A%20%20%20%20%20%20api_vips%3D10.100.0.50%0A%20%20%20%20%20%20ingress_vips%3D10.100.0.51%0A%20%20%20%20%20%20dynkeepalived%20%2Fvar%2Flib%2Fkubelet%2Fkubeconfig%20%2Fconfig%2Fkeepalived.conf.tmpl%20%2Fetc%2Fkeepalived%2Fkeepalived.conf%20--api-vips%20%22%24%7Bapi_vips%7D%22%20--ingress-vips%20%22%24%7Bingress_vips%7D%22%0A%20%20%20%20resources%3A%0A%20%20%20%20%20%20requests%3A%0A%20%20%20%20%20%20%20%20cpu%3A%20100m%0A%20%20%20%20%20%20%20%20memory%3A%20200Mi%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20resource-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fconfig%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20kubeconfigvarlib%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20conf-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fkeepalived%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20run-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Frun%2Fkeepalived%22%0A%20%20%20%20-%20name%3A%20chroot-host%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fhost%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20nodeip-configuration%0A%20%20%20%20%20%20mountPath%3A%20%22%2Frun%2Fnodeip-configuration%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20imagePullPolicy%3A%20IfNotPresent%0A%20%20hostNetwork%3A%20true%0A%20%20tolerations%3A%0A%20%20-%20operator%3A%20Exists%0A%20%20priorityClassName%3A%20system-node-critical%0Astatus%3A%20%7B%7D%0A
          mode: 420
          overwrite: true
          path: /etc/kubernetes/manifests/keepalived.yaml
        - contents:
            source: data:,NODE_SIZING_ENABLED%3Dfalse%0ASYSTEM_RESERVED_MEMORY%3D1Gi%0ASYSTEM_RESERVED_CPU%3D500m%0ASYSTEM_RESERVED_ES%3D1Gi
          mode: 420
          overwrite: true
          path: /etc/node-sizing-enabled.env
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-e%0ANODE_SIZES_ENV%3D%24%7BNODE_SIZES_ENV%3A-%2Fetc%2Fnode-sizing.env%7D%0AVERSION_1%3D1%0AVERSION_2%3D2%0ANODE_AUTO_SIZING_VERSION%3D%24%7BNODE_AUTO_SIZING_VERSION%3A-%24VERSION_2%7D%0ANODE_AUTO_SIZING_VERSION_FILE%3D%24%7BNODE_AUTO_SIZING_VERSION_FILE%3A-%2Fetc%2Fnode-sizing-version.json%7D%0Afunction%20dynamic_memory_sizing%20%7B%0A%20%20%20%20total_memory%3D%24(free%20-g%7Cawk%20'%2F%5EMem%3A%2F%7Bprint%20%242%7D')%0A%20%20%20%20%23%20total_memory%3D8%20test%20the%20recommended%20values%20by%20modifying%20this%20value%0A%20%20%20%20recommended_systemreserved_memory%3D0%0A%20%20%20%20if%20((%24total_memory%20%3C%3D%204))%3B%20then%20%23%2025%25%20of%20the%20first%204GB%20of%20memory%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24total_memory%200.25%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D0%0A%20%20%20%20else%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D1%0A%20%20%20%20%20%20%20%20total_memory%3D%24((total_memory-4))%0A%20%20%20%20fi%0A%20%20%20%20if%20((%24total_memory%20%3C%3D%204))%3B%20then%20%23%2020%25%20of%20the%20next%204GB%20of%20memory%20(up%20to%208GB)%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%20%24(echo%20%24total_memory%200.20%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D0%0A%20%20%20%20else%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%200.80%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D%24((total_memory-4))%0A%20%20%20%20fi%0A%20%20%20%20if%20((%24total_memory%20%3C%3D%208))%3B%20then%20%23%2010%25%20of%20the%20next%208GB%20of%20memory%20(up%20to%2016GB)%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%20%24(echo%20%24total_memory%200.10%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D0%0A%20%20%20%20else%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%200.80%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D%24((total_memory-8))%0A%20%20%20%20fi%0A%20%20%20%20if%20((%24total_memory%20%3C%3D%20112))%3B%20then%20%23%206%25%20of%20the%20next%20112GB%20of%20memory%20(up%20to%20128GB)%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%20%24(echo%20%24total_memory%200.06%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D0%0A%20%20%20%20else%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%206.72%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D%24((total_memory-112))%0A%20%20%20%20fi%0A%20%20%20%20if%20((%24total_memory%20%3E%3D%200))%3B%20then%20%23%202%25%20of%20any%20memory%20above%20128GB%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%20%24(echo%20%24total_memory%200.02%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20fi%0A%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%20%7C%20awk%20'%7Bprintf(%22%25d%5Cn%22%2C%241%20%2B%200.5)%7D')%20%23%20Round%20off%20so%20we%20avoid%20float%20conversions%0A%20%20%20%20echo%20%22SYSTEM_RESERVED_MEMORY%3D%24%7Brecommended_systemreserved_memory%7DGi%22%3E%3E%20%24%7BNODE_SIZES_ENV%7D%0A%7D%0Afunction%20dynamic_cpu_sizing%20%7B%0A%20%20%20%20total_cpu%3D%24(getconf%20_NPROCESSORS_ONLN)%0A%20%20%20%20if%20%5B%20%22%241%22%20-eq%20%22%24VERSION_1%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D0%0A%20%20%20%20%20%20%20%20if%20((%24total_cpu%20%3C%3D%201))%3B%20then%20%23%206%25%20of%20the%20first%20core%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24total_cpu%200.06%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D0%0A%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D0.06%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D%24((total_cpu-1))%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20if%20((%24total_cpu%20%3C%3D%201))%3B%20then%20%23%201%25%20of%20the%20next%20core%20(up%20to%202%20cores)%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24recommended_systemreserved_cpu%20%24(echo%20%24total_cpu%200.01%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D0%0A%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24recommended_systemreserved_cpu%200.01%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D%24((total_cpu-1))%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20if%20((%24total_cpu%20%3C%3D%202))%3B%20then%20%23%200.5%25%20of%20the%20next%202%20cores%20(up%20to%204%20cores)%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24recommended_systemreserved_cpu%20%24(echo%20%24total_cpu%200.005%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D0%0A%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24recommended_systemreserved_cpu%200.01%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D%24((total_cpu-2))%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20if%20((%24total_cpu%20%3E%3D%200))%3B%20then%20%23%200.25%25%20of%20any%20cores%20above%204%20cores%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24recommended_systemreserved_cpu%20%24(echo%20%24total_cpu%200.0025%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20else%0A%20%20%20%20%20%20%20%20%23%20Base%20allocation%20for%201%20CPU%20in%20fractions%20of%20a%20core%20(60%20millicores%20%3D%200.06%20CPU%20core)%0A%20%20%20%20%20%20%20%20base_allocation_fraction%3D0.06%0A%20%20%20%20%20%20%20%20%23%20Increment%20per%20additional%20CPU%20in%20fractions%20of%20a%20core%20(12%20millicores%20%3D%200.012%20CPU%20core)%0A%20%20%20%20%20%20%20%20increment_per_cpu_fraction%3D0.012%0A%20%20%20%20%20%20%20%20if%20((total_cpu%20%3E%201))%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Calculate%20the%20total%20system-reserved%20CPU%20in%20fractions%2C%20starting%20with%20the%20base%20allocation%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20and%20adding%20the%20incremental%20fraction%20for%20each%20additional%20CPU%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(awk%20-v%20base%3D%22%24base_allocation_fraction%22%20-v%20increment%3D%22%24increment_per_cpu_fraction%22%20-v%20cpus%3D%22%24total_cpu%22%20'BEGIN%20%7Bprintf%20%22%25.2f%5Cn%22%2C%20base%20%2B%20increment%20*%20(cpus%20-%201)%7D')%0A%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20For%20a%20single%20CPU%2C%20use%20the%20base%20allocation%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24base_allocation_fraction%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Enforce%20minimum%20threshold%20of%200.5%20CPU%0A%20%20%20%20recommended_systemreserved_cpu%3D%24(awk%20-v%20val%3D%22%24recommended_systemreserved_cpu%22%20'BEGIN%20%7Bif%20(val%20%3C%200.5)%20print%200.5%3B%20else%20print%20val%7D')%0A%0A%20%20%20%20echo%20%22SYSTEM_RESERVED_CPU%3D%24%7Brecommended_systemreserved_cpu%7D%22%3E%3E%20%24%7BNODE_SIZES_ENV%7D%0A%7D%0Afunction%20dynamic_ephemeral_sizing%20%7B%0A%20%20%20%20echo%20%22Not%20implemented%20yet%22%0A%7D%0Afunction%20dynamic_pid_sizing%20%7B%0A%20%20%20%20echo%20%22Not%20implemented%20yet%22%0A%7D%0Afunction%20set_memory%20%7B%0A%20%20%20%20SYSTEM_RESERVED_MEMORY%3D%241%0A%20%20%20%20if%20%5B%20-z%20%22%24%7BSYSTEM_RESERVED_MEMORY%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20SYSTEM_RESERVED_MEMORY%3D%221Gi%22%0A%20%20%20%20fi%0A%20%20%20%20echo%20%22SYSTEM_RESERVED_MEMORY%3D%24%7BSYSTEM_RESERVED_MEMORY%7D%22%20%3E%3E%20%24%7BNODE_SIZES_ENV%7D%0A%7D%0Afunction%20set_cpu%20%7B%0A%20%20%20%20SYSTEM_RESERVED_CPU%3D%241%0A%20%20%20%20if%20%5B%20-z%20%22%24%7BSYSTEM_RESERVED_CPU%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20SYSTEM_RESERVED_CPU%3D%22500m%22%0A%20%20%20%20fi%0A%20%20%20%20echo%20%22SYSTEM_RESERVED_CPU%3D%24%7BSYSTEM_RESERVED_CPU%7D%22%20%3E%3E%20%24%7BNODE_SIZES_ENV%7D%0A%7D%0Afunction%20set_es%20%7B%0A%20%20%20%20SYSTEM_RESERVED_ES%3D%241%0A%20%20%20%20if%20%5B%20-z%20%22%24%7BSYSTEM_RESERVED_ES%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20SYSTEM_RESERVED_ES%3D%221Gi%22%0A%20%20%20%20fi%0A%20%20%20%20echo%20%22SYSTEM_RESERVED_ES%3D%24%7BSYSTEM_RESERVED_ES%7D%22%20%3E%3E%20%24%7BNODE_SIZES_ENV%7D%0A%7D%0Afunction%20dynamic_node_sizing%20%7B%0A%20%20%20%20rm%20-f%20%24%7BNODE_SIZES_ENV%7D%0A%20%20%20%20dynamic_memory_sizing%0A%20%20%20%20dynamic_cpu_sizing%20%241%0A%20%20%20%20set_es%20%242%0A%20%20%20%20%23dynamic_ephemeral_sizing%0A%20%20%20%20%23dynamic_pid_sizing%0A%7D%0Afunction%20static_node_sizing%20%7B%0A%20%20%20%20rm%20-f%20%24%7BNODE_SIZES_ENV%7D%0A%20%20%20%20set_memory%20%241%0A%20%20%20%20set_cpu%20%242%0A%20%20%20%20set_es%20%243%0A%7D%0Afunction%20create_version_file%20%7B%0A%20%20%20%20echo%20%22%7B%5C%22version%5C%22%3A%20%241%7D%22%20%3E%20%242%0A%7D%0Aif%20!%20%5B%20-f%20%24NODE_AUTO_SIZING_VERSION_FILE%20%5D%3B%20then%0A%20%20%20%20create_version_file%20%24NODE_AUTO_SIZING_VERSION%20%24NODE_AUTO_SIZING_VERSION_FILE%0Afi%0Anew_version%3D%24(jq%20.version%20%24NODE_AUTO_SIZING_VERSION_FILE)%0Aif%20%5B%20%241%20%3D%3D%20%22true%22%20%5D%3B%20then%0A%20%20%20%20dynamic_node_sizing%20%24new_version%20%244%0Aelif%20%5B%20%241%20%3D%3D%20%22false%22%20%5D%3B%20then%0A%20%20%20%20static_node_sizing%20%242%20%243%20%244%0Aelse%0A%20%20%20%20echo%20%22Unrecognized%20command%20line%20option.%20Valid%20options%20are%20%5C%22true%5C%22%20or%20%5C%22false%5C%22%22%0Afi%0A
          mode: 493
          overwrite: true
          path: /usr/local/sbin/dynamic-system-reserved-calc.sh
        - contents:
            source: data:,%23%20Turning%20on%20Accounting%20helps%20track%20down%20performance%20issues.%0A%5BManager%5D%0ADefaultCPUAccounting%3Dyes%0ADefaultMemoryAccounting%3Dyes%0ADefaultBlockIOAccounting%3Dyes%0A
          mode: 420
          overwrite: true
          path: /etc/systemd/system.conf.d/kubelet-cgroups.conf
        - contents:
            source: data:,%5BService%5D%0AEnvironment%3D%22KUBELET_LOG_LEVEL%3D2%22%0A
          mode: 420
          overwrite: true
          path: /etc/systemd/system/kubelet.service.d/20-logging.conf
        - contents:
            source: data:,%23%20ignore%20known%20SDN-managed%20devices%0A%5Bdevice%5D%0Amatch-device%3Dinterface-name%3Abr-int%3Binterface-name%3Abr-local%3Binterface-name%3Abr-nexthop%3Binterface-name%3Aovn-k8s-*%3Binterface-name%3Ak8s-*%3Binterface-name%3Atun0%3Binterface-name%3Abr0%3Binterface-name%3Apatch-br-*%3Binterface-name%3Abr-ext%3Binterface-name%3Aext-vxlan%3Binterface-name%3Aext%3Binterface-name%3Aint%3Binterface-name%3Avxlan_sys_*%3Binterface-name%3Agenev_sys_*%3Bdriver%3Aveth%0Amanaged%3D0%0A
          mode: 420
          overwrite: true
          path: /etc/NetworkManager/conf.d/sdn.conf
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-eux%0A%0A%23%20Clean%20up%20old%20config%20on%20behalf%20of%20mtu-migration%0Aif%20!%20systemctl%20-q%20is-enabled%20mtu-migration%3B%20then%0A%20%20echo%20%22Cleaning%20up%20left%20over%20mtu%20migration%20configuration%22%0A%20%20rm%20-rf%20%2Fetc%2Fcno%2Fmtu-migration%0Afi%0A%0Aif%20%5B%20-e%20%2Fetc%2Fnmstate%2Fopenshift%2Fapplied%20%5D%3B%20then%0A%20%20echo%20%22Configuration%20already%20applied%2C%20exiting%22%0A%20%20exit%200%0Afi%0A%0Asrc_path%3D%22%2Fetc%2Fnmstate%2Fopenshift%22%0Adst_path%3D%22%2Fetc%2Fnmstate%22%0Ahostname%3D%24(hostname%20-s)%0Ahost_file%3D%22%24%7Bhostname%7D.yml%22%0Acluster_file%3D%22cluster.yml%22%0Aconfig_file%3D%22%22%0Aif%20%5B%20-s%20%22%24src_path%2F%24host_file%22%20%5D%3B%20then%0A%20%20config_file%3D%24host_file%0Aelif%20%5B%20-s%20%22%24src_path%2F%24cluster_file%22%20%5D%3B%20then%0A%20%20config_file%3D%24cluster_file%0Aelse%0A%20%20echo%20%22No%20configuration%20found%20at%20%24src_path%2F%24host_file%20or%20%24src_path%2F%24cluster_file%22%0A%20%20exit%200%0Afi%0A%0Aif%20%5B%20-e%20%22%24dst_path%2F%24config_file%22%20%5D%3B%20then%0A%20%20echo%20%22ERROR%3A%20File%20%24dst_path%2F%24config_file%20exists.%20Refusing%20to%20overwrite.%22%0A%20%20exit%201%0Afi%0A%0A%23%20Handle%20the%20case%20where%20we're%20migrating%20from%20configure-ovs%0Aovs-vsctl%20--timeout%3D30%20--if-exists%20del-br%20br-ex%0A%0A%23%20Handle%20the%20case%20where%20we're%20migrating%20from%20OpenShift%20SDN%0Aovs-vsctl%20--timeout%3D30%20--if-exists%20del-br%20br0%0A%0Acp%20%22%24src_path%2F%24config_file%22%20%2Fetc%2Fnmstate%0Atouch%20%2Fetc%2Fnmstate%2Fopenshift%2Fapplied%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/nmstate-configuration.sh
        - contents:
            source: data:,%5Bservice%5D%0Akeep_state_file_after_apply%20%3D%20true%0A
          mode: 420
          overwrite: true
          path: /etc/nmstate/nmstate.conf
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%23%20Set%20interface%20ofport_request%20to%20guarantee%20stable%20ofport%20numbers.%20This%20is%20important%20for%20flow%20matches.%0A%23%20Otherwise%2C%20another%20ofport%20number%20is%20assigned%20to%20the%20interface%20on%20every%20restart%20of%20NetworkManager.%0A%23%20This%20script%20will%20build%20an%20associative%20array%20INTERFACE_NAME-%3Eofport_request%20and%20will%20save%20it%20to%20file%20CONFIGURATION_FILE.%0A%23%20When%20an%20interface%20is%20brought%20up%2C%20this%20will%20reuse%20the%20value%20from%20the%20associative%20array%20if%20such%20a%20value%20exists.%0A%23%20Otherwise%2C%20this%20will%20try%20to%20use%20the%20current%20ofport%20value.%20If%20the%20ofport%20value%20is%20already%20reserved%2C%20then%0A%23%20this%20uses%20the%20lowest%20available%20numerical%20value%2C%20instead.%0Aset%20-eux%20-o%20pipefail%0Aif%20%5B%5B%20%22OVNKubernetes%22%20!%3D%20%22OVNKubernetes%22%20%5D%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0AINTERFACE_NAME%3D%241%0AOPERATION%3D%242%0A%0A%23%20Only%20execute%20this%20on%20pre-up%0Aif%20%5B%20%22%24%7BOPERATION%7D%22%20!%3D%20%22pre-up%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20interface's%20NM%20uuid%0AINTERFACE_CONNECTION_UUID%3D%24(nmcli%20-t%20-f%20device%2Ctype%2Cuuid%20conn%20%7C%20awk%20-F%20'%3A'%20'%7Bif(%241%3D%3D%22'%24%7BINTERFACE_NAME%7D'%22%20%26%26%20%242!~%2F%5Eovs*%2F)%20print%20%24NF%7D')%0Aif%20%5B%20%22%24%7BINTERFACE_CONNECTION_UUID%7D%22%20%3D%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20interface's%20slave-type.%20If%20this%20is%20not%20an%20ovs-port%2C%20then%20exit%0AINTERFACE_OVS_SLAVE_TYPE%3D%24(nmcli%20-t%20-f%20connection.slave-type%20conn%20show%20%22%24%7BINTERFACE_CONNECTION_UUID%7D%22%20%7C%20awk%20-F%20'%3A'%20'%7Bprint%20%24NF%7D')%0Aif%20%5B%20%22%24%7BINTERFACE_OVS_SLAVE_TYPE%7D%22%20!%3D%20%22ovs-port%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20This%20is%20not%20necessarily%20a%20UUID%20(can%20be%20a%20name%20in%20case%20of%20bonds)%20but%20this%20should%20be%20unique%0APORT%3D%24(nmcli%20-t%20-f%20connection.master%20conn%20show%20%22%24%7BINTERFACE_CONNECTION_UUID%7D%22%20%7C%20awk%20-F%20'%3A'%20'%7Bprint%20%24NF%7D')%0Aif%20%5B%20%22%24%7BPORT%7D%22%20%3D%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20interface's%20NM%20uuid%0APORT_CONNECTION_UUID%3D%24(nmcli%20-t%20-f%20device%2Ctype%2Cuuid%20conn%20%7C%20awk%20-F%20'%3A'%20'%7Bif(%20(%241%3D%3D%22'%24%7BPORT%7D'%22%20%7C%7C%20%243%3D%3D%22'%24%7BPORT%7D'%22)%20%26%26%20%242~%2F%5Eovs*%2F)%20print%20%24NF%7D')%0Aif%20%5B%20%22%24%7BPORT_CONNECTION_UUID%7D%22%20%3D%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20port's%20slave-type.%20If%20this%20is%20not%20an%20ovs-bridge%2C%20then%20exit%0APORT_OVS_SLAVE_TYPE%3D%24(nmcli%20-t%20-f%20connection.slave-type%20conn%20show%20%22%24%7BPORT_CONNECTION_UUID%7D%22%20%7C%20awk%20-F%20'%3A'%20'%7Bprint%20%24NF%7D')%0Aif%20%5B%20%22%24%7BPORT_OVS_SLAVE_TYPE%7D%22%20!%3D%20%22ovs-bridge%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20port's%20master.%20If%20it%20doesn't%20have%20any%2C%20assume%20it's%20not%20our%20bridge%0ABRIDGE_ID%3D%24(nmcli%20-t%20-f%20connection.master%20conn%20show%20%22%24%7BPORT_CONNECTION_UUID%7D%22%20%7C%20awk%20-F%20'%3A'%20'%7Bprint%20%24NF%7D')%0Aif%20%5B%20%22%24%7BBRIDGE_ID%7D%22%20%3D%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20bridge%20name%0ABRIDGE_NAME%3D%24(nmcli%20-t%20-f%20connection.interface-name%20conn%20show%20%22%24%7BBRIDGE_ID%7D%22%20%7C%20awk%20-F%20'%3A'%20'%7Bprint%20%24NF%7D')%0A%23%20Limit%20this%20to%20br-ex%20and%20br-ex1%20only.%20If%20one%20wanted%20to%20enable%20this%20for%20all%20OVS%20bridges%2C%0A%23%20the%20condition%20would%20be%3A%20if%20%5B%20%22%24BRIDGE_NAME%22%20%3D%3D%20%22%22%20%5D%3B%20then%0Aif%20%5B%20%22%24%7BBRIDGE_NAME%7D%22%20!%3D%20%22br-ex%22%20%5D%20%26%26%20%5B%20%22%24%7BBRIDGE_NAME%7D%22%20!%3D%20%22br-ex1%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Make%20sure%20that%20the%20interface%20is%20plugged%20into%20OVS%0A%23%20This%20should%20always%20be%20the%20case%20given%20that%20we%20are%20in%20pre-up%2C%20but%20exit%20gracefully%20in%20the%20odd%20case%20that%20it's%20not%0Aif%20!%20ovs-vsctl%20list%20interface%20%22%24%7BINTERFACE_NAME%7D%22%20%3E%2Fdev%2Fnull%202%3E%261%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0ACONFIGURATION_FILE%3D%22%2Frun%2Fofport_requests.%24%7BBRIDGE_NAME%7D%22%0A%0A%23%20Declare%20a%20new%20associative%20array.%20If%20CONFIGURATION_FILE%20exists%2C%20source%20entries%20from%20there%0Adeclare%20-A%20INTERFACES%0Aif%20%5B%20-f%20%22%24%7BCONFIGURATION_FILE%7D%22%20%5D%3B%20then%0A%20%20%20%20echo%20%22Sourcing%20configuration%20file%20'%24%7BCONFIGURATION_FILE%7D'%20with%20contents%3A%22%0A%20%20%20%20cat%20%22%24%7BCONFIGURATION_FILE%7D%22%0A%20%20%20%20source%20%22%24%7BCONFIGURATION_FILE%7D%22%0Afi%0A%0A%23%20get_interface_ofport_request%20will%20return%0A%23%20*%20either%3A%20the%20current%20ofport%20assignment%20for%20the%20port%20if%20no%20interface%20has%20claimed%20this%20ofport%20number%2C%20yet%0A%23%20*%20or%3A%20%20%20%20%20the%20lowest%20available%20free%20ofport%20number%0Afunction%20get_interface_ofport_request()%20%7B%0A%20%20%20%20%23%20Build%20an%20array%20that%20only%20contains%20the%20currently%20reserved%20ofport_requests%0A%20%20%20%20declare%20-A%20ofport_requests%0A%20%20%20%20for%20interface_name%20in%20%22%24%7B!INTERFACES%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20%20%20%20%20ofport_requests%5B%24%7BINTERFACES%5B%24interface_name%5D%7D%5D%3D%24%7BINTERFACES%5B%24interface_name%5D%7D%0A%20%20%20%20done%0A%0A%20%20%20%20%23%20Get%20the%20current%20ofport%20number%20assignment%0A%20%20%20%20local%20current_ofport%3D%24(ovs-vsctl%20get%20Interface%20%22%24%7BINTERFACE_NAME%7D%22%20ofport)%0A%0A%20%20%20%20%23%20If%20the%20current%20ofport%20number%20is%20still%20free%2C%20use%20it%0A%20%20%20%20if%20!%20%5B%20%22%24%7Bofport_requests%5B%24current_ofport%5D%2Ba%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%24current_ofport%0A%20%20%20%20%20%20%20%20return%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20If%20the%20current%20ofport%20number%20is%20not%20free%2C%20return%20the%20lowest%20free%20entry%0A%20%20%20%20i%3D0%0A%20%20%20%20for%20i%20in%20%7B1..65000%7D%3B%20do%0A%20%20%20%20%20%20%20%20if%20!%20%5B%20%22%24%7Bofport_requests%5B%24i%5D%2Ba%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20echo%20%24i%0A%20%20%20%20%20%20%20%20%20%20%20%20return%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20done%0A%0A%20%20%20%20%23%20if%20we%20still%20cannot%20find%20an%20ID%2C%20exit%20with%20an%20error%0A%20%20%20%20echo%20%22Impossible%20to%20find%20an%20ofport%20ID%20for%20interface%20%24%7BINTERFACE_NAME%7D%22%20%3E%262%0A%20%20%20%20exit%201%0A%7D%0A%0A%23%20If%20INTERFACES%5BINTERFACE_NAME%5D%20exists%2C%20use%20that%20value%0A%23%20If%20INTERFACES%5BINTERFACE_NAME%5D%20does%20not%20exists%2C%20use%20the%20value%20from%20get_interface_ofport_request%0Aif%20!%20%5B%20%22%24%7BINTERFACES%5B%24INTERFACE_NAME%5D%2Ba%7D%22%20%5D%3B%20then%0A%20%20%20%20INTERFACES%5B%24INTERFACE_NAME%5D%3D%24(get_interface_ofport_request)%0Afi%0A%23%20Set%20ofport_request%20according%20to%20INTERFACES%5BINTERFACE_NAME%5D%0Aovs-vsctl%20set%20Interface%20%22%24%7BINTERFACE_NAME%7D%22%20ofport_request%3D%24%7BINTERFACES%5B%24INTERFACE_NAME%5D%7D%0A%0A%23%20Save%20current%20state%20of%20INTERFACES%20to%20CONFIGURATION_FILE%0Adeclare%20-p%20INTERFACES%20%3E%7C%20%22%24%7BCONFIGURATION_FILE%7D%22%0A
          mode: 493
          overwrite: true
          path: /etc/NetworkManager/dispatcher.d/pre-up.d/10-ofport-request.sh
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%0A%23%20Extract%20Podman%20version%20and%20determine%20the%20signature%20policy%0A%2Fusr%2Fbin%2Fpodman%20-v%20%7C%20%2Fbin%2Fawk%20'%7B%0A%20%20%20%20split(%243%2C%20version%2C%20%22-%22)%3B%0A%20%20%20%20clean_version%20%3D%20version%5B1%5D%3B%0A%0A%20%20%20%20split(clean_version%2C%20current%2C%20%2F%5C.%2F)%3B%0A%20%20%20%20split(%224.4.1%22%2C%20target%2C%20%2F%5C.%2F)%3B%0A%0A%20%20%20%20for%20(i%20%3D%201%3B%20i%20%3C%3D%203%3B%20i%2B%2B)%20%7B%0A%20%20%20%20%20%20%20%20if%20((current%5Bi%5D%20%2B%200)%20%3C%20(target%5Bi%5D%20%2B%200))%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20print%20%22--signature-policy%20%2Fetc%2Fmachine-config-daemon%2Fpolicy-for-old-podman.json%22%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20exit%3B%0A%20%20%20%20%20%20%20%20%7D%20else%20if%20((current%5Bi%5D%20%2B%200)%20%3E%20(target%5Bi%5D%20%2B%200))%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20exit%3B%0A%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%7D%0A%7D'%20%3E%20%2Ftmp%2Fpodman_policy_args%0A
          mode: 493
          overwrite: true
          path: /etc/machine-config-daemon/generate_podman_policy_args.sh
        - contents:
            source: data:,%7B%22auths%22%3A%7B%22cloud.openshift.com%22%3A%7B%22auth%22%3A%22b3BlbnNoaWZ0LXJlbGVhc2UtZGV2K29jbV9hY2Nlc3NfOTRmZDViZTMwOTM3NGU5NDlkM2Q5NzhmOTQzZGFlYTI6TDc0UlozWjNEUUM1U0RFMjBUUUU3UDRZR1RNSDRIRUdMUkMySzk3MjJMSE1PMlBPVUNaUDJFVVo0UDc1N1RLQw%3D%3D%22%2C%22email%22%3A%22jgoldberg%40allcovered.com%22%7D%2C%22quay.io%22%3A%7B%22auth%22%3A%22b3BlbnNoaWZ0LXJlbGVhc2UtZGV2K29jbV9hY2Nlc3NfOTRmZDViZTMwOTM3NGU5NDlkM2Q5NzhmOTQzZGFlYTI6TDc0UlozWjNEUUM1U0RFMjBUUUU3UDRZR1RNSDRIRUdMUkMySzk3MjJMSE1PMlBPVUNaUDJFVVo0UDc1N1RLQw%3D%3D%22%2C%22email%22%3A%22jgoldberg%40allcovered.com%22%7D%2C%22registry.connect.redhat.com%22%3A%7B%22auth%22%3A%22fHVoYy1wb29sLTljZTJiZWU4LTUwYWQtNDVlNC04NDExLTNkNjQ1NWNkODI1NjpleUpoYkdjaU9pSlNVelV4TWlKOS5leUp6ZFdJaU9pSTNaakppTldOallXWXhZVEEwWXpZMVlUSTFaRGN6TjJSa05UVXlNbVJqWWlKOS5NZHFkUUgzenYyMHFzQ0dfR2hGYy1WSzFRNGRsOW05TFhqcmhQNjNjUDh0dDVGX25Wc1U5NGxlcmVVSEQ4R1FXRUxDZlIzeE5HQ2dOSXFPNWUyNC02U3NGOFNTQV9RSnZIODVzLTBBWXlWMHY2QnJxV21CRHNLSWdnSzE2SFhWUzd4cTlSZ05hN200RFRMdUF2RUdtVkRSQ05VUVNFN1FMTWMxaUVhSVI4RVdrT0pPUklQd3hQM3YyUDlsTHpSRWtKYl82WVRjUWRjQUR3T0d1OWkzUHIwMWRHX1d4QU90NkFxcFZBX0JSaHRhNFRjWTFwSHk1bXBlWWVIVnE3Q3hzZWFRV3FzR01Oc0lObkFFNGdjV0MyekVXVl9NZHpIQXVad203WWsxMjg5VVhfYnhVMWhDUkVzdG5zdGdCSERheFRpSTFjalZSZkJ4X05hb0RMU01GVXBzNmlDVXhTTUxzVmc3Mi04LVJHal9nVmMxRDZPNjJkODJoakdaaW5HekJsendzMkZLYlFnNDRjb1VWcWpDdUMwdktCdVJRbDhkX0taVGZTWFVSTS0wOE91YjBNdDRIMjVjZmx6bjNERWdDcUtlSVlUYVdMS3ZranRKVy1MaGdLRjlDUHFqWmozUjhwN2xja2ZkR0lPbHRvY0hZY0xXVlM3QURjdmRNaWVLa3p5STRHb2RPamp2NU5OVF9UWDdjRHBRRVdWUnlENkxkOElXODA4SHVoSmtfa2R0MWVDSkxSTTVUdFBSRHVxZ3UwODlqcWM4WXRVWFhfcm9KcFhoSE5iMUlnekZTdFJqZktTSVJ6YTdlV2g4VWxvRmNwNXJZOV9VeDFTaFVnZ3JlQXFmQ1Y4NXF5Wjlya2RibVNZUE5PRVdzTmtUeGJoY0Q4YWpkYlJrWkFCRQ%3D%3D%22%2C%22email%22%3A%22jgoldberg%40allcovered.com%22%7D%2C%22registry.redhat.io%22%3A%7B%22auth%22%3A%22fHVoYy1wb29sLTljZTJiZWU4LTUwYWQtNDVlNC04NDExLTNkNjQ1NWNkODI1NjpleUpoYkdjaU9pSlNVelV4TWlKOS5leUp6ZFdJaU9pSTNaakppTldOallXWXhZVEEwWXpZMVlUSTFaRGN6TjJSa05UVXlNbVJqWWlKOS5NZHFkUUgzenYyMHFzQ0dfR2hGYy1WSzFRNGRsOW05TFhqcmhQNjNjUDh0dDVGX25Wc1U5NGxlcmVVSEQ4R1FXRUxDZlIzeE5HQ2dOSXFPNWUyNC02U3NGOFNTQV9RSnZIODVzLTBBWXlWMHY2QnJxV21CRHNLSWdnSzE2SFhWUzd4cTlSZ05hN200RFRMdUF2RUdtVkRSQ05VUVNFN1FMTWMxaUVhSVI4RVdrT0pPUklQd3hQM3YyUDlsTHpSRWtKYl82WVRjUWRjQUR3T0d1OWkzUHIwMWRHX1d4QU90NkFxcFZBX0JSaHRhNFRjWTFwSHk1bXBlWWVIVnE3Q3hzZWFRV3FzR01Oc0lObkFFNGdjV0MyekVXVl9NZHpIQXVad203WWsxMjg5VVhfYnhVMWhDUkVzdG5zdGdCSERheFRpSTFjalZSZkJ4X05hb0RMU01GVXBzNmlDVXhTTUxzVmc3Mi04LVJHal9nVmMxRDZPNjJkODJoakdaaW5HekJsendzMkZLYlFnNDRjb1VWcWpDdUMwdktCdVJRbDhkX0taVGZTWFVSTS0wOE91YjBNdDRIMjVjZmx6bjNERWdDcUtlSVlUYVdMS3ZranRKVy1MaGdLRjlDUHFqWmozUjhwN2xja2ZkR0lPbHRvY0hZY0xXVlM3QURjdmRNaWVLa3p5STRHb2RPamp2NU5OVF9UWDdjRHBRRVdWUnlENkxkOElXODA4SHVoSmtfa2R0MWVDSkxSTTVUdFBSRHVxZ3UwODlqcWM4WXRVWFhfcm9KcFhoSE5iMUlnekZTdFJqZktTSVJ6YTdlV2g4VWxvRmNwNXJZOV9VeDFTaFVnZ3JlQXFmQ1Y4NXF5Wjlya2RibVNZUE5PRVdzTmtUeGJoY0Q4YWpkYlJrWkFCRQ%3D%3D%22%2C%22email%22%3A%22jgoldberg%40allcovered.com%22%7D%7D%7D%0A
          mode: 384
          overwrite: true
          path: /var/lib/kubelet/config.json
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-eo%20pipefail%0A%0Afunction%20pull_baremetal_runtime_cfg_image%20%7B%0A%20%20%20%20%23%20By%20default%20podman%20retries%20to%20pull%20an%20image%203%20times%20with%201%20second%20back-off.%20It%20is%20not%20configurable.%20For%20this%0A%20%20%20%20%23%20reason%20we%20are%20implementing%20our%20own%20logic%20of%20pulling%20image%20and%20retrying%20indefinitely.%0A%20%20%20%20%23%20Ref.%3A%20https%3A%2F%2Fgithub.com%2Fcontainers%2Fcommon%2Fblob%2Fe028741ef77fdfa3ae261b9d23cdd50253d586c4%2Flibimage%2Fcopier.go%23L27-L30%0A%0A%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Checking%20if%20baremetal%20runtime%20cfg%20image%20already%20exists%22%0A%20%20%20%20if%20!%20%2Fusr%2Fbin%2Fpodman%20image%20exists%20%22quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A93e7b8c870261726d44bddc7ba0a702d3720d1838141dac837fb8c3be7c6e1a1%22%3B%20then%0A%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Starting%20download%20of%20baremetal%20runtime%20cfg%20image%22%0A%20%20%20%20%20%20while%20!%20%2Fusr%2Fbin%2Fpodman%20pull%20--authfile%20%2Fvar%2Flib%2Fkubelet%2Fconfig.json%20%22quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A93e7b8c870261726d44bddc7ba0a702d3720d1838141dac837fb8c3be7c6e1a1%22%3B%20do%20sleep%201%3B%20done%0A%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Download%20of%20baremetal%20runtime%20cfg%20image%20completed%22%0A%20%20%20%20else%0A%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Image%20exists%2C%20no%20need%20to%20download%22%0A%20%20%20%20fi%0A%7D%0A%0Afunction%20resolv_prepender%20%7B%0A%20%20%20%20%20%20%20%20%23%20In%20DHCP%20connections%2C%20the%20resolv.conf%20content%20may%20be%20late%2C%20thus%20we%20wait%20for%20nameservers%0A%20%20%20%20%20%20%20%20while%20!%20grep%20nameserver%20%2Fvar%2Frun%2FNetworkManager%2Fresolv.conf%3B%20do%0A%20%20%20%20%20%20%20%20%20%20%20%20%3E%262%20echo%20%20%22NM%20resolv-prepender%3A%20NM%20resolv.conf%20still%20empty%20of%20nameserver%22%0A%20%20%20%20%20%20%20%20%20%20%20%20sleep%200.5%0A%20%20%20%20%20%20%20%20done%0A%0A%20%20%20%20%20%20%20%20%23%20Ensure%20resolv.conf%20exists%20and%20contains%20nameservers%20before%20we%20try%20to%20pull%20image%20or%20run%20podman%0A%20%20%20%20%20%20%20%20if%20%5B%5B%20!%20-e%20%2Fetc%2Fresolv.conf%20%5D%5D%20%7C%7C%20!%20grep%20-q%20nameserver%20%2Fetc%2Fresolv.conf%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20cp%20%2Fvar%2Frun%2FNetworkManager%2Fresolv.conf%20%2Fetc%2Fresolv.conf%0A%20%20%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20%20%20%23%20Ensure%20baremetalRuntimeCfgImage%20is%20pulled%20in%20a%20reliable%20way%20before%20trying%20to%20use%20it%0A%20%20%20%20%20%20%20%20%23%20in%20the%20subsequent%20code%0A%20%20%20%20%20%20%20%20pull_baremetal_runtime_cfg_image%0A%0A%20%20%20%20%20%20%20%20NAMESERVER_IP%3D%22%24(%2Fusr%2Fbin%2Fpodman%20run%20--rm%20%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20--authfile%20%2Fvar%2Flib%2Fkubelet%2Fconfig.json%20%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20--net%3Dhost%20%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A93e7b8c870261726d44bddc7ba0a702d3720d1838141dac837fb8c3be7c6e1a1%20%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20node-ip%20%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20show%20%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%2210.100.0.50%22%20%20%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%2210.100.0.51%22%20)%22%0A%20%20%20%20%20%20%20%20DOMAINS%3D%22%24%7BIP4_DOMAINS%3A-%7D%20%24%7BIP6_DOMAINS%3A-%7D%20comp-poc-rh01.rhpoc.int%22%0A%20%20%20%20%20%20%20%20if%20%5B%5B%20-n%20%22%24NAMESERVER_IP%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20KNICONFDONEPATH%3D%22%2Frun%2Fresolv-prepender-kni-conf-done%22%0A%20%20%20%20%20%20%20%20%20%20%20%20if%20systemctl%20-q%20is-enabled%20systemd-resolved%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Configure%20for%20OKD%20domain%20and%20local%20IP%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20mkdir%20-p%20%2Fetc%2Fsystemd%2Fresolved.conf.d%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20KNICONFTMPPATH%3D%22%24(mktemp)%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20KNICONFPATH%3D%22%2Fetc%2Fsystemd%2Fresolved.conf.d%2F60-kni.conf%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20echo%20%22%5BResolve%5D%22%20%3E%20%22%24%7BKNICONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20echo%20%22DNS%3D%24NAMESERVER_IP%22%20%3E%3E%20%22%24%7BKNICONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20echo%20%22Domains%3D%24%7BDOMAINS%7D%22%20%3E%3E%20%22%24%7BKNICONFTMPPATH%7D%22%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20If%20KNI%20conf%20is%20not%20created%20or%20doesn't%20match%20what%20is%20generated%20or%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20if%20we%20haven't%20completed%20a%20full%20update%20-%20create%20or%20update%20it%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20%5B%5B%20!%20-f%20%22%24%7BKNICONFPATH%7D%22%20%5D%5D%20%7C%7C%20%5B%5B%20!%20-f%20%22%24%7BKNICONFDONEPATH%7D%22%20%5D%5D%20%7C%7C%20!%20cmp%20--silent%20%22%24%7BKNICONFPATH%7D%22%20%22%24%7BKNICONFTMPPATH%7D%22%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Creating%2Fupdating%20%2Fetc%2Fsystemd%2Fresolved.conf.d%2F60-kni.conf%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Remove%20the%20done%20file%20flag%20before%20writing%20the%20config%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20This%20would%20guard%20against%20interruptions%20and%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20prevent%20double%20restart%20of%20systemd-resolved%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20rm%20-f%20%22%24%7BKNICONFDONEPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Copy%20tmp%20file%20contents%20to%20preserve%20permissions%20and%20SELinux%20label%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20cat%20%22%24%7BKNICONFTMPPATH%7D%22%20%3E%20%22%24%7BKNICONFPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20%5B%5B%20!%20-f%20%22%24%7BKNICONFDONEPATH%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20systemctl%20-q%20is-active%20systemd-resolved%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Restarting%20systemd-resolved%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20systemctl%20restart%20systemd-resolved%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20touch%20%22%24%7BKNICONFDONEPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20rm%20-rf%20%22%24%7BKNICONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Prepending%20'nameserver%20%24NAMESERVER_IP'%20to%20%2Fetc%2Fresolv.conf%20(other%20nameservers%20from%20%2Fvar%2Frun%2FNetworkManager%2Fresolv.conf)%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20RESOLVCONFTMPPATH%3D%22%24(mktemp)%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20sed%20-e%20%22%2FGenerated%20by%2Fc%23%20Generated%20by%20KNI%20resolv%20prepender%20NM%20dispatcher%20script%22%20%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%2Fvar%2Frun%2FNetworkManager%2Fresolv.conf%20%3E%20%22%24%7BRESOLVCONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20sed%20-i%20%220%2C%2F%5Enameserver.*%2Fs%2F%2Fnameserver%20%24NAMESERVER_IP%5Cn%5C0%2F%22%20%22%24%7BRESOLVCONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20!%20grep%20-q%20search%20%22%24%7BRESOLVCONFTMPPATH%7D%22%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Make%20sure%20we%20have%20a%20search%20entry%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20echo%20%22search%20comp-poc-rh01.rhpoc.int%22%20%3E%3E%20%22%24%7BRESOLVCONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Make%20sure%20cluster%20domain%20is%20first%20in%20the%20search%20list%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20sed%20-i%20%22s%2F%5Esearch%20%5C(.*%5C)%2Fsearch%20comp-poc-rh01.rhpoc.int%20%5C1%2F%22%20%22%24%7BRESOLVCONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Remove%20duplicate%20cluster%20domain%20entries%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20sed%20-i%20%22s%2F%5C(search%20comp-poc-rh01.rhpoc.int.*%5C)%20comp-poc-rh01.rhpoc.int%5C(%20.*%5C%7C%24%5C)%2F%5C1%5C2%2F%22%20%22%24%7BRESOLVCONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Only%20leave%20the%20first%203%20nameservers%20in%20%2Fetc%2Fresolv.conf%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20sed%20-i%20'%3Aa%20%24!%7BN%3B%20ba%7D%3B%20s%2F%5C(%5E%5C%7C%5Cn%5C)nameserver%2F%5Cn%23%20nameserver%2F4g'%20%22%24%7BRESOLVCONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Only%20touch%20existing%20resolv.conf%20if%20files%20actually%20differ%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20!%20cmp%20-s%20%22%24%7BRESOLVCONFTMPPATH%7D%22%20%2Fetc%2Fresolv.conf%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20chmod%20644%20%22%24%7BRESOLVCONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20mv%20-Zf%20%22%24%7BRESOLVCONFTMPPATH%7D%22%20%2Fetc%2Fresolv.conf%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Workaround%20for%20bz%201929160.%20Reload%20NetworkManager%20to%20force%20it%20to%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20re-run%20the%20lookup%20of%20the%20hostname%20now%20that%20we%20know%20we%20have%20DNS%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20servers%20configured%20correctly%20in%20resolv.conf.%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20nmcli%20general%20reload%20dns-rc%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20touch%20%22%24%7BKNICONFDONEPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20rm%20-rf%20%22%24%7BRESOLVCONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20fi%0A%7D%0A%0Aresolv_prepender%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/resolv-prepender.sh
        - contents:
            source: data:,%23%20Needed%20by%20the%20OpenShift%20SDN.%20See%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1758552%0Anet.ipv4.conf.all.arp_announce%20%3D%202%0A
          mode: 420
          overwrite: true
          path: /etc/sysctl.d/arp.conf
        - contents:
            source: data:,%23%20See%3A%20rhbz%231384746%2C%20OCPBUGS-24012%0Anet.ipv4.neigh.default.gc_thresh1%3D8192%0Anet.ipv4.neigh.default.gc_thresh2%3D32768%0Anet.ipv4.neigh.default.gc_thresh3%3D65536%0Anet.ipv6.neigh.default.gc_thresh1%3D8192%0Anet.ipv6.neigh.default.gc_thresh2%3D32768%0Anet.ipv6.neigh.default.gc_thresh3%3D65536%0A
          mode: 420
          overwrite: true
          path: /etc/sysctl.d/gc-thresh.conf
        - contents:
            source: data:,%0Afs.inotify.max_user_watches%20%3D%2065536%0Afs.inotify.max_user_instances%20%3D%208192%0A
          mode: 420
          overwrite: true
          path: /etc/sysctl.d/inotify.conf
        - contents:
            source: data:,vm.unprivileged_userfaultfd%20%3D%201
          mode: 420
          overwrite: true
          path: /etc/sysctl.d/enable-userfaultfd.conf
        - contents:
            source: data:,%23%20Needed%20for%20OpenShift%20Logging%20(ElasticSearch).%20See%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1793714%0Avm.max_map_count%20%3D%20262144%0A
          mode: 420
          overwrite: true
          path: /etc/sysctl.d/vm-max-map.conf
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-euo%20pipefail%0A%0A%23%20First%2C%20we%20need%20to%20wait%20until%20DHCP%20finishes%20and%20the%20node%20has%20a%20non-%60localhost%60%0A%23%20hostname%20before%20%60kubelet.service%60%20starts.%0A%23%20That's%20the%20%60--wait%60%20argument%20as%20used%20by%20%60node-valid-hostname.service%60.%0A%23%0A%23%20Second%2C%20on%20GCP%20specifically%20we%20truncate%20the%20hostname%20if%20it's%20%3E63%20characters.%0A%23%20That's%20%60gcp-hostname.service%60.%0A%0A%23%20Block%20indefinitely%20until%20the%20host%20gets%20a%20non-localhost%20name.%0A%23%20Note%20node-valid-hostname.service%20uses%20systemd%20to%20abort%20if%20this%20takes%20too%20long.%0Await_localhost()%20%7B%0A%20%20%20%20echo%20%22waiting%20for%20non-localhost%20hostname%20to%20be%20assigned%22%0A%20%20%20%20while%20%5B%5B%20%22%24(%3C%20%2Fproc%2Fsys%2Fkernel%2Fhostname)%22%20%3D~%20(localhost%7Clocalhost.localdomain)%20%5D%5D%3B%0A%20%20%20%20do%0A%20%20%20%20%20%20%20%20sleep%201%0A%20%20%20%20done%0A%20%20%20%20echo%20%22node%20identified%20as%20%24(%3C%2Fproc%2Fsys%2Fkernel%2Fhostname)%22%0A%20%20%20%20echo%20%22saving%20hostname%20to%20prevent%20NetworkManager%20from%20ever%20unsetting%20it%22%0A%20%20%20%20hostnamectl%20set-hostname%20--static%20--transient%20%24(%3C%2Fproc%2Fsys%2Fkernel%2Fhostname)%0A%20%20%20%20exit%200%0A%7D%0A%0Aset_gcp_hostname()%20%7B%0A%20%20%20%20%2Fusr%2Fbin%2Fafterburn%20--provider%20gcp%20--hostname%3D%2Frun%2Fafterburn.hostname%0A%0A%20%20%20%20local%20host_name%3D%24(cat%20%2Frun%2Fafterburn.hostname)%0A%20%20%20%20local%20type_arg%3D%22transient%22%0A%0A%20%20%20%20%23%20%2Fetc%2Fhostname%20is%20used%20for%20static%20hostnames%20and%20is%20authoritative.%0A%20%20%20%20%23%20This%20will%20check%20to%20make%20sure%20that%20the%20static%20hostname%20is%20the%0A%20%20%20%20%23%20less%20than%20or%20equal%20to%2063%20characters%20in%20length.%0A%20%20%20%20if%20%5B%20-f%20%2Fetc%2Fhostname%20%5D%20%26%26%20%5B%20%22%24(cat%20%2Fetc%2Fhostname%20%7C%20wc%20-m)%22%20-gt%200%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20etc_name%3D%22%24(%3C%20%2Fetc%2Fhostname)%22%0A%20%20%20%20%20%20%20%20type_arg%3D%22static%22%0A%20%20%20%20%20%20%20%20if%20%5B%20%22%24%7Betc_name%7D%22%20!%3D%20%22%24%7Bhost_name%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20echo%20%22%2Fetc%2Fhostname%20is%20set%20to%20%24%7Betc_name%7D%20but%20does%20not%20match%20%24%7Bhost_name%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20echo%20%22using%20%2Fetc%2Fhostname%20as%20the%20authoritative%20name%22%0A%20%20%20%20%20%20%20%20%20%20%20%20host_name%3D%22%24%7Betc_name%7D%22%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Only%20mutate%20the%20hostname%20if%20the%20length%20is%20longer%20than%2063%20characters.%20The%0A%20%20%20%20%23%20hostname%20will%20be%20the%20lesser%20of%2063%20characters%20after%20the%20first%20dot%20in%20the%0A%20%20%20%20%23%20FQDN.%20%20This%20algorithm%20is%20only%20known%20to%20work%20in%20GCP%2C%20and%20hence%20is%20only%0A%20%20%20%20%23%20executed%20in%20GCP.%0A%20%20%20%20if%20%5B%20%22%24%7B%23host_name%7D%22%20-gt%2063%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20alt_name%3D%24(printf%20%22%24%7Bhost_name%7D%22%20%7C%20cut%20-f1%20-d'.'%20%7C%20cut%20-c%20-63)%0A%20%20%20%20%20%20%20%20echo%20%22%24%7Bhost_name%7D%20is%20longer%20than%2063%20characters%2C%20using%20truncated%20hostname%22%0A%20%20%20%20%20%20%20%20host_name%3D%22%24%7Balt_name%7D%22%0A%20%20%20%20fi%0A%20%20%20%20echo%20%22setting%20%24%7Btype_arg%7D%20hostname%20to%20%24%7Bhost_name%7D%22%0A%20%20%20%20%2Fbin%2Fhostnamectl%20%22--%24%7Btype_arg%7D%22%20set-hostname%20%22%24%7Bhost_name%7D%22%0A%20%20%20%20exit%200%0A%7D%0A%0Aset_openstack_hostname()%20%7B%0A%20%20%20%20%23%20Read%20metadata%20written%20by%20afterburn%20service%0A%20%20%20%20.%20%2Frun%2Fmetadata%2Fafterburn%0A%0A%20%20%20%20%23%20node-valid-hostname%20sets%20persistent%20hostname%20from%20%2Fproc%2Fsys%2Fkernel%2Fhostname%0A%20%20%20%20echo%20%22%24AFTERBURN_OPENSTACK_HOSTNAME%22%20%3E%20%2Fproc%2Fsys%2Fkernel%2Fhostname%0A%7D%0A%0Aset_powervs_hostname()%20%7B%0A%20%20%20%20%23%20Read%20metadata%20written%20by%20afterburn%20service%0A%20%20%20%20.%20%2Frun%2Fmetadata%2Fafterburn%0A%0A%20%20%20%20%23%20node-valid-hostname%20sets%20persistent%20hostname%20from%20%2Fproc%2Fsys%2Fkernel%2Fhostname%0A%20%20%20%20echo%20%22%24AFTERBURN_POWERVS_LOCAL_HOSTNAME%22%20%3E%20%2Fproc%2Fsys%2Fkernel%2Fhostname%0A%7D%0A%0Aarg%3D%24%7B1%7D%3B%20shift%3B%0Acase%20%22%24%7Barg%7D%22%20in%0A%20%20%20%20--wait)%20wait_localhost%3B%3B%0A%20%20%20%20--gcp)%20set_gcp_hostname%3B%3B%0A%20%20%20%20--openstack)%20set_openstack_hostname%3B%3B%0A%20%20%20%20--powervs)%20set_powervs_hostname%3B%3B%0A%20%20%20%20*)%20echo%20%22Unhandled%20arg%20%24arg%22%3B%20exit%201%0Aesac%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/mco-hostname
        - contents:
            source: data:,
          mode: 493
          overwrite: true
          path: /etc/kubernetes/kubelet-plugins/volume/exec/.dummy
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%23%20Workaround%3A%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1941714%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1935539%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1987108%0A%0Adriver%3D%24(nmcli%20-t%20-m%20tabular%20-f%20general.driver%20dev%20show%20%22%24%7BDEVICE_IFACE%7D%22)%0A%0Aif%20%5B%5B%20%22%242%22%20%3D%3D%20%22up%22%20%26%26%20%22%24%7Bdriver%7D%22%20%3D%3D%20%22vmxnet3%22%20%5D%5D%3B%20then%0A%20%20logger%20-s%20%2299-vsphere-disable-tx-udp-tnl%20triggered%20by%20%24%7B2%7D%20on%20device%20%24%7BDEVICE_IFACE%7D.%22%0A%20%20ethtool%20-K%20%24%7BDEVICE_IFACE%7D%20tx-udp_tnl-segmentation%20off%0A%20%20ethtool%20-K%20%24%7BDEVICE_IFACE%7D%20tx-udp_tnl-csum-segmentation%20off%0A%20%20ethtool%20-K%20%24%7BDEVICE_IFACE%7D%20tx-checksum-ip-generic%20off%0Afi%0A
          mode: 484
          overwrite: true
          path: /etc/NetworkManager/dispatcher.d/99-vsphere-disable-tx-udp-tnl
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%0Auntil%20%5B%20-e%20%2Frun%2Fnodeip-configuration%2Fbr-ex-up%20%5D%0Ado%0A%20%20sleep%201%0Adone%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/wait-for-br-ex-up.sh
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-x%0A%0Aif%20%5B%20!%20-e%20%22%2Fetc%2Fipsec.d%2Fopenshift.conf%22%20%5D%3B%20then%0A%20%20exit%200%0Afi%0A%0A%23%20Modify%20existing%20IPsec%20connection%20entries%20with%20%22auto%3Dstart%22%0A%23%20option%20and%20restart%20ipsec%20systemd%20service.%20This%20helps%20to%0A%23%20establish%20IKE%20SAs%20for%20the%20existing%20IPsec%20connections%20with%0A%23%20peer%20nodes.%20This%20option%20will%20be%20deleted%20from%20connections%0A%23%20once%20ovs-monitor-ipsec%20process%20spinned%20up%20on%20the%20node%20by%0A%23%20ovn-ipsec-host%20pod%2C%20but%20still%20it%20won't%20reestablish%20IKE%20SAs%0A%23%20again%20with%20peer%20nodes%2C%20so%20it%20shouldn't%20be%20a%20problem.%0Aif%20!%20grep%20-q%20%22auto%3Dstart%22%20%2Fetc%2Fipsec.d%2Fopenshift.conf%3B%20then%0A%20%20sed%20-i%20'%2F%5E.*conn%20ovn.*%24%2Fa%5C%20%20%20%20auto%3Dstart'%20%2Fetc%2Fipsec.d%2Fopenshift.conf%0Afi%0Achroot%20%2Fproc%2F1%2Froot%20ipsec%20restart%0A%0A%23%20Wait%20for%20upto%2060s%20to%20get%20IPsec%20SAs%20to%20establish%20with%20peer%20nodes.%0Atimeout%3D60%0Aelapsed%3D0%0Adesiredconn%3D%22%22%0Aestablishedsa%3D%22%22%0Awhile%20%5B%5B%20%24elapsed%20-lt%20%24timeout%20%5D%5D%3B%20do%0A%20%20desiredconn%3D%24(grep%20-E%20'%5E%5Cs*conn%5Cs%2B'%20%2Fetc%2Fipsec.d%2Fopenshift.conf%20%7C%20grep%20-v%20'%25default'%20%7C%20awk%20'%7Bprint%20%242%7D'%20%7C%20tr%20'%20'%20'%5Cn'%20%7C%20sort%20%7C%20tr%20'%5Cn'%20'%20')%0A%20%20establishedsa%3D%24(ipsec%20showstates%20%7C%20grep%20STATE_V2_ESTABLISHED_CHILD_SA%20%7C%20grep%20-o%20'%22%5B%5E%22%5D*%22'%20%7C%20sed%20's%2F%22%2F%2Fg'%20%7C%20tr%20'%20'%20'%5Cn'%20%7C%20sort%20%7C%20uniq%20%7C%20tr%20'%5Cn'%20'%20')%0A%20%20if%20%5B%20%22%24desiredconn%22%20%3D%3D%20%22%24establishedsa%22%20%5D%3B%20then%0A%20%20%20%20echo%20%22IPsec%20SAs%20are%20established%20for%20desired%20connections%20after%20%24%7Belapsed%7Ds%22%0A%20%20%20%20break%0A%20%20else%0A%20%20%20%20echo%20%22IPsec%20SAs%20are%20not%20established%20yet%2C%20total%20waited%20time%20%24%7Belapsed%7Ds%22%0A%20%20%20%20sleep%202s%0A%20%20fi%0A%20%20elapsed%3D%24((elapsed%20%2B%202))%0Adone%0A%0Aif%20%5B%5B%20%24elapsed%20-ge%20%24timeout%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22Timed%20out%20waiting%2C%20some%20connections%20are%20not%20established%2C%20desired%20conns%20%24desiredconn%2C%20established%20conns%20%24establishedsa%22%0Afi%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/ipsec-connect-wait.sh
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-eux%0A%0Aif%20%5B%20!%20-e%20%2Fetc%2Fnmstate%2Fopenshift%2Fapplied%20%5D%3B%20then%0A%20%20%23%20No%20need%20to%20do%20this%20if%20no%20NMState%20configuration%20was%20applied%0A%20%20exit%200%0Afi%0A%0A%23%20This%20logic%20is%20borrowed%20from%20configure-ovs.sh%0A%23%20TODO%3A%20Find%20a%20platform-agnostic%20way%20to%20do%20this.%20It%20won't%20work%20on%20platforms%20where%0A%23%20nodeip-configuration%20is%20not%20used.%0Aip%3D%24(cat%20%2Frun%2Fnodeip-configuration%2Fprimary-ip)%0Aif%20%5B%5B%20%22%24%7Bip%7D%22%20%3D%3D%20%22%22%20%5D%5D%3B%20then%0A%20%20echo%20%22No%20ip%20to%20bind%20was%20found%22%0A%20%20exit%201%0Afi%0Awhile%20%3A%0Ado%0A%20%20random_port%3D%24(shuf%20-i%2050000-60000%20-n%201)%0A%20%20echo%20%22Trying%20to%20bind%20%24%7Bip%7D%20on%20port%20%24%7Brandom_port%7D%22%0A%20%20exit_code%3D%24(timeout%202s%20nc%20-l%20%22%24%7Bip%7D%22%20%24%7Brandom_port%7D%3B%20echo%20%24%3F)%0A%20%20if%20%5B%5B%20exit_code%20-eq%20124%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22Address%20bound%20successfully%22%0A%20%20%20%20exit%200%0A%20%20fi%0A%20%20sleep%2010%0Adone%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/wait-for-primary-ip.sh
        - contents:
            source: data:,unqualified-search-registries%20%3D%20%5B'registry.access.redhat.com'%2C%20'docker.io'%5D%0A
          mode: 420
          overwrite: true
          path: /etc/containers/registries.conf
        - contents:
            source: data:,%5Bcrio%5D%0Ainternal_wipe%20%3D%20true%0Ainternal_repair%20%3D%20true%0A%0A%5Bcrio.api%5D%0Astream_address%20%3D%20%22127.0.0.1%22%0Astream_port%20%3D%20%220%22%0A%0A%5Bcrio.runtime%5D%0Aselinux%20%3D%20true%0Aconmon%20%3D%20%22%22%0Aconmon_cgroup%20%3D%20%22pod%22%0Adefault_env%20%3D%20%5B%0A%20%20%20%20%22NSS_SDB_USE_CACHE%3Dno%22%2C%0A%5D%0Alog_level%20%3D%20%22info%22%0Acgroup_manager%20%3D%20%22systemd%22%0Adefault_sysctls%20%3D%20%5B%0A%20%20%20%20%22net.ipv4.ping_group_range%3D0%202147483647%22%2C%0A%5D%0Adefault_runtime%20%3D%20%22crun%22%0Ahooks_dir%20%3D%20%5B%0A%20%20%20%20%22%2Fetc%2Fcontainers%2Foci%2Fhooks.d%22%2C%0A%20%20%20%20%22%2Frun%2Fcontainers%2Foci%2Fhooks.d%22%2C%0A%20%20%20%20%22%2Fusr%2Fshare%2Fcontainers%2Foci%2Fhooks.d%22%2C%0A%5D%0Amanage_ns_lifecycle%20%3D%20true%0Aabsent_mount_sources_to_reject%20%3D%20%5B%0A%20%20%20%20%22%2Fetc%2Fhostname%22%2C%0A%5D%0Adrop_infra_ctr%20%3D%20true%0A%0A%5Bcrio.runtime.runtimes.runc%5D%0Aruntime_root%20%3D%20%22%2Frun%2Frunc%22%0Aallowed_annotations%20%3D%20%5B%0A%20%20%20%20%22io.containers.trace-syscall%22%2C%0A%20%20%20%20%22io.kubernetes.cri-o.Devices%22%2C%0A%20%20%20%20%22io.kubernetes.cri-o.LinkLogs%22%2C%0A%5D%0A%0A%5Bcrio.runtime.runtimes.crun%5D%0Aruntime_root%20%3D%20%22%2Frun%2Fcrun%22%0Aallowed_annotations%20%3D%20%5B%0A%20%20%20%20%22io.containers.trace-syscall%22%2C%0A%20%20%20%20%22io.kubernetes.cri-o.Devices%22%2C%0A%20%20%20%20%22io.kubernetes.cri-o.LinkLogs%22%2C%0A%5D%0A%23%20Based%20on%20https%3A%2F%2Fgithub.com%2Fcontainers%2Fcrun%2Fblob%2F27d7dd3a0%2FREADME.md%3Fplain%3D1%23L48%0Acontainer_min_memory%20%3D%20%22512KiB%22%0Adefault_annotations%20%3D%20%7B%22run.oci.systemd.subgroup%22%20%3D%20%22%22%7D%0A%0A%5Bcrio.runtime.workloads.openshift-builder%5D%0Aactivation_annotation%20%3D%20%22io.openshift.builder%22%0Aallowed_annotations%20%3D%20%5B%0A%20%20%22io.kubernetes.cri-o.userns-mode%22%2C%0A%20%20%22io.kubernetes.cri-o.Devices%22%0A%5D%0A%5Bcrio.runtime.workloads.openshift-builder.resources%5D%0A%0A%5Bcrio.image%5D%0Aglobal_auth_file%20%3D%20%22%2Fvar%2Flib%2Fkubelet%2Fconfig.json%22%0Apause_image%20%3D%20%22quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A2f61599219ee63c77391e05d2e02a8a5baae1c463d0ef965c49a5c470546db90%22%0Apause_image_auth_file%20%3D%20%22%2Fvar%2Flib%2Fkubelet%2Fconfig.json%22%0Apause_command%20%3D%20%22%2Fusr%2Fbin%2Fpod%22%0A%0A%5Bcrio.network%5D%0Anetwork_dir%20%3D%20%22%2Fetc%2Fkubernetes%2Fcni%2Fnet.d%2F%22%0Aplugin_dirs%20%3D%20%5B%0A%20%20%20%20%22%2Fvar%2Flib%2Fcni%2Fbin%22%2C%0A%20%20%20%20%22%2Fusr%2Flibexec%2Fcni%22%2C%0A%5D%0A%0A%5Bcrio.metrics%5D%0Aenable_metrics%20%3D%20true%0Ametrics_host%20%3D%20%22127.0.0.1%22%0Ametrics_port%20%3D%209537%0Ametrics_collectors%20%3D%20%5B%0A%20%20%22operations%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22operations_total%22%0A%20%20%22operations_latency_microseconds_total%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22operations_latency_seconds_total%22%0A%20%20%22operations_latency_microseconds%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22operations_latency_seconds%22%0A%20%20%22operations_errors%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22operations_errors_total%22%0A%20%20%22image_pulls_layer_size%22%2C%0A%20%20%22containers_oom_total%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22containers_oom_count_total%22%0A%20%20%22containers_oom%22%2C%0A%20%20%23%20Drop%20metrics%20with%20excessive%20label%20cardinality.%0A%20%20%23%20%22image_pulls_by_digest%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_pulls_bytes_total%22%0A%20%20%23%20%22image_pulls_by_name%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_pulls_bytes_total%22%0A%20%20%23%20%22image_pulls_by_name_skipped%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_pulls_skipped_bytes_total%22%0A%20%20%23%20%22image_pulls_failures%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_pulls_failure_total%22%0A%20%20%23%20%22image_pulls_successes%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_pulls_success_total%22%0A%20%20%23%20%22image_layer_reuse%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_layer_reuse_total%22%0A%20%20%22operations_total%22%2C%0A%20%20%22operations_latency_seconds_total%22%2C%0A%20%20%22operations_latency_seconds%22%2C%0A%20%20%22operations_errors_total%22%2C%0A%20%20%22image_pulls_bytes_total%22%2C%0A%20%20%22image_pulls_skipped_bytes_total%22%2C%0A%20%20%22image_pulls_success_total%22%2C%0A%20%20%22image_pulls_failure_total%22%2C%0A%20%20%22image_layer_reuse_total%22%2C%0A%20%20%22containers_oom_count_total%22%2C%0A%20%20%22processes_defunct%22%0A%5D%0A
          mode: 420
          overwrite: true
          path: /etc/crio/crio.conf.d/00-default
        - contents:
            source: data:,%7B%0A%20%20%20%20%22default%22%3A%20%5B%0A%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%22type%22%3A%20%22insecureAcceptAnything%22%0A%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%5D%2C%0A%20%20%20%20%22transports%22%3A%0A%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%22docker-daemon%22%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22%22%3A%20%5B%7B%22type%22%3A%22insecureAcceptAnything%22%7D%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20%20%20%7D%0A%7D%0A
          mode: 420
          overwrite: true
          path: /etc/machine-config-daemon/policy-for-old-podman.json
        - contents:
            source: data:,%7B%0A%20%20%20%20%22default%22%3A%20%5B%0A%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%22type%22%3A%20%22insecureAcceptAnything%22%0A%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%5D%2C%0A%20%20%20%20%22transports%22%3A%0A%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%22docker-daemon%22%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22%22%3A%20%5B%7B%22type%22%3A%22insecureAcceptAnything%22%7D%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20%20%20%7D%0A%7D
          mode: 420
          overwrite: true
          path: /etc/containers/policy.json
        - contents:
            source: data:,
          mode: 420
          overwrite: true
          path: /etc/kubernetes/cloud.conf
        - contents:
            source: data:,authorization%3A%0A%20%20static%3A%0A%20%20%20%20-%20resourceRequest%3A%20false%0A%20%20%20%20%20%20path%3A%20%2Fmetrics%0A%20%20%20%20%20%20verb%3A%20get%0A%20%20%20%20%20%20user%3A%0A%20%20%20%20%20%20%20%20name%3A%20system%3Aserviceaccount%3Aopenshift-monitoring%3Aprometheus-k8s
          mode: 420
          overwrite: true
          path: /etc/kubernetes/crio-metrics-proxy.cfg
        - contents:
            source: data:,apiVersion%3A%20v1%0Akind%3A%20Pod%0Ametadata%3A%0A%20%20name%3A%20kube-rbac-proxy-crio%0A%20%20namespace%3A%20openshift-machine-config-operator%0A%20%20annotations%3A%0A%20%20%20%20target.workload.openshift.io%2Fmanagement%3A%20'%7B%22effect%22%3A%20%22PreferredDuringScheduling%22%7D'%0A%20%20%20%20openshift.io%2Frequired-scc%3A%20privileged%0Aspec%3A%0A%20%20volumes%3A%0A%20%20-%20name%3A%20etc-kube%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fetc%2Fkubernetes%22%0A%20%20-%20name%3A%20var-lib-kubelet%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20hostNetwork%3A%20true%0A%20%20priorityClassName%3A%20system-cluster-critical%0A%20%20initContainers%3A%0A%20%20-%20name%3A%20setup%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3Ab6413e64e7d5885315b3cabc65c2af82135ee649b1664976b3d300884d302414%0A%20%20%20%20imagePullPolicy%3A%20IfNotPresent%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20var-lib-kubelet%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20command%3A%20%5B'%2Fbin%2Fbash'%2C%20'-ec'%5D%0A%20%20%20%20args%3A%0A%20%20%20%20-%20%7C%0A%20%20%20%20%20%20echo%20-n%20%22Waiting%20for%20kubelet%20key%20and%20certificate%20to%20be%20available%22%0A%20%20%20%20%20%20while%20%5B%20-n%20%22%24(test%20-e%20%2Fvar%2Flib%2Fkubelet%2Fpki%2Fkubelet-server-current.pem)%22%20%5D%20%3B%20do%0A%20%20%20%20%20%20%20%20echo%20-n%20%22.%22%0A%20%20%20%20%20%20%20%20sleep%201%0A%20%20%20%20%20%20%20%20((%20tries%20%2B%3D%201%20))%0A%20%20%20%20%20%20%20%20if%20%5B%5B%20%22%24%7Btries%7D%22%20-gt%2010%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20echo%20%22Timed%20out%20waiting%20for%20kubelet%20key%20and%20cert.%22%0A%20%20%20%20%20%20%20%20%20%20exit%201%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20done%0A%20%20%20%20securityContext%3A%0A%20%20%20%20%20%20privileged%3A%20true%0A%20%20%20%20resources%3A%0A%20%20%20%20%20%20requests%3A%0A%20%20%20%20%20%20%20%20memory%3A%2050Mi%0A%20%20%20%20%20%20%20%20cpu%3A%205m%0A%20%20containers%3A%0A%20%20-%20name%3A%20kube-rbac-proxy-crio%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3Ab6413e64e7d5885315b3cabc65c2af82135ee649b1664976b3d300884d302414%0A%20%20%20%20securityContext%3A%0A%20%20%20%20%20%20privileged%3A%20true%0A%20%20%20%20ports%3A%0A%20%20%20%20-%20containerPort%3A%209637%0A%20%20%20%20args%3A%0A%20%20%20%20-%20--secure-listen-address%3D%3A9637%0A%20%20%20%20-%20--config-file%3D%2Fetc%2Fkubernetes%2Fcrio-metrics-proxy.cfg%0A%20%20%20%20-%20--client-ca-file%3D%2Fetc%2Fkubernetes%2Fkubelet-ca.crt%0A%20%20%20%20-%20--logtostderr%3Dtrue%0A%20%20%20%20-%20--kubeconfig%3D%2Fvar%2Flib%2Fkubelet%2Fkubeconfig%0A%20%20%20%20-%20--tls-cipher-suites%3DTLS_AES_128_GCM_SHA256%2CTLS_AES_256_GCM_SHA384%2CTLS_CHACHA20_POLY1305_SHA256%2CTLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256%2CTLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256%2CTLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384%2CTLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384%2CTLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256%2CTLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256%20%0A%20%20%20%20-%20--tls-min-version%3DVersionTLS12%0A%20%20%20%20-%20--upstream%3Dhttp%3A%2F%2F127.0.0.1%3A9537%0A%20%20%20%20-%20--tls-cert-file%3D%2Fvar%2Flib%2Fkubelet%2Fpki%2Fkubelet-server-current.pem%0A%20%20%20%20-%20--tls-private-key-file%3D%2Fvar%2Flib%2Fkubelet%2Fpki%2Fkubelet-server-current.pem%0A%20%20%20%20resources%3A%0A%20%20%20%20%20%20requests%3A%0A%20%20%20%20%20%20%20%20cpu%3A%2020m%0A%20%20%20%20%20%20%20%20memory%3A%2050Mi%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20etc-kube%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fkubernetes%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20%20%20readOnly%3A%20true%0A%20%20%20%20-%20name%3A%20var-lib-kubelet%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20%20%20readOnly%3A%20true
          mode: 420
          overwrite: true
          path: /etc/kubernetes/manifests/criometricsproxy.yaml
        - contents:
            compression: ""
            source: data:text/plain;charset=utf-8;base64,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
          mode: 420
          overwrite: true
          path: /etc/kubernetes/kubelet.conf
        - contents:
            source: data:,%23!%2Fbin%2Fsh%0Aif%20%5B%20-x%20%2Fusr%2Fbin%2Fkubensenter%20%5D%3B%20then%0A%20%20exec%20%2Fusr%2Fbin%2Fkubensenter%20%22%24%40%22%0Aelse%0A%20%20exec%20%22%24%40%22%0Afi%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/kubenswrapper
        - contents:
            source: data:text/plain;charset=utf-8;base64,CnBvb2wgMC5yaGVsLnBvb2wubnRwLm9yZyBpYnVyc3QKZHJpZnRmaWxlIC92YXIvbGliL2Nocm9ueS9kcmlmdAptYWtlc3RlcCAxLjAgMwpydGNzeW5jCmxvZ2RpciAvdmFyL2xvZy9jaHJvbnkKc2VydmVyIDc0LjIwOC4yNS40NiBpYnVyc3QKc2VydmVyIHRpbWUubG10bGFicy5jb20gaWJ1cnN0CnNlcnZlciBsaXRoaXVtLmNvbnN0YW50LmNvbSBpYnVyc3QKc2VydmVyIDY5LjE3Ni44NC4zOCBpYnVyc3QKc2VydmVyIGFybTEubWF4aG9zdC5pbyBpYnVyc3QKc2VydmVyIG50cDEubGF4LnVzLmhvam1hcmsubmV0IGlidXJzdApzZXJ2ZXIgbnRwMTEua2VybmZ1c2lvbi5hdCBpYnVyc3QKc2VydmVyIHRyaWFuZ2xlLmthbnNhcy5uZXQgaWJ1cnN0
          mode: 420
          overwrite: true
          path: /etc/chrony.conf
      systemd:
        units:
        - contents: |
            [Unit]
            Description=Cleans NetworkManager state generated by dracut
            # Removal of this file signals firstboot completion
            ConditionPathExists=!/etc/ignition-machine-config-encapsulated.json
            # This is opt-in for some deployment types, and opt-out for others.
            ConditionPathExists=/var/lib/mco/nm-clean-initrd-state
            Wants=network-pre.target
            Before=network-pre.target

            [Service]
            Type=oneshot
            # Remove any existing state possibly generated NM run by dracut. We want NM to
            # consider all profiles autoconnect priority when it starts instead of
            # remembering which profile was a device activated with when NM is run by
            # dracut.
            ExecStart=/usr/local/bin/nm-clean-initrd-state.sh
            StandardOutput=journal+console
            StandardError=journal+console

            [Install]
            WantedBy=network-online.target
          enabled: true
          name: NetworkManager-clean-initrd-state.service
        - dropins:
          - contents: |
              # vim:set ft=systemd :
              #
              # This drop-in will enable any service built with this
              # github.com/containers/kubemntns library to properly join the mount namespace
              # managed by kubens.service
              #

              [Unit]
              After=kubens.service

              [Service]
              EnvironmentFile=-/run/kubens/env
            name: 01-kubens.conf
          - contents: ""
            name: 10-mco-default-env.conf
          - contents: |
              [Service]
              Environment="ENABLE_PROFILE_UNIX_SOCKET=true"
            name: 10-mco-profile-unix-socket.conf
          - contents: |
              [Unit]
              After=kubelet-dependencies.target
              Requires=kubelet-dependencies.target
            name: 05-mco-ordering.conf
          - contents: |
              [Service]
              Environment="GODEBUG=x509ignoreCN=0,madvdontneed=1"
            name: 10-mco-default-madv.conf
          name: crio.service
        - dropins:
          - contents: |
              [Unit]
              ConditionPathExists=/enoent
            name: mco-disabled.conf
          name: docker.socket
        - contents: |
            [Unit]
            Description=The firstboot OS update has completed
            Documentation=https://github.com/openshift/machine-config-operator/
            Requires=basic.target

            [Install]
            WantedBy=default.target
          enabled: true
          name: firstboot-osupdate.target
        - dropins:
          - contents: |
              [Unit]
              After=ovs-configuration.service
              Before=crio.service
            name: 01-after-configure-ovs.conf
          name: ipsec.service
        - contents: |
            [Unit]
            Description=Dynamically sets the system reserved for the kubelet
            Wants=network-online.target
            After=network-online.target firstboot-osupdate.target
            Before=kubelet-dependencies.target

            [Service]
            # Need oneshot to delay kubelet
            Type=oneshot
            RemainAfterExit=yes
            EnvironmentFile=/etc/node-sizing-enabled.env
            ExecStart=/bin/bash /usr/local/sbin/dynamic-system-reserved-calc.sh ${NODE_SIZING_ENABLED} ${SYSTEM_RESERVED_MEMORY} ${SYSTEM_RESERVED_CPU} ${SYSTEM_RESERVED_ES}
            [Install]
            RequiredBy=kubelet-dependencies.target
          enabled: true
          name: kubelet-auto-node-size.service
        - contents: |
            [Unit]
            Description=Dependencies necessary to run kubelet
            Documentation=https://github.com/openshift/machine-config-operator/
            Requires=basic.target network-online.target
            Wants=NetworkManager-wait-online.service crio-wipe.service
            Wants=rpc-statd.service chrony-wait.service
          name: kubelet-dependencies.target
        - contents: |
            [Unit]
            Description=Kubernetes Kubelet
            Requires=crio.service kubelet-dependencies.target
            After=kubelet-dependencies.target
            After=ostree-finalize-staged.service

            [Service]
            Type=notify
            ExecStartPre=/bin/mkdir --parents /etc/kubernetes/manifests
            ExecStartPre=-/usr/sbin/restorecon -ri /var/lib/kubelet/pod-resources /usr/local/bin/kubenswrapper /usr/bin/kubensenter
            Environment="KUBELET_NODE_IP=0.0.0.0"
            EnvironmentFile=/etc/os-release
            EnvironmentFile=-/etc/kubernetes/kubelet-workaround
            EnvironmentFile=-/etc/kubernetes/kubelet-env
            EnvironmentFile=/etc/node-sizing.env

            ExecStart=/usr/local/bin/kubenswrapper \
                /usr/bin/kubelet \
                  --config=/etc/kubernetes/kubelet.conf \
                  --bootstrap-kubeconfig=/etc/kubernetes/kubeconfig \
                  --kubeconfig=/var/lib/kubelet/kubeconfig \
                  --container-runtime-endpoint=/var/run/crio/crio.sock \
                  --runtime-cgroups=/system.slice/crio.service \
                  --node-labels=node-role.kubernetes.io/worker,node.openshift.io/os_id=${ID},${CUSTOM_KUBELET_LABELS} \
                  --node-ip=${KUBELET_NODE_IP} \
                  --address=${KUBELET_NODE_IP} \
                  --minimum-container-ttl-duration=6m0s \
                  --volume-plugin-dir=/etc/kubernetes/kubelet-plugins/volume/exec \
                  --cloud-provider= \
                  --hostname-override=${KUBELET_NODE_NAME} \
                  --pod-infra-container-image=quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:2f61599219ee63c77391e05d2e02a8a5baae1c463d0ef965c49a5c470546db90 \
                  --system-reserved=cpu=${SYSTEM_RESERVED_CPU},memory=${SYSTEM_RESERVED_MEMORY},ephemeral-storage=${SYSTEM_RESERVED_ES} \
                  --v=${KUBELET_LOG_LEVEL}

            Restart=always
            RestartSec=10

            [Install]
            WantedBy=multi-user.target
          dropins:
          - contents: |
              # vim:set ft=systemd :
              #
              # This drop-in will enable any service built with this
              # github.com/containers/kubemntns library to properly join the mount namespace
              # managed by kubens.service
              #

              [Unit]
              After=kubens.service

              [Service]
              EnvironmentFile=-/run/kubens/env
            name: 01-kubens.conf
          - contents: ""
            name: 10-mco-default-env.conf
          - contents: |
              [Service]
              # Wait for resolv-prepender to configure nameservers, exit 255 otherwise
              # to mark the unit as failed and retry later
              ExecCondition=/bin/bash -c '[ -f /run/resolv-prepender-kni-conf-done ] || { echo "NM resolv-prepender failed"; exit 255; }'
            name: 10-mco-on-prem-wait-resolv.conf
          - contents: |
              [Service]
              Environment="GODEBUG=x509ignoreCN=0,madvdontneed=1"
            name: 10-mco-default-madv.conf
          enabled: true
          name: kubelet.service
        - contents: |
            [Unit]
            Description=Manages a mount namespace for kubernetes-specific mounts

            [Service]
            Type=oneshot
            RemainAfterExit=yes
            RuntimeDirectory=kubens
            Environment=RUNTIME_DIRECTORY=%t/kubens
            Environment=BIND_POINT=%t/kubens/mnt
            Environment=ENVFILE=%t/kubens/env

            # Set up the runtime directory as an unbindable mountpoint
            ExecStartPre=bash -c "findmnt ${RUNTIME_DIRECTORY} || mount --make-unbindable --bind ${RUNTIME_DIRECTORY} ${RUNTIME_DIRECTORY}"
            # Ensure the bind point exists
            ExecStartPre=touch ${BIND_POINT}
            # Use 'unshare' to create the new mountpoint, then 'mount --make-rshared' so it cascades internally
            ExecStart=unshare --mount=${BIND_POINT} --propagation slave mount --make-rshared /
            # Finally, set an env pointer for ease-of-use
            ExecStartPost=bash -c 'echo "KUBENSMNT=${BIND_POINT}" > "${ENVFILE}"'

            # On stop, a recursive unmount cleans up the namespace and bind-mounted unbindable parent directory
            ExecStop=umount -R ${RUNTIME_DIRECTORY}

            [Install]
            WantedBy=multi-user.target
          enabled: false
          name: kubens.service
        - contents: |
            [Unit]
            Description=Machine Config Daemon Firstboot
            # Make sure it runs only on OSTree booted system
            ConditionPathExists=/run/ostree-booted
            # Removal of this file signals firstboot completion
            ConditionPathExists=/etc/ignition-machine-config-encapsulated.json
            After=machine-config-daemon-pull.service
            Before=kubelet-dependencies.target

            [Service]
            Type=oneshot
            RemainAfterExit=yes
            # Disable existing repos (if any) so that OS extensions would use embedded RPMs only
            ExecStartPre=-/usr/bin/sh -c "sed -i 's/enabled=1/enabled=0/' /etc/yum.repos.d/*.repo"
            # Run this via podman because we want to use the nmstatectl binary in our container
            ExecStart=/usr/bin/podman run --rm --privileged --net=host -v /:/rootfs  --entrypoint machine-config-daemon 'quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:94bac6c3782cf6579032c7c9dabca74146753d9a44591125acd30d606d7d340c' firstboot-complete-machineconfig --persist-nics
            ExecStart=/usr/bin/podman run --rm --privileged --pid=host --net=host -v /:/rootfs  --entrypoint machine-config-daemon 'quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:94bac6c3782cf6579032c7c9dabca74146753d9a44591125acd30d606d7d340c' firstboot-complete-machineconfig
            [Install]
            RequiredBy=firstboot-osupdate.target
          enabled: true
          name: machine-config-daemon-firstboot.service
        - contents: |
            [Unit]
            Description=Machine Config Daemon Pull
            # Make sure it runs only on OSTree booted system
            ConditionPathExists=/run/ostree-booted
            # This "stamp file" is unlinked when we complete
            # machine-config-daemon-firstboot.service
            ConditionPathExists=/etc/ignition-machine-config-encapsulated.json
            # Run after crio-wipe so the pulled MCD image is protected against a corrupted storage from a forced shutdown
            Wants=crio-wipe.service NetworkManager-wait-online.service
            After=crio-wipe.service NetworkManager-wait-online.service network.service

            [Service]
            Type=oneshot
            RemainAfterExit=yes
            ExecStartPre=/etc/machine-config-daemon/generate_podman_policy_args.sh
            ExecStart=/bin/sh -c "while ! /usr/bin/podman pull $(cat /tmp/podman_policy_args) --authfile=/var/lib/kubelet/config.json 'quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:94bac6c3782cf6579032c7c9dabca74146753d9a44591125acd30d606d7d340c'; do sleep 1; done"

            [Install]
            RequiredBy=machine-config-daemon-firstboot.service
          enabled: true
          name: machine-config-daemon-pull.service
        - contents: |
            [Unit]
            Description=Applies per-node NMState network configuration
            Requires=openvswitch.service
            Wants=NetworkManager-wait-online.service
            After=NetworkManager-wait-online.service openvswitch.service network.service nodeip-configuration.service
            Before=nmstate.service kubelet-dependencies.target ovs-configuration.service node-valid-hostname.service

            [Service]
            Type=oneshot
            # Would prefer to do Restart=on-failure instead of this bash retry loop, but
            # the version of systemd we have right now doesn't support it. It should be
            # available in systemd v244 and higher.
            ExecStart=/usr/local/bin/nmstate-configuration.sh
            StandardOutput=journal+console
            StandardError=journal+console

            [Install]
            WantedBy=network-online.target
          enabled: true
          name: nmstate-configuration.service
        - contents: |
            [Unit]
            Description=Apply nmstate on-disk state
            Documentation=man:nmstate.service(8) https://www.nmstate.io
            After=NetworkManager-wait-online.service
            Before=network-online.target
            Wants=NetworkManager-wait-online.service
            Requires=NetworkManager.service

            [Service]
            Type=oneshot
            ExecStart=/usr/bin/nmstatectl service
            RemainAfterExit=yes

            [Install]
            WantedBy=NetworkManager.service
          enabled: true
          name: nmstate.service
        - contents: |
            [Unit]
            Description=Wait for a non-localhost hostname
            Before=kubelet-dependencies.target

            [Service]
            Type=oneshot
            RemainAfterExit=yes
            User=root
            ExecStart=/usr/local/bin/mco-hostname --wait

            # Wait up to 5min for the node to get a non-localhost name
            TimeoutSec=300

            [Install]
            # TODO: Change this to RequiredBy after we fix https://github.com/openshift/machine-config-operator/pull/3865#issuecomment-1746963115
            WantedBy=kubelet-dependencies.target
          enabled: true
          name: node-valid-hostname.service
        - contents: |
            [Unit]
            Description=Writes IP address configuration so that kubelet and crio services select a valid node IP
            # This only applies to VIP managing environments where the kubelet and crio IP
            # address picking logic is flawed and may end up selecting an address from a
            # different subnet or a deprecated address
            Wants=NetworkManager-wait-online.service
            After=NetworkManager-wait-online.service firstboot-osupdate.target
            Before=kubelet-dependencies.target ovs-configuration.service

            [Service]
            # Need oneshot to delay kubelet
            Type=oneshot
            # Would prefer to do Restart=on-failure instead of this bash retry loop, but
            # the version of systemd we have right now doesn't support it. It should be
            # available in systemd v244 and higher.
            ExecStart=/bin/bash -c " \
              until \
              /usr/bin/podman run --rm \
              --authfile /var/lib/kubelet/config.json \
              --net=host \
              --security-opt label=disable \
              --volume /etc/systemd/system:/etc/systemd/system \
              --volume /run/nodeip-configuration:/run/nodeip-configuration \
              quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:93e7b8c870261726d44bddc7ba0a702d3720d1838141dac837fb8c3be7c6e1a1 \
              node-ip \
              set \
              --platform BareMetal \
              --retry-on-failure \
              ${NODEIP_HINT:-} \
              10.100.0.50  \
              10.100.0.51 ; \
              do \
              sleep 5; \
              done"
            ExecStart=/bin/systemctl daemon-reload
            ExecStartPre=/bin/mkdir -p /run/nodeip-configuration
            ExecStartPost=+/usr/local/bin/configure-ip-forwarding.sh
            StandardOutput=journal+console
            StandardError=journal+console
            EnvironmentFile=-/etc/default/nodeip-configuration

            [Install]
            RequiredBy=kubelet-dependencies.target
          enabled: true
          name: nodeip-configuration.service
        - contents: |
            [Unit]
            Description=Watches for changes in /var/run/NetworkManager/resolv.conf according to on-prem IPI needs
            [Path]
            PathModified=/var/run/NetworkManager/resolv.conf
            PathModified=/run/resolv-prepender/env
            Unit=on-prem-resolv-prepender.service
            [Install]
            WantedBy=multi-user.target
          enabled: true
          name: on-prem-resolv-prepender.path
        - contents: |
            [Unit]
            Description=Populates resolv.conf according to on-prem IPI needs
            # Per https://issues.redhat.com/browse/OCPBUGS-27162 there is a problem if this is started before crio-wipe
            After=crio-wipe.service
            StartLimitIntervalSec=0
            [Service]
            Type=oneshot
            # Would prefer to do Restart=on-failure instead of this bash retry loop, but
            # the version of systemd we have right now doesn't support it. It should be
            # available in systemd v244 and higher.
            ExecStart=/bin/bash -c " \
              until \
              /usr/local/bin/resolv-prepender.sh; \
              do \
              sleep 10; \
              done"
            EnvironmentFile=-/run/resolv-prepender/env
          enabled: false
          name: on-prem-resolv-prepender.service
        - enabled: true
          name: openvswitch.service
        - contents: |
            [Unit]
            # Kdump will generate it's initramfs based on the running state when kdump.service run
            # If OVS has already run, the kdump fails to gather a working network config,
            # which prevent network log exports, sush as SSH.
            # See https://issues.redhat.com/browse/OCPBUGS-28239
            After=kdump.service
            Description=Configures OVS with proper host networking configuration
            # This service is used to move a physical NIC into OVS and reconfigure OVS to use the host IP
            Requires=openvswitch.service
            Wants=NetworkManager-wait-online.service
            After=firstboot-osupdate.target
            After=NetworkManager-wait-online.service openvswitch.service network.service nodeip-configuration.service nmstate.service
            Before=kubelet-dependencies.target node-valid-hostname.service

            [Service]
            # Need oneshot to delay kubelet
            Type=oneshot
            ExecStart=/usr/local/bin/configure-ovs.sh OVNKubernetes
            StandardOutput=journal+console
            StandardError=journal+console

            [Install]
            RequiredBy=kubelet-dependencies.target
          enabled: true
          name: ovs-configuration.service
        - dropins:
          - contents: |
              [Service]
              Restart=always
              ExecStartPre=-/bin/sh -c '/usr/bin/chown -R :$${OVS_USER_ID##*:} /var/lib/openvswitch'
              ExecStartPre=-/bin/sh -c '/usr/bin/chown -R :$${OVS_USER_ID##*:} /etc/openvswitch'
              ExecStartPre=-/bin/sh -c '/usr/bin/chown -R :$${OVS_USER_ID##*:} /run/openvswitch'
              ExecStartPost=-/usr/bin/ovs-appctl vlog/set syslog:info
              ExecReload=-/usr/bin/ovs-appctl vlog/set syslog:info
            name: 10-ovs-vswitchd-restart.conf
          name: ovs-vswitchd.service
        - dropins:
          - contents: |
              [Service]
              Restart=always
            name: 10-ovsdb-restart.conf
          enabled: true
          name: ovsdb-server.service
        - dropins:
          - contents: ""
            name: 10-mco-default-env.conf
          name: rpm-ostreed.service
        - contents: |
            [Unit]
            Description=Wait for br-ex up event from NetworkManager
            Wants=ovs-configuration.service
            After=ovs-configuration.service
            Before=node-valid-hostname.service

            [Service]
            Type=oneshot
            ExecStart=/usr/local/bin/wait-for-br-ex-up.sh

            [Install]
            RequiredBy=node-valid-hostname.service
          enabled: true
          name: wait-for-br-ex-up.service
        - contents: |
            [Unit]
            Description=Ensure IKE SA established for existing IPsec connections.
            After=ipsec.service
            Before=kubelet-dependencies.target node-valid-hostname.service

            [Service]
            Type=oneshot
            ExecStart=/usr/local/bin/ipsec-connect-wait.sh
            StandardOutput=journal+console
            StandardError=journal+console

            [Install]
            WantedBy=ipsec.service
          enabled: true
          name: wait-for-ipsec-connect.service
        - contents: |
            [Unit]
            Description=Ensure primary IP is assigned and usable
            Requires=nmstate.service
            After=nmstate.service
            Before=kubelet-dependencies.target

            [Service]
            Type=oneshot
            # Would prefer to do Restart=on-failure instead of this bash retry loop, but
            # the version of systemd we have right now doesn't support it. It should be
            # available in systemd v244 and higher.
            ExecStart=/bin/bash -c " \
              until \
              /usr/local/bin/wait-for-primary-ip.sh; \
              do \
              sleep 10; \
              done"
            StandardOutput=journal+console
            StandardError=journal+console

            [Install]
            WantedBy=network-online.target
          enabled: true
          name: wait-for-primary-ip.service
        - dropins:
          - contents: |
              [Unit]
              ConditionPathExists=/enoent
            name: mco-disabled.conf
          name: zincati.service
        - contents: |
            [Unit]
            Description=Kubernetes Kubelet After Reboot Cleanup
            Before=kubelet.service

            [Service]
            Type=oneshot
            ExecStart=/bin/rm -f /var/lib/kubelet/cpu_manager_state
            ExecStart=/bin/rm -f /var/lib/kubelet/memory_manager_state
            ExecStart=-/bin/rm -f /var/lib/kubelet/dra_manager_state

            [Install]
            WantedBy=multi-user.target
          enabled: true
          name: kubelet-cleanup.service
    extensions: []
    fips: false
    kernelArguments:
    - schedstats=enable
    - systemd.unified_cgroup_hierarchy=1
    - cgroup_no_v1="all"
    - psi=0
    - psi=1
    kernelType: default
    osImageURL: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4e309dd906392e783a404b92dfd4fa4c32d74e2804ee37d1fb8a00c9355d5978
- apiVersion: machineconfiguration.openshift.io/v1
  kind: MachineConfig
  metadata:
    annotations:
      machineconfiguration.openshift.io/generated-by-controller-version: fcf8f254943cbcba1400ba55f3978cc292b6460b
      machineconfiguration.openshift.io/release-image-version: 4.18.26
    creationTimestamp: "2025-12-18T20:53:45Z"
    generation: 1
    name: rendered-worker-ab2040a4a9286b39411b0e4c2a09785d
    ownerReferences:
    - apiVersion: machineconfiguration.openshift.io/v1
      blockOwnerDeletion: true
      controller: true
      kind: MachineConfigPool
      name: worker
      uid: 7ac2da7a-3f0d-4ad8-974e-12dd34c8fded
    resourceVersion: "54724209"
    uid: 84fb0307-9fe9-4a45-9d5a-9d7dadeb0f3a
  spec:
    baseOSExtensionsContainerImage: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:7033f46996eddcbad8c8b8aeb18e601bdeef3d04bd7f79cd194db5e6346a7fc4
    config:
      ignition:
        version: 3.4.0
      passwd:
        users:
        - name: core
          sshAuthorizedKeys:
          - ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQDaG45aoa4HpJ+V029gSYKSv5IenhVmZcJvicGrs+D0PgzzwNIGG52iK4r3YOoEYJn4nX80OHf4ob23avJ1ruDPR9inD1c+oiAk5BLRE7CNdU1mllWE0l6pYRHfpIuCOXC6iWpX1kXbVPJZk3ytVZOgff7LkaIIzbAjDjJ+N1MQSUmKvnioh8c6WtFfQNAZ2gFBCRWPLxcjHdyTYvy+oB0qR10WpQYHrGVB0LawtudQrO/8zHcfZJpI0uFwSAvYqspgiO3hPfuT0Fx8xzAb66AK/2vF/WrMOH3AbBu5S954B+xZI4apPJN/Yy5ENRVIoL7w9V5pV5FENtsSvQ+fpFat9yoVewvy5CMo8qJHrvAqlBJ9JriVX2mnigJRkshG0F+Z7BLZUjMcueSIIzasQ2igc8nbpfElSnTmoyweiMbFIXNJJwaV/tKbFkF3J7A3fz1qbfSQ7AIHAigoUf/CnCr+j+BQs1ZZMoWGQOPwFo00OBDICnP0Pc6wBr4iN6gnDFs=
            jnakamura@JNakamura-22
      storage:
        files:
        - contents:
            source: data:,%23%20This%20file%20signals%20NetworkManager-clean-initrd-state%20service%20to%20run%20on%0A%23%20boot.%20This%20service%20is%20used%20to%20clean%20up%20the%20network%20activation%20state%0A%23%20generated%20by%20dracut%20so%20that%20other%20network%20configuration%20deployed%20by%20the%0A%23%20user%20can%20be%20activated.%20This%20only%20happens%20if%20dracut%20activated%20a%20default%0A%23%20network%20configuration%20and%20there%20is%20an%20alternate%20configuration%20available%20in%0A%23%20the%20root%20filesystem.%20Otherwise%2C%20it%20is%20assumed%20that%20the%20network%0A%23%20configuration%20activated%20by%20dracut%20is%20the%20one%20that%20is%20intended%20to%20be%20used%0A%23%20throughout%20the%20life%20of%20the%20system.%0A%23%20Opt-out%20for%20baremetal%20IPI%20deplyments%2C%20opt-in%20otherwise.%0A
          mode: 493
          overwrite: true
          path: /var/lib/mco/nm-clean-initrd-state
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-ex%20-o%20pipefail%0A%0ANM_DEVICES_DIR%3D%2Frun%2FNetworkManager%2Fdevices%0ANM_RUN_CONN_DIR%3D%2Frun%2FNetworkManager%2Fsystem-connections%0ANM_ETC_CONN_DIR%3D%2Fetc%2FNetworkManager%2Fsystem-connections%0A%0Alogger%20-t%20nm-clean-initrd-state%20%22Cleaning%20network%20activation%20state%20generated%20by%20dracut...%22%0Alogger%20-t%20nm-clean-initrd-state%20%22To%20disable%2C%20remove%20%2Fvar%2Flib%2Fmco%2Fnm-clean-initrd-state%22%0A%0Aif%20%5B%20!%20-e%20%22%24NM_DEVICES_DIR%22%20%5D%20%7C%7C%20%5B%20!%20-e%20%22%24NM_RUN_CONN_DIR%22%20%5D%20%7C%7C%20%5B%20!%20-e%20%22%24NM_ETC_CONN_DIR%22%20%5D%3B%20then%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22There%20is%20no%20network%20activation%20state%20to%20clean%22%0A%20%20exit%0Afi%0A%0A%23%20Some%20deployments%20require%20an%20active%20network%20early%20in%20the%20boot%20process.%20To%0A%23%20achieve%20this%2C%20dracut%20runs%20specific%20NetworkManager%20modules.%20This%20results%20in%0A%23%20NetworkManager%20keyfiles%20being%20generated%20(either%20default%20or%20from%20ip%20kernel%0A%23%20arguments)%20and%20activated.%20This%20activation%20generates%20state%20that%20makes%20those%0A%23%20profiles%20to%20be%20re-activated%20by%20the%20NetworkManager%20service%20later%20in%20the%0A%23%20boot%20process.%20And%20this%20has%20the%20effect%20that%20other%20profiles%20deployed%20by%20the%0A%23%20user%20for%20the%20same%20set%20of%20devices%20are%20ignored.%0A%0A%23%20Most%20of%20the%20time%20this%20is%20the%20desired%20behavior.%20The%20exception%20to%20this%20rule%0A%23%20is%20when%20the%20user%20wants%20to%20run%20the%20boot%20process%20with%20a%20different%20network%0A%23%20setup%20than%20the%20real%20root%20which%20is%20usually%20related%20to%20the%20fact%20that%0A%23%20generating%20images%20with%20customized%20kernel%20arguments%20is%20a%20complication%20in%0A%23%20the%20deployment%20pipeline.%0A%0A%23%20This%20need%20has%20been%20exacerbated%20by%20past%20NetworkManager%20bugs%20that%20activated%0A%23%20the%20network%20on%20boot%20when%20it%20was%20not%20really%20needed.%20Most%20notably%20when%20ip%0A%23%20kernel%20argument%20is%20present%2C%20something%20that%20the%20baremetal%20installer%20adds%20by%0A%23%20default.%0A%0A%23%20The%20intention%20here%20is%20to%20remove%20the%20state%20that%20was%20generated%20with%20the%0A%23%20activation%20of%20those%20profiles%20during%20dracut%20execution.%20Then%20when%0A%23%20NetworkManager%20service%20runs%2C%20the%20profiles%20generated%20by%20dracut%2C%20along%20with%0A%23%20other%20profiles%20configured%20by%20the%20user%2C%20are%20evaluated%20towards%20finding%20the%0A%23%20most%20appropriate%20profile%20to%20connect%20a%20device%20with.%20As%20a%20precaution%2C%20clean%0A%23%20state%20only%20for%20devices%20that%3A%0A%23%20-%20have%20been%20activated%20with%20a%20default%20profile%20(assume%20that%20a%20non-default%0A%23%20%20%20configuration%20expresses%20intention%20by%20user%20to%20run%20with%20it%20permanently)%0A%23%20-%20have%20a%20specific%20configured%20profile%20set%20to%20auto-connect%20(if%20there%20is%20no%0A%23%20%20%20alternate%20configured%20profile%20for%20a%20device%20it%20makes%20no%20sense%20to%0A%23%20%20%20de-activate%20anything)%0A%23%0A%23%20Although%20this%20can%20theoretically%20happen%20on%20any%20deployment%20type%2C%20need%20has%0A%23%20mostly%20come%20from%20IPI%20bare%20metal%20deployments.%20For%20the%20time%20being%2C%20this%0A%23%20should%20be%20opt-in%20in%20any%20other%20deploment%20type.%0A%23%0A%23%20There%20is%20an%20RFE%20filed%20against%20NM%20that%20once%20implemented%20would%20make%20this%0A%23%20script%20unnecessary%3A%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D2089707%0A%0Afor%20device%20in%20%22%24%7BNM_DEVICES_DIR%7D%22%2F*%3B%20do%0A%20%20if%20%5B%20!%20-e%20%22%24device%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20the%20device%20file%20name%20is%20the%20ifindex%0A%20%20ifindex%3D%24(basename%20%22%24device%22)%0A%20%20%0A%20%20%23%20get%20the%20interface%20name%20by%20ifindex%0A%20%20ifname%3D%24(ip%20-j%20link%20show%20%7C%20jq%20-r%20%22.%5B%5D%20%7C%20select(.ifindex%20%3D%3D%20%24%7Bifindex%7D)%20%7C%20.ifname%20%2F%2F%20empty%22)%0A%0A%20%20%23%20no%20interface%20name%20found%2C%20ignore%0A%20%20if%20%5B%20-z%20%22%24ifname%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20get%20the%20uuid%20of%20the%20profile%20the%20device%20has%20been%20activated%20with%0A%20%20active_profile_uuid%3D%24(sed%20-nr%20'%2F%5E%5C%5Bdevice%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Econnection-uuid%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24device%22)%0A%0A%20%20%23%20the%20device%20was%20not%20activated%20with%20any%20profile%2C%20ignore%0A%20%20if%20%5B%20-z%20%22%24active_profile_uuid%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20find%20the%20generated%20profile%20by%20uuid%0A%20%20for%20profile%20in%20%22%24%7BNM_RUN_CONN_DIR%7D%22%2F*%3B%20do%0A%20%20%20%20generated_profile_uuid%3D%24(sed%20-nr%20'%2F%5E%5C%5Bconnection%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Euuid%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20%20%20if%20%5B%20%22%24active_profile_uuid%22%20%3D%20%22%24generated_profile_uuid%22%20%5D%3B%20then%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20done%0A%0A%20%20%23%20generated%20profile%20not%20found%2C%20ignore%0A%20%20if%20%5B%20%22%24active_profile_uuid%22%20!%3D%20%22%24generated_profile_uuid%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20check%20that%20it%20is%20not%20specific%20for%20the%20device%2C%20otherwise%20ignore%0A%20%20profile_ifname%3D%24(sed%20-nr%20'%2F%5E%5C%5Bconnection%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Einterface-name%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20if%20%5B%20-n%20%22%24profile_ifname%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20profile%20not%20generated%20by%20nm-initrd-generator%2C%20ignore%0A%20%20%23%20only%20check%20it%20if%20the%20key%20is%20set%20(from%20NM%201.32.4)%0A%20%20origin%3D%24(sed%20-nr%20'%2F%5E%5C%5Buser%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Eorg.freedesktop.NetworkManager.origin%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20if%20%5B%20-n%20%22%24origin%22%20%5D%20%26%26%20%5B%20%22%24origin%22%20!%3D%20%22nm-initrd-generator%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20find%20the%20configured%20profile%20by%20name%20with%20auto-connect%20set%0A%20%20for%20profile%20in%20%22%24%7BNM_ETC_CONN_DIR%7D%22%2F*%3B%20do%0A%20%20%20%20profile_ifname%3D%24(sed%20-nr%20'%2F%5E%5C%5Bconnection%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Einterface-name%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20%20%20autoconnect%3D%24(sed%20-nr%20'%2F%5E%5C%5Bconnection%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Eautoconnect%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20%20%20if%20%5B%20%22%24profile_ifname%22%20%3D%20%22%24ifname%22%20%5D%20%26%26%20%5B%20%22%24autoconnect%22%20!%3D%20%22false%22%20%5D%3B%20then%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20done%0A%0A%20%20%23%20configured%20profile%20not%20found%2C%20ignore%0A%20%20if%20%5B%20%22%24profile_ifname%22%20!%3D%20%22%24ifname%22%20%5D%20%7C%7C%20%5B%20%22%24autoconnect%22%20%3D%20%22false%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20configured_profile_uuid%3D%24(sed%20-nr%20'%2F%5E%5C%5Bconnection%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Euuid%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22%24ifname%20activated%20with%20default%20generated%20profile%20%24generated_profile_uuid%22%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22%24ifname%20has%20different%20configured%20specific%20profile%20%24configured_profile_uuid%22%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22%24ifname%3A%20removing%20state...%22%0A%20%20%0A%20%20%23%20NM%20can%20still%20generate%20internal%20profiles%20from%20the%20IP%20address%0A%20%20%23%20configuration%20of%20devices%2C%20so%20flush%20addresses%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22Flushing%20IP%20addresses%20from%20%24ifname%22%0A%20%20ip%20addr%20flush%20%22%24ifname%22%0A%20%20ip%20-6%20addr%20flush%20%22%24ifname%22%0A%0A%20%20%23%20remove%20device%20state%20file%20to%20prevent%20NM%20to%20unilaterally%20connect%20with%20the%0A%20%20%23%20latest%20activated%20profile%20without%20evaluating%20other%20profiles%20%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22Removing%20%24device%22%0A%20%20rm%20-f%20--%20%22%24device%22%0A%0Adone%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/nm-clean-initrd-state.sh
        - contents:
            source: data:,%5Bconnection%5D%0Aipv6.dhcp-duid%3Dll%0Aipv6.dhcp-iaid%3Dmac%0A
          mode: 420
          overwrite: true
          path: /etc/NetworkManager/conf.d/01-ipv6.conf
        - contents:
            source: data:,%5Bmain%5D%0Aplugins%3Dkeyfile%2Cifcfg-rh%0A%5Bkeyfile%5D%0Apath%3D%2Fetc%2FNetworkManager%2Fsystem-connections%0A
          mode: 420
          overwrite: true
          path: /etc/NetworkManager/conf.d/20-keyfiles.conf
        - contents:
            source: data:,%5Bmain%5D%0Arc-manager%3Dunmanaged%0A
          mode: 420
          overwrite: true
          path: /etc/NetworkManager/conf.d/99-kni.conf
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-eo%20pipefail%0AIFACE%3D%241%0ASTATUS%3D%242%0A%0Afunction%20resolv_prepender%20%7B%0A%20%20mkdir%20-p%20%2Frun%2Fresolv-prepender%0A%20%20echo%20%22IP4_DOMAINS%3D%24IP4_DOMAINS%22%20%3E%20%2Frun%2Fresolv-prepender%2Fenv.new%0A%20%20echo%20%22IP6_DOMAINS%3D%24IP6_DOMAINS%22%20%3E%3E%20%2Frun%2Fresolv-prepender%2Fenv.new%0A%0A%20%20if%20!%20diff%20-q%20%2Frun%2Fresolv-prepender%2Fenv%20%2Frun%2Fresolv-prepender%2Fenv.new%3B%20then%0A%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Environment%20variable(s)%20changed.%20Systemd%20path%20unit%20will%20pick%20the%20change.%22%0A%20%20%20%20mv%20-f%20%2Frun%2Fresolv-prepender%2Fenv.new%20%2Frun%2Fresolv-prepender%2Fenv%0A%20%20fi%0A%7D%0A%0Aexport%20IP4_DOMAINS%20IP6_DOMAINS%0Aexport%20-f%20resolv_prepender%0A%0A%23%20For%20RHEL8%20with%20NetworkManager%20%3E%3D%201.36%20and%20RHEL9%20with%20NetworkManager%20%3E%3D1.42%20we%20can%20use%20simplified%20logic%0A%23%20of%20observing%20only%20a%20single%20%22dns-change%22%20event.%20Older%20version%20of%20NetworkManager%20require%20however%20that%20we%0A%23%20react%20on%20a%20set%20of%20multiple%20events.%20Once%20dns-change%20event%20is%20detected%20we%20create%20a%20flag%20file%20to%20ignore%0A%23%20subsequent%20up%26co.%20events%20as%20undesired.%0A%23%0A%23%20Given%20an%20overall%20Network%20Manager%20dispatcher%20timeout%20of%2090%20seconds%2C%20we%20are%20enforcing%20a%20slightly%20shorter%0A%23%20timeout%20for%20the%20observed%20events.%20It%20is%20not%20really%20required%20because%20all%20we%20do%20in%20this%20function%20is%20to%20write%20a%20file.%0A%23%20We%20could%20get%20rid%20of%20this%20timeout%20completely%2C%20but%20it%20also%20does%20not%20cost%20much%20to%20keep%20it.%0Acase%20%22%24STATUS%22%20in%0A%20%20dns-change)%0A%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%20triggered%20by%20%24%7BIFACE%7D%20%24%7BSTATUS%7D.%22%0A%20%20%20%20if%20%5B%20!%20-f%20%22%2Frun%2Fnetworkmanager-dns-event-detected%22%20%5D%3B%20then%0A%20%20%20%20%20%20touch%20%2Frun%2Fnetworkmanager-dns-event-detected%0A%20%20%20%20fi%0A%20%20%20%20if%20!%20timeout%2060s%20bash%20-c%20resolv_prepender%3B%20then%0A%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Timeout%20occurred%22%0A%20%20%20%20%20%20exit%201%0A%20%20%20%20fi%0A%20%20%3B%3B%0A%0A%20%20up%7Cdhcp4-change%7Cdhcp6-change%7Creapply)%0A%20%20%20%20if%20%5B%20!%20-f%20%22%2Frun%2Fnetworkmanager-dns-event-detected%22%20%5D%3B%20then%0A%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%20triggered%20by%20%24%7BIFACE%7D%20%24%7BSTATUS%7D.%22%0A%20%20%20%20%20%20if%20!%20timeout%2030s%20bash%20-c%20resolv_prepender%3B%20then%0A%20%20%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Timeout%20occurred%22%0A%20%20%20%20%20%20%20%20exit%201%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20If%20%24DHCP6_FQDN_FQDN%20is%20not%20empty%20and%20is%20not%20localhost.localdomain%20and%20static%20hostname%20was%20not%20already%20set%0A%20%20%20%20if%20%5B%5B%20-n%20%22%24DHCP6_FQDN_FQDN%22%20%26%26%20%22%24DHCP6_FQDN_FQDN%22%20!%3D%20%22localhost.localdomain%22%20%26%26%20%22%24DHCP6_FQDN_FQDN%22%20%3D~%20%22.%22%20%5D%5D%20%3B%20then%0A%20%20%20%20%20%20%20STATIC_HOSTNAME%3D%22%24(test%20!%20-e%20%2Fetc%2Fhostname%20%26%26%20echo%20-n%20%7C%7C%20cat%20%2Fetc%2Fhostname%20%7C%20xargs)%22%0A%0A%20%20%20%20%20%20%20if%20%5B%5B%20-z%20%22%24STATIC_HOSTNAME%22%20%7C%7C%20%22%24STATIC_HOSTNAME%22%20%3D%3D%20%22localhost.localdomain%22%20%5D%5D%20%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%23%20run%20with%20systemd-run%20to%20avoid%20selinux%20problems%0A%20%20%20%20%20%20%20%20%20%20systemd-run%20--property%3DType%3Doneshot%20--unit%20resolve-prepender-hostnamectl%20-Pq%20%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20hostnamectl%20set-hostname%20--static%20--transient%20%24DHCP6_FQDN_FQDN%0A%20%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20if%20%5B%5B%20%22%24STATUS%22%20%3D%3D%20%22up%22%20%5D%5D%20%26%26%20%5B%5B%20%24IFACE%20%3D%3D%20%22br-ex%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20%2Fbin%2Fmkdir%20-p%20%2Frun%2Fnodeip-configuration%0A%20%20%20%20%20%20%20%20touch%20%2Frun%2Fnodeip-configuration%2Fbr-ex-up%0A%20%20%20%20fi%0A%20%20%3B%3B%0A%20%20*)%0A%20%20%3B%3B%0Aesac%0A
          mode: 493
          overwrite: true
          path: /etc/NetworkManager/dispatcher.d/30-resolv-prepender
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-ex%20-o%20pipefail%0A%0Aif%20%5B%5B%20%22OVNKubernetes%22%20%3D%3D%20%22OVNKubernetes%22%20%26%26%20%22%24CONNECTION_ID%22%20%3D%3D%20%22Wired%20Connection%22%20%5D%5D%0Athen%0A%20%20%20%20%3E%262%20echo%20%22Refusing%20to%20modify%20default%20connection.%22%0A%20%20%20%20exit%200%0Afi%0A%0Aif%20%5B%20-z%20%24%7BDHCP4_IP_ADDRESS%3A-%7D%20%5D%0Athen%0A%20%20%20%20%3E%262%20echo%20%22Not%20a%20DHCP4%20address.%20Ignoring.%22%0A%20%20%20%20exit%200%0Afi%0A%0Aif%20%5B%20%24%7BDHCP4_DHCP_LEASE_TIME%3A-0%7D%20-lt%204294967295%20%5D%0Athen%0A%20%20%20%20%3E%262%20echo%20%22Not%20an%20infinite%20DHCP4%20lease.%20Ignoring.%22%0A%20%20%20%20exit%200%0Afi%0A%0AIPS%3D(%24IP4_ADDRESS_0)%0ACIDR%3D%24%7BIPS%5B0%5D%7D%0AGATEWAY%3D%24%7BIPS%5B1%5D%7D%0A%0ATYPE%3D%24(nmcli%20--get-values%20connection.type%20connection%20show%20%22%24CONNECTION_ID%22)%0A%0A%23%20Modifying%20the%20default%20connection%20id%20directly%20doesn't%20do%20what%20we%20want.%0A%23%20If%20we%20see%20that%2C%20then%20we%20need%20to%20create%20a%20new%20connection.%0Aif%20%5B%20%22%24CONNECTION_ID%22%20%3D%3D%20%22Wired%20Connection%22%20%5D%0Athen%0A%20%20%20%20if%20!%20nmcli%20con%20show%20inf-lease-to-static%0A%20%20%20%20then%0A%20%20%20%20%20%20%20%20nmcli%20con%20add%20type%20%22%24TYPE%22%20con-name%20inf-lease-to-static%0A%20%20%20%20fi%0A%20%20%20%20STATIC_INT_NAME%3Dinf-lease-to-static%0Aelse%0A%20%20%20%20STATIC_INT_NAME%3D%22%24CONNECTION_ID%22%0Afi%0Anmcli%20con%20mod%20%22%24STATIC_INT_NAME%22%20%5C%0A%20%20conn.interface%20%22%241%22%20%5C%0A%20%20connection.autoconnect%20yes%20%5C%0A%20%20ipv4.addresses%20%22%24CIDR%22%20%5C%0A%20%20ipv4.method%20manual%20%5C%0A%20%20ipv4.gateway%20%22%24GATEWAY%22%20%5C%0A%20%20ipv4.dns%20%22%24IP4_NAMESERVERS%22%0A%0Aif%20%5B%20-n%20%22%24IP4_DOMAINS%22%20%5D%3B%20then%0A%20%20%20%20nmcli%20con%20mod%20%22%24STATIC_INT_NAME%22%20ipv4.dns-search%20%22%24IP4_DOMAINS%22%0Afi%0Aplus%3D''%0Afor%20i%20in%20%24(seq%200%20%24((%24IP4_NUM_ROUTES-1))%20)%0Ado%0A%20%20%20%20varname%3D%22IP4_ROUTE_%24i%22%0A%20%20%20%20nmcli%20con%20mod%20%22%24STATIC_INT_NAME%22%20%24%7Bplus%7Dipv4.routes%20%22%24%7B!varname%7D%22%0A%20%20%20%20plus%3D'%2B'%0Adone%0A%0Anmcli%20con%20up%20%22%24STATIC_INT_NAME%22%0A%0Aif%20%5B%20-n%20%22%24%7BDHCP4_HOST_NAME%3A-%7D%22%20%5D%0Athen%0A%20%20%20%20systemd-run%20--property%3DType%3Doneshot%20--unit%20static-dhcp-hostnamectl%20-Pq%20%5C%0A%20%20%20%20%20%20hostnamectl%20set-hostname%20--static%20--transient%20%22%24DHCP4_HOST_NAME%22%0Afi%0A
          mode: 493
          overwrite: true
          path: /etc/NetworkManager/dispatcher.d/30-static-dhcp
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-ex%20-o%20pipefail%0A%0Aif%20%5B%20-z%20%22%24DHCP6_IP6_ADDRESS%22%20%5D%0Athen%0A%20%20%20%20%3E%262%20echo%20%22Not%20a%20DHCP6%20address.%20Ignoring.%22%0A%20%20%20%20exit%200%0Afi%0A%0ALEASE_TIME%3D%24(ip%20-j%20-6%20a%20show%20%22%24DEVICE_IFACE%22%20%7C%20jq%20-r%20%22.%5B%5D.addr_info%5B%5D%20%7C%20select(.scope%3D%3D%5C%22global%5C%22)%20%7C%20select(.deprecated!%3Dtrue)%20%7C%20select(.local%3D%3D%5C%22%24DHCP6_IP6_ADDRESS%5C%22)%20%7C%20.preferred_life_time%22)%0APREFIX_LEN%3D%24(ip%20-j%20-6%20a%20show%20%22%24DEVICE_IFACE%22%20%7C%20jq%20-r%20%22.%5B%5D.addr_info%5B%5D%20%7C%20select(.scope%3D%3D%5C%22global%5C%22)%20%7C%20select(.deprecated!%3Dtrue)%20%7C%20select(.local%3D%3D%5C%22%24DHCP6_IP6_ADDRESS%5C%22)%20%7C%20.prefixlen%22)%0A%0Aif%20%5B%20%24%7BLEASE_TIME%3A-0%7D%20-lt%204294967295%20%5D%0Athen%0A%20%20%20%20%3E%262%20echo%20%22Not%20an%20infinite%20DHCP6%20lease.%20Ignoring.%22%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20We%20don't%20want%20this%20to%20run%20before%20OVNKubernetes%20creates%20its%20bridge.%20If%20we%0A%23%20see%20the%20default%20CONNECTION_ID%20we%20know%20to%20wait.%0Aif%20%5B%20%22%24CONNECTION_ID%22%20%3D%3D%20%22Wired%20Connection%22%20%5D%0Athen%0A%20%20%20%20%3E%262%20echo%20%22Refusing%20to%20modify%20default%20connection.%22%0A%20%20%20%20exit%200%0Afi%0A%0ACIDR%3D%22%24DHCP6_IP6_ADDRESS%2F%24PREFIX_LEN%22%0Anmcli%20con%20mod%20%22%24CONNECTION_ID%22%20ipv6.addresses%20%22%24CIDR%22%0Anmcli%20con%20mod%20%22%24CONNECTION_ID%22%20connection.autoconnect%20%22yes%22%0Anmcli%20con%20mod%20%22%24CONNECTION_ID%22%20ipv6.method%20%22manual%22%0Anmcli%20con%20mod%20%22%24CONNECTION_ID%22%20ipv6.gateway%20%22%24IP6_GATEWAY%22%0Anmcli%20con%20mod%20%22%24CONNECTION_ID%22%20ipv6.dns%20%22%24IP6_NAMESERVERS%22%0ASEARCH_DOMAIN%3D%22%24%7BDHCP6_FQDN_FQDN%23*.%7D%22%0Aif%20%5B%20-n%20%22%24SEARCH_DOMAIN%22%20%5D%3B%20then%0A%20%20%20%20nmcli%20con%20mod%20%22%24CONNECTION_ID%22%20ipv6.dns-search%20%22%24SEARCH_DOMAIN%22%0Afi%0Aplus%3D''%0Afor%20i%20in%20%24(seq%200%20%24((%24IP6_NUM_ROUTES-1))%20)%0Ado%0A%20%20%20%20varname%3D%22IP6_ROUTE_%24i%22%0A%20%20%20%20nmcli%20con%20mod%20%22%24CONNECTION_ID%22%20%24%7Bplus%7Dipv6.routes%20%22%24%7B!varname%7D%22%0A%20%20%20%20plus%3D'%2B'%0Adone%0A%0A%23%20Copy%20it%20from%20the%20OverlayFS%20mount%20to%20the%20persistent%20lowerdir%0Acp%20%22%24CONNECTION_FILENAME%22%20%2Fetc%2FNetworkManager%2Fsystem-connections%0A
          mode: 493
          overwrite: true
          path: /etc/NetworkManager/dispatcher.d/30-static-dhcpv6
        - contents:
            source: data:,
          mode: 384
          overwrite: true
          path: /etc/pki/ca-trust/source/anchors/openshift-config-user-ca-bundle.crt
        - contents:
            source: data:,KUBERNETES_SERVICE_HOST%3D'api-int.comp-poc-rh01.rhpoc.int'%0AKUBERNETES_SERVICE_PORT%3D'6443'%0A
          mode: 420
          overwrite: true
          path: /etc/kubernetes/apiserver-url.env
        - contents:
            source: data:,%23%20This%20file%20is%20managed%20by%20machine-config-operator.%0A%23%20Suppress%20audit%20rules%20which%20always%20trigger%20for%20container%0A%23%20workloads%2C%20as%20they%20spam%20the%20audit%20log.%20%20Workloads%20are%20expected%0A%23%20to%20be%20dynamic%2C%20and%20the%20networking%20stack%20uses%20iptables.%0A-a%20exclude%2Calways%20-F%20msgtype%3DNETFILTER_CFG%0A%23%20The%20default%20bridged%20networking%20enables%20promiscuous%20on%20the%20veth%0A%23%20device.%20%20Ideally%2C%20we'd%20teach%20audit%20to%20ignore%20only%20veth%20devices%2C%0A%23%20since%20one%20might%20legitimately%20care%20about%20promiscuous%20on%20real%20physical%0A%23%20devices.%20%20But%20we%20can't%20currently%20differentiate.%0A-a%20exclude%2Calways%20-F%20msgtype%3DANOM_PROMISCUOUS%0A
          mode: 420
          overwrite: true
          path: /etc/audit/rules.d/mco-audit-quiet-containers.rules
        - contents:
            source: data:,mode%3A%20unicast%0A
          mode: 420
          overwrite: true
          path: /etc/keepalived/monitor.conf
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%0A%23%20ESP%20offload%2C%20either%20in%20actual%20hardware%20or%20as%20part%20as%20GRO%20(generic%0A%23%20recieve%20offload)%20does%20not%20work%20for%20interfaces%20attached%20to%20an%20OVS%20bridge%0A%23%20so%20turn%20it%20off%20for%20the%20time%20being.%0A%23%20https%3A%2F%2Fissues.redhat.com%2Fbrowse%2FRHEL-58811%0A%0A%23%20Depends%20on%20ipsec%20service%20drop-in%20to%20start%20it%20after%20configure-ovs%20to%20make%0A%23%20sure%20offloads%20are%20disabled%20before%20ipsec%20starts.%0A%0Aif%20%5B%5B%20%22%242%22%20!%3D%20%22up%22%20%5D%5D%3B%20then%0A%20%20exit%0Afi%0A%0Adevice%3D%24DEVICE_IFACE%0Akind_slave%3D%24(ip%20-j%20-d%20link%20show%20%22%24device%22%20%7C%20jq%20-r%20'.%5B0%5D%20%7C%20.linkinfo.info_slave_kind%20%2F%2F%20empty')%0A%0Aif%20%5B%20%22%24kind_slave%22%20%3D%20%22openvswitch%22%20%5D%3B%20then%0A%20%20for%20feature%20in%20tx-esp-segmentation%20esp-hw-offload%20esp-tx-csum-hw-offload%3B%20do%0A%20%20%20%20if%20ethtool%20-k%20%22%24device%22%20%7C%20grep%20-qE%20%22%5E%24%7Bfeature%7D%3A%20off%22%3B%20then%0A%20%20%20%20%20%20%23%20already%20disabled%2C%20nothing%20to%20do%0A%20%20%20%20%20%20continue%0A%20%20%20%20fi%0A%20%20%20%20%0A%20%20%20%20logger%20-t%2099-esp-offload%20-s%20%22Setting%20%24feature%20off%20for%20%24device%3A%20unsupported%20when%20attached%20to%20Open%20vSwitch%20bridge%22%0A%20%20%20%20ethtool%20-K%20%22%24device%22%20%22%24feature%22%20off%0A%20%20done%0Afi%0A
          mode: 484
          overwrite: true
          path: /etc/NetworkManager/dispatcher.d/99-esp-offload
        - contents:
            source: data:,r%20%2Fetc%2Fkubernetes%2Fcni%2Fnet.d%2F80-openshift-network.conf%0Ar%20%2Fetc%2Fkubernetes%2Fcni%2Fnet.d%2F10-ovn-kubernetes.conf%0Ad%20%2Frun%2Fmultus%2Fcni%2Fnet.d%2F%200755%20root%20root%20-%20-%0AD%20%2Fvar%2Flib%2Fcni%2Fnetworks%2Fopenshift-sdn%2F%200755%20root%20root%20-%20-%0A
          mode: 420
          overwrite: true
          path: /etc/tmpfiles.d/cleanup-cni.conf
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-ex%0A%0A%23%20Used%20for%20on-prem%20deployments%20to%20enable%20ip%20forwarding%20as%20part%20of%20nodeip-configuration%20service.%0A%23%20IP%20forwarding%20is%20required%20on%20the%20node%20IP%20(k8s%20API)%20interface%20in%20order%20for%20keepalived%20to%20function.%0A%0Aecho%20%22Configuring%20IP%20Forwarding...%22%0Aovnk_config_dir%3D'%2Fetc%2Fovnk'%0Aip_hint_file%3D%22%2Frun%2Fnodeip-configuration%2Fprimary-ip%22%0A%0Aget_ip_from_ip_hint_file()%20%7B%0A%20%20local%20ip_hint_file%3D%22%241%22%0A%20%20if%20%5B%5B%20!%20-f%20%22%24%7Bip_hint_file%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22error%3A%20unable%20to%20enable%20IP%20forwarding.%20IP%20hint%20file%3A%20%24%7Bip_hint_file%7D%20does%20not%20exist!%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%20%20ip_hint%3D%24(cat%20%22%24%7Bip_hint_file%7D%22)%0A%20%20echo%20%22%24%7Bip_hint%7D%22%0A%7D%0A%0Aget_nodeip_hint_interface()%20%7B%0A%20%20local%20ip_hint%3D%22%22%0A%20%20local%20ip_hint_file%3D%22%241%22%0A%20%20local%20iface%3D%22%22%0A%0A%20%20ip_hint%3D%24(get_ip_from_ip_hint_file%20%22%24%7Bip_hint_file%7D%22)%0A%20%20if%20%5B%5B%20-z%20%22%24%7Bip_hint%7D%22%20%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22error%3A%20unable%20to%20enable%20IP%20forwarding.%20IP%20hint%20file%3A%20%24%7Bip_hint_file%7D%20is%20empty!%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%0A%20%20iface%3D%24(ip%20-j%20addr%20%7C%20jq%20-r%20%22first(.%5B%5D%20%7C%20select(any(.addr_info%5B%5D%3B%20.local%3D%3D%5C%22%24%7Bip_hint%7D%5C%22)))%20%7C%20.ifname%22)%0A%20%20if%20%5B%5B%20-z%20%22%24%7Biface%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22error%3A%20unable%20to%20enable%20IP%20forwarding.%20Cannot%20detect%20valid%20interface%20within%20file%3A%20%24%7Bip_hint_file%7D%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%20%20echo%20%22%24%7Biface%7D%22%0A%7D%0A%0Aiface%3D%24(get_nodeip_hint_interface%20%22%24%7Bip_hint_file%7D%22)%0A%0Aecho%20%22Node%20IP%20interface%20determined%20as%3A%20%24%7Biface%7D.%20Enabling%20IP%20forwarding...%22%0Afile_paths%3D(%22%2Fproc%2Fsys%2Fnet%2Fipv4%2Fconf%2F%24%7Biface%7D%2Fforwarding%22%20%22%2Fproc%2Fsys%2Fnet%2Fipv6%2Fconf%2F%24%7Biface%7D%2Fforwarding%22)%0Afor%20file_path%20in%20%22%24%7Bfile_paths%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20if%20%5B%20-f%20%22%24%7Bfile_path%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%221%22%20%3E%20%22%24%7Bfile_path%7D%22%0A%20%20%20%20fi%0Adone%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/configure-ip-forwarding.sh
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-x%0A%0Aif%20%5B%20-e%20%2Fetc%2Fnmstate%2Fopenshift%2Fapplied%20%5D%3B%20then%0A%20%20echo%20%22Skipping%20configure-ovs%20due%20to%20manual%20network%20configuration%22%0A%20%20exit%200%0Afi%0A%0A%23%20This%20file%20is%20not%20needed%20anymore%20in%204.7%2B%2C%20but%20when%20rolling%20back%20to%204.6%0A%23%20the%20ovs%20pod%20needs%20it%20to%20know%20ovs%20is%20running%20on%20the%20host.%0Atouch%20%2Fvar%2Frun%2Fovs-config-executed%0A%0A%23%20These%20are%20well%20knwon%20NM%20default%20paths%0ANM_CONN_ETC_PATH%3D%22%2Fetc%2FNetworkManager%2Fsystem-connections%22%0ANM_CONN_RUN_PATH%3D%22%2Frun%2FNetworkManager%2Fsystem-connections%22%0A%0A%23%20This%20is%20the%20path%20where%20NM%20is%20known%20to%20be%20configured%20to%20store%20user%20keyfiles%20%0ANM_CONN_CONF_PATH%3D%22%24NM_CONN_ETC_PATH%22%0A%0A%23%20This%20is%20where%20we%20want%20our%20keyfiles%20to%20finally%20reside.%20configure-ovs%0A%23%20operates%20with%20temporary%20keyfiles%20in%20NM_CONN_RUN_PATH%20and%20then%20as%20a%20last%0A%23%20step%20moves%20those%20keyfiles%20to%20NM_CONN_SET_PATH%20if%20it%20is%20a%20different%20path%0A%23%20(not%20by%20default).%20This%20mitigates%20hard%20interruptions%20(SIGKILL%2C%20hard%20reboot)%0A%23%20of%20configure-ovs%20leaving%20the%20machine%20with%20a%20half-baked%20set%20of%20keyfiles%0A%23%20that%20might%20prevent%20machine%20networking%20from%20working%20correctly.%0ANM_CONN_SET_PATH%3D%22%24%7BNM_CONN_SET_PATH%3A-%24NM_CONN_RUN_PATH%7D%22%0A%0AMANAGED_NM_CONN_SUFFIX%3D%22-slave-ovs-clone%22%0A%23%20Workaround%20to%20ensure%20OVS%20is%20installed%20due%20to%20bug%20in%20systemd%20Requires%3A%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1888017%0Acopy_nm_conn_files()%20%7B%0A%20%20local%20dst_path%3D%22%241%22%0A%20%20for%20src%20in%20%22%24%7BMANAGED_NM_CONN_FILES%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20src_path%3D%24(dirname%20%22%24src%22)%0A%20%20%20%20file%3D%24(basename%20%22%24src%22)%0A%20%20%20%20if%20%5B%20-f%20%22%24src_path%2F%24file%22%20%5D%3B%20then%0A%20%20%20%20%20%20if%20%5B%20!%20-f%20%22%24dst_path%2F%24file%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22Copying%20configuration%20%24file%22%0A%20%20%20%20%20%20%20%20cp%20%22%24src_path%2F%24file%22%20%22%24dst_path%2F%24file%22%0A%20%20%20%20%20%20elif%20!%20cmp%20--silent%20%22%24src_path%2F%24file%22%20%22%24dst_path%2F%24file%22%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22Copying%20updated%20configuration%20%24file%22%0A%20%20%20%20%20%20%20%20cp%20-f%20%22%24src_path%2F%24file%22%20%22%24dst_path%2F%24file%22%0A%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20echo%20%22Skipping%20%24file%20since%20it's%20equal%20at%20destination%22%0A%20%20%20%20%20%20fi%0A%20%20%20%20else%0A%20%20%20%20%20%20echo%20%22Skipping%20%24file%20since%20it%20does%20not%20exist%20at%20source%22%0A%20%20%20%20fi%0A%20%20done%0A%7D%0A%0Aupdate_nm_conn_files_base()%20%7B%0A%20%20base_path%3D%24%7B1%7D%0A%20%20bridge_name%3D%24%7B2%7D%0A%20%20port_name%3D%24%7B3%7D%0A%20%20ovs_port%3D%22ovs-port-%24%7Bbridge_name%7D%22%0A%20%20ovs_interface%3D%22ovs-if-%24%7Bbridge_name%7D%22%0A%20%20default_port_name%3D%22ovs-port-%24%7Bport_name%7D%22%20%23%20ovs-port-phys0%0A%20%20bridge_interface_name%3D%22ovs-if-%24%7Bport_name%7D%22%20%23%20ovs-if-phys0%0A%20%20%23%20In%20RHEL7%20files%20in%20%2F%7Betc%2Crun%7D%2FNetworkManager%2Fsystem-connections%20end%20without%20the%20suffix%20'.nmconnection'%2C%20whereas%20in%20RHCOS%20they%20end%20with%20the%20suffix.%0A%20%20MANAGED_NM_CONN_FILES%3D(%24(echo%20%22%24%7Bbase_path%7D%22%2F%7B%22%24bridge_name%22%2C%22%24ovs_interface%22%2C%22%24ovs_port%22%2C%22%24bridge_interface_name%22%2C%22%24default_port_name%22%7D%7B%2C.nmconnection%7D))%0A%20%20shopt%20-s%20nullglob%0A%20%20MANAGED_NM_CONN_FILES%2B%3D(%24%7Bbase_path%7D%2F*%24%7BMANAGED_NM_CONN_SUFFIX%7D.nmconnection%20%24%7Bbase_path%7D%2F*%24%7BMANAGED_NM_CONN_SUFFIX%7D)%0A%20%20shopt%20-u%20nullglob%0A%7D%0A%0Aupdate_nm_conn_run_files()%20%7B%0A%20%20update_nm_conn_files_base%20%22%24%7BNM_CONN_RUN_PATH%7D%22%20%22%24%7B1%7D%22%20%22%24%7B2%7D%22%0A%7D%0A%0Aupdate_nm_conn_set_files()%20%7B%0A%20%20update_nm_conn_files_base%20%22%24%7BNM_CONN_SET_PATH%7D%22%20%22%24%7B1%7D%22%20%22%24%7B2%7D%22%0A%7D%0A%0Aupdate_nm_conn_etc_files()%20%7B%0A%20%20update_nm_conn_files_base%20%22%24%7BNM_CONN_ETC_PATH%7D%22%20%22%24%7B1%7D%22%20%22%24%7B2%7D%22%0A%7D%0A%0A%23%20Move%20and%20reload%20keyfiles%20at%20their%20final%20destination%0Aset_nm_conn_files()%20%7B%0A%20%20if%20%5B%20%22%24NM_CONN_RUN_PATH%22%20!%3D%20%22%24NM_CONN_SET_PATH%22%20%5D%3B%20then%0A%20%20%20%20update_nm_conn_run_files%20br-ex%20phys0%0A%20%20%20%20copy_nm_conn_files%20%22%24NM_CONN_SET_PATH%22%0A%20%20%20%20rm_nm_conn_files%0A%20%20%20%20update_nm_conn_run_files%20br-ex1%20phys1%0A%20%20%20%20copy_nm_conn_files%20%22%24NM_CONN_SET_PATH%22%0A%20%20%20%20rm_nm_conn_files%0A%0A%20%20%20%20%23%20reload%20keyfiles%0A%20%20%20%20nmcli%20connection%20reload%0A%20%20fi%0A%7D%0A%0A%23%20Used%20to%20remove%20files%20managed%20by%20configure-ovs%20and%20temporary%20leftover%20files%20from%20network%20manager%0Arm_nm_conn_files()%20%7B%0A%20%20for%20file%20in%20%22%24%7BMANAGED_NM_CONN_FILES%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20if%20%5B%20-f%20%22%24file%22%20%5D%3B%20then%0A%20%20%20%20%20%20rm%20-f%20%22%24file%22%0A%20%20%20%20%20%20echo%20%22Removed%20nmconnection%20file%20%24file%22%0A%20%20%20%20%20%20nm_config_changed%3D1%0A%20%20%20%20fi%0A%20%20done%0A%20%20for%20file%20in%20%22%24%7BMANAGED_NM_CONN_FILES%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20for%20temp%20in%20%24(compgen%20-G%20%22%24%7Bfile%7D.*%22)%3B%20do%0A%20%20%20%20%20%20rm%20-f%20%22%24temp%22%0A%20%20%20%20%20%20echo%20%22Removed%20nmconnection%20temporary%20file%20%24temp%22%0A%20%20%20%20%20%20nm_config_changed%3D1%0A%20%20%20%20done%0A%20%20done%0A%7D%0A%0A%23%20Used%20to%20clone%20a%20slave%20connection%20by%20uuid%2C%20returns%20new%20name%0Aclone_slave_connection()%20%7B%0A%20%20local%20uuid%3D%22%241%22%0A%20%20local%20old_name%0A%20%20old_name%3D%22%24(nmcli%20-g%20connection.id%20connection%20show%20uuid%20%22%24uuid%22)%22%0A%20%20local%20new_name%3D%22%24%7Bold_name%7D%24%7BMANAGED_NM_CONN_SUFFIX%7D%22%0A%20%20if%20nmcli%20connection%20show%20id%20%22%24%7Bnew_name%7D%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20echo%20%22WARNING%3A%20existing%20ovs%20slave%20%24%7Bnew_name%7D%20connection%20profile%20file%20found%2C%20overwriting...%22%20%3E%262%0A%20%20%20%20nmcli%20connection%20delete%20id%20%22%24%7Bnew_name%7D%22%20%26%3E%20%2Fdev%2Fnull%0A%20%20fi%0A%20%20clone_nm_conn%20%24uuid%20%22%24%7Bnew_name%7D%22%0A%20%20echo%20%22%24%7Bnew_name%7D%22%0A%7D%0A%0A%23%20Used%20to%20replace%20an%20old%20master%20connection%20uuid%20with%20a%20new%20one%20on%20all%20connections%0Areplace_connection_master()%20%7B%0A%20%20local%20old%3D%22%241%22%0A%20%20local%20new%3D%22%242%22%0A%20%20for%20conn_uuid%20in%20%24(nmcli%20-g%20UUID%20connection%20show)%20%3B%20do%0A%20%20%20%20if%20%5B%20%22%24(nmcli%20-g%20connection.master%20connection%20show%20uuid%20%22%24conn_uuid%22)%22%20!%3D%20%22%24old%22%20%5D%3B%20then%0A%20%20%20%20%20%20continue%0A%20%20%20%20fi%0A%0A%20%20%20%20local%20active_state%3D%24(nmcli%20-g%20GENERAL.STATE%20connection%20show%20%22%24conn_uuid%22)%0A%20%20%20%20local%20autoconnect%3D%24(nmcli%20-g%20connection.autoconnect%20connection%20show%20%22%24conn_uuid%22)%0A%20%20%20%20if%20%5B%20%22%24active_state%22%20!%3D%20%22activated%22%20%5D%20%26%26%20%5B%20%22%24autoconnect%22%20!%3D%20%22yes%22%20%5D%3B%20then%0A%20%20%20%20%20%20%23%20Assume%20that%20slave%20profiles%20intended%20to%20be%20used%20are%20those%20that%20are%3A%0A%20%20%20%20%20%20%23%20-%20active%0A%20%20%20%20%20%20%23%20-%20or%20inactive%20(which%20might%20be%20due%20to%20link%20being%20down)%20but%20to%20be%20autoconnected.%0A%20%20%20%20%20%20%23%20Otherwise%2C%20ignore%20them.%0A%20%20%20%20%20%20continue%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20make%20changes%20for%20slave%20profiles%20in%20a%20new%20clone%0A%20%20%20%20local%20new_name%0A%20%20%20%20new_name%3D%24(clone_slave_connection%20%24conn_uuid)%0A%0A%20%20%20%20mod_nm_conn%20%22%24new_name%22%20connection.master%20%22%24new%22%20connection.autoconnect-priority%20100%20connection.autoconnect%20no%20%0A%20%20%20%20echo%20%22Replaced%20master%20%24old%20with%20%24new%20for%20slave%20profile%20%24new_name%22%0A%20%20done%0A%7D%0A%0A%23%20when%20creating%20the%20bridge%2C%20we%20use%20a%20value%20lower%20than%20NM's%20ethernet%20device%20default%20route%20metric%0A%23%20(we%20pick%2048%20and%2049%20to%20be%20lower%20than%20anything%20that%20NM%20chooses%20by%20default)%0ABRIDGE_METRIC%3D%2248%22%0ABRIDGE1_METRIC%3D%2249%22%0A%23%20Given%20an%20interface%2C%20generates%20NM%20configuration%20to%20add%20to%20an%20OVS%20bridge%0Aconvert_to_bridge()%20%7B%0A%20%20local%20iface%3D%24%7B1%7D%0A%20%20local%20bridge_name%3D%24%7B2%7D%0A%20%20local%20port_name%3D%24%7B3%7D%0A%20%20local%20bridge_metric%3D%24%7B4%7D%0A%20%20local%20ovs_port%3D%22ovs-port-%24%7Bbridge_name%7D%22%0A%20%20local%20ovs_interface%3D%22ovs-if-%24%7Bbridge_name%7D%22%0A%20%20local%20default_port_name%3D%22ovs-port-%24%7Bport_name%7D%22%20%23%20ovs-port-phys0%0A%20%20local%20bridge_interface_name%3D%22ovs-if-%24%7Bport_name%7D%22%20%23%20ovs-if-phys0%0A%0A%20%20if%20%5B%20%22%24iface%22%20%3D%20%22%24bridge_name%22%20%5D%3B%20then%0A%20%20%20%20%23%20handle%20vlans%20and%20bonds%20etc%20if%20they%20have%20already%20been%0A%20%20%20%20%23%20configured%20via%20nm%20key%20files%20and%20br-ex%20is%20already%20up%0A%20%20%20%20ifaces%3D%24(ovs-vsctl%20list-ifaces%20%24%7Biface%7D)%0A%20%20%20%20for%20intf%20in%20%24ifaces%3B%20do%20configure_driver_options%20%24intf%3B%20done%0A%20%20%20%20echo%20%22Networking%20already%20configured%20and%20up%20for%20%24%7Bbridge-name%7D!%22%0A%20%20%20%20return%0A%20%20fi%0A%0A%20%20%23%20flag%20to%20reload%20NM%20to%20account%20for%20all%20the%20configuration%20changes%0A%20%20%23%20going%20forward%0A%20%20nm_config_changed%3D1%0A%0A%20%20if%20%5B%20-z%20%22%24iface%22%20%5D%3B%20then%0A%20%20%20%20echo%20%22ERROR%3A%20Unable%20to%20find%20default%20gateway%20interface%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%20%20%23%20find%20the%20MAC%20from%20OVS%20config%20or%20the%20default%20interface%20to%20use%20for%20OVS%20internal%20port%0A%20%20%23%20this%20prevents%20us%20from%20getting%20a%20different%20DHCP%20lease%20and%20dropping%20connection%0A%20%20if%20!%20iface_mac%3D%24(%3C%22%2Fsys%2Fclass%2Fnet%2F%24%7Biface%7D%2Faddress%22)%3B%20then%0A%20%20%20%20echo%20%22Unable%20to%20determine%20default%20interface%20MAC%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%0A%20%20echo%20%22MAC%20address%20found%20for%20iface%3A%20%24%7Biface%7D%3A%20%24%7Biface_mac%7D%22%0A%0A%20%20%23%20find%20MTU%20from%20original%20iface%0A%20%20iface_mtu%3D%24(ip%20link%20show%20%22%24iface%22%20%7C%20awk%20'%7Bprint%20%245%3B%20exit%7D')%0A%20%20if%20%5B%5B%20-z%20%22%24iface_mtu%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22Unable%20to%20determine%20default%20interface%20MTU%2C%20defaulting%20to%201500%22%0A%20%20%20%20iface_mtu%3D1500%0A%20%20else%0A%20%20%20%20echo%20%22MTU%20found%20for%20iface%3A%20%24%7Biface%7D%3A%20%24%7Biface_mtu%7D%22%0A%20%20fi%0A%0A%20%20%23%20store%20old%20conn%20for%20later%0A%20%20old_conn%3D%24(nmcli%20--fields%20UUID%2CDEVICE%20conn%20show%20--active%20%7C%20awk%20%22%2F%5Cs%24%7Biface%7D%5Cs*%5C%24%2F%20%7Bprint%20%5C%241%7D%22)%0A%0A%20%20if%20%5B%5B%20-z%20%22%24old_conn%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22ERROR%3A%20cannot%20find%20connection%20for%20interface%3A%20%24%7Biface%7D%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%0A%20%20%23%20create%20bridge%0A%20%20if%20!%20nmcli%20connection%20show%20%22%24bridge_name%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-br%20%22%24bridge_name%22%0A%20%20%20%20add_nm_conn%20%22%24bridge_name%22%20type%20ovs-bridge%20conn.interface%20%22%24bridge_name%22%20802-3-ethernet.mtu%20%24%7Biface_mtu%7D%20%5C%0A%20%20%20%20connection.autoconnect-slaves%201%0A%20%20fi%0A%0A%20%20%23%20find%20default%20port%20to%20add%20to%20bridge%0A%20%20if%20!%20nmcli%20connection%20show%20%22%24default_port_name%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-port%20%22%24bridge_name%22%20%24%7Biface%7D%0A%20%20%20%20add_nm_conn%20%22%24default_port_name%22%20type%20ovs-port%20conn.interface%20%24%7Biface%7D%20slave-type%20ovs-bridge%20master%20%22%24bridge_name%22%20%5C%0A%20%20%20%20connection.autoconnect-slaves%201%0A%20%20fi%0A%0A%20%20if%20!%20nmcli%20connection%20show%20%22%24ovs_port%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-port%20%22%24bridge_name%22%20%22%24bridge_name%22%0A%20%20%20%20add_nm_conn%20%22%24ovs_port%22%20type%20ovs-port%20conn.interface%20%22%24bridge_name%22%20slave-type%20ovs-bridge%20master%20%22%24bridge_name%22%0A%20%20fi%0A%0A%20%20extra_phys_args%3D()%0A%20%20%23%20check%20if%20this%20interface%20is%20a%20vlan%2C%20bond%2C%20team%2C%20or%20ethernet%20type%0A%20%20if%20%5B%20%22%24(nmcli%20--get-values%20connection.type%20conn%20show%20%24%7Bold_conn%7D)%22%20%3D%3D%20%22vlan%22%20%5D%3B%20then%0A%20%20%20%20iface_type%3Dvlan%0A%20%20%20%20vlan_id%3D%24(nmcli%20--get-values%20vlan.id%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20if%20%5B%20-z%20%22%24vlan_id%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22ERROR%3A%20unable%20to%20determine%20vlan_id%20for%20vlan%20connection%3A%20%24%7Bold_conn%7D%22%0A%20%20%20%20%20%20exit%201%0A%20%20%20%20fi%0A%20%20%20%20vlan_parent%3D%24(nmcli%20--get-values%20vlan.parent%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20if%20%5B%20-z%20%22%24vlan_parent%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22ERROR%3A%20unable%20to%20determine%20vlan_parent%20for%20vlan%20connection%3A%20%24%7Bold_conn%7D%22%0A%20%20%20%20%20%20exit%201%0A%20%20%20%20fi%0A%0A%20%20%20%20if%20nmcli%20connection%20show%20uuid%20%22%24vlan_parent%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20%20%20%23%20if%20the%20VLAN%20connection%20is%20configured%20with%20a%20connection%20UUID%20as%20parent%2C%20we%20need%20to%20find%20the%20underlying%20device%0A%20%20%20%20%20%20%23%20and%20create%20the%20bridge%20against%20it%2C%20as%20the%20parent%20connection%20can%20be%20replaced%20by%20another%20bridge.%0A%20%20%20%20%20%20vlan_parent%3D%24(nmcli%20--get-values%20GENERAL.DEVICES%20conn%20show%20uuid%20%24%7Bvlan_parent%7D)%0A%20%20%20%20fi%0A%0A%20%20%20%20extra_phys_args%3D(%20dev%20%22%24%7Bvlan_parent%7D%22%20id%20%22%24%7Bvlan_id%7D%22%20)%0A%20%20elif%20%5B%20%22%24(nmcli%20--get-values%20connection.type%20conn%20show%20%24%7Bold_conn%7D)%22%20%3D%3D%20%22bond%22%20%5D%3B%20then%0A%20%20%20%20iface_type%3Dbond%0A%20%20%20%20%23%20check%20bond%20options%0A%20%20%20%20bond_opts%3D%24(nmcli%20--get-values%20bond.options%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20if%20%5B%20-n%20%22%24bond_opts%22%20%5D%3B%20then%0A%20%20%20%20%20%20extra_phys_args%2B%3D(%20bond.options%20%22%24%7Bbond_opts%7D%22%20)%0A%20%20%20%20%20%20MODE_REGEX%3D%22(%5E%7C%2C)mode%3Dactive-backup(%2C%7C%24)%22%0A%20%20%20%20%20%20MAC_REGEX%3D%22(%5E%7C%2C)fail_over_mac%3D(1%7Cactive%7C2%7Cfollow)(%2C%7C%24)%22%0A%20%20%20%20%20%20if%20%5B%5B%20%24bond_opts%20%3D~%20%24MODE_REGEX%20%5D%5D%20%26%26%20%5B%5B%20%24bond_opts%20%3D~%20%24MAC_REGEX%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20clone_mac%3D0%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%20%20elif%20%5B%20%22%24(nmcli%20--get-values%20connection.type%20conn%20show%20%24%7Bold_conn%7D)%22%20%3D%3D%20%22team%22%20%5D%3B%20then%0A%20%20%20%20iface_type%3Dteam%0A%20%20%20%20%23%20check%20team%20config%20options%0A%20%20%20%20team_config_opts%3D%24(nmcli%20--get-values%20team.config%20-e%20no%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20if%20%5B%20-n%20%22%24team_config_opts%22%20%5D%3B%20then%0A%20%20%20%20%20%20%23%20team.config%20is%20json%2C%20remove%20spaces%20to%20avoid%20problems%20later%20on%0A%20%20%20%20%20%20extra_phys_args%2B%3D(%20team.config%20%22%24%7Bteam_config_opts%2F%2F%5B%5B%3Aspace%3A%5D%5D%2F%7D%22%20)%0A%20%20%20%20%20%20team_mode%3D%24(echo%20%22%24%7Bteam_config_opts%7D%22%20%7C%20jq%20-r%20%22.runner.name%20%2F%2F%20empty%22)%0A%20%20%20%20%20%20team_mac_policy%3D%24(echo%20%22%24%7Bteam_config_opts%7D%22%20%7C%20jq%20-r%20%22.runner.hwaddr_policy%20%2F%2F%20empty%22)%0A%20%20%20%20%20%20MAC_REGEX%3D%22(by_active%7Conly_active)%22%0A%20%20%20%20%20%20if%20%5B%20%22%24team_mode%22%20%3D%20%22activebackup%22%20%5D%20%26%26%20%5B%5B%20%22%24team_mac_policy%22%20%3D~%20%24MAC_REGEX%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20clone_mac%3D0%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%20%20elif%20%5B%20%22%24(nmcli%20--get-values%20connection.type%20conn%20show%20%24%7Bold_conn%7D)%22%20%3D%3D%20%22tun%22%20%5D%3B%20then%0A%20%20%20%20iface_type%3Dtun%0A%20%20%20%20tun_mode%3D%24(nmcli%20--get-values%20tun.mode%20-e%20no%20connection%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20extra_phys_args%2B%3D(%20tun.mode%20%22%24%7Btun_mode%7D%22%20)%0A%20%20elif%20%5B%20%22%24(nmcli%20--get-values%20connection.type%20conn%20show%20%24%7Bold_conn%7D)%22%20%3D%3D%20%22bridge%22%20%5D%3B%20then%0A%20%20%20%20iface_type%3Dbridge%0A%20%20else%0A%20%20%20%20iface_type%3D802-3-ethernet%0A%20%20fi%0A%0A%20%20if%20%5B%20!%20%22%24%7Bclone_mac%3A-%7D%22%20%3D%20%220%22%20%5D%3B%20then%0A%20%20%20%20%23%20In%20active-backup%20link%20aggregation%2C%20with%20fail_over_mac%20mode%20enabled%2C%0A%20%20%20%20%23%20cloning%20the%20mac%20address%20is%20not%20supported.%20It%20is%20possible%20then%20that%0A%20%20%20%20%23%20br-ex%20has%20a%20different%20mac%20address%20than%20the%20bond%20which%20might%20be%0A%20%20%20%20%23%20troublesome%20on%20some%20platforms%20where%20the%20nic%20won't%20accept%20packets%20with%0A%20%20%20%20%23%20a%20different%20destination%20mac.%20But%20nobody%20has%20complained%20so%20far%20so%20go%20on%0A%20%20%20%20%23%20with%20what%20we%20got.%20%0A%20%20%20%20%0A%20%20%20%20%23%20Do%20set%20it%20though%20for%20other%20link%20aggregation%20configurations%20where%20the%0A%20%20%20%20%23%20mac%20address%20would%20otherwise%20depend%20on%20enslave%20order%20for%20which%20we%20have%0A%20%20%20%20%23%20no%20control%20going%20forward.%0A%20%20%20%20extra_phys_args%2B%3D(%20802-3-ethernet.cloned-mac-address%20%22%24%7Biface_mac%7D%22%20)%0A%20%20fi%0A%0A%20%20%23%20use%20%24%7Bextra_phys_args%5B%40%5D%2B%22%24%7Bextra_phys_args%5B%40%5D%7D%22%7D%20instead%20of%20%24%7Bextra_phys_args%5B%40%5D%7D%20to%20be%20compatible%20with%20bash%204.2%20in%20RHEL7.9%0A%20%20if%20!%20nmcli%20connection%20show%20%22%24bridge_interface_name%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20destroy%20interface%20%24%7Biface%7D%0A%20%20%20%20ovs_default_port_conn%3D%24(nmcli%20-g%20connection.uuid%20conn%20show%20%22%24default_port_name%22)%0A%20%20%20%20add_nm_conn%20%22%24bridge_interface_name%22%20type%20%24%7Biface_type%7D%20conn.interface%20%24%7Biface%7D%20master%20%22%24ovs_default_port_conn%22%20%5C%0A%20%20%20%20%20%20slave-type%20ovs-port%20connection.autoconnect-priority%20100%20connection.autoconnect-slaves%201%20802-3-ethernet.mtu%20%24%7Biface_mtu%7D%20%5C%0A%20%20%20%20%20%20%24%7Bextra_phys_args%5B%40%5D%2B%22%24%7Bextra_phys_args%5B%40%5D%7D%22%7D%0A%20%20fi%0A%0A%20%20%23%20Get%20the%20new%20connection%20uuids%0A%20%20new_conn%3D%24(nmcli%20-g%20connection.uuid%20conn%20show%20%22%24bridge_interface_name%22)%0A%20%20ovs_port_conn%3D%24(nmcli%20-g%20connection.uuid%20conn%20show%20%22%24ovs_port%22)%0A%0A%20%20%23%20Update%20connections%20with%20master%20property%20set%20to%20use%20the%20new%20connection%0A%20%20replace_connection_master%20%24old_conn%20%24new_conn%0A%20%20replace_connection_master%20%24iface%20%24new_conn%0A%0A%20%20ipv4_method%3D%24(nmcli%20-g%20ipv4.method%20conn%20show%20%22%24old_conn%22)%0A%20%20ipv6_method%3D%24(nmcli%20-g%20ipv6.method%20conn%20show%20%22%24old_conn%22)%0A%0A%20%20ipv4_addresses%3D%24(nmcli%20-g%20ipv4.addresses%20conn%20show%20%22%24old_conn%22)%0A%20%20ipv6_addresses%3D%24(nmcli%20-g%20ipv6.addresses%20conn%20show%20%22%24old_conn%22)%0A%0A%20%20%23%20Warn%20about%20an%20invalid%20MTU%20that%20will%20most%20likely%20fail%20in%20one%20way%20or%0A%20%20%23%20another%0A%20%20if%20%5B%20%24%7Biface_mtu%7D%20-lt%201280%20%5D%20%26%26%20%5B%20%22%24%7Bipv6_method%7D%22%20!%3D%20%22disabled%22%20%5D%3B%20then%0A%20%20%20%20echo%20%22WARNING%3A%20MTU%20%24%7Biface_mtu%7D%20is%20lower%20than%20the%20minimum%20required%20of%201280%20for%20IPv6%22%0A%20%20fi%0A%0A%20%20if%20!%20nmcli%20connection%20show%20%22%24ovs_interface%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20destroy%20interface%20%22%24bridge_name%22%0A%20%20%20%20%23%20Clone%20the%20connection%20in%20case%20the%20method%20is%20manual%20or%20in%20case%20the%20an%20address%20is%20set%20(DHCP%20%2B%20static%20IP)%0A%20%20%20%20if%20%5B%20%22%24%7Bipv4_method%7D%22%20%3D%20%22manual%22%20%5D%20%7C%7C%20%5B%20%22%24%7Bipv4_addresses%7D%22%20!%3D%20%22%22%20%5D%20%7C%7C%20%5B%20%22%24%7Bipv6_method%7D%22%20%3D%20%22manual%22%20%5D%20%7C%7C%20%5B%20%22%24%7Bipv6_addresses%7D%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22Static%20IP%20addressing%20detected%20on%20default%20gateway%20connection%3A%20%24%7Bold_conn%7D%22%0A%20%20%20%20%20%20%23%20clone%20the%20old%20connection%20to%20get%20the%20address%20settings%0A%20%20%20%20%20%20%23%20prefer%20cloning%20vs%20copying%20the%20connection%20file%20to%20avoid%20problems%20with%20selinux%0A%20%20%20%20%20%20clone_nm_conn%20%22%24%7Bold_conn%7D%22%20%22%24%7Bovs_interface%7D%22%0A%20%20%20%20%20%20shopt%20-s%20nullglob%0A%20%20%20%20%20%20new_conn_files%3D(%24%7BNM_CONN_RUN_PATH%7D%2F%22%24%7Bovs_interface%7D%22*)%0A%20%20%20%20%20%20shopt%20-u%20nullglob%0A%20%20%20%20%20%20if%20%5B%20%24%7B%23new_conn_files%5B%40%5D%7D%20-ne%201%20%5D%20%7C%7C%20%5B%20!%20-f%20%22%24%7Bnew_conn_files%5B0%5D%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22ERROR%3A%20could%20not%20find%20%24%7Bovs_interface%7D%20conn%20file%20after%20cloning%20from%20%24%7Bold_conn%7D%22%0A%20%20%20%20%20%20%20%20exit%201%0A%20%20%20%20%20%20fi%0A%20%20%20%20%20%20new_conn_file%3D%22%24%7Bnew_conn_files%5B0%5D%7D%22%0A%0A%20%20%20%20%20%20%23%20modify%20the%20connection%20type%20directly%20because%20it%20can't%20be%20modified%0A%20%20%20%20%20%20%23%20through%20nmcli%0A%20%20%20%20%20%20sed%20-i%20'%2F%5E%5C%5Bconnection%5C%5D%24%2F%2C%2F%5E%5C%5B%2F%20s%2F%5Etype%3D.*%24%2Ftype%3Dovs-interface%2F'%20%24%7Bnew_conn_file%7D%0A%0A%20%20%20%20%20%20%23%20modify%20some%20more%20settings%20through%20nmcli%0A%20%20%20%20%20%20mod_nm_conn%20%22%24%7Bovs_interface%7D%22%20conn.interface%20%22%24bridge_name%22%20%5C%0A%20%20%20%20%20%20%20%20connection.multi-connect%20%22%22%20connection.autoconnect%20no%20%5C%0A%20%20%20%20%20%20%20%20connection.master%20%22%24ovs_port_conn%22%20connection.slave-type%20ovs-port%20%5C%0A%20%20%20%20%20%20%20%20ovs-interface.type%20internal%20%5C%0A%20%20%20%20%20%20%20%20802-3-ethernet.mtu%20%24%7Biface_mtu%7D%20802-3-ethernet.cloned-mac-address%20%24%7Biface_mac%7D%20%5C%0A%20%20%20%20%20%20%20%20ipv4.route-metric%20%22%24%7Bbridge_metric%7D%22%20ipv6.route-metric%20%22%24%7Bbridge_metric%7D%22%0A%0A%20%20%20%20%20%20echo%20%22Loaded%20new%20%24ovs_interface%20connection%20file%3A%20%24%7Bnew_conn_file%7D%22%0A%20%20%20%20else%0A%20%20%20%20%20%20extra_if_brex_args%3D%22%22%0A%20%20%20%20%20%20%23%20check%20if%20interface%20had%20ipv4%2Fipv6%20addresses%20assigned%0A%20%20%20%20%20%20num_ipv4_addrs%3D%24(ip%20-j%20a%20show%20dev%20%24%7Biface%7D%20%7C%20jq%20%22.%5B0%5D.addr_info%20%7C%20map(.%20%7C%20select(.family%20%3D%3D%20%5C%22inet%5C%22))%20%7C%20length%22)%0A%20%20%20%20%20%20if%20%5B%20%22%24num_ipv4_addrs%22%20-gt%200%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20extra_if_brex_args%2B%3D%22ipv4.may-fail%20no%20%22%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20%23%20IPV6%20should%20have%20at%20least%20a%20link%20local%20address.%20Check%20for%20more%20than%201%20to%20see%20if%20there%20is%20an%0A%20%20%20%20%20%20%23%20assigned%20address.%0A%20%20%20%20%20%20num_ip6_addrs%3D%24(ip%20-j%20a%20show%20dev%20%24%7Biface%7D%20%7C%20jq%20%22.%5B0%5D.addr_info%20%7C%20map(.%20%7C%20select(.family%20%3D%3D%20%5C%22inet6%5C%22%20and%20.scope%20!%3D%20%5C%22link%5C%22))%20%7C%20length%22)%0A%20%20%20%20%20%20if%20%5B%20%22%24num_ip6_addrs%22%20-gt%200%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20extra_if_brex_args%2B%3D%22ipv6.may-fail%20no%20%22%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20%23%20check%20for%20dhcp%20client%20ids%0A%20%20%20%20%20%20dhcp_client_id%3D%24(nmcli%20--get-values%20ipv4.dhcp-client-id%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20%20%20if%20%5B%20-n%20%22%24dhcp_client_id%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20extra_if_brex_args%2B%3D%22ipv4.dhcp-client-id%20%24%7Bdhcp_client_id%7D%20%22%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20dhcp6_client_id%3D%24(nmcli%20--get-values%20ipv6.dhcp-duid%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20%20%20if%20%5B%20-n%20%22%24dhcp6_client_id%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20extra_if_brex_args%2B%3D%22ipv6.dhcp-duid%20%24%7Bdhcp6_client_id%7D%20%22%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20ipv6_addr_gen_mode%3D%24(nmcli%20--get-values%20ipv6.addr-gen-mode%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20%20%20if%20%5B%20-n%20%22%24ipv6_addr_gen_mode%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20extra_if_brex_args%2B%3D%22ipv6.addr-gen-mode%20%24%7Bipv6_addr_gen_mode%7D%20%22%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20add_nm_conn%20%22%24ovs_interface%22%20type%20ovs-interface%20slave-type%20ovs-port%20conn.interface%20%22%24bridge_name%22%20master%20%22%24ovs_port_conn%22%20%5C%0A%20%20%20%20%20%20%20%20802-3-ethernet.mtu%20%24%7Biface_mtu%7D%20802-3-ethernet.cloned-mac-address%20%24%7Biface_mac%7D%20%5C%0A%20%20%20%20%20%20%20%20ipv4.method%20%22%24%7Bipv4_method%7D%22%20ipv4.route-metric%20%22%24%7Bbridge_metric%7D%22%20%5C%0A%20%20%20%20%20%20%20%20ipv6.method%20%22%24%7Bipv6_method%7D%22%20ipv6.route-metric%20%22%24%7Bbridge_metric%7D%22%20%5C%0A%20%20%20%20%20%20%20%20%24%7Bextra_if_brex_args%7D%0A%20%20%20%20fi%0A%20%20fi%0A%0A%20%20configure_driver_options%20%22%24%7Biface%7D%22%0A%7D%0A%0A%23%20Used%20to%20remove%20a%20bridge%0Aremove_ovn_bridges()%20%7B%0A%20%20bridge_name%3D%24%7B1%7D%0A%20%20port_name%3D%24%7B2%7D%0A%0A%20%20%23%20Remove%20the%20keyfiles%20from%20known%20configuration%20paths%0A%20%20update_nm_conn_run_files%20%24%7Bbridge_name%7D%20%24%7Bport_name%7D%0A%20%20rm_nm_conn_files%0A%20%20update_nm_conn_set_files%20%24%7Bbridge_name%7D%20%24%7Bport_name%7D%0A%20%20rm_nm_conn_files%0A%20%20%23%20Shouldn't%20be%20necessary%2C%20workaround%20for%20https%3A%2F%2Fissues.redhat.com%2Fbrowse%2FOCPBUGS-41489%0A%20%20update_nm_conn_etc_files%20%24%7Bbridge_name%7D%20%24%7Bport_name%7D%0A%20%20rm_nm_conn_files%0A%0A%20%20%23%20NetworkManager%20will%20not%20remove%20%24%7Bbridge_name%7D%20if%20it%20has%20the%20patch%20port%20created%20by%20ovn-kubernetes%0A%20%20%23%20so%20remove%20explicitly%0A%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-br%20%24%7Bbridge_name%7D%0A%7D%0A%0A%23%20Removes%20any%20previous%20ovs%20configuration%0Aremove_all_ovn_bridges()%20%7B%0A%20%20echo%20%22Reverting%20any%20previous%20OVS%20configuration%22%0A%20%20%0A%20%20remove_ovn_bridges%20br-ex%20phys0%0A%20%20remove_ovn_bridges%20br-ex1%20phys1%0A%20%20%0A%20%20echo%20%22OVS%20configuration%20successfully%20reverted%22%0A%7D%0A%0A%23%20Reloads%20NM%20NetworkManager%20profiles%20if%20any%20configuration%20change%20was%20done.%0A%23%20Accepts%20a%20list%20of%20devices%20that%20should%20be%20re-connect%20after%20reload.%0Areload_profiles_nm()%20%7B%0A%20%20if%20%5B%20%24%7Bnm_config_changed%3A-0%7D%20-eq%200%20%5D%3B%20then%0A%20%20%20%20%23%20no%20config%20was%20changed%2C%20no%20need%20to%20reload%0A%20%20%20%20return%0A%20%20fi%0A%0A%20%20%23%20reload%20profiles%0A%20%20nmcli%20connection%20reload%0A%0A%20%20%23%20precautionary%20sleep%20of%2010s%20(default%20timeout%20of%20NM%20to%20bring%20down%20devices)%0A%20%20sleep%2010%0A%0A%20%20%23%20After%20reload%2C%20devices%20that%20were%20already%20connected%20should%20connect%20again%0A%20%20%23%20if%20any%20profile%20is%20available.%20If%20no%20profile%20is%20available%2C%20a%20device%20can%0A%20%20%23%20remain%20disconnected%20and%20we%20have%20to%20explicitly%20connect%20it%20so%20that%20a%0A%20%20%23%20profile%20is%20generated.%20This%20can%20happen%20for%20physical%20devices%20but%20should%0A%20%20%23%20not%20happen%20for%20software%20devices%20as%20those%20always%20require%20a%20profile.%0A%20%20for%20dev%20in%20%24%40%3B%20do%0A%20%20%20%20%23%20Only%20attempt%20to%20connect%20a%20disconnected%20device%0A%20%20%20%20local%20connected_state%3D%24(nmcli%20-g%20GENERAL.STATE%20device%20show%20%22%24dev%22%20%7C%7C%20echo%20%22%22)%0A%20%20%20%20if%20%5B%5B%20%22%24connected_state%22%20%3D~%20%22disconnected%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%23%20keep%20track%20if%20a%20profile%20by%20the%20same%20name%20as%20the%20device%20existed%20%0A%20%20%20%20%20%20%23%20before%20we%20attempt%20activation%0A%20%20%20%20%20%20local%20named_profile_existed%3D%24(%5B%20-f%20%22%24%7BNM_CONN_CONF_PATH%7D%2F%24%7Bdev%7D%22%20%5D%20%7C%7C%20%5B%20-f%20%22%24%7BNM_CONN_CONF_PATH%7D%2F%24%7Bdev%7D.nmconnection%22%20%5D%20%26%26%20echo%20%22yes%22)%0A%20%20%20%20%20%20%0A%20%20%20%20%20%20for%20i%20in%20%7B1..10%7D%3B%20do%0A%20%20%20%20%20%20%20%20%20%20echo%20%22Attempt%20%24i%20to%20connect%20device%20%24dev%22%0A%20%20%20%20%20%20%20%20%20%20nmcli%20device%20connect%20%22%24dev%22%20%26%26%20break%0A%20%20%20%20%20%20%20%20%20%20sleep%205%0A%20%20%20%20%20%20done%0A%0A%20%20%20%20%20%20%23%20if%20a%20profile%20did%20not%20exist%20before%20but%20does%20now%2C%20it%20was%20generated%0A%20%20%20%20%20%20%23%20but%20we%20want%20it%20to%20be%20ephemeral%2C%20so%20move%20it%20back%20to%20%2Frun%0A%20%20%20%20%20%20if%20%5B%20!%20%22%24named_profile_existed%22%20%3D%20%22yes%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20MANAGED_NM_CONN_FILES%3D(%22%24%7BNM_CONN_CONF_PATH%7D%2F%24%7Bdev%7D%22%20%22%24%7BNM_CONN_CONF_PATH%7D%2F%24%7Bdev%7D.nmconnection%22)%0A%20%20%20%20%20%20%20%20copy_nm_conn_files%20%22%24%7BNM_CONN_RUN_PATH%7D%22%0A%20%20%20%20%20%20%20%20rm_nm_conn_files%0A%20%20%20%20%20%20%20%20%23%20reload%20profiles%20so%20that%20NM%20notices%20that%20some%20might%20have%20been%20moved%0A%20%20%20%20%20%20%20%20nmcli%20connection%20reload%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20echo%20%22Waiting%20for%20interface%20%24dev%20to%20activate...%22%0A%20%20%20%20if%20!%20timeout%2060%20bash%20-c%20%22while%20!%20nmcli%20-g%20DEVICE%2CSTATE%20c%20%7C%20grep%20%22'%22'%22%24dev%22%3Aactivated'%22'%22%3B%20do%20sleep%205%3B%20done%22%3B%20then%0A%20%20%20%20%20%20echo%20%22WARNING%3A%20%24dev%20did%20not%20activate%22%0A%20%20%20%20fi%0A%20%20done%0A%0A%20%20nm_config_changed%3D0%0A%7D%0A%0A%23%20Removes%20all%20configuration%20and%20reloads%20NM%20if%20necessary%0Arollback_nm()%20%7B%0A%20%20phys0%3D%24(get_bridge_physical_interface%20ovs-if-phys0)%0A%20%20phys1%3D%24(get_bridge_physical_interface%20ovs-if-phys1)%0A%20%20%0A%20%20%23%20Revert%20changes%20made%20by%20%2Fusr%2Flocal%2Fbin%2Fconfigure-ovs.sh%20during%20SDN%20migration.%0A%20%20remove_all_ovn_bridges%0A%20%20%0A%20%20%23%20reload%20profiles%20so%20that%20NM%20notices%20that%20some%20were%20removed%0A%20%20reload_profiles_nm%20%22%24phys0%22%20%22%24phys1%22%0A%7D%0A%0A%23%20Add%20a%20temporary%20deactivated%20connection%20profile%20%0A%23%20First%20argument%20is%20the%20connection%20name%20folowed%20by%20arguments%20passed%20to%0A%23%20%60nmcli%20connection%20add%60%0Aadd_nm_conn()%20%7B%0A%20%20%23%20Use%20%60save%20no%60%20to%20add%20a%20temporary%20profile%0A%20%20nmcli%20c%20add%20save%20no%20con-name%20%22%24%40%22%20connection.autoconnect%20no%0A%7D%0A%0A%23%20Modify%20a%20temporary%20connection%20profile%20%0A%23%20First%20argument%20is%20the%20connection%20name%20followed%20by%20arguments%20passed%20to%0A%23%20%60nmcli%20connection%20modify%60%0Amod_nm_conn()%20%7B%0A%20%20%23%20the%20easiest%20thing%20to%20do%20here%20would%20be%20to%20use%20%60nmcli%20c%20mod%20--temporary%60%0A%20%20%23%20but%20there%20is%20a%20bug%20in%20selinux%20profiles%20that%20denies%20NM%20from%20performing%0A%20%20%23%20the%20operation%0A%20%20local%20dst_path%3D%24%7BNM_CONN_RUN_PATH%7D%2F%241.nmconnection%0A%20%20local%20src_path%0A%20%20src_path%3D%24(mktemp)%0A%20%20shift%0A%20%20cat%20%22%24dst_path%22%20%3E%20%22%24src_path%22%0A%20%20rm%20-f%20%22%24dst_path%22%0A%20%20nmcli%20--offline%20c%20mod%20%22%24%40%22%20%3C%20%22%24src_path%22%20%3E%20%22%24dst_path%22%0A%20%20rm%20-f%20%22%24src_path%22%0A%20%20chmod%20600%20%22%24dst_path%22%0A%20%20nmcli%20c%20load%20%22%24dst_path%22%0A%7D%0A%0A%23%20Clone%20to%20a%20temporary%20connection%20profile%20%0A%23%20First%20argument%20is%20the%20connection%20to%20clone%2C%20second%20argument%20is%20the%20clone%20name%0Aclone_nm_conn()%20%7B%0A%20%20%23%20clone%20as%20temporary%20so%20that%20it%20is%20generated%20in%20NM_CONN_RUN_PATH%0A%20%20nmcli%20connection%20clone%20--temporary%20%22%241%22%20%22%242%22%20%26%3E%20%2Fdev%2Fnull%0A%7D%0A%0A%23%20Activates%20an%20ordered%20set%20of%20NM%20connection%20profiles%0Aactivate_nm_connections()%20%7B%0A%20%20local%20connections%3D(%22%24%40%22)%0A%0A%20%20%23%20We%20want%20autoconnect%20set%20for%20our%20cloned%20slave%20profiles%20so%20that%20they%20are%0A%20%20%23%20used%20over%20the%20original%20profiles%20if%20implicitly%20re-activated%20with%20other%0A%20%20%23%20dependant%20profiles.%20Otherwise%20if%20a%20slave%20activates%20with%20an%20old%20profile%2C%0A%20%20%23%20the%20old%20master%20profile%20might%20activate%20as%20well%2C%20interfering%20and%20causing%0A%20%20%23%20further%20activations%20to%20fail.%0A%20%20%23%20Slave%20interfaces%20should%20already%20be%20active%20so%20setting%20autoconnect%20here%0A%20%20%23%20won't%20implicitly%20activate%20them%20but%20there%20is%20an%20edge%20case%20where%20a%20slave%0A%20%20%23%20might%20be%20inactive%20(link%20down%20for%20example)%20and%20in%20that%20case%20setting%0A%20%20%23%20autoconnect%20will%20cause%20an%20implicit%20activation.%20This%20is%20not%20necessarily%20a%0A%20%20%23%20problem%20and%20hopefully%20we%20can%20make%20sure%20everything%20is%20activated%20as%20we%0A%20%20%23%20want%20next.%0A%20%20for%20conn%20in%20%22%24%7Bconnections%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20local%20slave_type%3D%24(nmcli%20-g%20connection.slave-type%20connection%20show%20%22%24conn%22)%0A%20%20%20%20if%20%5B%20%22%24slave_type%22%20%3D%20%22team%22%20%5D%20%7C%7C%20%5B%20%22%24slave_type%22%20%3D%20%22bond%22%20%5D%3B%20then%0A%20%20%20%20%20%20mod_nm_conn%20%22%24conn%22%20connection.autoconnect%20yes%0A%20%20%20%20fi%0A%20%20done%0A%0A%20%20%23%20Activate%20all%20connections%20and%20fail%20if%20activation%20fails%0A%20%20%23%20For%20slave%20connections%20-%20for%20as%20long%20as%20at%20least%20one%20slave%20that%20belongs%20to%20a%20bond%2Fteam%0A%20%20%23%20comes%20up%2C%20we%20should%20not%20fail%0A%20%20declare%20-A%20master_interfaces%0A%20%20for%20conn%20in%20%22%24%7Bconnections%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20%23%20Get%20the%20slave%20type%0A%20%20%20%20local%20slave_type%3D%24(nmcli%20-g%20connection.slave-type%20connection%20show%20%22%24conn%22)%0A%20%20%20%20local%20is_slave%3Dfalse%0A%20%20%20%20if%20%5B%20%22%24slave_type%22%20%3D%20%22team%22%20%5D%20%7C%7C%20%5B%20%22%24slave_type%22%20%3D%20%22bond%22%20%5D%3B%20then%0A%20%20%20%20%20%20is_slave%3Dtrue%0A%20%20%20%20fi%20%0A%0A%20%20%20%20%23%20For%20slave%20interfaces%2C%20initialize%20the%20master%20interface%20to%20false%20if%20the%20key%20is%20not%20yet%20in%20the%20array%0A%20%20%20%20local%20master_interface%0A%20%20%20%20if%20%24is_slave%3B%20then%0A%20%20%20%20%20%20master_interface%3D%24(nmcli%20-g%20connection.master%20connection%20show%20%22%24conn%22)%0A%20%20%20%20%20%20if%20!%20%5B%5B%20-v%20%22master_interfaces%5B%24master_interface%5D%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20master_interfaces%5B%22%24master_interface%22%5D%3Dfalse%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20slaves%20should%20implicitly%20activate%2C%20give%20them%20a%20chance%20to%20do%20so%0A%20%20%20%20if%20%24is_slave%3B%20then%0A%20%20%20%20%20%20if%20!%20timeout%205%20bash%20-c%20%22while%20!%20nmcli%20-g%20GENERAL.STATE%20conn%20show%20%22%24conn%22%20%7C%20grep%20activated%3B%20do%20sleep%201%3B%20done%22%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22WARNING%3A%20slave%20%24conn%20did%20not%20implicitly%20activate%20in%205s%2C%20activating%20explicitly.%22%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Do%20not%20activate%20interfaces%20that%20are%20already%20active%0A%20%20%20%20%23%20But%20set%20the%20entry%20in%20master_interfaces%20to%20true%20if%20this%20is%20a%20slave%0A%20%20%20%20%23%20Also%20set%20autoconnect%20to%20yes%0A%20%20%20%20local%20active_state%3D%24(nmcli%20-g%20GENERAL.STATE%20conn%20show%20%22%24conn%22)%0A%20%20%20%20if%20%5B%20%22%24active_state%22%20%3D%3D%20%22activated%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22Connection%20%24conn%20already%20activated%22%0A%20%20%20%20%20%20if%20%24is_slave%3B%20then%0A%20%20%20%20%20%20%20%20master_interfaces%5B%24master_interface%5D%3Dtrue%0A%20%20%20%20%20%20fi%0A%20%20%20%20%20%20mod_nm_conn%20%22%24conn%22%20connection.autoconnect%20yes%0A%20%20%20%20%20%20continue%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Activate%20all%20interfaces%20that%20are%20not%20yet%20active%0A%20%20%20%20for%20i%20in%20%7B1..10%7D%3B%20do%0A%20%20%20%20%20%20echo%20%22Attempt%20%24i%20to%20bring%20up%20connection%20%24conn%22%0A%20%20%20%20%20%20nmcli%20conn%20up%20%22%24conn%22%20%26%26%20s%3D0%20%26%26%20break%20%7C%7C%20s%3D%24%3F%0A%20%20%20%20%20%20sleep%205%0A%20%20%20%20done%0A%20%20%20%20if%20%5B%20%24s%20-eq%200%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22Brought%20up%20connection%20%24conn%20successfully%22%0A%20%20%20%20%20%20if%20%24is_slave%3B%20then%0A%20%20%20%20%20%20%20%20master_interfaces%5B%22%24master_interface%22%5D%3Dtrue%0A%20%20%20%20%20%20fi%0A%20%20%20%20elif%20!%20%24is_slave%3B%20then%0A%20%20%20%20%20%20echo%20%22ERROR%3A%20Cannot%20bring%20up%20connection%20%24conn%20after%20%24i%20attempts%22%0A%20%20%20%20%20%20return%20%24s%0A%20%20%20%20fi%0A%20%20%20%20mod_nm_conn%20%22%24conn%22%20connection.autoconnect%20yes%0A%20%20done%0A%20%20%23%20Check%20that%20all%20master%20interfaces%20report%20at%20least%20a%20single%20active%20slave%0A%20%20%23%20Note%3A%20associative%20arrays%20require%20an%20exclamation%20mark%20when%20looping%0A%20%20for%20i%20in%20%22%24%7B!master_interfaces%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20if%20!%20%24%7Bmaster_interfaces%5B%22%24i%22%5D%7D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22ERROR%3A%20Cannot%20bring%20up%20any%20slave%20interface%20for%20master%20interface%3A%20%24i%22%0A%20%20%20%20%20%20%20%20return%201%0A%20%20%20%20fi%0A%20%20done%0A%7D%0A%0A%23%20Accepts%20parameters%20%24iface_default_hint_file%2C%20%24iface%0A%23%20Writes%20content%20of%20%24iface%20into%20%24iface_default_hint_file%0Awrite_iface_default_hint()%20%7B%0A%20%20local%20iface_default_hint_file%3D%22%241%22%0A%20%20local%20iface%3D%22%242%22%0A%0A%20%20echo%20%22%24%7Biface%7D%22%20%3E%7C%20%22%24%7Biface_default_hint_file%7D%22%0A%7D%0A%0A%23%20Accepts%20parameters%20%24iface_default_hint_file%0A%23%20Returns%20the%20stored%20interface%20default%20hint%20if%20the%20hint%20is%20non-empty%2C%0A%23%20not%20br-ex%2C%20not%20br-ex1%20and%20if%20the%20interface%20can%20be%20found%20in%20%2Fsys%2Fclass%2Fnet%0Aget_iface_default_hint()%20%7B%0A%20%20local%20iface_default_hint_file%3D%241%0A%20%20if%20%5B%20-f%20%22%24%7Biface_default_hint_file%7D%22%20%5D%3B%20then%0A%20%20%20%20local%20iface_default_hint%3D%24(cat%20%22%24%7Biface_default_hint_file%7D%22)%0A%20%20%20%20if%20%5B%20%22%24%7Biface_default_hint%7D%22%20!%3D%20%22%22%20%5D%20%26%26%0A%20%20%20%20%20%20%20%20%5B%20%22%24%7Biface_default_hint%7D%22%20!%3D%20%22br-ex%22%20%5D%20%26%26%0A%20%20%20%20%20%20%20%20%5B%20%22%24%7Biface_default_hint%7D%22%20!%3D%20%22br-ex1%22%20%5D%20%26%26%0A%20%20%20%20%20%20%20%20%5B%20-d%20%22%2Fsys%2Fclass%2Fnet%2F%24%7Biface_default_hint%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22%24%7Biface_default_hint%7D%22%0A%20%20%20%20%20%20%20%20return%0A%20%20%20%20fi%0A%20%20fi%0A%20%20echo%20%22%22%0A%7D%0A%0Aget_ip_from_ip_hint_file()%20%7B%0A%20%20local%20ip_hint_file%3D%22%241%22%0A%20%20if%20%5B%5B%20!%20-f%20%22%24%7Bip_hint_file%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20return%0A%20%20fi%0A%20%20ip_hint%3D%24(cat%20%22%24%7Bip_hint_file%7D%22)%0A%20%20echo%20%22%24%7Bip_hint%7D%22%0A%7D%0A%0A%23%20This%20function%20waits%20for%20ip%20address%20of%20br-ex%20to%20be%20bindable%20only%20in%20case%20of%20ipv6%0A%23%20This%20is%20workaround%20for%20OCPBUGS-673%20as%20it%20will%20not%20allow%20starting%20crio%0A%23%20before%20address%20is%20bindable%0Atry_to_bind_ipv6_address()%20%7B%0A%20%20%23%20Retry%20for%201%20minute%0A%20%20retries%3D60%0A%20%20until%20%5B%5B%20%24%7Bretries%7D%20-eq%200%20%5D%5D%3B%20do%0A%20%20%20%20ip%3D%24(ip%20-6%20-j%20addr%20%7C%20jq%20-r%20%22first(.%5B%5D%20%7C%20select(.ifname%3D%3D%5C%22br-ex%5C%22)%20%7C%20.addr_info%5B%5D%20%7C%20select(.scope%3D%3D%5C%22global%5C%22)%20%7C%20.local)%22)%0A%20%20%20%20if%20%5B%5B%20%22%24%7Bip%7D%22%20%3D%3D%20%22%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22No%20ipv6%20ip%20to%20bind%20was%20found%22%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20%20%20random_port%3D%24(shuf%20-i%2050000-60000%20-n%201)%0A%20%20%20%20echo%20%22Trying%20to%20bind%20%24%7Bip%7D%20on%20port%20%24%7Brandom_port%7D%22%0A%20%20%20%20exit_code%3D%24(timeout%202s%20nc%20-l%20%22%24%7Bip%7D%22%20%24%7Brandom_port%7D%3B%20echo%20%24%3F)%0A%20%20%20%20if%20%5B%5B%20exit_code%20-eq%20124%20%5D%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22Address%20bound%20successfully%22%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20%20%20sleep%201%0A%20%20%20%20((%20retries--%20))%0A%20%20done%0A%20%20if%20%5B%5B%20%24%7Bretries%7D%20-eq%200%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22Failed%20to%20bind%20ip%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%7D%0A%0A%23%20Get%20interface%20that%20matches%20ip%20from%20node%20ip%20hint%20file%0A%23%20in%20case%20file%20not%20exists%20return%20nothing%20and%0A%23%20fallback%20to%20default%20interface%20search%20flow%0Aget_nodeip_hint_interface()%20%7B%0A%20%20local%20ip_hint%3D%22%22%0A%20%20local%20ip_hint_file%3D%22%241%22%0A%20%20local%20extra_bridge%3D%22%242%22%0A%20%20local%20iface%3D%22%22%0A%0A%20%20ip_hint%3D%24(get_ip_from_ip_hint_file%20%22%24%7Bip_hint_file%7D%22)%0A%20%20if%20%5B%5B%20-z%20%22%24%7Bip_hint%7D%22%20%20%5D%5D%3B%20then%0A%20%20%20%20return%0A%20%20fi%0A%0A%20%20iface%3D%24(ip%20-j%20addr%20%7C%20jq%20-r%20%22first(.%5B%5D%20%7C%20select(any(.addr_info%5B%5D%3B%20.local%3D%3D%5C%22%24%7Bip_hint%7D%5C%22)%20and%20.ifname!%3D%5C%22br-ex1%5C%22%20and%20.ifname!%3D%5C%22%24%7Bextra_bridge%7D%5C%22))%20%7C%20.ifname%22)%0A%20%20if%20%5B%5B%20-n%20%22%24%7Biface%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22%24%7Biface%7D%22%0A%20%20fi%0A%7D%0A%0A%23%20Accepts%20parameters%20%24bridge_interface%20(e.g.%20ovs-port-phys0)%0A%23%20Returns%20the%20physical%20interface%20name%20if%20%24bridge_interface%20exists%2C%20%22%22%20otherwise%0Aget_bridge_physical_interface()%20%7B%0A%20%20local%20bridge_interface%3D%22%241%22%0A%20%20local%20physical_interface%3D%22%22%0A%20%20physical_interface%3D%24(nmcli%20-g%20connection.interface-name%20conn%20show%20%22%24%7Bbridge_interface%7D%22%202%3E%2Fdev%2Fnull%20%7C%7C%20echo%20%22%22)%0A%20%20echo%20%22%24%7Bphysical_interface%7D%22%0A%7D%0A%0A%23%20Accepts%20parameters%20%24iface_default_hint_file%2C%20%24extra_bridge_file%2C%20%24ip_hint_file%2C%20%24default_bridge_file%0A%23%20Determines%20the%20interface%20to%20be%20used%20for%20br-ex.%20Order%20of%20priority%20is%3A%0A%23%201.%20Use%20the%20user%20specified%20interface%20if%20provided%20in%20the%20default%20bridge%20file%0A%23%202.%20Use%20the%20node%20IP%20hint%20interface%0A%23%203.%20Use%20the%20previously%20selected%20interface%0A%23%204.%20Use%20the%20interface%20detected%20as%20default%20gateway%0A%23%0A%23%20Read%20%24default_bridge_file%20and%20return%20the%20contained%20interface.%20Otherwise%2C%0A%23%20read%20%24ip_hint_file%20and%20return%20the%20interface%20that%20matches%20this%20ip.%20Otherwise%2C%0A%23%20if%20the%20default%20interface%20is%20br-ex%2C%20use%20that%20and%20return.%0A%23%20If%20the%20default%20interface%20is%20not%20br-ex%3A%0A%23%20Check%20if%20there%20is%20a%20valid%20hint%20inside%20%24iface_default_hint_file.%20If%20so%2C%20use%20that%20hint.%0A%23%20If%20there%20is%20no%20valid%20hint%2C%20use%20the%20default%20interface%20that%20we%20found%20during%20the%20step%0A%23%20earlier.%0A%23%20Never%20use%20the%20interface%20that%20is%20provided%20inside%20%24extra_bridge_file%20for%20br-ex1.%0A%23%20Never%20use%20br-ex1.%0A%23%20Write%20the%20default%20interface%20to%20%24iface_default_hint_file%0Aget_default_bridge_interface()%20%7B%0A%20%20local%20iface%3D%22%22%0A%20%20local%20counter%3D0%0A%20%20local%20iface_default_hint_file%3D%22%241%22%0A%20%20local%20extra_bridge_file%3D%22%242%22%0A%20%20local%20ip_hint_file%3D%22%243%22%0A%20%20local%20default_bridge_file%3D%22%244%22%0A%20%20local%20extra_bridge%3D%22%22%0A%0A%20%20if%20%5B%20-f%20%22%24%7Bextra_bridge_file%7D%22%20%5D%3B%20then%0A%20%20%20%20extra_bridge%3D%24(cat%20%24%7Bextra_bridge_file%7D)%0A%20%20fi%0A%0A%20%20%23%20try%20to%20use%20user%20specified%20file%20first%0A%20%20if%20%5B%20-f%20%22%24default_bridge_file%22%20%5D%3B%20then%0A%20%20%20%20iface%3D%24(cat%20%22%24%7Bdefault_bridge_file%7D%22)%0A%20%20%20%20if%20%5B%20-z%20%22%24iface%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22ERROR%3A%20User%20specified%20bridge%20file%20detected%20without%20any%20data%22%0A%20%20%20%20%20%20exit%201%0A%20%20%20%20fi%0A%20%20%20%20echo%20%22%24%7Biface%7D%22%0A%20%20%20%20return%0A%20%20fi%0A%0A%20%20%23%20if%20node%20ip%20was%20set%2C%20we%20should%20search%20for%20interface%20that%20matches%20it%0A%20%20iface%3D%24(get_nodeip_hint_interface%20%22%24%7Bip_hint_file%7D%22%20%22%24%7Bextra_bridge%7D%22)%0A%20%20if%20%5B%5B%20-n%20%22%24%7Biface%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22%24%7Biface%7D%22%0A%20%20%20%20return%0A%20%20fi%0A%0A%20%20%23%20find%20default%20interface%0A%20%20%23%20the%20default%20interface%20might%20be%20br-ex%2C%20so%20check%20this%20before%20looking%20at%20the%20hint%0A%20%20while%20%5B%20%24%7Bcounter%7D%20-lt%2012%20%5D%3B%20do%0A%20%20%20%20%23%20check%20ipv4%0A%20%20%20%20%23%20never%20use%20the%20interface%20that's%20specified%20in%20extra_bridge_file%0A%20%20%20%20%23%20never%20use%20br-ex1%0A%20%20%20%20if%20%5B%20%22%24%7Bextra_bridge%7D%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20iface%3D%24(ip%20route%20show%20default%20%7C%20grep%20-v%20%22br-ex1%22%20%7C%20grep%20-v%20%22%24%7Bextra_bridge%7D%22%20%7C%20awk%20'%7B%20if%20(%244%20%3D%3D%20%22dev%22)%20%7B%20print%20%245%3B%20exit%20%7D%20%7D')%0A%20%20%20%20else%0A%20%20%20%20%20%20iface%3D%24(ip%20route%20show%20default%20%7C%20grep%20-v%20%22br-ex1%22%20%7C%20awk%20'%7B%20if%20(%244%20%3D%3D%20%22dev%22)%20%7B%20print%20%245%3B%20exit%20%7D%20%7D')%0A%20%20%20%20fi%0A%20%20%20%20if%20%5B%5B%20-n%20%22%24%7Biface%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20%20%20%23%20check%20ipv6%0A%20%20%20%20%23%20never%20use%20the%20interface%20that's%20specified%20in%20extra_bridge_file%0A%20%20%20%20%23%20never%20use%20br-ex1%0A%20%20%20%20if%20%5B%20%22%24%7Bextra_bridge%7D%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20iface%3D%24(ip%20-6%20route%20show%20default%20%7C%20grep%20-v%20%22br-ex1%22%20%7C%20grep%20-v%20%22%24%7Bextra_bridge%7D%22%20%7C%20awk%20'%7B%20if%20(%244%20%3D%3D%20%22dev%22)%20%7B%20print%20%245%3B%20exit%20%7D%20%7D')%0A%20%20%20%20else%0A%20%20%20%20%20%20iface%3D%24(ip%20-6%20route%20show%20default%20%7C%20grep%20-v%20%22br-ex1%22%20%7C%20awk%20'%7B%20if%20(%244%20%3D%3D%20%22dev%22)%20%7B%20print%20%245%3B%20exit%20%7D%20%7D')%0A%20%20%20%20fi%0A%20%20%20%20if%20%5B%5B%20-n%20%22%24%7Biface%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20%20%20counter%3D%24((counter%2B1))%0A%20%20%20%20sleep%205%0A%20%20done%0A%0A%20%20%23%20if%20the%20default%20interface%20does%20not%20point%20out%20of%20br-ex%20or%20br-ex1%0A%20%20if%20%5B%20%22%24%7Biface%7D%22%20!%3D%20%22br-ex%22%20%5D%20%26%26%20%5B%20%22%24%7Biface%7D%22%20!%3D%20%22br-ex1%22%20%5D%3B%20then%0A%20%20%20%20%23%20determine%20if%20an%20interface%20default%20hint%20exists%20from%20a%20previous%20run%0A%20%20%20%20%23%20and%20if%20the%20interface%20has%20a%20valid%20default%20route%0A%20%20%20%20iface_default_hint%3D%24(get_iface_default_hint%20%22%24%7Biface_default_hint_file%7D%22)%0A%20%20%20%20if%20%5B%20%22%24%7Biface_default_hint%7D%22%20!%3D%20%22%22%20%5D%20%26%26%0A%20%20%20%20%20%20%20%20%5B%20%22%24%7Biface_default_hint%7D%22%20!%3D%20%22%24%7Biface%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%23%20start%20wherever%20count%20left%20off%20in%20the%20previous%20loop%0A%20%20%20%20%20%20%23%20allow%20this%20for%20one%20more%20iteration%20than%20the%20previous%20loop%0A%20%20%20%20%20%20while%20%5B%20%24%7Bcounter%7D%20-le%2012%20%5D%3B%20do%0A%20%20%20%20%20%20%20%20%23%20check%20ipv4%0A%20%20%20%20%20%20%20%20if%20%5B%20%22%24(ip%20route%20show%20default%20dev%20%22%24%7Biface_default_hint%7D%22)%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20iface%3D%22%24%7Biface_default_hint%7D%22%0A%20%20%20%20%20%20%20%20%20%20break%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20%23%20check%20ipv6%0A%20%20%20%20%20%20%20%20if%20%5B%20%22%24(ip%20-6%20route%20show%20default%20dev%20%22%24%7Biface_default_hint%7D%22)%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20iface%3D%22%24%7Biface_default_hint%7D%22%0A%20%20%20%20%20%20%20%20%20%20break%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20counter%3D%24((counter%2B1))%0A%20%20%20%20%20%20%20%20sleep%205%0A%20%20%20%20%20%20done%0A%20%20%20%20fi%0A%20%20%20%20%23%20store%20what%20was%20determined%20was%20the%20(new)%20default%20interface%20inside%0A%20%20%20%20%23%20the%20default%20hint%20file%20for%20future%20reference%0A%20%20%20%20if%20%5B%20%22%24%7Biface%7D%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20write_iface_default_hint%20%22%24%7Biface_default_hint_file%7D%22%20%22%24%7Biface%7D%22%0A%20%20%20%20fi%0A%20%20fi%0A%20%20echo%20%22%24%7Biface%7D%22%0A%7D%0A%0A%23%20Used%20to%20print%20network%20state%0Aprint_state()%20%7B%0A%20%20echo%20%22Current%20device%2C%20connection%2C%20interface%20and%20routing%20state%3A%22%0A%20%20nmcli%20-g%20all%20device%20%7C%20grep%20-v%20unmanaged%0A%20%20nmcli%20-g%20all%20connection%0A%20%20ip%20-d%20address%20show%0A%20%20ip%20route%20show%0A%20%20ip%20-6%20route%20show%0A%7D%0A%0A%23%20Setup%20an%20exit%20trap%20to%20rollback%20on%20error%0Ahandle_exit()%20%7B%0A%20%20e%3D%24%3F%0A%20%20tdir%3D%24(mktemp%20-u%20-d%20-t%20%22configure-ovs-%24(date%20%2B%25Y-%25m-%25d-%25H-%25M-%25S)-XXXXXXXXXX%22)%0A%20%20%0A%20%20if%20%5B%20%24e%20-eq%200%20%5D%3B%20then%0A%20%20%20%20print_state%0A%20%20%20%20%23%20remove%20previous%20troubleshooting%20information%0A%20%20%20%20rm%20-rf%20%22%24(dirname%20%22%24tdir%22)%2Fconfigure-ovs-*%22%0A%20%20%20%20exit%200%0A%20%20fi%0A%0A%20%20echo%20%22ERROR%3A%20configure-ovs%20exited%20with%20error%3A%20%24e%22%0A%20%20print_state%0A%0A%20%20%23%20remove%20previous%20troubleshooting%20information%20except%20the%20oldest%20one%0A%20%20mapfile%20-t%20tdirs%20%3C%20%3C(compgen%20-G%20%22%24(dirname%20%22%24tdir%22)%2Fconfigure-ovs-*%22)%0A%20%20unset%20-v%20%22tdirs%5B0%5D%22%0A%20%20for%20dir%20in%20%22%24%7Btdirs%5B%40%5D%7D%22%3B%20do%20rm%20-rf%20%22%24dir%22%3B%20done%0A%0A%20%20%23%20copy%20configuration%20to%20tmp%20for%20troubleshooting%0A%20%20mkdir%20-p%20%22%24tdir%22%0A%20%20update_nm_conn_run_files%20br-ex%20phys0%0A%20%20copy_nm_conn_files%20%22%24tdir%22%0A%20%20update_nm_conn_run_files%20br-ex1%20phys1%0A%20%20copy_nm_conn_files%20%22%24tdir%22%0A%20%20echo%20%22Copied%20OVS%20configuration%20to%20%24tdir%20for%20troubleshooting%22%0A%0A%20%20%23%20attempt%20to%20restore%20the%20previous%20network%20state%0A%20%20echo%20%22Attempting%20to%20restore%20previous%20configuration...%22%0A%20%20rollback_nm%0A%20%20print_state%0A%0A%20%20exit%20%24e%0A%7D%0A%0A%23%20Setup%20a%20signal%20trap%20to%20rollback%0Ahandle_termination()%20%7B%0A%20%20echo%20%22WARNING%3A%20configure-ovs%20has%20been%20requested%20to%20terminate%2C%20quitting...%22%0A%20%20%0A%20%20%23%20by%20exiting%20with%20an%20error%20we%20will%20cleanup%20after%20ourselves%20in%20a%0A%20%20%23%20subsequent%20call%20to%20handle_exit%0A%20%20exit%201%0A%7D%0A%0A%23%20main%20function%0Aconfigure_ovs()%20%7B%0A%20%20set%20-eu%0A%0A%20%20%23%20setup%20traps%20to%20handle%20signals%20and%20other%20abnormal%20exits%0A%20%20trap%20'handle_termination'%20TERM%20INT%0A%20%20trap%20'handle_exit'%20EXIT%0A%0A%20%20%23%20this%20flag%20tracks%20if%20any%20config%20change%20was%20made%0A%20%20nm_config_changed%3D0%0A%0A%20%20%23%20Check%20that%20we%20are%20provided%20a%20valid%20NM%20connection%20path%0A%20%20if%20%5B%20%22%24NM_CONN_SET_PATH%22%20!%3D%20%22%24NM_CONN_CONF_PATH%22%20%5D%20%26%26%20%5B%20%22%24NM_CONN_SET_PATH%22%20!%3D%20%22%24NM_CONN_RUN_PATH%22%20%5D%3B%20then%0A%20%20%20%20echo%20%22Error%3A%20Incorrect%20NM%20connection%20path%3A%20%24NM_CONN_SET_PATH%20is%20not%20%24NM_CONN_CONF_PATH%20nor%20%24NM_CONN_RUN_PATH%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%0A%20%20%23%20Clean%20up%20old%20config%20on%20behalf%20of%20mtu-migration%0A%20%20if%20!%20systemctl%20-q%20is-enabled%20mtu-migration%3B%20then%0A%20%20%20%20echo%20%22Cleaning%20up%20left%20over%20mtu%20migration%20configuration%22%0A%20%20%20%20rm%20-rf%20%2Fetc%2Fcno%2Fmtu-migration%0A%20%20fi%0A%0A%20%20if%20!%20rpm%20-qa%20%7C%20grep%20-q%20openvswitch%3B%20then%0A%20%20%20%20echo%20%22WARNING%3A%20Openvswitch%20package%20is%20not%20installed!%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%0A%20%20%23%20print%20initial%20state%0A%20%20print_state%0A%0A%20%20if%20%5B%20%22%241%22%20%3D%3D%20%22OVNKubernetes%22%20%5D%3B%20then%0A%20%20%20%20%23%20Configures%20NICs%20onto%20OVS%20bridge%20%22br-ex%22%0A%20%20%20%20%23%20Configuration%20is%20either%20auto-detected%20or%20provided%20through%20a%20config%20file%20written%20already%20in%20Network%20Manager%0A%20%20%20%20%23%20key%20files%20under%20%2Fetc%2FNetworkManager%2Fsystem-connections%2F%0A%20%20%20%20%23%20Managing%20key%20files%20is%20outside%20of%20the%20scope%20of%20this%20script%0A%0A%20%20%20%20%23%20if%20the%20interface%20is%20of%20type%20vmxnet3%20add%20multicast%20capability%20for%20that%20driver%0A%20%20%20%20%23%20History%3A%20BZ%3A1854355%0A%20%20%20%20function%20configure_driver_options%20%7B%0A%20%20%20%20%20%20intf%3D%241%0A%20%20%20%20%20%20if%20%5B%20!%20-f%20%22%2Fsys%2Fclass%2Fnet%2F%24%7Bintf%7D%2Fdevice%2Fuevent%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22Device%20file%20doesn't%20exist%2C%20skipping%20setting%20multicast%20mode%22%0A%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20driver%3D%24(cat%20%22%2Fsys%2Fclass%2Fnet%2F%24%7Bintf%7D%2Fdevice%2Fuevent%22%20%7C%20grep%20DRIVER%20%7C%20awk%20-F%20%22%3D%22%20'%7Bprint%20%242%7D')%0A%20%20%20%20%20%20%20%20echo%20%22Driver%20name%20is%22%20%24driver%0A%20%20%20%20%20%20%20%20if%20%5B%20%22%24driver%22%20%3D%20%22vmxnet3%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20ip%20link%20set%20dev%20%22%24%7Bintf%7D%22%20allmulticast%20on%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20fi%0A%20%20%20%20%7D%0A%0A%20%20%20%20ovnk_config_dir%3D'%2Fetc%2Fovnk'%0A%20%20%20%20ovnk_var_dir%3D'%2Fvar%2Flib%2Fovnk'%0A%20%20%20%20extra_bridge_file%3D%22%24%7Bovnk_config_dir%7D%2Fextra_bridge%22%0A%20%20%20%20iface_default_hint_file%3D%22%24%7Bovnk_var_dir%7D%2Fiface_default_hint%22%0A%20%20%20%20ip_hint_file%3D%22%2Frun%2Fnodeip-configuration%2Fprimary-ip%22%0A%20%20%20%20%23%20explicitly%20specify%20which%20interface%20should%20be%20used%20with%20the%20default%20bridge%0A%20%20%20%20default_bridge_file%3D%22%24%7Bovnk_config_dir%7D%2Fdefault_bridge%22%0A%0A%20%20%20%20%23%20make%20sure%20to%20create%20ovnk_config_dir%20if%20it%20does%20not%20exist%2C%20yet%0A%20%20%20%20mkdir%20-p%20%22%24%7Bovnk_config_dir%7D%22%0A%20%20%20%20%23%20make%20sure%20to%20create%20ovnk_var_dir%20if%20it%20does%20not%20exist%2C%20yet%0A%20%20%20%20mkdir%20-p%20%22%24%7Bovnk_var_dir%7D%22%0A%0A%20%20%20%20%23%20For%20upgrade%20scenarios%2C%20make%20sure%20that%20we%20stabilize%20what%20we%20already%20configured%0A%20%20%20%20%23%20before.%20If%20we%20do%20not%20have%20a%20valid%20interface%20hint%2C%20find%20the%20physical%20interface%0A%20%20%20%20%23%20that's%20attached%20to%20ovs-if-phys0.%0A%20%20%20%20%23%20If%20we%20find%20such%20an%20interface%2C%20write%20it%20to%20the%20hint%20file.%0A%20%20%20%20iface_default_hint%3D%24(get_iface_default_hint%20%22%24%7Biface_default_hint_file%7D%22)%0A%20%20%20%20if%20%5B%20%22%24%7Biface_default_hint%7D%22%20%3D%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20current_interface%3D%24(get_bridge_physical_interface%20ovs-if-phys0)%0A%20%20%20%20%20%20if%20%5B%20%22%24%7Bcurrent_interface%7D%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20write_iface_default_hint%20%22%24%7Biface_default_hint_file%7D%22%20%22%24%7Bcurrent_interface%7D%22%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20delete%20iface_default_hint_file%20if%20it%20has%20the%20same%20content%20as%20extra_bridge_file%0A%20%20%20%20%23%20in%20that%20case%2C%20we%20must%20also%20force%20a%20reconfiguration%20of%20our%20network%20interfaces%0A%20%20%20%20%23%20to%20make%20sure%20that%20we%20reconcile%20this%20conflict%0A%20%20%20%20if%20%5B%20-f%20%22%24%7Biface_default_hint_file%7D%22%20%5D%20%26%26%0A%20%20%20%20%20%20%5B%20-f%20%22%24%7Bextra_bridge_file%7D%22%20%5D%20%26%26%0A%20%20%20%20%20%20%5B%20%22%24(cat%20%22%24%7Biface_default_hint_file%7D%22)%22%20%3D%3D%20%22%24(cat%20%22%24%7Bextra_bridge_file%7D%22)%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22%24%7Biface_default_hint_file%7D%20and%20%24%7Bextra_bridge_file%7D%20share%20the%20same%20content%22%0A%20%20%20%20%20%20echo%20%22Deleting%20file%20%24%7Biface_default_hint_file%7D%20to%20choose%20a%20different%20interface%22%0A%20%20%20%20%20%20rm%20-f%20%22%24%7Biface_default_hint_file%7D%22%0A%20%20%20%20%20%20rm%20-f%20%2Frun%2Fconfigure-ovs-boot-done%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20on%20every%20boot%20we%20rollback%20and%20generate%20the%20configuration%20again%2C%20to%20take%0A%20%20%20%20%23%20in%20any%20changes%20that%20have%20possibly%20been%20applied%20in%20the%20standard%0A%20%20%20%20%23%20configuration%20sources%0A%20%20%20%20if%20%5B%20!%20-f%20%2Frun%2Fconfigure-ovs-boot-done%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22Running%20on%20boot%2C%20restoring%20previous%20configuration%20before%20proceeding...%22%0A%20%20%20%20%20%20rollback_nm%0A%20%20%20%20%20%20print_state%0A%20%20%20%20fi%0A%20%20%20%20touch%20%2Frun%2Fconfigure-ovs-boot-done%0A%0A%20%20%20%20iface%3D%24(get_default_bridge_interface%20%22%24%7Biface_default_hint_file%7D%22%20%22%24%7Bextra_bridge_file%7D%22%20%22%24%7Bip_hint_file%7D%22%20%22%24%7Bdefault_bridge_file%7D%22)%0A%0A%20%20%20%20if%20%5B%20%22%24iface%22%20!%3D%20%22br-ex%22%20%5D%3B%20then%0A%20%20%20%20%20%20%23%20Specified%20interface%20is%20not%20br-ex.%0A%20%20%20%20%20%20%23%20Some%20deployments%20use%20a%20temporary%20solution%20where%20br-ex%20is%20moved%20out%20from%20the%20default%20gateway%20interface%0A%20%20%20%20%20%20%23%20and%20bound%20to%20a%20different%20nic%20(https%3A%2F%2Fgithub.com%2Ftrozet%2Fopenshift-ovn-migration).%0A%20%20%20%20%20%20%23%20This%20is%20now%20supported%20through%20an%20extra%20bridge%20if%20requested.%20If%20that%20is%20the%20case%2C%20we%20rollback.%0A%20%20%20%20%20%20%23%20We%20also%20rollback%20if%20it%20looks%20like%20we%20need%20to%20configure%20things%2C%20just%20in%20case%20there%20are%20any%20leftovers%0A%20%20%20%20%20%20%23%20from%20previous%20attempts.%0A%20%20%20%20%20%20if%20%5B%20-f%20%22%24extra_bridge_file%22%20%5D%20%7C%7C%20%5B%20-z%20%22%24(nmcli%20connection%20show%20--active%20br-ex%202%3E%20%2Fdev%2Fnull)%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22Bridge%20br-ex%20is%20not%20active%2C%20restoring%20previous%20configuration%20before%20proceeding...%22%0A%20%20%20%20%20%20%20%20rollback_nm%0A%20%20%20%20%20%20%20%20print_state%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20convert_to_bridge%20%22%24iface%22%20%22br-ex%22%20%22phys0%22%20%22%24%7BBRIDGE_METRIC%7D%22%0A%0A%20%20%20%20%23%20Check%20if%20we%20need%20to%20configure%20the%20second%20bridge%0A%20%20%20%20if%20%5B%20-f%20%22%24extra_bridge_file%22%20%5D%20%26%26%20(!%20nmcli%20connection%20show%20br-ex1%20%26%3E%20%2Fdev%2Fnull%20%7C%7C%20!%20nmcli%20connection%20show%20ovs-if-phys1%20%26%3E%20%2Fdev%2Fnull)%3B%20then%0A%20%20%20%20%20%20interface%3D%24(head%20-n%201%20%24extra_bridge_file)%0A%20%20%20%20%20%20convert_to_bridge%20%22%24interface%22%20%22br-ex1%22%20%22phys1%22%20%22%24%7BBRIDGE1_METRIC%7D%22%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Check%20if%20we%20need%20to%20remove%20the%20second%20bridge%0A%20%20%20%20if%20%5B%20!%20-f%20%22%24extra_bridge_file%22%20%5D%20%26%26%20(nmcli%20connection%20show%20br-ex1%20%26%3E%20%2Fdev%2Fnull%20%7C%7C%20nmcli%20connection%20show%20ovs-if-phys1%20%26%3E%20%2Fdev%2Fnull)%3B%20then%0A%20%20%20%20%20%20remove_ovn_bridges%20br-ex1%20phys1%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Remove%20bridges%20created%20by%20openshift-sdn%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-br%20br0%0A%0A%20%20%20%20%23%20Make%20sure%20everything%20is%20activated.%20Do%20it%20in%20a%20specific%20order%3A%0A%20%20%20%20%23%20-%20activate%20br-ex%20first%2C%20due%20to%20autoconnect-slaves%20this%20will%20also%0A%20%20%20%20%23%20%20%20activate%20ovs-port-br-ex%2C%20ovs-port-phys0%20and%20ovs-if-phys0.%20It%20is%0A%20%20%20%20%23%20%20%20important%20that%20ovs-if-phys0%20activates%20with%20br-ex%20to%20avoid%20the%0A%20%20%20%20%23%20%20%20ovs-if-phys0%20profile%20being%20overridden%20with%20a%20profile%20generated%20from%0A%20%20%20%20%23%20%20%20kargs.%20The%20activation%20of%20ovs-if-phys0%2C%20if%20a%20bond%2C%20might%20cause%20the%0A%20%20%20%20%23%20%20%20slaves%20to%20re-activate%2C%20but%20it%20should%20be%20with%20our%20profiles%20since%20they%0A%20%20%20%20%23%20%20%20have%20higher%20priority%0A%20%20%20%20%23%20-%20make%20sure%20that%20ovs-if-phys0%20and%20its%20slaves%2C%20if%20any%2C%20are%20activated.%0A%20%20%20%20%23%20-%20finally%20activate%20ovs-if-br-ex%20which%20holds%20the%20IP%20configuration.%0A%20%20%20%20connections%3D(br-ex%20ovs-if-phys0)%0A%20%20%20%20if%20%5B%20-f%20%22%24extra_bridge_file%22%20%5D%3B%20then%0A%20%20%20%20%20%20connections%2B%3D(br-ex1%20ovs-if-phys1)%0A%20%20%20%20fi%0A%20%20%20%20while%20IFS%3D%20read%20-r%20connection%3B%20do%0A%20%20%20%20%20%20if%20%5B%5B%20%24connection%20%3D%3D%20*%22%24MANAGED_NM_CONN_SUFFIX%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20connections%2B%3D(%22%24connection%22)%0A%20%20%20%20%20%20fi%0A%20%20%20%20done%20%3C%20%3C(nmcli%20-g%20NAME%20c)%0A%20%20%20%20connections%2B%3D(ovs-if-br-ex)%0A%20%20%20%20if%20%5B%20-f%20%22%24extra_bridge_file%22%20%5D%3B%20then%0A%20%20%20%20%20%20connections%2B%3D(ovs-if-br-ex1)%0A%20%20%20%20fi%0A%20%20%20%20activate_nm_connections%20%22%24%7Bconnections%5B%40%5D%7D%22%0A%20%20%20%20try_to_bind_ipv6_address%0A%20%20%20%20set_nm_conn_files%0A%20%20elif%20%5B%20%22%241%22%20%3D%3D%20%22OpenShiftSDN%22%20%5D%3B%20then%0A%20%20%20%20%23%20Revert%20changes%20made%20by%20%2Fusr%2Flocal%2Fbin%2Fconfigure-ovs.sh%20during%20SDN%20migration.%0A%20%20%20%20rollback_nm%0A%20%20%20%20%0A%20%20%20%20%23%20Remove%20bridges%20created%20by%20ovn-kubernetes%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-br%20br-int%20--%20--if-exists%20del-br%20br-local%0A%20%20fi%0A%7D%0A%0A%23%20Retry%20configure_ovs%20until%20it%20succeeds.%0A%23%20By%20default%2C%20retry%20every%2015%20minutes%20to%20give%20enough%20time%20to%20gather%0A%23%20troubleshooting%20information%20in%20between.%20Note%20that%20configure_ovs%20has%20other%0A%23%20internal%20retry%20mechanisms.%20This%20retry%20is%20intended%20to%20give%20some%0A%23%20self-healing%20capabilities%20to%20temporary%20but%20not%20necessarily%20short-lived%0A%23%20infrastructure%20problems.%0ARETRY%3D%22%24%7BRETRY-15m%7D%22%0Awhile%20true%3B%20do%0A%0A%20%20%23%20Disable%20retries%20if%20termination%20signal%20is%20received.%20Note%20that%20systemd%0A%20%20%23%20sends%20the%20signals%20to%20all%20processes%20in%20the%20group%20by%20default%20so%20we%20expect%0A%20%20%23%20configure_ovs%20to%20get%20its%20own%20signals.%0A%20%20trap%20'echo%20%22WARNING%3A%20termination%20requested%2C%20disabling%20retries%22%3B%20RETRY%3D%22%22'%20INT%20TERM%0A%20%20%0A%20%20%23%20Run%20configure_ovs%20in%20a%20sub-shell.%20%0A%20%20(%20configure_ovs%20%22%24%40%22%20)%0A%20%20e%3D%24%3F%0A%0A%20%20%23%20Handle%20signals%20while%20we%20sleep%0A%20%20trap%20'handle_termination'%20INT%20TERM%0A%20%20%0A%20%20%23%20Exit%20if%20succesful%20and%20not%20configured%20to%20retry%0A%20%20%5B%20%22%24e%22%20-eq%200%20%5D%20%7C%7C%20%5B%20-z%20%22%24RETRY%22%20%5D%20%26%26%20exit%20%22%24e%22%0A%20%20%0A%20%20echo%20%22configure-ovs%20failed%2C%20will%20retry%20after%20%24RETRY%22%0A%20%20%23%20flag%20that%20a%20retry%20has%20happened%0A%20%20touch%20%2Ftmp%2Fconfigure-ovs-retry%0A%20%20sleep%20%22%24RETRY%22%0A%0Adone%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/configure-ovs.sh
        - contents:
            source: data:,%23%20This%20file%20is%20generated%20by%20the%20Machine%20Config%20Operator's%20containerruntimeconfig%20controller.%0A%23%0A%23%20storage.conf%20is%20the%20configuration%20file%20for%20all%20tools%0A%23%20that%20share%20the%20containers%2Fstorage%20libraries%0A%23%20See%20man%205%20containers-storage.conf%20for%20more%20information%0A%23%20The%20%22container%20storage%22%20table%20contains%20all%20of%20the%20server%20options.%0A%5Bstorage%5D%0A%0A%23%20Default%20storage%20driver%2C%20must%20be%20set%20for%20proper%20operation.%0Adriver%20%3D%20%22overlay%22%0A%0A%23%20Temporary%20storage%20location%0Arunroot%20%3D%20%22%2Frun%2Fcontainers%2Fstorage%22%0A%0A%23%20Primary%20Read%2FWrite%20location%20of%20container%20storage%0Agraphroot%20%3D%20%22%2Fvar%2Flib%2Fcontainers%2Fstorage%22%0A%0A%5Bstorage.options%5D%0A%23%20Storage%20options%20to%20be%20passed%20to%20underlying%20storage%20drivers%0A%0A%23%20AdditionalImageStores%20is%20used%20to%20pass%20paths%20to%20additional%20Read%2FOnly%20image%20stores%0A%23%20Must%20be%20comma%20separated%20list.%0Aadditionalimagestores%20%3D%20%5B%0A%5D%0A%0A%23%20Remap-UIDs%2FGIDs%20is%20the%20mapping%20from%20UIDs%2FGIDs%20as%20they%20should%20appear%20inside%20of%0A%23%20a%20container%2C%20to%20UIDs%2FGIDs%20as%20they%20should%20appear%20outside%20of%20the%20container%2C%20and%0A%23%20the%20length%20of%20the%20range%20of%20UIDs%2FGIDs.%20%20Additional%20mapped%20sets%20can%20be%20listed%0A%23%20and%20will%20be%20heeded%20by%20libraries%2C%20but%20there%20are%20limits%20to%20the%20number%20of%0A%23%20mappings%20which%20the%20kernel%20will%20allow%20when%20you%20later%20attempt%20to%20run%20a%0A%23%20container.%0A%23%0A%23%20remap-uids%20%3D%200%3A1668442479%3A65536%0A%23%20remap-gids%20%3D%200%3A1668442479%3A65536%0A%0A%23%20Remap-User%2FGroup%20is%20a%20name%20which%20can%20be%20used%20to%20look%20up%20one%20or%20more%20UID%2FGID%0A%23%20ranges%20in%20the%20%2Fetc%2Fsubuid%20or%20%2Fetc%2Fsubgid%20file.%20%20Mappings%20are%20set%20up%20starting%0A%23%20with%20an%20in-container%20ID%20of%200%20and%20the%20a%20host-level%20ID%20taken%20from%20the%20lowest%0A%23%20range%20that%20matches%20the%20specified%20name%2C%20and%20using%20the%20length%20of%20that%20range.%0A%23%20Additional%20ranges%20are%20then%20assigned%2C%20using%20the%20ranges%20which%20specify%20the%0A%23%20lowest%20host-level%20IDs%20first%2C%20to%20the%20lowest%20not-yet-mapped%20container-level%20ID%2C%0A%23%20until%20all%20of%20the%20entries%20have%20been%20used%20for%20maps.%20This%20setting%20overrides%20the%0A%23%20Remap-UIDs%2FGIDs%20setting.%0A%23%0A%23%20remap-user%20%3D%20%22storage%22%0A%23%20remap-group%20%3D%20%22storage%22%0A%0A%5Bstorage.options.pull_options%5D%0A%23%20Options%20controlling%20how%20storage%20is%20populated%20when%20pulling%20images.%0A%0A%23%20Enable%20the%20%22zstd%3Achunked%22%20feature%2C%20which%20allows%20partial%20pulls%2C%20reusing%0A%23%20content%20that%20already%20exists%20on%20the%20system.%20This%20is%20disabled%20by%20default%2C%0A%23%20and%20must%20be%20explicitly%20enabled%20to%20be%20used.%20For%20more%20on%20zstd%3Achunked%2C%20see%0A%23%20https%3A%2F%2Fgithub.com%2Fcontainers%2Fstorage%2Fblob%2Fmain%2Fdocs%2Fcontainers-storage-zstd-chunked.md%0Aenable_partial_images%20%3D%20%22false%22%0A%0A%23%20Tells%20containers%2Fstorage%20to%20use%20hard%20links%20rather%20then%20create%20new%20files%20in%0A%23%20the%20image%2C%20if%20an%20identical%20file%20already%20existed%20in%20storage.%0Ause_hard_links%20%3D%20%22false%22%0A%0A%23%20Path%20to%20an%20ostree%20repository%20that%20might%20have%0A%23%20previously%20pulled%20content%20which%20can%20be%20used%20when%20attempting%20to%20avoid%0A%23%20pulling%20content%20from%20the%20container%20registry.%0Aostree_repos%20%3D%20%22%22%0A%0A%5Bstorage.options.overlay%5D%0A%23%20Storage%20Options%20for%20overlay%0A%0A%23%20Do%20not%20create%20a%20PRIVATE%20bind%20mount%20on%20the%20home%20directory.%0Askip_mount_home%20%3D%20%22true%22%0A%0A%23%20Size%20is%20used%20to%20set%20a%20maximum%20size%20of%20the%20container%20image.%20%20Only%20supported%20by%0A%23%20certain%20container%20storage%20drivers.%0Asize%20%3D%20%22%22%0A
          mode: 420
          overwrite: true
          path: /etc/containers/storage.conf
        - contents:
            source: data:,.%20%7B%0A%20%20%20%20errors%0A%20%20%20%20bufsize%20512%0A%20%20%20%20health%20%3A18080%0A%20%20%20%20forward%20.%20%7B%7B-%20range%20%24upstream%20%3A%3D%20.DNSUpstreams%7D%7D%20%7B%7B%24upstream%7D%7D%7B%7B-%20end%7D%7D%20%7B%0A%20%20%20%20%20%20%20%20policy%20sequential%0A%20%20%20%20%7D%0A%20%20%20%20cache%2030%0A%20%20%20%20reload%0A%20%20%20%20template%20IN%20%7B%7B%20.Cluster.IngressVIPRecordType%20%7D%7D%20comp-poc-rh01.rhpoc.int%20%7B%0A%20%20%20%20%20%20%20%20match%20.*%5B.%5Dapps.comp-poc-rh01.rhpoc.int%0A%20%20%20%20%20%20%20%20answer%20%22%7B%7B%22%7B%7B%20.Name%20%7D%7D%22%7D%7D%2060%20in%20%7B%7B%22%7B%7B%20.Type%20%7D%7D%22%7D%7D%2010.100.0.51%22%0A%20%20%20%20%20%20%20%20fallthrough%0A%20%20%20%20%7D%0A%20%20%20%20template%20IN%20%7B%7B%20.Cluster.IngressVIPEmptyType%20%7D%7D%20comp-poc-rh01.rhpoc.int%20%7B%0A%20%20%20%20%20%20%20%20match%20.*%5B.%5Dapps.comp-poc-rh01.rhpoc.int%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20fallthrough%0A%20%20%20%20%7D%0A%20%20%20%20template%20IN%20%7B%7B%20.Cluster.APIVIPRecordType%20%7D%7D%20comp-poc-rh01.rhpoc.int%20%7B%0A%20%20%20%20%20%20%20%20match%20%5Eapi.comp-poc-rh01.rhpoc.int%0A%20%20%20%20%20%20%20%20answer%20%22%7B%7B%22%7B%7B%20.Name%20%7D%7D%22%7D%7D%2060%20in%20%7B%7B%22%7B%7B%20.Type%20%7D%7D%22%7D%7D%2010.100.0.50%22%0A%20%20%20%20%20%20%20%20fallthrough%0A%20%20%20%20%7D%0A%20%20%20%20template%20IN%20%7B%7B%20.Cluster.APIVIPEmptyType%20%7D%7D%20comp-poc-rh01.rhpoc.int%20%7B%0A%20%20%20%20%20%20%20%20match%20%5Eapi.comp-poc-rh01.rhpoc.int%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20fallthrough%0A%20%20%20%20%7D%0A%20%20%20%20template%20IN%20%7B%7B%20.Cluster.APIVIPRecordType%20%7D%7D%20comp-poc-rh01.rhpoc.int%20%7B%0A%20%20%20%20%20%20%20%20match%20%5Eapi-int.comp-poc-rh01.rhpoc.int%0A%20%20%20%20%20%20%20%20answer%20%22%7B%7B%22%7B%7B%20.Name%20%7D%7D%22%7D%7D%2060%20in%20%7B%7B%22%7B%7B%20.Type%20%7D%7D%22%7D%7D%2010.100.0.50%22%0A%20%20%20%20%20%20%20%20fallthrough%0A%20%20%20%20%7D%0A%20%20%20%20template%20IN%20%7B%7B%20.Cluster.APIVIPEmptyType%20%7D%7D%20comp-poc-rh01.rhpoc.int%20%7B%0A%20%20%20%20%20%20%20%20match%20%5Eapi-int.comp-poc-rh01.rhpoc.int%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20fallthrough%0A%20%20%20%20%7D%0A%20%20%20%20hosts%20%7B%0A%20%20%20%20%20%20%20%20%7B%7B-%20range%20.Cluster.NodeAddresses%20%7D%7D%0A%20%20%20%20%20%20%20%20%7B%7B%20.Address%20%7D%7D%20%7B%7B%20.Name%20%7D%7D%20%7B%7B%20.Name%20%7D%7D.%7B%7B%20%24.Cluster.Name%20%7D%7D.%7B%7B%20%24.Cluster.Domain%20%7D%7D%0A%20%20%20%20%20%20%20%20%7B%7B-%20end%20%7D%7D%0A%20%20%20%20%20%20%20%20fallthrough%0A%20%20%20%20%7D%0A%7D%0A
          mode: 420
          overwrite: true
          path: /etc/kubernetes/static-pod-resources/coredns/Corefile.tmpl
        - contents:
            source: data:,kind%3A%20Pod%0AapiVersion%3A%20v1%0Ametadata%3A%0A%20%20name%3A%20coredns%0A%20%20namespace%3A%20openshift-kni-infra%0A%20%20creationTimestamp%3A%0A%20%20deletionGracePeriodSeconds%3A%2065%0A%20%20labels%3A%0A%20%20%20%20app%3A%20kni-infra-coredns%0A%20%20annotations%3A%0A%20%20%20%20target.workload.openshift.io%2Fmanagement%3A%20'%7B%22effect%22%3A%20%22PreferredDuringScheduling%22%7D'%0A%20%20%20%20openshift.io%2Frequired-scc%3A%20privileged%0Aspec%3A%0A%20%20volumes%3A%0A%20%20-%20name%3A%20resource-dir%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fetc%2Fkubernetes%2Fstatic-pod-resources%2Fcoredns%22%0A%20%20-%20name%3A%20kubeconfig%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20-%20name%3A%20conf-dir%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fetc%2Fcoredns%22%0A%20%20-%20name%3A%20nm-resolv%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fvar%2Frun%2FNetworkManager%22%0A%20%20-%20name%3A%20nodeip-configuration%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Frun%2Fnodeip-configuration%22%0A%20%20initContainers%3A%0A%20%20-%20name%3A%20render-config-coredns%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A93e7b8c870261726d44bddc7ba0a702d3720d1838141dac837fb8c3be7c6e1a1%0A%20%20%20%20command%3A%0A%20%20%20%20-%20runtimecfg%0A%20%20%20%20-%20render%0A%20%20%20%20-%20%22%2Fvar%2Flib%2Fkubelet%2Fkubeconfig%22%0A%20%20%20%20-%20%22--api-vips%22%0A%20%20%20%20-%20%2210.100.0.50%22%0A%20%20%20%20-%20%22--ingress-vips%22%0A%20%20%20%20-%20%2210.100.0.51%22%0A%20%20%20%20-%20%22%2Fconfig%22%0A%20%20%20%20-%20%22--out-dir%22%0A%20%20%20%20-%20%22%2Fetc%2Fcoredns%22%0A%20%20%20%20-%20%22--resolvconf-path%22%0A%20%20%20%20-%20%22%2Fvar%2Frun%2FNetworkManager%2Fresolv.conf%22%0A%20%20%20%20resources%3A%20%7B%7D%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20kubeconfig%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20resource-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fconfig%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20conf-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fcoredns%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20nm-resolv%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Frun%2FNetworkManager%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20nodeip-configuration%0A%20%20%20%20%20%20mountPath%3A%20%22%2Frun%2Fnodeip-configuration%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20imagePullPolicy%3A%20IfNotPresent%0A%20%20containers%3A%0A%20%20-%20name%3A%20coredns%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A4f6294ed30ab476019aaaa77874157facc77413988f82ffc46f94d3a98d2e4f1%0A%20%20%20%20args%3A%0A%20%20%20%20-%20%22--conf%22%0A%20%20%20%20-%20%22%2Fetc%2Fcoredns%2FCorefile%22%0A%20%20%20%20resources%3A%0A%20%20%20%20%20%20requests%3A%0A%20%20%20%20%20%20%20%20cpu%3A%20100m%0A%20%20%20%20%20%20%20%20memory%3A%20200Mi%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20conf-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fcoredns%22%0A%20%20%20%20-%20name%3A%20nodeip-configuration%0A%20%20%20%20%20%20mountPath%3A%20%22%2Frun%2Fnodeip-configuration%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20livenessProbe%3A%0A%20%20%20%20%20%20httpGet%3A%0A%20%20%20%20%20%20%20%20path%3A%20%2Fhealth%0A%20%20%20%20%20%20%20%20port%3A%2018080%0A%20%20%20%20%20%20%20%20scheme%3A%20HTTP%0A%20%20%20%20%20%20initialDelaySeconds%3A%2060%0A%20%20%20%20%20%20timeoutSeconds%3A%205%0A%20%20%20%20%20%20successThreshold%3A%201%0A%20%20%20%20%20%20failureThreshold%3A%205%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20imagePullPolicy%3A%20IfNotPresent%0A%20%20-%20name%3A%20coredns-monitor%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A93e7b8c870261726d44bddc7ba0a702d3720d1838141dac837fb8c3be7c6e1a1%0A%20%20%20%20command%3A%0A%20%20%20%20-%20corednsmonitor%0A%20%20%20%20-%20%22%2Fvar%2Flib%2Fkubelet%2Fkubeconfig%22%0A%20%20%20%20-%20%22%2Fconfig%2FCorefile.tmpl%22%0A%20%20%20%20-%20%22%2Fetc%2Fcoredns%2FCorefile%22%0A%20%20%20%20-%20%22--api-vips%22%0A%20%20%20%20-%20%2210.100.0.50%22%0A%20%20%20%20-%20%22--ingress-vips%22%0A%20%20%20%20-%20%2210.100.0.51%22%0A%20%20%20%20resources%3A%0A%20%20%20%20%20%20requests%3A%0A%20%20%20%20%20%20%20%20cpu%3A%20100m%0A%20%20%20%20%20%20%20%20memory%3A%20200Mi%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20kubeconfig%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20resource-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fconfig%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20conf-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fcoredns%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20nm-resolv%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Frun%2FNetworkManager%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20nodeip-configuration%0A%20%20%20%20%20%20mountPath%3A%20%22%2Frun%2Fnodeip-configuration%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20imagePullPolicy%3A%20IfNotPresent%0A%20%20hostNetwork%3A%20true%0A%20%20tolerations%3A%0A%20%20-%20operator%3A%20Exists%0A%20%20priorityClassName%3A%20system-node-critical%0Astatus%3A%20%7B%7D%0A
          mode: 420
          overwrite: true
          path: /etc/kubernetes/manifests/coredns.yaml
        - contents:
            source: data:,Initial%20Creation%0A
          mode: 384
          overwrite: true
          path: /etc/docker/certs.d/.create
        - contents:
            source: data:,%23%20Proxy%20environment%20variables%20will%20be%20populated%20in%20this%20file.%20Properly%0A%23%20url%20encoded%20passwords%20with%20special%20characters%20will%20use%20'%25%3CHEX%3E%3CHEX%3E'.%0A%23%20Systemd%20requires%20that%20any%20%25%20used%20in%20a%20password%20be%20represented%20as%0A%23%20%25%25%20in%20a%20unit%20file%20since%20%25%20is%20a%20prefix%20for%20macros%3B%20this%20restriction%20does%20not%0A%23%20apply%20for%20environment%20files.%20Templates%20that%20need%20the%20proxy%20set%20should%20use%0A%23%20'EnvironmentFile%3D%2Fetc%2Fmco%2Fproxy.env'.%0A
          mode: 420
          overwrite: true
          path: /etc/mco/proxy.env
        - contents:
            source: data:,%5BManager%5D%0ADefaultEnvironment%3DGODEBUG%3Dx509ignoreCN%3D0%0A
          mode: 420
          overwrite: true
          path: /etc/systemd/system.conf.d/10-default-env-godebug.conf
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%23%20Workaround%3A%0A%23%20https%3A%2F%2Fissues.redhat.com%2Fbrowse%2FOCPBUGS-38779%0A%0Adriver%3D%24(nmcli%20-t%20-m%20tabular%20-f%20general.driver%20dev%20show%20%22%24%7BDEVICE_IFACE%7D%22)%0A%0Aif%20%5B%5B%20%22%242%22%20%3D%3D%20%22up%22%20%26%26%20%22%24%7Bdriver%7D%22%20%3D%3D%20%22idpf%22%20%5D%5D%3B%20then%0A%20%20ethtool%20-K%20%24%7BDEVICE_IFACE%7D%20tx-checksumming%20off%0Afi
          mode: 484
          overwrite: true
          path: /etc/NetworkManager/dispatcher.d/99-gcp-disable-idpf-tx-checksum-off
        - contents:
            source: data:,%23%20Force-load%20legacy%20iptables%20so%20it%20is%20usable%20from%20pod%20network%20namespaces%0Aip_tables%0A
          mode: 420
          overwrite: true
          path: /etc/modules-load.d/iptables.conf
        - contents:
            source: data:,global_defs%20%7B%0A%20%20%20%20enable_script_security%0A%20%20%20%20script_user%20root%0A%20%20%20%20max_auto_priority%20-1%0A%20%20%20%20vrrp_garp_master_refresh%2060%0A%7D%0A%0A%23%20TODO%3A%20Improve%20this%20check.%20The%20port%20is%20assumed%20to%20be%20alive.%0A%23%20Need%20to%20assess%20what%20is%20the%20ramification%20if%20the%20port%20is%20not%20there.%0Avrrp_script%20chk_ingress_ready%20%7B%0A%20%20%20%20script%20%22%2Fusr%2Fbin%2Ftimeout%200.9%20%2Fusr%2Fbin%2Fcurl%20-o%20%2Fdev%2Fnull%20-Lfs%20http%3A%2F%2Flocalhost%3A1936%2Fhealthz%2Fready%22%0A%20%20%20%20interval%201%0A%20%20%20%20weight%2010%0A%20%20%20%20rise%203%0A%20%20%20%20fall%202%0A%7D%0A%0Avrrp_script%20chk_ingress%20%7B%0A%20%20%20%20script%20%22%2Fusr%2Fbin%2Ftimeout%200.9%20%2Fusr%2Fbin%2Fcurl%20-o%20%2Fdev%2Fnull%20-Lfs%20http%3A%2F%2Flocalhost%3A1936%2Fhealthz%22%0A%20%20%20%20interval%201%0A%20%20%20%20rise%203%0A%20%20%20%20fall%202%0A%7D%0A%0Avrrp_script%20chk_default_ingress%20%7B%0A%20%20%20%20script%20%22%2Fusr%2Fbin%2Ftimeout%204.9%20%2Fetc%2Fkeepalived%2Fchk_default_ingress.sh%22%0A%20%20%20%20interval%205%0A%20%20%20%20weight%2050%0A%20%20%20%20rise%203%0A%20%20%20%20fall%202%0A%7D%0A%0A%7B%7B%20range%20%24i%2C%20%24config%20%3A%3D%20.Configs%20%7D%7D%0A%7B%7B%24nonVirtualIP%20%3A%3D%20.NonVirtualIP%7D%7D%0A%0A%7B%7B%24participateInIngressVRPP%20%3A%3D%20not%20.EnableUnicast%7D%7D%0A%7B%7B-%20if%20.EnableUnicast%7D%7D%0A%7B%7B-%20range%20.IngressConfig.Peers%7D%7D%0A%7B%7B-%20if%20eq%20%24nonVirtualIP%20.%7D%7D%0A%7B%7B%24participateInIngressVRPP%20%3D%20true%7D%7D%0A%7B%7B-%20end%7D%7D%0A%7B%7B-%20end%7D%7D%0A%7B%7B-%20end%7D%7D%0A%0A%7B%7Bif%20%24participateInIngressVRPP%7D%7D%0Avrrp_instance%20%7B%7B%20.Cluster.Name%20%7D%7D_INGRESS_%7B%7B%24i%7D%7D%20%7B%0A%20%20%20%20state%20BACKUP%0A%20%20%20%20interface%20%7B%7B%20.VRRPInterface%20%7D%7D%0A%20%20%20%20virtual_router_id%20%7B%7B%20.Cluster.IngressVirtualRouterID%20%7D%7D%0A%20%20%20%20priority%2020%0A%20%20%20%20advert_int%201%0A%20%20%20%20%7B%7Bif%20.EnableUnicast%7D%7D%0A%20%20%20%20unicast_src_ip%20%7B%7B.NonVirtualIP%7D%7D%0A%20%20%20%20unicast_peer%20%7B%0A%20%20%20%20%20%20%20%20%7B%7B-%20range%20.IngressConfig.Peers%7D%7D%0A%20%20%20%20%20%20%20%20%7B%7B-%20if%20ne%20%24nonVirtualIP%20.%7D%7D%0A%20%20%20%20%20%20%20%20%7B%7B.%7D%7D%0A%20%20%20%20%20%20%20%20%7B%7B-%20end%7D%7D%0A%20%20%20%20%20%20%20%20%7B%7B-%20end%7D%7D%0A%20%20%20%20%7D%0A%20%20%20%20%7B%7Bend%7D%7D%0A%20%20%20%20authentication%20%7B%0A%20%20%20%20%20%20%20%20auth_type%20PASS%0A%20%20%20%20%20%20%20%20auth_pass%20%7B%7B%20.Cluster.Name%20%7D%7D_ingress_vip%0A%20%20%20%20%7D%0A%20%20%20%20virtual_ipaddress%20%7B%0A%20%20%20%20%20%20%20%20%7B%7B%20.Cluster.IngressVIP%20%7D%7D%2F%7B%7B%20.Cluster.VIPNetmask%20%7D%7D%20label%20vip%0A%20%20%20%20%7D%0A%20%20%20%20track_script%20%7B%0A%20%20%20%20%20%20%20%20chk_ingress%0A%20%20%20%20%20%20%20%20chk_ingress_ready%0A%20%20%20%20%20%20%20%20chk_default_ingress%0A%20%20%20%20%7D%0A%7D%0A%7B%7B%20end%20%7D%7D%0A%7B%7B%20end%20%7D%7D%0A
          mode: 420
          overwrite: true
          path: /etc/kubernetes/static-pod-resources/keepalived/keepalived.conf.tmpl
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Achroot%20%2Fhost%20%2Fbin%2Fcrictl%20pods%20--namespace%20openshift-ingress%20--state%20Ready%20%7C%20grep%20-qE%20'router-default-%5B%5B%3Aalnum%3A%5D%5D%7B5%2C%7D-%5B%5B%3Aalnum%3A%5D%5D%7B5%2C%7D'%0A
          mode: 493
          overwrite: true
          path: /etc/kubernetes/static-pod-resources/keepalived/scripts/chk_default_ingress.sh.tmpl
        - contents:
            source: data:,kind%3A%20Pod%0AapiVersion%3A%20v1%0Ametadata%3A%0A%20%20name%3A%20keepalived%0A%20%20namespace%3A%20openshift-kni-infra%0A%20%20creationTimestamp%3A%0A%20%20deletionGracePeriodSeconds%3A%2065%0A%20%20labels%3A%0A%20%20%20%20app%3A%20kni-infra-vrrp%0A%20%20annotations%3A%0A%20%20%20%20target.workload.openshift.io%2Fmanagement%3A%20'%7B%22effect%22%3A%20%22PreferredDuringScheduling%22%7D'%0A%20%20%20%20openshift.io%2Frequired-scc%3A%20privileged%0Aspec%3A%0A%20%20volumes%3A%0A%20%20-%20name%3A%20resource-dir%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fetc%2Fkubernetes%2Fstatic-pod-resources%2Fkeepalived%22%0A%20%20-%20name%3A%20script-dir%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fetc%2Fkubernetes%2Fstatic-pod-resources%2Fkeepalived%2Fscripts%22%0A%20%20-%20name%3A%20kubeconfig%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fetc%2Fkubernetes%22%0A%20%20-%20name%3A%20kubeconfigvarlib%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20-%20name%3A%20conf-dir%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fetc%2Fkeepalived%22%0A%20%20-%20name%3A%20run-dir%0A%20%20%20%20empty-dir%3A%20%7B%7D%0A%20%20-%20name%3A%20chroot-host%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2F%22%0A%20%20-%20name%3A%20nodeip-configuration%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Frun%2Fnodeip-configuration%22%0A%20%20initContainers%3A%0A%20%20-%20name%3A%20render-config-keepalived%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A93e7b8c870261726d44bddc7ba0a702d3720d1838141dac837fb8c3be7c6e1a1%0A%20%20%20%20command%3A%0A%20%20%20%20-%20runtimecfg%0A%20%20%20%20-%20render%0A%20%20%20%20-%20%22%2Fetc%2Fkubernetes%2Fkubeconfig%22%0A%20%20%20%20-%20%22--api-vips%22%0A%20%20%20%20-%20%2210.100.0.50%22%0A%20%20%20%20-%20%22--ingress-vips%22%0A%20%20%20%20-%20%2210.100.0.51%22%0A%20%20%20%20-%20%22%2Fconfig%22%0A%20%20%20%20-%20%22--out-dir%22%0A%20%20%20%20-%20%22%2Fetc%2Fkeepalived%22%0A%20%20%20%20resources%3A%20%7B%7D%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20kubeconfig%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fkubernetes%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20script-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fconfig%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20conf-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fkeepalived%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20nodeip-configuration%0A%20%20%20%20%20%20mountPath%3A%20%22%2Frun%2Fnodeip-configuration%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20imagePullPolicy%3A%20IfNotPresent%0A%20%20containers%3A%0A%20%20-%20name%3A%20keepalived%0A%20%20%20%20securityContext%3A%0A%20%20%20%20%20%20capabilities%3A%0A%20%20%20%20%20%20%20%20add%3A%20%5B%22NET_ADMIN%22%2C%20%22NET_RAW%22%2C%20%22SYS_CHROOT%22%5D%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A3b0561a80561d95854d5f364f8cd6c3458d27cfb798bf93e09ffcfab97609216%0A%20%20%20%20env%3A%0A%20%20%20%20%20%20-%20name%3A%20NSS_SDB_USE_CACHE%0A%20%20%20%20%20%20%20%20value%3A%20%22no%22%0A%20%20%20%20command%3A%0A%20%20%20%20-%20%2Fbin%2Fbash%0A%20%20%20%20-%20-c%0A%20%20%20%20-%20%7C%0A%20%20%20%20%20%20%23%2Fbin%2Fbash%0A%20%20%20%20%20%20sigterm_handler()%0A%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20if%20pid%3D%24(pgrep%20-o%20keepalived)%3B%20then%0A%20%20%20%20%20%20%20%20%20%20kill%20-s%20SIGTERM%20%22%24pid%22%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%7D%0A%0A%20%20%20%20%20%20reload_keepalived()%0A%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20if%20pid%3D%24(pgrep%20-o%20keepalived)%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20kill%20-s%20SIGHUP%20%22%24pid%22%0A%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20%2Fusr%2Fsbin%2Fkeepalived%20-f%20%2Fetc%2Fkeepalived%2Fkeepalived.conf%20--dont-fork%20--vrrp%20--log-detail%20--log-console%20%26%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%7D%0A%0A%20%20%20%20%20%20msg_handler()%0A%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20while%20read%20-r%20line%3B%20do%0A%20%20%20%20%20%20%20%20%20%20echo%20%22The%20client%20sent%3A%20%24line%22%20%3E%262%0A%20%20%20%20%20%20%20%20%20%20%23%20currently%20only%20'reload'%20msg%20is%20supported%0A%20%20%20%20%20%20%20%20%20%20if%20%5B%20%22%24line%22%20%3D%20reload%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20reload_keepalived%0A%20%20%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20done%0A%20%20%20%20%20%20%7D%0A%0A%20%20%20%20%20%20remove_vip()%0A%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20address%3D%241%0A%20%20%20%20%20%20%20%20interface%3D%24(ip%20-o%20a%20%7C%20awk%20%22%2F%5Cs%24%7Baddress%7D%5C%2F%2F%20%7Bprint%20%5C%242%7D%22)%0A%20%20%20%20%20%20%20%20cidr%3D%24(ip%20-o%20a%20%7C%20awk%20%22%2F%5Cs%24%7Baddress%7D%5C%2F%2F%20%7Bprint%20%5C%244%7D%22)%0A%20%20%20%20%20%20%20%20if%20%5B%20-n%20%22%24interface%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20ip%20a%20del%20%24cidr%20dev%20%24interface%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%7D%0A%0A%20%20%20%20%20%20set%20-ex%0A%20%20%20%20%20%20%23%20Ensure%20that%20we%20don't%20have%20stale%20VIPs%20configured%0A%20%20%20%20%20%20%23%20See%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1931505%0A%20%20%20%20%20%20remove_vip%20%2210.100.0.50%22%0A%20%20%20%20%20%20remove_vip%20%2210.100.0.51%22%0A%20%20%20%20%20%20declare%20-r%20keepalived_sock%3D%22%2Fvar%2Frun%2Fkeepalived%2Fkeepalived.sock%22%0A%20%20%20%20%20%20export%20-f%20msg_handler%0A%20%20%20%20%20%20export%20-f%20reload_keepalived%0A%20%20%20%20%20%20export%20-f%20sigterm_handler%0A%0A%20%20%20%20%20%20%23%20in%20remote%20worker%20case%20sleep%20forever%0A%20%20%20%20%20%20if%20%5B%20-f%20%22%2Frun%2Fnodeip-configuration%2Fremote-worker%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20sleep%20infinity%0A%20%20%20%20%20%20%20%20%20exit%200%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20trap%20sigterm_handler%20SIGTERM%0A%20%20%20%20%20%20if%20%5B%20-s%20%22%2Fetc%2Fkeepalived%2Fkeepalived.conf%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%2Fusr%2Fsbin%2Fkeepalived%20-f%20%2Fetc%2Fkeepalived%2Fkeepalived.conf%20--dont-fork%20--vrrp%20--log-detail%20--log-console%20%26%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20rm%20-f%20%22%24keepalived_sock%22%0A%20%20%20%20%20%20socat%20UNIX-LISTEN%3A%24%7Bkeepalived_sock%7D%2Cfork%20system%3A'bash%20-c%20msg_handler'%0A%20%20%20%20resources%3A%0A%20%20%20%20%20%20requests%3A%0A%20%20%20%20%20%20%20%20cpu%3A%20100m%0A%20%20%20%20%20%20%20%20memory%3A%20200Mi%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20conf-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fkeepalived%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20run-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Frun%2Fkeepalived%22%0A%20%20%20%20-%20name%3A%20chroot-host%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fhost%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20kubeconfigvarlib%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20nodeip-configuration%0A%20%20%20%20%20%20mountPath%3A%20%22%2Frun%2Fnodeip-configuration%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20livenessProbe%3A%0A%20%20%20%20%20%20exec%3A%0A%20%20%20%20%20%20%20%20command%3A%0A%20%20%20%20%20%20%20%20-%20%2Fbin%2Fbash%0A%20%20%20%20%20%20%20%20-%20-c%0A%20%20%20%20%20%20%20%20-%20%7C%0A%20%20%20%20%20%20%20%20%20%20%5B%20!%20-s%20%22%2Fetc%2Fkeepalived%2Fkeepalived.conf%22%20%5D%20%7C%7C%20(echo%20%22%22%20%3E%20%2Ftmp%2Fkeepalived.data%20%26%26%20kill%20-s%20SIGUSR1%20%22%24(pgrep%20-o%20keepalived)%22%20%26%26%20for%20i%20in%20%24(seq%205)%3B%20do%20grep%20-q%20%22VRRP%20Instance%22%20%2Ftmp%2Fkeepalived.data%20%26%26%20exit%200%20%7C%7C%20sleep%201%3B%20done%20%26%26%20exit%201)%0A%20%20%20%20%20%20initialDelaySeconds%3A%2020%0A%20%20%20%20%20%20timeoutSeconds%3A%205%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20imagePullPolicy%3A%20IfNotPresent%0A%20%20-%20name%3A%20keepalived-monitor%0A%20%20%20%20securityContext%3A%0A%20%20%20%20%20%20capabilities%3A%0A%20%20%20%20%20%20%20%20add%3A%20%5B%22NET_ADMIN%22%2C%20%22SYS_CHROOT%22%5D%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A93e7b8c870261726d44bddc7ba0a702d3720d1838141dac837fb8c3be7c6e1a1%0A%20%20%20%20env%3A%0A%20%20%20%20%20%20-%20name%3A%20ENABLE_UNICAST%0A%20%20%20%20%20%20%20%20value%3A%20%22yes%22%0A%20%20%20%20%20%20-%20name%3A%20IS_BOOTSTRAP%0A%20%20%20%20%20%20%20%20value%3A%20%22no%22%0A%20%20%20%20%20%20-%20name%3A%20POD_NAMESPACE%0A%20%20%20%20%20%20%20%20valueFrom%3A%0A%20%20%20%20%20%20%20%20%20%20fieldRef%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20fieldPath%3A%20metadata.namespace%0A%20%20%20%20command%3A%0A%20%20%20%20-%20%2Fbin%2Fbash%0A%20%20%20%20-%20-c%0A%20%20%20%20-%20%7C%0A%20%20%20%20%20%20%23%2Fbin%2Fbash%0A%20%20%20%20%20%20%23%20in%20remote%20worker%20case%20sleep%20forever%0A%20%20%20%20%20%20if%20%5B%20-f%20%22%2Frun%2Fnodeip-configuration%2Fremote-worker%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20sleep%20infinity%0A%20%20%20%20%20%20%20%20%20%20exit%200%0A%20%20%20%20%20%20fi%0A%20%20%20%20%20%20api_vips%3D10.100.0.50%0A%20%20%20%20%20%20ingress_vips%3D10.100.0.51%0A%20%20%20%20%20%20dynkeepalived%20%2Fvar%2Flib%2Fkubelet%2Fkubeconfig%20%2Fconfig%2Fkeepalived.conf.tmpl%20%2Fetc%2Fkeepalived%2Fkeepalived.conf%20--api-vips%20%22%24%7Bapi_vips%7D%22%20--ingress-vips%20%22%24%7Bingress_vips%7D%22%0A%20%20%20%20resources%3A%0A%20%20%20%20%20%20requests%3A%0A%20%20%20%20%20%20%20%20cpu%3A%20100m%0A%20%20%20%20%20%20%20%20memory%3A%20200Mi%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20resource-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fconfig%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20kubeconfigvarlib%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20conf-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fkeepalived%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20run-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Frun%2Fkeepalived%22%0A%20%20%20%20-%20name%3A%20chroot-host%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fhost%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20nodeip-configuration%0A%20%20%20%20%20%20mountPath%3A%20%22%2Frun%2Fnodeip-configuration%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20imagePullPolicy%3A%20IfNotPresent%0A%20%20hostNetwork%3A%20true%0A%20%20tolerations%3A%0A%20%20-%20operator%3A%20Exists%0A%20%20priorityClassName%3A%20system-node-critical%0Astatus%3A%20%7B%7D%0A
          mode: 420
          overwrite: true
          path: /etc/kubernetes/manifests/keepalived.yaml
        - contents:
            source: data:,NODE_SIZING_ENABLED%3Dfalse%0ASYSTEM_RESERVED_MEMORY%3D1Gi%0ASYSTEM_RESERVED_CPU%3D500m%0ASYSTEM_RESERVED_ES%3D1Gi
          mode: 420
          overwrite: true
          path: /etc/node-sizing-enabled.env
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-e%0ANODE_SIZES_ENV%3D%24%7BNODE_SIZES_ENV%3A-%2Fetc%2Fnode-sizing.env%7D%0AVERSION_1%3D1%0AVERSION_2%3D2%0ANODE_AUTO_SIZING_VERSION%3D%24%7BNODE_AUTO_SIZING_VERSION%3A-%24VERSION_2%7D%0ANODE_AUTO_SIZING_VERSION_FILE%3D%24%7BNODE_AUTO_SIZING_VERSION_FILE%3A-%2Fetc%2Fnode-sizing-version.json%7D%0Afunction%20dynamic_memory_sizing%20%7B%0A%20%20%20%20total_memory%3D%24(free%20-g%7Cawk%20'%2F%5EMem%3A%2F%7Bprint%20%242%7D')%0A%20%20%20%20%23%20total_memory%3D8%20test%20the%20recommended%20values%20by%20modifying%20this%20value%0A%20%20%20%20recommended_systemreserved_memory%3D0%0A%20%20%20%20if%20((%24total_memory%20%3C%3D%204))%3B%20then%20%23%2025%25%20of%20the%20first%204GB%20of%20memory%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24total_memory%200.25%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D0%0A%20%20%20%20else%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D1%0A%20%20%20%20%20%20%20%20total_memory%3D%24((total_memory-4))%0A%20%20%20%20fi%0A%20%20%20%20if%20((%24total_memory%20%3C%3D%204))%3B%20then%20%23%2020%25%20of%20the%20next%204GB%20of%20memory%20(up%20to%208GB)%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%20%24(echo%20%24total_memory%200.20%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D0%0A%20%20%20%20else%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%200.80%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D%24((total_memory-4))%0A%20%20%20%20fi%0A%20%20%20%20if%20((%24total_memory%20%3C%3D%208))%3B%20then%20%23%2010%25%20of%20the%20next%208GB%20of%20memory%20(up%20to%2016GB)%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%20%24(echo%20%24total_memory%200.10%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D0%0A%20%20%20%20else%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%200.80%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D%24((total_memory-8))%0A%20%20%20%20fi%0A%20%20%20%20if%20((%24total_memory%20%3C%3D%20112))%3B%20then%20%23%206%25%20of%20the%20next%20112GB%20of%20memory%20(up%20to%20128GB)%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%20%24(echo%20%24total_memory%200.06%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D0%0A%20%20%20%20else%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%206.72%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D%24((total_memory-112))%0A%20%20%20%20fi%0A%20%20%20%20if%20((%24total_memory%20%3E%3D%200))%3B%20then%20%23%202%25%20of%20any%20memory%20above%20128GB%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%20%24(echo%20%24total_memory%200.02%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20fi%0A%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%20%7C%20awk%20'%7Bprintf(%22%25d%5Cn%22%2C%241%20%2B%200.5)%7D')%20%23%20Round%20off%20so%20we%20avoid%20float%20conversions%0A%20%20%20%20echo%20%22SYSTEM_RESERVED_MEMORY%3D%24%7Brecommended_systemreserved_memory%7DGi%22%3E%3E%20%24%7BNODE_SIZES_ENV%7D%0A%7D%0Afunction%20dynamic_cpu_sizing%20%7B%0A%20%20%20%20total_cpu%3D%24(getconf%20_NPROCESSORS_ONLN)%0A%20%20%20%20if%20%5B%20%22%241%22%20-eq%20%22%24VERSION_1%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D0%0A%20%20%20%20%20%20%20%20if%20((%24total_cpu%20%3C%3D%201))%3B%20then%20%23%206%25%20of%20the%20first%20core%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24total_cpu%200.06%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D0%0A%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D0.06%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D%24((total_cpu-1))%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20if%20((%24total_cpu%20%3C%3D%201))%3B%20then%20%23%201%25%20of%20the%20next%20core%20(up%20to%202%20cores)%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24recommended_systemreserved_cpu%20%24(echo%20%24total_cpu%200.01%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D0%0A%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24recommended_systemreserved_cpu%200.01%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D%24((total_cpu-1))%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20if%20((%24total_cpu%20%3C%3D%202))%3B%20then%20%23%200.5%25%20of%20the%20next%202%20cores%20(up%20to%204%20cores)%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24recommended_systemreserved_cpu%20%24(echo%20%24total_cpu%200.005%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D0%0A%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24recommended_systemreserved_cpu%200.01%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D%24((total_cpu-2))%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20if%20((%24total_cpu%20%3E%3D%200))%3B%20then%20%23%200.25%25%20of%20any%20cores%20above%204%20cores%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24recommended_systemreserved_cpu%20%24(echo%20%24total_cpu%200.0025%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20else%0A%20%20%20%20%20%20%20%20%23%20Base%20allocation%20for%201%20CPU%20in%20fractions%20of%20a%20core%20(60%20millicores%20%3D%200.06%20CPU%20core)%0A%20%20%20%20%20%20%20%20base_allocation_fraction%3D0.06%0A%20%20%20%20%20%20%20%20%23%20Increment%20per%20additional%20CPU%20in%20fractions%20of%20a%20core%20(12%20millicores%20%3D%200.012%20CPU%20core)%0A%20%20%20%20%20%20%20%20increment_per_cpu_fraction%3D0.012%0A%20%20%20%20%20%20%20%20if%20((total_cpu%20%3E%201))%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Calculate%20the%20total%20system-reserved%20CPU%20in%20fractions%2C%20starting%20with%20the%20base%20allocation%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20and%20adding%20the%20incremental%20fraction%20for%20each%20additional%20CPU%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(awk%20-v%20base%3D%22%24base_allocation_fraction%22%20-v%20increment%3D%22%24increment_per_cpu_fraction%22%20-v%20cpus%3D%22%24total_cpu%22%20'BEGIN%20%7Bprintf%20%22%25.2f%5Cn%22%2C%20base%20%2B%20increment%20*%20(cpus%20-%201)%7D')%0A%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20For%20a%20single%20CPU%2C%20use%20the%20base%20allocation%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24base_allocation_fraction%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Enforce%20minimum%20threshold%20of%200.5%20CPU%0A%20%20%20%20recommended_systemreserved_cpu%3D%24(awk%20-v%20val%3D%22%24recommended_systemreserved_cpu%22%20'BEGIN%20%7Bif%20(val%20%3C%200.5)%20print%200.5%3B%20else%20print%20val%7D')%0A%0A%20%20%20%20echo%20%22SYSTEM_RESERVED_CPU%3D%24%7Brecommended_systemreserved_cpu%7D%22%3E%3E%20%24%7BNODE_SIZES_ENV%7D%0A%7D%0Afunction%20dynamic_ephemeral_sizing%20%7B%0A%20%20%20%20echo%20%22Not%20implemented%20yet%22%0A%7D%0Afunction%20dynamic_pid_sizing%20%7B%0A%20%20%20%20echo%20%22Not%20implemented%20yet%22%0A%7D%0Afunction%20set_memory%20%7B%0A%20%20%20%20SYSTEM_RESERVED_MEMORY%3D%241%0A%20%20%20%20if%20%5B%20-z%20%22%24%7BSYSTEM_RESERVED_MEMORY%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20SYSTEM_RESERVED_MEMORY%3D%221Gi%22%0A%20%20%20%20fi%0A%20%20%20%20echo%20%22SYSTEM_RESERVED_MEMORY%3D%24%7BSYSTEM_RESERVED_MEMORY%7D%22%20%3E%3E%20%24%7BNODE_SIZES_ENV%7D%0A%7D%0Afunction%20set_cpu%20%7B%0A%20%20%20%20SYSTEM_RESERVED_CPU%3D%241%0A%20%20%20%20if%20%5B%20-z%20%22%24%7BSYSTEM_RESERVED_CPU%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20SYSTEM_RESERVED_CPU%3D%22500m%22%0A%20%20%20%20fi%0A%20%20%20%20echo%20%22SYSTEM_RESERVED_CPU%3D%24%7BSYSTEM_RESERVED_CPU%7D%22%20%3E%3E%20%24%7BNODE_SIZES_ENV%7D%0A%7D%0Afunction%20set_es%20%7B%0A%20%20%20%20SYSTEM_RESERVED_ES%3D%241%0A%20%20%20%20if%20%5B%20-z%20%22%24%7BSYSTEM_RESERVED_ES%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20SYSTEM_RESERVED_ES%3D%221Gi%22%0A%20%20%20%20fi%0A%20%20%20%20echo%20%22SYSTEM_RESERVED_ES%3D%24%7BSYSTEM_RESERVED_ES%7D%22%20%3E%3E%20%24%7BNODE_SIZES_ENV%7D%0A%7D%0Afunction%20dynamic_node_sizing%20%7B%0A%20%20%20%20rm%20-f%20%24%7BNODE_SIZES_ENV%7D%0A%20%20%20%20dynamic_memory_sizing%0A%20%20%20%20dynamic_cpu_sizing%20%241%0A%20%20%20%20set_es%20%242%0A%20%20%20%20%23dynamic_ephemeral_sizing%0A%20%20%20%20%23dynamic_pid_sizing%0A%7D%0Afunction%20static_node_sizing%20%7B%0A%20%20%20%20rm%20-f%20%24%7BNODE_SIZES_ENV%7D%0A%20%20%20%20set_memory%20%241%0A%20%20%20%20set_cpu%20%242%0A%20%20%20%20set_es%20%243%0A%7D%0Afunction%20create_version_file%20%7B%0A%20%20%20%20echo%20%22%7B%5C%22version%5C%22%3A%20%241%7D%22%20%3E%20%242%0A%7D%0Aif%20!%20%5B%20-f%20%24NODE_AUTO_SIZING_VERSION_FILE%20%5D%3B%20then%0A%20%20%20%20create_version_file%20%24NODE_AUTO_SIZING_VERSION%20%24NODE_AUTO_SIZING_VERSION_FILE%0Afi%0Anew_version%3D%24(jq%20.version%20%24NODE_AUTO_SIZING_VERSION_FILE)%0Aif%20%5B%20%241%20%3D%3D%20%22true%22%20%5D%3B%20then%0A%20%20%20%20dynamic_node_sizing%20%24new_version%20%244%0Aelif%20%5B%20%241%20%3D%3D%20%22false%22%20%5D%3B%20then%0A%20%20%20%20static_node_sizing%20%242%20%243%20%244%0Aelse%0A%20%20%20%20echo%20%22Unrecognized%20command%20line%20option.%20Valid%20options%20are%20%5C%22true%5C%22%20or%20%5C%22false%5C%22%22%0Afi%0A
          mode: 493
          overwrite: true
          path: /usr/local/sbin/dynamic-system-reserved-calc.sh
        - contents:
            source: data:,%23%20Turning%20on%20Accounting%20helps%20track%20down%20performance%20issues.%0A%5BManager%5D%0ADefaultCPUAccounting%3Dyes%0ADefaultMemoryAccounting%3Dyes%0ADefaultBlockIOAccounting%3Dyes%0A
          mode: 420
          overwrite: true
          path: /etc/systemd/system.conf.d/kubelet-cgroups.conf
        - contents:
            source: data:,%5BService%5D%0AEnvironment%3D%22KUBELET_LOG_LEVEL%3D2%22%0A
          mode: 420
          overwrite: true
          path: /etc/systemd/system/kubelet.service.d/20-logging.conf
        - contents:
            source: data:,%23%20ignore%20known%20SDN-managed%20devices%0A%5Bdevice%5D%0Amatch-device%3Dinterface-name%3Abr-int%3Binterface-name%3Abr-local%3Binterface-name%3Abr-nexthop%3Binterface-name%3Aovn-k8s-*%3Binterface-name%3Ak8s-*%3Binterface-name%3Atun0%3Binterface-name%3Abr0%3Binterface-name%3Apatch-br-*%3Binterface-name%3Abr-ext%3Binterface-name%3Aext-vxlan%3Binterface-name%3Aext%3Binterface-name%3Aint%3Binterface-name%3Avxlan_sys_*%3Binterface-name%3Agenev_sys_*%3Bdriver%3Aveth%0Amanaged%3D0%0A
          mode: 420
          overwrite: true
          path: /etc/NetworkManager/conf.d/sdn.conf
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-eux%0A%0A%23%20Clean%20up%20old%20config%20on%20behalf%20of%20mtu-migration%0Aif%20!%20systemctl%20-q%20is-enabled%20mtu-migration%3B%20then%0A%20%20echo%20%22Cleaning%20up%20left%20over%20mtu%20migration%20configuration%22%0A%20%20rm%20-rf%20%2Fetc%2Fcno%2Fmtu-migration%0Afi%0A%0Aif%20%5B%20-e%20%2Fetc%2Fnmstate%2Fopenshift%2Fapplied%20%5D%3B%20then%0A%20%20echo%20%22Configuration%20already%20applied%2C%20exiting%22%0A%20%20exit%200%0Afi%0A%0Asrc_path%3D%22%2Fetc%2Fnmstate%2Fopenshift%22%0Adst_path%3D%22%2Fetc%2Fnmstate%22%0Ahostname%3D%24(hostname%20-s)%0Ahost_file%3D%22%24%7Bhostname%7D.yml%22%0Acluster_file%3D%22cluster.yml%22%0Aconfig_file%3D%22%22%0Aif%20%5B%20-s%20%22%24src_path%2F%24host_file%22%20%5D%3B%20then%0A%20%20config_file%3D%24host_file%0Aelif%20%5B%20-s%20%22%24src_path%2F%24cluster_file%22%20%5D%3B%20then%0A%20%20config_file%3D%24cluster_file%0Aelse%0A%20%20echo%20%22No%20configuration%20found%20at%20%24src_path%2F%24host_file%20or%20%24src_path%2F%24cluster_file%22%0A%20%20exit%200%0Afi%0A%0Aif%20%5B%20-e%20%22%24dst_path%2F%24config_file%22%20%5D%3B%20then%0A%20%20echo%20%22ERROR%3A%20File%20%24dst_path%2F%24config_file%20exists.%20Refusing%20to%20overwrite.%22%0A%20%20exit%201%0Afi%0A%0A%23%20Handle%20the%20case%20where%20we're%20migrating%20from%20configure-ovs%0Aovs-vsctl%20--timeout%3D30%20--if-exists%20del-br%20br-ex%0A%0A%23%20Handle%20the%20case%20where%20we're%20migrating%20from%20OpenShift%20SDN%0Aovs-vsctl%20--timeout%3D30%20--if-exists%20del-br%20br0%0A%0Acp%20%22%24src_path%2F%24config_file%22%20%2Fetc%2Fnmstate%0Atouch%20%2Fetc%2Fnmstate%2Fopenshift%2Fapplied%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/nmstate-configuration.sh
        - contents:
            source: data:,%5Bservice%5D%0Akeep_state_file_after_apply%20%3D%20true%0A
          mode: 420
          overwrite: true
          path: /etc/nmstate/nmstate.conf
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%23%20Set%20interface%20ofport_request%20to%20guarantee%20stable%20ofport%20numbers.%20This%20is%20important%20for%20flow%20matches.%0A%23%20Otherwise%2C%20another%20ofport%20number%20is%20assigned%20to%20the%20interface%20on%20every%20restart%20of%20NetworkManager.%0A%23%20This%20script%20will%20build%20an%20associative%20array%20INTERFACE_NAME-%3Eofport_request%20and%20will%20save%20it%20to%20file%20CONFIGURATION_FILE.%0A%23%20When%20an%20interface%20is%20brought%20up%2C%20this%20will%20reuse%20the%20value%20from%20the%20associative%20array%20if%20such%20a%20value%20exists.%0A%23%20Otherwise%2C%20this%20will%20try%20to%20use%20the%20current%20ofport%20value.%20If%20the%20ofport%20value%20is%20already%20reserved%2C%20then%0A%23%20this%20uses%20the%20lowest%20available%20numerical%20value%2C%20instead.%0Aset%20-eux%20-o%20pipefail%0Aif%20%5B%5B%20%22OVNKubernetes%22%20!%3D%20%22OVNKubernetes%22%20%5D%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0AINTERFACE_NAME%3D%241%0AOPERATION%3D%242%0A%0A%23%20Only%20execute%20this%20on%20pre-up%0Aif%20%5B%20%22%24%7BOPERATION%7D%22%20!%3D%20%22pre-up%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20interface's%20NM%20uuid%0AINTERFACE_CONNECTION_UUID%3D%24(nmcli%20-t%20-f%20device%2Ctype%2Cuuid%20conn%20%7C%20awk%20-F%20'%3A'%20'%7Bif(%241%3D%3D%22'%24%7BINTERFACE_NAME%7D'%22%20%26%26%20%242!~%2F%5Eovs*%2F)%20print%20%24NF%7D')%0Aif%20%5B%20%22%24%7BINTERFACE_CONNECTION_UUID%7D%22%20%3D%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20interface's%20slave-type.%20If%20this%20is%20not%20an%20ovs-port%2C%20then%20exit%0AINTERFACE_OVS_SLAVE_TYPE%3D%24(nmcli%20-t%20-f%20connection.slave-type%20conn%20show%20%22%24%7BINTERFACE_CONNECTION_UUID%7D%22%20%7C%20awk%20-F%20'%3A'%20'%7Bprint%20%24NF%7D')%0Aif%20%5B%20%22%24%7BINTERFACE_OVS_SLAVE_TYPE%7D%22%20!%3D%20%22ovs-port%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20This%20is%20not%20necessarily%20a%20UUID%20(can%20be%20a%20name%20in%20case%20of%20bonds)%20but%20this%20should%20be%20unique%0APORT%3D%24(nmcli%20-t%20-f%20connection.master%20conn%20show%20%22%24%7BINTERFACE_CONNECTION_UUID%7D%22%20%7C%20awk%20-F%20'%3A'%20'%7Bprint%20%24NF%7D')%0Aif%20%5B%20%22%24%7BPORT%7D%22%20%3D%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20interface's%20NM%20uuid%0APORT_CONNECTION_UUID%3D%24(nmcli%20-t%20-f%20device%2Ctype%2Cuuid%20conn%20%7C%20awk%20-F%20'%3A'%20'%7Bif(%20(%241%3D%3D%22'%24%7BPORT%7D'%22%20%7C%7C%20%243%3D%3D%22'%24%7BPORT%7D'%22)%20%26%26%20%242~%2F%5Eovs*%2F)%20print%20%24NF%7D')%0Aif%20%5B%20%22%24%7BPORT_CONNECTION_UUID%7D%22%20%3D%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20port's%20slave-type.%20If%20this%20is%20not%20an%20ovs-bridge%2C%20then%20exit%0APORT_OVS_SLAVE_TYPE%3D%24(nmcli%20-t%20-f%20connection.slave-type%20conn%20show%20%22%24%7BPORT_CONNECTION_UUID%7D%22%20%7C%20awk%20-F%20'%3A'%20'%7Bprint%20%24NF%7D')%0Aif%20%5B%20%22%24%7BPORT_OVS_SLAVE_TYPE%7D%22%20!%3D%20%22ovs-bridge%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20port's%20master.%20If%20it%20doesn't%20have%20any%2C%20assume%20it's%20not%20our%20bridge%0ABRIDGE_ID%3D%24(nmcli%20-t%20-f%20connection.master%20conn%20show%20%22%24%7BPORT_CONNECTION_UUID%7D%22%20%7C%20awk%20-F%20'%3A'%20'%7Bprint%20%24NF%7D')%0Aif%20%5B%20%22%24%7BBRIDGE_ID%7D%22%20%3D%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20bridge%20name%0ABRIDGE_NAME%3D%24(nmcli%20-t%20-f%20connection.interface-name%20conn%20show%20%22%24%7BBRIDGE_ID%7D%22%20%7C%20awk%20-F%20'%3A'%20'%7Bprint%20%24NF%7D')%0A%23%20Limit%20this%20to%20br-ex%20and%20br-ex1%20only.%20If%20one%20wanted%20to%20enable%20this%20for%20all%20OVS%20bridges%2C%0A%23%20the%20condition%20would%20be%3A%20if%20%5B%20%22%24BRIDGE_NAME%22%20%3D%3D%20%22%22%20%5D%3B%20then%0Aif%20%5B%20%22%24%7BBRIDGE_NAME%7D%22%20!%3D%20%22br-ex%22%20%5D%20%26%26%20%5B%20%22%24%7BBRIDGE_NAME%7D%22%20!%3D%20%22br-ex1%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Make%20sure%20that%20the%20interface%20is%20plugged%20into%20OVS%0A%23%20This%20should%20always%20be%20the%20case%20given%20that%20we%20are%20in%20pre-up%2C%20but%20exit%20gracefully%20in%20the%20odd%20case%20that%20it's%20not%0Aif%20!%20ovs-vsctl%20list%20interface%20%22%24%7BINTERFACE_NAME%7D%22%20%3E%2Fdev%2Fnull%202%3E%261%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0ACONFIGURATION_FILE%3D%22%2Frun%2Fofport_requests.%24%7BBRIDGE_NAME%7D%22%0A%0A%23%20Declare%20a%20new%20associative%20array.%20If%20CONFIGURATION_FILE%20exists%2C%20source%20entries%20from%20there%0Adeclare%20-A%20INTERFACES%0Aif%20%5B%20-f%20%22%24%7BCONFIGURATION_FILE%7D%22%20%5D%3B%20then%0A%20%20%20%20echo%20%22Sourcing%20configuration%20file%20'%24%7BCONFIGURATION_FILE%7D'%20with%20contents%3A%22%0A%20%20%20%20cat%20%22%24%7BCONFIGURATION_FILE%7D%22%0A%20%20%20%20source%20%22%24%7BCONFIGURATION_FILE%7D%22%0Afi%0A%0A%23%20get_interface_ofport_request%20will%20return%0A%23%20*%20either%3A%20the%20current%20ofport%20assignment%20for%20the%20port%20if%20no%20interface%20has%20claimed%20this%20ofport%20number%2C%20yet%0A%23%20*%20or%3A%20%20%20%20%20the%20lowest%20available%20free%20ofport%20number%0Afunction%20get_interface_ofport_request()%20%7B%0A%20%20%20%20%23%20Build%20an%20array%20that%20only%20contains%20the%20currently%20reserved%20ofport_requests%0A%20%20%20%20declare%20-A%20ofport_requests%0A%20%20%20%20for%20interface_name%20in%20%22%24%7B!INTERFACES%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20%20%20%20%20ofport_requests%5B%24%7BINTERFACES%5B%24interface_name%5D%7D%5D%3D%24%7BINTERFACES%5B%24interface_name%5D%7D%0A%20%20%20%20done%0A%0A%20%20%20%20%23%20Get%20the%20current%20ofport%20number%20assignment%0A%20%20%20%20local%20current_ofport%3D%24(ovs-vsctl%20get%20Interface%20%22%24%7BINTERFACE_NAME%7D%22%20ofport)%0A%0A%20%20%20%20%23%20If%20the%20current%20ofport%20number%20is%20still%20free%2C%20use%20it%0A%20%20%20%20if%20!%20%5B%20%22%24%7Bofport_requests%5B%24current_ofport%5D%2Ba%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%24current_ofport%0A%20%20%20%20%20%20%20%20return%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20If%20the%20current%20ofport%20number%20is%20not%20free%2C%20return%20the%20lowest%20free%20entry%0A%20%20%20%20i%3D0%0A%20%20%20%20for%20i%20in%20%7B1..65000%7D%3B%20do%0A%20%20%20%20%20%20%20%20if%20!%20%5B%20%22%24%7Bofport_requests%5B%24i%5D%2Ba%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20echo%20%24i%0A%20%20%20%20%20%20%20%20%20%20%20%20return%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20done%0A%0A%20%20%20%20%23%20if%20we%20still%20cannot%20find%20an%20ID%2C%20exit%20with%20an%20error%0A%20%20%20%20echo%20%22Impossible%20to%20find%20an%20ofport%20ID%20for%20interface%20%24%7BINTERFACE_NAME%7D%22%20%3E%262%0A%20%20%20%20exit%201%0A%7D%0A%0A%23%20If%20INTERFACES%5BINTERFACE_NAME%5D%20exists%2C%20use%20that%20value%0A%23%20If%20INTERFACES%5BINTERFACE_NAME%5D%20does%20not%20exists%2C%20use%20the%20value%20from%20get_interface_ofport_request%0Aif%20!%20%5B%20%22%24%7BINTERFACES%5B%24INTERFACE_NAME%5D%2Ba%7D%22%20%5D%3B%20then%0A%20%20%20%20INTERFACES%5B%24INTERFACE_NAME%5D%3D%24(get_interface_ofport_request)%0Afi%0A%23%20Set%20ofport_request%20according%20to%20INTERFACES%5BINTERFACE_NAME%5D%0Aovs-vsctl%20set%20Interface%20%22%24%7BINTERFACE_NAME%7D%22%20ofport_request%3D%24%7BINTERFACES%5B%24INTERFACE_NAME%5D%7D%0A%0A%23%20Save%20current%20state%20of%20INTERFACES%20to%20CONFIGURATION_FILE%0Adeclare%20-p%20INTERFACES%20%3E%7C%20%22%24%7BCONFIGURATION_FILE%7D%22%0A
          mode: 493
          overwrite: true
          path: /etc/NetworkManager/dispatcher.d/pre-up.d/10-ofport-request.sh
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%0A%23%20Extract%20Podman%20version%20and%20determine%20the%20signature%20policy%0A%2Fusr%2Fbin%2Fpodman%20-v%20%7C%20%2Fbin%2Fawk%20'%7B%0A%20%20%20%20split(%243%2C%20version%2C%20%22-%22)%3B%0A%20%20%20%20clean_version%20%3D%20version%5B1%5D%3B%0A%0A%20%20%20%20split(clean_version%2C%20current%2C%20%2F%5C.%2F)%3B%0A%20%20%20%20split(%224.4.1%22%2C%20target%2C%20%2F%5C.%2F)%3B%0A%0A%20%20%20%20for%20(i%20%3D%201%3B%20i%20%3C%3D%203%3B%20i%2B%2B)%20%7B%0A%20%20%20%20%20%20%20%20if%20((current%5Bi%5D%20%2B%200)%20%3C%20(target%5Bi%5D%20%2B%200))%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20print%20%22--signature-policy%20%2Fetc%2Fmachine-config-daemon%2Fpolicy-for-old-podman.json%22%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20exit%3B%0A%20%20%20%20%20%20%20%20%7D%20else%20if%20((current%5Bi%5D%20%2B%200)%20%3E%20(target%5Bi%5D%20%2B%200))%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20exit%3B%0A%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%7D%0A%7D'%20%3E%20%2Ftmp%2Fpodman_policy_args%0A
          mode: 493
          overwrite: true
          path: /etc/machine-config-daemon/generate_podman_policy_args.sh
        - contents:
            source: data:,%7B%22auths%22%3A%7B%22cloud.openshift.com%22%3A%7B%22auth%22%3A%22b3BlbnNoaWZ0LXJlbGVhc2UtZGV2K29jbV9hY2Nlc3NfOTRmZDViZTMwOTM3NGU5NDlkM2Q5NzhmOTQzZGFlYTI6TDc0UlozWjNEUUM1U0RFMjBUUUU3UDRZR1RNSDRIRUdMUkMySzk3MjJMSE1PMlBPVUNaUDJFVVo0UDc1N1RLQw%3D%3D%22%2C%22email%22%3A%22jgoldberg%40allcovered.com%22%7D%2C%22quay.io%22%3A%7B%22auth%22%3A%22b3BlbnNoaWZ0LXJlbGVhc2UtZGV2K29jbV9hY2Nlc3NfOTRmZDViZTMwOTM3NGU5NDlkM2Q5NzhmOTQzZGFlYTI6TDc0UlozWjNEUUM1U0RFMjBUUUU3UDRZR1RNSDRIRUdMUkMySzk3MjJMSE1PMlBPVUNaUDJFVVo0UDc1N1RLQw%3D%3D%22%2C%22email%22%3A%22jgoldberg%40allcovered.com%22%7D%2C%22registry.connect.redhat.com%22%3A%7B%22auth%22%3A%22fHVoYy1wb29sLTljZTJiZWU4LTUwYWQtNDVlNC04NDExLTNkNjQ1NWNkODI1NjpleUpoYkdjaU9pSlNVelV4TWlKOS5leUp6ZFdJaU9pSTNaakppTldOallXWXhZVEEwWXpZMVlUSTFaRGN6TjJSa05UVXlNbVJqWWlKOS5NZHFkUUgzenYyMHFzQ0dfR2hGYy1WSzFRNGRsOW05TFhqcmhQNjNjUDh0dDVGX25Wc1U5NGxlcmVVSEQ4R1FXRUxDZlIzeE5HQ2dOSXFPNWUyNC02U3NGOFNTQV9RSnZIODVzLTBBWXlWMHY2QnJxV21CRHNLSWdnSzE2SFhWUzd4cTlSZ05hN200RFRMdUF2RUdtVkRSQ05VUVNFN1FMTWMxaUVhSVI4RVdrT0pPUklQd3hQM3YyUDlsTHpSRWtKYl82WVRjUWRjQUR3T0d1OWkzUHIwMWRHX1d4QU90NkFxcFZBX0JSaHRhNFRjWTFwSHk1bXBlWWVIVnE3Q3hzZWFRV3FzR01Oc0lObkFFNGdjV0MyekVXVl9NZHpIQXVad203WWsxMjg5VVhfYnhVMWhDUkVzdG5zdGdCSERheFRpSTFjalZSZkJ4X05hb0RMU01GVXBzNmlDVXhTTUxzVmc3Mi04LVJHal9nVmMxRDZPNjJkODJoakdaaW5HekJsendzMkZLYlFnNDRjb1VWcWpDdUMwdktCdVJRbDhkX0taVGZTWFVSTS0wOE91YjBNdDRIMjVjZmx6bjNERWdDcUtlSVlUYVdMS3ZranRKVy1MaGdLRjlDUHFqWmozUjhwN2xja2ZkR0lPbHRvY0hZY0xXVlM3QURjdmRNaWVLa3p5STRHb2RPamp2NU5OVF9UWDdjRHBRRVdWUnlENkxkOElXODA4SHVoSmtfa2R0MWVDSkxSTTVUdFBSRHVxZ3UwODlqcWM4WXRVWFhfcm9KcFhoSE5iMUlnekZTdFJqZktTSVJ6YTdlV2g4VWxvRmNwNXJZOV9VeDFTaFVnZ3JlQXFmQ1Y4NXF5Wjlya2RibVNZUE5PRVdzTmtUeGJoY0Q4YWpkYlJrWkFCRQ%3D%3D%22%2C%22email%22%3A%22jgoldberg%40allcovered.com%22%7D%2C%22registry.redhat.io%22%3A%7B%22auth%22%3A%22fHVoYy1wb29sLTljZTJiZWU4LTUwYWQtNDVlNC04NDExLTNkNjQ1NWNkODI1NjpleUpoYkdjaU9pSlNVelV4TWlKOS5leUp6ZFdJaU9pSTNaakppTldOallXWXhZVEEwWXpZMVlUSTFaRGN6TjJSa05UVXlNbVJqWWlKOS5NZHFkUUgzenYyMHFzQ0dfR2hGYy1WSzFRNGRsOW05TFhqcmhQNjNjUDh0dDVGX25Wc1U5NGxlcmVVSEQ4R1FXRUxDZlIzeE5HQ2dOSXFPNWUyNC02U3NGOFNTQV9RSnZIODVzLTBBWXlWMHY2QnJxV21CRHNLSWdnSzE2SFhWUzd4cTlSZ05hN200RFRMdUF2RUdtVkRSQ05VUVNFN1FMTWMxaUVhSVI4RVdrT0pPUklQd3hQM3YyUDlsTHpSRWtKYl82WVRjUWRjQUR3T0d1OWkzUHIwMWRHX1d4QU90NkFxcFZBX0JSaHRhNFRjWTFwSHk1bXBlWWVIVnE3Q3hzZWFRV3FzR01Oc0lObkFFNGdjV0MyekVXVl9NZHpIQXVad203WWsxMjg5VVhfYnhVMWhDUkVzdG5zdGdCSERheFRpSTFjalZSZkJ4X05hb0RMU01GVXBzNmlDVXhTTUxzVmc3Mi04LVJHal9nVmMxRDZPNjJkODJoakdaaW5HekJsendzMkZLYlFnNDRjb1VWcWpDdUMwdktCdVJRbDhkX0taVGZTWFVSTS0wOE91YjBNdDRIMjVjZmx6bjNERWdDcUtlSVlUYVdMS3ZranRKVy1MaGdLRjlDUHFqWmozUjhwN2xja2ZkR0lPbHRvY0hZY0xXVlM3QURjdmRNaWVLa3p5STRHb2RPamp2NU5OVF9UWDdjRHBRRVdWUnlENkxkOElXODA4SHVoSmtfa2R0MWVDSkxSTTVUdFBSRHVxZ3UwODlqcWM4WXRVWFhfcm9KcFhoSE5iMUlnekZTdFJqZktTSVJ6YTdlV2g4VWxvRmNwNXJZOV9VeDFTaFVnZ3JlQXFmQ1Y4NXF5Wjlya2RibVNZUE5PRVdzTmtUeGJoY0Q4YWpkYlJrWkFCRQ%3D%3D%22%2C%22email%22%3A%22jgoldberg%40allcovered.com%22%7D%7D%7D%0A
          mode: 384
          overwrite: true
          path: /var/lib/kubelet/config.json
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-eo%20pipefail%0A%0Afunction%20pull_baremetal_runtime_cfg_image%20%7B%0A%20%20%20%20%23%20By%20default%20podman%20retries%20to%20pull%20an%20image%203%20times%20with%201%20second%20back-off.%20It%20is%20not%20configurable.%20For%20this%0A%20%20%20%20%23%20reason%20we%20are%20implementing%20our%20own%20logic%20of%20pulling%20image%20and%20retrying%20indefinitely.%0A%20%20%20%20%23%20Ref.%3A%20https%3A%2F%2Fgithub.com%2Fcontainers%2Fcommon%2Fblob%2Fe028741ef77fdfa3ae261b9d23cdd50253d586c4%2Flibimage%2Fcopier.go%23L27-L30%0A%0A%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Checking%20if%20baremetal%20runtime%20cfg%20image%20already%20exists%22%0A%20%20%20%20if%20!%20%2Fusr%2Fbin%2Fpodman%20image%20exists%20%22quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A93e7b8c870261726d44bddc7ba0a702d3720d1838141dac837fb8c3be7c6e1a1%22%3B%20then%0A%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Starting%20download%20of%20baremetal%20runtime%20cfg%20image%22%0A%20%20%20%20%20%20while%20!%20%2Fusr%2Fbin%2Fpodman%20pull%20--authfile%20%2Fvar%2Flib%2Fkubelet%2Fconfig.json%20%22quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A93e7b8c870261726d44bddc7ba0a702d3720d1838141dac837fb8c3be7c6e1a1%22%3B%20do%20sleep%201%3B%20done%0A%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Download%20of%20baremetal%20runtime%20cfg%20image%20completed%22%0A%20%20%20%20else%0A%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Image%20exists%2C%20no%20need%20to%20download%22%0A%20%20%20%20fi%0A%7D%0A%0Afunction%20resolv_prepender%20%7B%0A%20%20%20%20%20%20%20%20%23%20In%20DHCP%20connections%2C%20the%20resolv.conf%20content%20may%20be%20late%2C%20thus%20we%20wait%20for%20nameservers%0A%20%20%20%20%20%20%20%20while%20!%20grep%20nameserver%20%2Fvar%2Frun%2FNetworkManager%2Fresolv.conf%3B%20do%0A%20%20%20%20%20%20%20%20%20%20%20%20%3E%262%20echo%20%20%22NM%20resolv-prepender%3A%20NM%20resolv.conf%20still%20empty%20of%20nameserver%22%0A%20%20%20%20%20%20%20%20%20%20%20%20sleep%200.5%0A%20%20%20%20%20%20%20%20done%0A%0A%20%20%20%20%20%20%20%20%23%20Ensure%20resolv.conf%20exists%20and%20contains%20nameservers%20before%20we%20try%20to%20pull%20image%20or%20run%20podman%0A%20%20%20%20%20%20%20%20if%20%5B%5B%20!%20-e%20%2Fetc%2Fresolv.conf%20%5D%5D%20%7C%7C%20!%20grep%20-q%20nameserver%20%2Fetc%2Fresolv.conf%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20cp%20%2Fvar%2Frun%2FNetworkManager%2Fresolv.conf%20%2Fetc%2Fresolv.conf%0A%20%20%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20%20%20%23%20Ensure%20baremetalRuntimeCfgImage%20is%20pulled%20in%20a%20reliable%20way%20before%20trying%20to%20use%20it%0A%20%20%20%20%20%20%20%20%23%20in%20the%20subsequent%20code%0A%20%20%20%20%20%20%20%20pull_baremetal_runtime_cfg_image%0A%0A%20%20%20%20%20%20%20%20NAMESERVER_IP%3D%22%24(%2Fusr%2Fbin%2Fpodman%20run%20--rm%20%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20--authfile%20%2Fvar%2Flib%2Fkubelet%2Fconfig.json%20%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20--net%3Dhost%20%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A93e7b8c870261726d44bddc7ba0a702d3720d1838141dac837fb8c3be7c6e1a1%20%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20node-ip%20%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20show%20%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%2210.100.0.50%22%20%20%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%2210.100.0.51%22%20)%22%0A%20%20%20%20%20%20%20%20DOMAINS%3D%22%24%7BIP4_DOMAINS%3A-%7D%20%24%7BIP6_DOMAINS%3A-%7D%20comp-poc-rh01.rhpoc.int%22%0A%20%20%20%20%20%20%20%20if%20%5B%5B%20-n%20%22%24NAMESERVER_IP%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20KNICONFDONEPATH%3D%22%2Frun%2Fresolv-prepender-kni-conf-done%22%0A%20%20%20%20%20%20%20%20%20%20%20%20if%20systemctl%20-q%20is-enabled%20systemd-resolved%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Configure%20for%20OKD%20domain%20and%20local%20IP%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20mkdir%20-p%20%2Fetc%2Fsystemd%2Fresolved.conf.d%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20KNICONFTMPPATH%3D%22%24(mktemp)%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20KNICONFPATH%3D%22%2Fetc%2Fsystemd%2Fresolved.conf.d%2F60-kni.conf%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20echo%20%22%5BResolve%5D%22%20%3E%20%22%24%7BKNICONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20echo%20%22DNS%3D%24NAMESERVER_IP%22%20%3E%3E%20%22%24%7BKNICONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20echo%20%22Domains%3D%24%7BDOMAINS%7D%22%20%3E%3E%20%22%24%7BKNICONFTMPPATH%7D%22%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20If%20KNI%20conf%20is%20not%20created%20or%20doesn't%20match%20what%20is%20generated%20or%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20if%20we%20haven't%20completed%20a%20full%20update%20-%20create%20or%20update%20it%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20%5B%5B%20!%20-f%20%22%24%7BKNICONFPATH%7D%22%20%5D%5D%20%7C%7C%20%5B%5B%20!%20-f%20%22%24%7BKNICONFDONEPATH%7D%22%20%5D%5D%20%7C%7C%20!%20cmp%20--silent%20%22%24%7BKNICONFPATH%7D%22%20%22%24%7BKNICONFTMPPATH%7D%22%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Creating%2Fupdating%20%2Fetc%2Fsystemd%2Fresolved.conf.d%2F60-kni.conf%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Remove%20the%20done%20file%20flag%20before%20writing%20the%20config%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20This%20would%20guard%20against%20interruptions%20and%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20prevent%20double%20restart%20of%20systemd-resolved%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20rm%20-f%20%22%24%7BKNICONFDONEPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Copy%20tmp%20file%20contents%20to%20preserve%20permissions%20and%20SELinux%20label%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20cat%20%22%24%7BKNICONFTMPPATH%7D%22%20%3E%20%22%24%7BKNICONFPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20%5B%5B%20!%20-f%20%22%24%7BKNICONFDONEPATH%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20systemctl%20-q%20is-active%20systemd-resolved%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Restarting%20systemd-resolved%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20systemctl%20restart%20systemd-resolved%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20touch%20%22%24%7BKNICONFDONEPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20rm%20-rf%20%22%24%7BKNICONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Prepending%20'nameserver%20%24NAMESERVER_IP'%20to%20%2Fetc%2Fresolv.conf%20(other%20nameservers%20from%20%2Fvar%2Frun%2FNetworkManager%2Fresolv.conf)%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20RESOLVCONFTMPPATH%3D%22%24(mktemp)%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20sed%20-e%20%22%2FGenerated%20by%2Fc%23%20Generated%20by%20KNI%20resolv%20prepender%20NM%20dispatcher%20script%22%20%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%2Fvar%2Frun%2FNetworkManager%2Fresolv.conf%20%3E%20%22%24%7BRESOLVCONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20sed%20-i%20%220%2C%2F%5Enameserver.*%2Fs%2F%2Fnameserver%20%24NAMESERVER_IP%5Cn%5C0%2F%22%20%22%24%7BRESOLVCONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20!%20grep%20-q%20search%20%22%24%7BRESOLVCONFTMPPATH%7D%22%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Make%20sure%20we%20have%20a%20search%20entry%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20echo%20%22search%20comp-poc-rh01.rhpoc.int%22%20%3E%3E%20%22%24%7BRESOLVCONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Make%20sure%20cluster%20domain%20is%20first%20in%20the%20search%20list%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20sed%20-i%20%22s%2F%5Esearch%20%5C(.*%5C)%2Fsearch%20comp-poc-rh01.rhpoc.int%20%5C1%2F%22%20%22%24%7BRESOLVCONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Remove%20duplicate%20cluster%20domain%20entries%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20sed%20-i%20%22s%2F%5C(search%20comp-poc-rh01.rhpoc.int.*%5C)%20comp-poc-rh01.rhpoc.int%5C(%20.*%5C%7C%24%5C)%2F%5C1%5C2%2F%22%20%22%24%7BRESOLVCONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Only%20leave%20the%20first%203%20nameservers%20in%20%2Fetc%2Fresolv.conf%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20sed%20-i%20'%3Aa%20%24!%7BN%3B%20ba%7D%3B%20s%2F%5C(%5E%5C%7C%5Cn%5C)nameserver%2F%5Cn%23%20nameserver%2F4g'%20%22%24%7BRESOLVCONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Only%20touch%20existing%20resolv.conf%20if%20files%20actually%20differ%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20!%20cmp%20-s%20%22%24%7BRESOLVCONFTMPPATH%7D%22%20%2Fetc%2Fresolv.conf%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20chmod%20644%20%22%24%7BRESOLVCONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20mv%20-Zf%20%22%24%7BRESOLVCONFTMPPATH%7D%22%20%2Fetc%2Fresolv.conf%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Workaround%20for%20bz%201929160.%20Reload%20NetworkManager%20to%20force%20it%20to%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20re-run%20the%20lookup%20of%20the%20hostname%20now%20that%20we%20know%20we%20have%20DNS%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20servers%20configured%20correctly%20in%20resolv.conf.%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20nmcli%20general%20reload%20dns-rc%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20touch%20%22%24%7BKNICONFDONEPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20rm%20-rf%20%22%24%7BRESOLVCONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20fi%0A%7D%0A%0Aresolv_prepender%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/resolv-prepender.sh
        - contents:
            source: data:,%23%20Needed%20by%20the%20OpenShift%20SDN.%20See%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1758552%0Anet.ipv4.conf.all.arp_announce%20%3D%202%0A
          mode: 420
          overwrite: true
          path: /etc/sysctl.d/arp.conf
        - contents:
            source: data:,%23%20See%3A%20rhbz%231384746%2C%20OCPBUGS-24012%0Anet.ipv4.neigh.default.gc_thresh1%3D8192%0Anet.ipv4.neigh.default.gc_thresh2%3D32768%0Anet.ipv4.neigh.default.gc_thresh3%3D65536%0Anet.ipv6.neigh.default.gc_thresh1%3D8192%0Anet.ipv6.neigh.default.gc_thresh2%3D32768%0Anet.ipv6.neigh.default.gc_thresh3%3D65536%0A
          mode: 420
          overwrite: true
          path: /etc/sysctl.d/gc-thresh.conf
        - contents:
            source: data:,%0Afs.inotify.max_user_watches%20%3D%2065536%0Afs.inotify.max_user_instances%20%3D%208192%0A
          mode: 420
          overwrite: true
          path: /etc/sysctl.d/inotify.conf
        - contents:
            source: data:,vm.unprivileged_userfaultfd%20%3D%201
          mode: 420
          overwrite: true
          path: /etc/sysctl.d/enable-userfaultfd.conf
        - contents:
            source: data:,%23%20Needed%20for%20OpenShift%20Logging%20(ElasticSearch).%20See%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1793714%0Avm.max_map_count%20%3D%20262144%0A
          mode: 420
          overwrite: true
          path: /etc/sysctl.d/vm-max-map.conf
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-euo%20pipefail%0A%0A%23%20First%2C%20we%20need%20to%20wait%20until%20DHCP%20finishes%20and%20the%20node%20has%20a%20non-%60localhost%60%0A%23%20hostname%20before%20%60kubelet.service%60%20starts.%0A%23%20That's%20the%20%60--wait%60%20argument%20as%20used%20by%20%60node-valid-hostname.service%60.%0A%23%0A%23%20Second%2C%20on%20GCP%20specifically%20we%20truncate%20the%20hostname%20if%20it's%20%3E63%20characters.%0A%23%20That's%20%60gcp-hostname.service%60.%0A%0A%23%20Block%20indefinitely%20until%20the%20host%20gets%20a%20non-localhost%20name.%0A%23%20Note%20node-valid-hostname.service%20uses%20systemd%20to%20abort%20if%20this%20takes%20too%20long.%0Await_localhost()%20%7B%0A%20%20%20%20echo%20%22waiting%20for%20non-localhost%20hostname%20to%20be%20assigned%22%0A%20%20%20%20while%20%5B%5B%20%22%24(%3C%20%2Fproc%2Fsys%2Fkernel%2Fhostname)%22%20%3D~%20(localhost%7Clocalhost.localdomain)%20%5D%5D%3B%0A%20%20%20%20do%0A%20%20%20%20%20%20%20%20sleep%201%0A%20%20%20%20done%0A%20%20%20%20echo%20%22node%20identified%20as%20%24(%3C%2Fproc%2Fsys%2Fkernel%2Fhostname)%22%0A%20%20%20%20echo%20%22saving%20hostname%20to%20prevent%20NetworkManager%20from%20ever%20unsetting%20it%22%0A%20%20%20%20hostnamectl%20set-hostname%20--static%20--transient%20%24(%3C%2Fproc%2Fsys%2Fkernel%2Fhostname)%0A%20%20%20%20exit%200%0A%7D%0A%0Aset_gcp_hostname()%20%7B%0A%20%20%20%20%2Fusr%2Fbin%2Fafterburn%20--provider%20gcp%20--hostname%3D%2Frun%2Fafterburn.hostname%0A%0A%20%20%20%20local%20host_name%3D%24(cat%20%2Frun%2Fafterburn.hostname)%0A%20%20%20%20local%20type_arg%3D%22transient%22%0A%0A%20%20%20%20%23%20%2Fetc%2Fhostname%20is%20used%20for%20static%20hostnames%20and%20is%20authoritative.%0A%20%20%20%20%23%20This%20will%20check%20to%20make%20sure%20that%20the%20static%20hostname%20is%20the%0A%20%20%20%20%23%20less%20than%20or%20equal%20to%2063%20characters%20in%20length.%0A%20%20%20%20if%20%5B%20-f%20%2Fetc%2Fhostname%20%5D%20%26%26%20%5B%20%22%24(cat%20%2Fetc%2Fhostname%20%7C%20wc%20-m)%22%20-gt%200%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20etc_name%3D%22%24(%3C%20%2Fetc%2Fhostname)%22%0A%20%20%20%20%20%20%20%20type_arg%3D%22static%22%0A%20%20%20%20%20%20%20%20if%20%5B%20%22%24%7Betc_name%7D%22%20!%3D%20%22%24%7Bhost_name%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20echo%20%22%2Fetc%2Fhostname%20is%20set%20to%20%24%7Betc_name%7D%20but%20does%20not%20match%20%24%7Bhost_name%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20echo%20%22using%20%2Fetc%2Fhostname%20as%20the%20authoritative%20name%22%0A%20%20%20%20%20%20%20%20%20%20%20%20host_name%3D%22%24%7Betc_name%7D%22%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Only%20mutate%20the%20hostname%20if%20the%20length%20is%20longer%20than%2063%20characters.%20The%0A%20%20%20%20%23%20hostname%20will%20be%20the%20lesser%20of%2063%20characters%20after%20the%20first%20dot%20in%20the%0A%20%20%20%20%23%20FQDN.%20%20This%20algorithm%20is%20only%20known%20to%20work%20in%20GCP%2C%20and%20hence%20is%20only%0A%20%20%20%20%23%20executed%20in%20GCP.%0A%20%20%20%20if%20%5B%20%22%24%7B%23host_name%7D%22%20-gt%2063%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20alt_name%3D%24(printf%20%22%24%7Bhost_name%7D%22%20%7C%20cut%20-f1%20-d'.'%20%7C%20cut%20-c%20-63)%0A%20%20%20%20%20%20%20%20echo%20%22%24%7Bhost_name%7D%20is%20longer%20than%2063%20characters%2C%20using%20truncated%20hostname%22%0A%20%20%20%20%20%20%20%20host_name%3D%22%24%7Balt_name%7D%22%0A%20%20%20%20fi%0A%20%20%20%20echo%20%22setting%20%24%7Btype_arg%7D%20hostname%20to%20%24%7Bhost_name%7D%22%0A%20%20%20%20%2Fbin%2Fhostnamectl%20%22--%24%7Btype_arg%7D%22%20set-hostname%20%22%24%7Bhost_name%7D%22%0A%20%20%20%20exit%200%0A%7D%0A%0Aset_openstack_hostname()%20%7B%0A%20%20%20%20%23%20Read%20metadata%20written%20by%20afterburn%20service%0A%20%20%20%20.%20%2Frun%2Fmetadata%2Fafterburn%0A%0A%20%20%20%20%23%20node-valid-hostname%20sets%20persistent%20hostname%20from%20%2Fproc%2Fsys%2Fkernel%2Fhostname%0A%20%20%20%20echo%20%22%24AFTERBURN_OPENSTACK_HOSTNAME%22%20%3E%20%2Fproc%2Fsys%2Fkernel%2Fhostname%0A%7D%0A%0Aset_powervs_hostname()%20%7B%0A%20%20%20%20%23%20Read%20metadata%20written%20by%20afterburn%20service%0A%20%20%20%20.%20%2Frun%2Fmetadata%2Fafterburn%0A%0A%20%20%20%20%23%20node-valid-hostname%20sets%20persistent%20hostname%20from%20%2Fproc%2Fsys%2Fkernel%2Fhostname%0A%20%20%20%20echo%20%22%24AFTERBURN_POWERVS_LOCAL_HOSTNAME%22%20%3E%20%2Fproc%2Fsys%2Fkernel%2Fhostname%0A%7D%0A%0Aarg%3D%24%7B1%7D%3B%20shift%3B%0Acase%20%22%24%7Barg%7D%22%20in%0A%20%20%20%20--wait)%20wait_localhost%3B%3B%0A%20%20%20%20--gcp)%20set_gcp_hostname%3B%3B%0A%20%20%20%20--openstack)%20set_openstack_hostname%3B%3B%0A%20%20%20%20--powervs)%20set_powervs_hostname%3B%3B%0A%20%20%20%20*)%20echo%20%22Unhandled%20arg%20%24arg%22%3B%20exit%201%0Aesac%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/mco-hostname
        - contents:
            source: data:,
          mode: 493
          overwrite: true
          path: /etc/kubernetes/kubelet-plugins/volume/exec/.dummy
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%23%20Workaround%3A%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1941714%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1935539%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1987108%0A%0Adriver%3D%24(nmcli%20-t%20-m%20tabular%20-f%20general.driver%20dev%20show%20%22%24%7BDEVICE_IFACE%7D%22)%0A%0Aif%20%5B%5B%20%22%242%22%20%3D%3D%20%22up%22%20%26%26%20%22%24%7Bdriver%7D%22%20%3D%3D%20%22vmxnet3%22%20%5D%5D%3B%20then%0A%20%20logger%20-s%20%2299-vsphere-disable-tx-udp-tnl%20triggered%20by%20%24%7B2%7D%20on%20device%20%24%7BDEVICE_IFACE%7D.%22%0A%20%20ethtool%20-K%20%24%7BDEVICE_IFACE%7D%20tx-udp_tnl-segmentation%20off%0A%20%20ethtool%20-K%20%24%7BDEVICE_IFACE%7D%20tx-udp_tnl-csum-segmentation%20off%0A%20%20ethtool%20-K%20%24%7BDEVICE_IFACE%7D%20tx-checksum-ip-generic%20off%0Afi%0A
          mode: 484
          overwrite: true
          path: /etc/NetworkManager/dispatcher.d/99-vsphere-disable-tx-udp-tnl
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%0Auntil%20%5B%20-e%20%2Frun%2Fnodeip-configuration%2Fbr-ex-up%20%5D%0Ado%0A%20%20sleep%201%0Adone%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/wait-for-br-ex-up.sh
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-x%0A%0Aif%20%5B%20!%20-e%20%22%2Fetc%2Fipsec.d%2Fopenshift.conf%22%20%5D%3B%20then%0A%20%20exit%200%0Afi%0A%0A%23%20Modify%20existing%20IPsec%20connection%20entries%20with%20%22auto%3Dstart%22%0A%23%20option%20and%20restart%20ipsec%20systemd%20service.%20This%20helps%20to%0A%23%20establish%20IKE%20SAs%20for%20the%20existing%20IPsec%20connections%20with%0A%23%20peer%20nodes.%20This%20option%20will%20be%20deleted%20from%20connections%0A%23%20once%20ovs-monitor-ipsec%20process%20spinned%20up%20on%20the%20node%20by%0A%23%20ovn-ipsec-host%20pod%2C%20but%20still%20it%20won't%20reestablish%20IKE%20SAs%0A%23%20again%20with%20peer%20nodes%2C%20so%20it%20shouldn't%20be%20a%20problem.%0Aif%20!%20grep%20-q%20%22auto%3Dstart%22%20%2Fetc%2Fipsec.d%2Fopenshift.conf%3B%20then%0A%20%20sed%20-i%20'%2F%5E.*conn%20ovn.*%24%2Fa%5C%20%20%20%20auto%3Dstart'%20%2Fetc%2Fipsec.d%2Fopenshift.conf%0Afi%0Achroot%20%2Fproc%2F1%2Froot%20ipsec%20restart%0A%0A%23%20Wait%20for%20upto%2060s%20to%20get%20IPsec%20SAs%20to%20establish%20with%20peer%20nodes.%0Atimeout%3D60%0Aelapsed%3D0%0Adesiredconn%3D%22%22%0Aestablishedsa%3D%22%22%0Awhile%20%5B%5B%20%24elapsed%20-lt%20%24timeout%20%5D%5D%3B%20do%0A%20%20desiredconn%3D%24(grep%20-E%20'%5E%5Cs*conn%5Cs%2B'%20%2Fetc%2Fipsec.d%2Fopenshift.conf%20%7C%20grep%20-v%20'%25default'%20%7C%20awk%20'%7Bprint%20%242%7D'%20%7C%20tr%20'%20'%20'%5Cn'%20%7C%20sort%20%7C%20tr%20'%5Cn'%20'%20')%0A%20%20establishedsa%3D%24(ipsec%20showstates%20%7C%20grep%20STATE_V2_ESTABLISHED_CHILD_SA%20%7C%20grep%20-o%20'%22%5B%5E%22%5D*%22'%20%7C%20sed%20's%2F%22%2F%2Fg'%20%7C%20tr%20'%20'%20'%5Cn'%20%7C%20sort%20%7C%20uniq%20%7C%20tr%20'%5Cn'%20'%20')%0A%20%20if%20%5B%20%22%24desiredconn%22%20%3D%3D%20%22%24establishedsa%22%20%5D%3B%20then%0A%20%20%20%20echo%20%22IPsec%20SAs%20are%20established%20for%20desired%20connections%20after%20%24%7Belapsed%7Ds%22%0A%20%20%20%20break%0A%20%20else%0A%20%20%20%20echo%20%22IPsec%20SAs%20are%20not%20established%20yet%2C%20total%20waited%20time%20%24%7Belapsed%7Ds%22%0A%20%20%20%20sleep%202s%0A%20%20fi%0A%20%20elapsed%3D%24((elapsed%20%2B%202))%0Adone%0A%0Aif%20%5B%5B%20%24elapsed%20-ge%20%24timeout%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22Timed%20out%20waiting%2C%20some%20connections%20are%20not%20established%2C%20desired%20conns%20%24desiredconn%2C%20established%20conns%20%24establishedsa%22%0Afi%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/ipsec-connect-wait.sh
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-eux%0A%0Aif%20%5B%20!%20-e%20%2Fetc%2Fnmstate%2Fopenshift%2Fapplied%20%5D%3B%20then%0A%20%20%23%20No%20need%20to%20do%20this%20if%20no%20NMState%20configuration%20was%20applied%0A%20%20exit%200%0Afi%0A%0A%23%20This%20logic%20is%20borrowed%20from%20configure-ovs.sh%0A%23%20TODO%3A%20Find%20a%20platform-agnostic%20way%20to%20do%20this.%20It%20won't%20work%20on%20platforms%20where%0A%23%20nodeip-configuration%20is%20not%20used.%0Aip%3D%24(cat%20%2Frun%2Fnodeip-configuration%2Fprimary-ip)%0Aif%20%5B%5B%20%22%24%7Bip%7D%22%20%3D%3D%20%22%22%20%5D%5D%3B%20then%0A%20%20echo%20%22No%20ip%20to%20bind%20was%20found%22%0A%20%20exit%201%0Afi%0Awhile%20%3A%0Ado%0A%20%20random_port%3D%24(shuf%20-i%2050000-60000%20-n%201)%0A%20%20echo%20%22Trying%20to%20bind%20%24%7Bip%7D%20on%20port%20%24%7Brandom_port%7D%22%0A%20%20exit_code%3D%24(timeout%202s%20nc%20-l%20%22%24%7Bip%7D%22%20%24%7Brandom_port%7D%3B%20echo%20%24%3F)%0A%20%20if%20%5B%5B%20exit_code%20-eq%20124%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22Address%20bound%20successfully%22%0A%20%20%20%20exit%200%0A%20%20fi%0A%20%20sleep%2010%0Adone%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/wait-for-primary-ip.sh
        - contents:
            source: data:,unqualified-search-registries%20%3D%20%5B'registry.access.redhat.com'%2C%20'docker.io'%5D%0A
          mode: 420
          overwrite: true
          path: /etc/containers/registries.conf
        - contents:
            source: data:,%5Bcrio%5D%0Ainternal_wipe%20%3D%20true%0Ainternal_repair%20%3D%20true%0A%0A%5Bcrio.api%5D%0Astream_address%20%3D%20%22127.0.0.1%22%0Astream_port%20%3D%20%220%22%0A%0A%5Bcrio.runtime%5D%0Aselinux%20%3D%20true%0Aconmon%20%3D%20%22%22%0Aconmon_cgroup%20%3D%20%22pod%22%0Adefault_env%20%3D%20%5B%0A%20%20%20%20%22NSS_SDB_USE_CACHE%3Dno%22%2C%0A%5D%0Alog_level%20%3D%20%22info%22%0Acgroup_manager%20%3D%20%22systemd%22%0Adefault_sysctls%20%3D%20%5B%0A%20%20%20%20%22net.ipv4.ping_group_range%3D0%202147483647%22%2C%0A%5D%0Adefault_runtime%20%3D%20%22crun%22%0Ahooks_dir%20%3D%20%5B%0A%20%20%20%20%22%2Fetc%2Fcontainers%2Foci%2Fhooks.d%22%2C%0A%20%20%20%20%22%2Frun%2Fcontainers%2Foci%2Fhooks.d%22%2C%0A%20%20%20%20%22%2Fusr%2Fshare%2Fcontainers%2Foci%2Fhooks.d%22%2C%0A%5D%0Amanage_ns_lifecycle%20%3D%20true%0Aabsent_mount_sources_to_reject%20%3D%20%5B%0A%20%20%20%20%22%2Fetc%2Fhostname%22%2C%0A%5D%0Adrop_infra_ctr%20%3D%20true%0A%0A%5Bcrio.runtime.runtimes.runc%5D%0Aruntime_root%20%3D%20%22%2Frun%2Frunc%22%0Aallowed_annotations%20%3D%20%5B%0A%20%20%20%20%22io.containers.trace-syscall%22%2C%0A%20%20%20%20%22io.kubernetes.cri-o.Devices%22%2C%0A%20%20%20%20%22io.kubernetes.cri-o.LinkLogs%22%2C%0A%5D%0A%0A%5Bcrio.runtime.runtimes.crun%5D%0Aruntime_root%20%3D%20%22%2Frun%2Fcrun%22%0Aallowed_annotations%20%3D%20%5B%0A%20%20%20%20%22io.containers.trace-syscall%22%2C%0A%20%20%20%20%22io.kubernetes.cri-o.Devices%22%2C%0A%20%20%20%20%22io.kubernetes.cri-o.LinkLogs%22%2C%0A%5D%0A%23%20Based%20on%20https%3A%2F%2Fgithub.com%2Fcontainers%2Fcrun%2Fblob%2F27d7dd3a0%2FREADME.md%3Fplain%3D1%23L48%0Acontainer_min_memory%20%3D%20%22512KiB%22%0Adefault_annotations%20%3D%20%7B%22run.oci.systemd.subgroup%22%20%3D%20%22%22%7D%0A%0A%5Bcrio.runtime.workloads.openshift-builder%5D%0Aactivation_annotation%20%3D%20%22io.openshift.builder%22%0Aallowed_annotations%20%3D%20%5B%0A%20%20%22io.kubernetes.cri-o.userns-mode%22%2C%0A%20%20%22io.kubernetes.cri-o.Devices%22%0A%5D%0A%5Bcrio.runtime.workloads.openshift-builder.resources%5D%0A%0A%5Bcrio.image%5D%0Aglobal_auth_file%20%3D%20%22%2Fvar%2Flib%2Fkubelet%2Fconfig.json%22%0Apause_image%20%3D%20%22quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A2f61599219ee63c77391e05d2e02a8a5baae1c463d0ef965c49a5c470546db90%22%0Apause_image_auth_file%20%3D%20%22%2Fvar%2Flib%2Fkubelet%2Fconfig.json%22%0Apause_command%20%3D%20%22%2Fusr%2Fbin%2Fpod%22%0A%0A%5Bcrio.network%5D%0Anetwork_dir%20%3D%20%22%2Fetc%2Fkubernetes%2Fcni%2Fnet.d%2F%22%0Aplugin_dirs%20%3D%20%5B%0A%20%20%20%20%22%2Fvar%2Flib%2Fcni%2Fbin%22%2C%0A%20%20%20%20%22%2Fusr%2Flibexec%2Fcni%22%2C%0A%5D%0A%0A%5Bcrio.metrics%5D%0Aenable_metrics%20%3D%20true%0Ametrics_host%20%3D%20%22127.0.0.1%22%0Ametrics_port%20%3D%209537%0Ametrics_collectors%20%3D%20%5B%0A%20%20%22operations%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22operations_total%22%0A%20%20%22operations_latency_microseconds_total%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22operations_latency_seconds_total%22%0A%20%20%22operations_latency_microseconds%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22operations_latency_seconds%22%0A%20%20%22operations_errors%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22operations_errors_total%22%0A%20%20%22image_pulls_layer_size%22%2C%0A%20%20%22containers_oom_total%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22containers_oom_count_total%22%0A%20%20%22containers_oom%22%2C%0A%20%20%23%20Drop%20metrics%20with%20excessive%20label%20cardinality.%0A%20%20%23%20%22image_pulls_by_digest%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_pulls_bytes_total%22%0A%20%20%23%20%22image_pulls_by_name%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_pulls_bytes_total%22%0A%20%20%23%20%22image_pulls_by_name_skipped%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_pulls_skipped_bytes_total%22%0A%20%20%23%20%22image_pulls_failures%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_pulls_failure_total%22%0A%20%20%23%20%22image_pulls_successes%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_pulls_success_total%22%0A%20%20%23%20%22image_layer_reuse%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_layer_reuse_total%22%0A%20%20%22operations_total%22%2C%0A%20%20%22operations_latency_seconds_total%22%2C%0A%20%20%22operations_latency_seconds%22%2C%0A%20%20%22operations_errors_total%22%2C%0A%20%20%22image_pulls_bytes_total%22%2C%0A%20%20%22image_pulls_skipped_bytes_total%22%2C%0A%20%20%22image_pulls_success_total%22%2C%0A%20%20%22image_pulls_failure_total%22%2C%0A%20%20%22image_layer_reuse_total%22%2C%0A%20%20%22containers_oom_count_total%22%2C%0A%20%20%22processes_defunct%22%0A%5D%0A
          mode: 420
          overwrite: true
          path: /etc/crio/crio.conf.d/00-default
        - contents:
            source: data:,%7B%0A%20%20%20%20%22default%22%3A%20%5B%0A%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%22type%22%3A%20%22insecureAcceptAnything%22%0A%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%5D%2C%0A%20%20%20%20%22transports%22%3A%0A%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%22docker-daemon%22%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22%22%3A%20%5B%7B%22type%22%3A%22insecureAcceptAnything%22%7D%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20%20%20%7D%0A%7D%0A
          mode: 420
          overwrite: true
          path: /etc/machine-config-daemon/policy-for-old-podman.json
        - contents:
            source: data:,%7B%0A%20%20%20%20%22default%22%3A%20%5B%0A%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%22type%22%3A%20%22insecureAcceptAnything%22%0A%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%5D%2C%0A%20%20%20%20%22transports%22%3A%0A%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%22docker-daemon%22%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22%22%3A%20%5B%7B%22type%22%3A%22insecureAcceptAnything%22%7D%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20%20%20%7D%0A%7D
          mode: 420
          overwrite: true
          path: /etc/containers/policy.json
        - contents:
            source: data:,
          mode: 420
          overwrite: true
          path: /etc/kubernetes/cloud.conf
        - contents:
            source: data:,authorization%3A%0A%20%20static%3A%0A%20%20%20%20-%20resourceRequest%3A%20false%0A%20%20%20%20%20%20path%3A%20%2Fmetrics%0A%20%20%20%20%20%20verb%3A%20get%0A%20%20%20%20%20%20user%3A%0A%20%20%20%20%20%20%20%20name%3A%20system%3Aserviceaccount%3Aopenshift-monitoring%3Aprometheus-k8s
          mode: 420
          overwrite: true
          path: /etc/kubernetes/crio-metrics-proxy.cfg
        - contents:
            source: data:,apiVersion%3A%20v1%0Akind%3A%20Pod%0Ametadata%3A%0A%20%20name%3A%20kube-rbac-proxy-crio%0A%20%20namespace%3A%20openshift-machine-config-operator%0A%20%20annotations%3A%0A%20%20%20%20target.workload.openshift.io%2Fmanagement%3A%20'%7B%22effect%22%3A%20%22PreferredDuringScheduling%22%7D'%0A%20%20%20%20openshift.io%2Frequired-scc%3A%20privileged%0Aspec%3A%0A%20%20volumes%3A%0A%20%20-%20name%3A%20etc-kube%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fetc%2Fkubernetes%22%0A%20%20-%20name%3A%20var-lib-kubelet%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20hostNetwork%3A%20true%0A%20%20priorityClassName%3A%20system-cluster-critical%0A%20%20initContainers%3A%0A%20%20-%20name%3A%20setup%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3Ab6413e64e7d5885315b3cabc65c2af82135ee649b1664976b3d300884d302414%0A%20%20%20%20imagePullPolicy%3A%20IfNotPresent%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20var-lib-kubelet%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20command%3A%20%5B'%2Fbin%2Fbash'%2C%20'-ec'%5D%0A%20%20%20%20args%3A%0A%20%20%20%20-%20%7C%0A%20%20%20%20%20%20echo%20-n%20%22Waiting%20for%20kubelet%20key%20and%20certificate%20to%20be%20available%22%0A%20%20%20%20%20%20while%20%5B%20-n%20%22%24(test%20-e%20%2Fvar%2Flib%2Fkubelet%2Fpki%2Fkubelet-server-current.pem)%22%20%5D%20%3B%20do%0A%20%20%20%20%20%20%20%20echo%20-n%20%22.%22%0A%20%20%20%20%20%20%20%20sleep%201%0A%20%20%20%20%20%20%20%20((%20tries%20%2B%3D%201%20))%0A%20%20%20%20%20%20%20%20if%20%5B%5B%20%22%24%7Btries%7D%22%20-gt%2010%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20echo%20%22Timed%20out%20waiting%20for%20kubelet%20key%20and%20cert.%22%0A%20%20%20%20%20%20%20%20%20%20exit%201%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20done%0A%20%20%20%20securityContext%3A%0A%20%20%20%20%20%20privileged%3A%20true%0A%20%20%20%20resources%3A%0A%20%20%20%20%20%20requests%3A%0A%20%20%20%20%20%20%20%20memory%3A%2050Mi%0A%20%20%20%20%20%20%20%20cpu%3A%205m%0A%20%20containers%3A%0A%20%20-%20name%3A%20kube-rbac-proxy-crio%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3Ab6413e64e7d5885315b3cabc65c2af82135ee649b1664976b3d300884d302414%0A%20%20%20%20securityContext%3A%0A%20%20%20%20%20%20privileged%3A%20true%0A%20%20%20%20ports%3A%0A%20%20%20%20-%20containerPort%3A%209637%0A%20%20%20%20args%3A%0A%20%20%20%20-%20--secure-listen-address%3D%3A9637%0A%20%20%20%20-%20--config-file%3D%2Fetc%2Fkubernetes%2Fcrio-metrics-proxy.cfg%0A%20%20%20%20-%20--client-ca-file%3D%2Fetc%2Fkubernetes%2Fkubelet-ca.crt%0A%20%20%20%20-%20--logtostderr%3Dtrue%0A%20%20%20%20-%20--kubeconfig%3D%2Fvar%2Flib%2Fkubelet%2Fkubeconfig%0A%20%20%20%20-%20--tls-cipher-suites%3DTLS_AES_128_GCM_SHA256%2CTLS_AES_256_GCM_SHA384%2CTLS_CHACHA20_POLY1305_SHA256%2CTLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256%2CTLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256%2CTLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384%2CTLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384%2CTLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256%2CTLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256%20%0A%20%20%20%20-%20--tls-min-version%3DVersionTLS12%0A%20%20%20%20-%20--upstream%3Dhttp%3A%2F%2F127.0.0.1%3A9537%0A%20%20%20%20-%20--tls-cert-file%3D%2Fvar%2Flib%2Fkubelet%2Fpki%2Fkubelet-server-current.pem%0A%20%20%20%20-%20--tls-private-key-file%3D%2Fvar%2Flib%2Fkubelet%2Fpki%2Fkubelet-server-current.pem%0A%20%20%20%20resources%3A%0A%20%20%20%20%20%20requests%3A%0A%20%20%20%20%20%20%20%20cpu%3A%2020m%0A%20%20%20%20%20%20%20%20memory%3A%2050Mi%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20etc-kube%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fkubernetes%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20%20%20readOnly%3A%20true%0A%20%20%20%20-%20name%3A%20var-lib-kubelet%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20%20%20readOnly%3A%20true
          mode: 420
          overwrite: true
          path: /etc/kubernetes/manifests/criometricsproxy.yaml
        - contents:
            compression: ""
            source: data:text/plain;charset=utf-8;base64,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
          mode: 420
          overwrite: true
          path: /etc/kubernetes/kubelet.conf
        - contents:
            source: data:,%23!%2Fbin%2Fsh%0Aif%20%5B%20-x%20%2Fusr%2Fbin%2Fkubensenter%20%5D%3B%20then%0A%20%20exec%20%2Fusr%2Fbin%2Fkubensenter%20%22%24%40%22%0Aelse%0A%20%20exec%20%22%24%40%22%0Afi%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/kubenswrapper
        - contents:
            source: data:text/plain;charset=utf-8;base64,CnBvb2wgMC5yaGVsLnBvb2wubnRwLm9yZyBpYnVyc3QKZHJpZnRmaWxlIC92YXIvbGliL2Nocm9ueS9kcmlmdAptYWtlc3RlcCAxLjAgMwpydGNzeW5jCmxvZ2RpciAvdmFyL2xvZy9jaHJvbnkKc2VydmVyIDc0LjIwOC4yNS40NiBpYnVyc3QKc2VydmVyIHRpbWUubG10bGFicy5jb20gaWJ1cnN0CnNlcnZlciBsaXRoaXVtLmNvbnN0YW50LmNvbSBpYnVyc3QKc2VydmVyIDY5LjE3Ni44NC4zOCBpYnVyc3QKc2VydmVyIGFybTEubWF4aG9zdC5pbyBpYnVyc3QKc2VydmVyIG50cDEubGF4LnVzLmhvam1hcmsubmV0IGlidXJzdApzZXJ2ZXIgbnRwMTEua2VybmZ1c2lvbi5hdCBpYnVyc3QKc2VydmVyIHRyaWFuZ2xlLmthbnNhcy5uZXQgaWJ1cnN0
          mode: 420
          overwrite: true
          path: /etc/chrony.conf
        - contents:
            source: data:text/plain;charset=utf-8;base64,W0dlbmVyYWxdCkRvbWFpbiA9IHJocG9jLmludAoKW01hcHBpbmddCgpOb2JvZHktVXNlciA9IG5vYm9keQpOb2JvZHktR3JvdXAgPSBub2JvZHkK
          mode: 420
          overwrite: true
          path: /etc/idmapd.conf
      systemd:
        units:
        - contents: |
            [Unit]
            Description=Cleans NetworkManager state generated by dracut
            # Removal of this file signals firstboot completion
            ConditionPathExists=!/etc/ignition-machine-config-encapsulated.json
            # This is opt-in for some deployment types, and opt-out for others.
            ConditionPathExists=/var/lib/mco/nm-clean-initrd-state
            Wants=network-pre.target
            Before=network-pre.target

            [Service]
            Type=oneshot
            # Remove any existing state possibly generated NM run by dracut. We want NM to
            # consider all profiles autoconnect priority when it starts instead of
            # remembering which profile was a device activated with when NM is run by
            # dracut.
            ExecStart=/usr/local/bin/nm-clean-initrd-state.sh
            StandardOutput=journal+console
            StandardError=journal+console

            [Install]
            WantedBy=network-online.target
          enabled: true
          name: NetworkManager-clean-initrd-state.service
        - dropins:
          - contents: |
              # vim:set ft=systemd :
              #
              # This drop-in will enable any service built with this
              # github.com/containers/kubemntns library to properly join the mount namespace
              # managed by kubens.service
              #

              [Unit]
              After=kubens.service

              [Service]
              EnvironmentFile=-/run/kubens/env
            name: 01-kubens.conf
          - contents: ""
            name: 10-mco-default-env.conf
          - contents: |
              [Service]
              Environment="ENABLE_PROFILE_UNIX_SOCKET=true"
            name: 10-mco-profile-unix-socket.conf
          - contents: |
              [Unit]
              After=kubelet-dependencies.target
              Requires=kubelet-dependencies.target
            name: 05-mco-ordering.conf
          - contents: |
              [Service]
              Environment="GODEBUG=x509ignoreCN=0,madvdontneed=1"
            name: 10-mco-default-madv.conf
          name: crio.service
        - dropins:
          - contents: |
              [Unit]
              ConditionPathExists=/enoent
            name: mco-disabled.conf
          name: docker.socket
        - contents: |
            [Unit]
            Description=The firstboot OS update has completed
            Documentation=https://github.com/openshift/machine-config-operator/
            Requires=basic.target

            [Install]
            WantedBy=default.target
          enabled: true
          name: firstboot-osupdate.target
        - dropins:
          - contents: |
              [Unit]
              After=ovs-configuration.service
              Before=crio.service
            name: 01-after-configure-ovs.conf
          name: ipsec.service
        - contents: |
            [Unit]
            Description=Dynamically sets the system reserved for the kubelet
            Wants=network-online.target
            After=network-online.target firstboot-osupdate.target
            Before=kubelet-dependencies.target

            [Service]
            # Need oneshot to delay kubelet
            Type=oneshot
            RemainAfterExit=yes
            EnvironmentFile=/etc/node-sizing-enabled.env
            ExecStart=/bin/bash /usr/local/sbin/dynamic-system-reserved-calc.sh ${NODE_SIZING_ENABLED} ${SYSTEM_RESERVED_MEMORY} ${SYSTEM_RESERVED_CPU} ${SYSTEM_RESERVED_ES}
            [Install]
            RequiredBy=kubelet-dependencies.target
          enabled: true
          name: kubelet-auto-node-size.service
        - contents: |
            [Unit]
            Description=Dependencies necessary to run kubelet
            Documentation=https://github.com/openshift/machine-config-operator/
            Requires=basic.target network-online.target
            Wants=NetworkManager-wait-online.service crio-wipe.service
            Wants=rpc-statd.service chrony-wait.service
          name: kubelet-dependencies.target
        - contents: |
            [Unit]
            Description=Kubernetes Kubelet
            Requires=crio.service kubelet-dependencies.target
            After=kubelet-dependencies.target
            After=ostree-finalize-staged.service

            [Service]
            Type=notify
            ExecStartPre=/bin/mkdir --parents /etc/kubernetes/manifests
            ExecStartPre=-/usr/sbin/restorecon -ri /var/lib/kubelet/pod-resources /usr/local/bin/kubenswrapper /usr/bin/kubensenter
            Environment="KUBELET_NODE_IP=0.0.0.0"
            EnvironmentFile=/etc/os-release
            EnvironmentFile=-/etc/kubernetes/kubelet-workaround
            EnvironmentFile=-/etc/kubernetes/kubelet-env
            EnvironmentFile=/etc/node-sizing.env

            ExecStart=/usr/local/bin/kubenswrapper \
                /usr/bin/kubelet \
                  --config=/etc/kubernetes/kubelet.conf \
                  --bootstrap-kubeconfig=/etc/kubernetes/kubeconfig \
                  --kubeconfig=/var/lib/kubelet/kubeconfig \
                  --container-runtime-endpoint=/var/run/crio/crio.sock \
                  --runtime-cgroups=/system.slice/crio.service \
                  --node-labels=node-role.kubernetes.io/worker,node.openshift.io/os_id=${ID},${CUSTOM_KUBELET_LABELS} \
                  --node-ip=${KUBELET_NODE_IP} \
                  --address=${KUBELET_NODE_IP} \
                  --minimum-container-ttl-duration=6m0s \
                  --volume-plugin-dir=/etc/kubernetes/kubelet-plugins/volume/exec \
                  --cloud-provider= \
                  --hostname-override=${KUBELET_NODE_NAME} \
                  --pod-infra-container-image=quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:2f61599219ee63c77391e05d2e02a8a5baae1c463d0ef965c49a5c470546db90 \
                  --system-reserved=cpu=${SYSTEM_RESERVED_CPU},memory=${SYSTEM_RESERVED_MEMORY},ephemeral-storage=${SYSTEM_RESERVED_ES} \
                  --v=${KUBELET_LOG_LEVEL}

            Restart=always
            RestartSec=10

            [Install]
            WantedBy=multi-user.target
          dropins:
          - contents: |
              # vim:set ft=systemd :
              #
              # This drop-in will enable any service built with this
              # github.com/containers/kubemntns library to properly join the mount namespace
              # managed by kubens.service
              #

              [Unit]
              After=kubens.service

              [Service]
              EnvironmentFile=-/run/kubens/env
            name: 01-kubens.conf
          - contents: ""
            name: 10-mco-default-env.conf
          - contents: |
              [Service]
              # Wait for resolv-prepender to configure nameservers, exit 255 otherwise
              # to mark the unit as failed and retry later
              ExecCondition=/bin/bash -c '[ -f /run/resolv-prepender-kni-conf-done ] || { echo "NM resolv-prepender failed"; exit 255; }'
            name: 10-mco-on-prem-wait-resolv.conf
          - contents: |
              [Service]
              Environment="GODEBUG=x509ignoreCN=0,madvdontneed=1"
            name: 10-mco-default-madv.conf
          enabled: true
          name: kubelet.service
        - contents: |
            [Unit]
            Description=Manages a mount namespace for kubernetes-specific mounts

            [Service]
            Type=oneshot
            RemainAfterExit=yes
            RuntimeDirectory=kubens
            Environment=RUNTIME_DIRECTORY=%t/kubens
            Environment=BIND_POINT=%t/kubens/mnt
            Environment=ENVFILE=%t/kubens/env

            # Set up the runtime directory as an unbindable mountpoint
            ExecStartPre=bash -c "findmnt ${RUNTIME_DIRECTORY} || mount --make-unbindable --bind ${RUNTIME_DIRECTORY} ${RUNTIME_DIRECTORY}"
            # Ensure the bind point exists
            ExecStartPre=touch ${BIND_POINT}
            # Use 'unshare' to create the new mountpoint, then 'mount --make-rshared' so it cascades internally
            ExecStart=unshare --mount=${BIND_POINT} --propagation slave mount --make-rshared /
            # Finally, set an env pointer for ease-of-use
            ExecStartPost=bash -c 'echo "KUBENSMNT=${BIND_POINT}" > "${ENVFILE}"'

            # On stop, a recursive unmount cleans up the namespace and bind-mounted unbindable parent directory
            ExecStop=umount -R ${RUNTIME_DIRECTORY}

            [Install]
            WantedBy=multi-user.target
          enabled: false
          name: kubens.service
        - contents: |
            [Unit]
            Description=Machine Config Daemon Firstboot
            # Make sure it runs only on OSTree booted system
            ConditionPathExists=/run/ostree-booted
            # Removal of this file signals firstboot completion
            ConditionPathExists=/etc/ignition-machine-config-encapsulated.json
            After=machine-config-daemon-pull.service
            Before=kubelet-dependencies.target

            [Service]
            Type=oneshot
            RemainAfterExit=yes
            # Disable existing repos (if any) so that OS extensions would use embedded RPMs only
            ExecStartPre=-/usr/bin/sh -c "sed -i 's/enabled=1/enabled=0/' /etc/yum.repos.d/*.repo"
            # Run this via podman because we want to use the nmstatectl binary in our container
            ExecStart=/usr/bin/podman run --rm --privileged --net=host -v /:/rootfs  --entrypoint machine-config-daemon 'quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:94bac6c3782cf6579032c7c9dabca74146753d9a44591125acd30d606d7d340c' firstboot-complete-machineconfig --persist-nics
            ExecStart=/usr/bin/podman run --rm --privileged --pid=host --net=host -v /:/rootfs  --entrypoint machine-config-daemon 'quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:94bac6c3782cf6579032c7c9dabca74146753d9a44591125acd30d606d7d340c' firstboot-complete-machineconfig
            [Install]
            RequiredBy=firstboot-osupdate.target
          enabled: true
          name: machine-config-daemon-firstboot.service
        - contents: |
            [Unit]
            Description=Machine Config Daemon Pull
            # Make sure it runs only on OSTree booted system
            ConditionPathExists=/run/ostree-booted
            # This "stamp file" is unlinked when we complete
            # machine-config-daemon-firstboot.service
            ConditionPathExists=/etc/ignition-machine-config-encapsulated.json
            # Run after crio-wipe so the pulled MCD image is protected against a corrupted storage from a forced shutdown
            Wants=crio-wipe.service NetworkManager-wait-online.service
            After=crio-wipe.service NetworkManager-wait-online.service network.service

            [Service]
            Type=oneshot
            RemainAfterExit=yes
            ExecStartPre=/etc/machine-config-daemon/generate_podman_policy_args.sh
            ExecStart=/bin/sh -c "while ! /usr/bin/podman pull $(cat /tmp/podman_policy_args) --authfile=/var/lib/kubelet/config.json 'quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:94bac6c3782cf6579032c7c9dabca74146753d9a44591125acd30d606d7d340c'; do sleep 1; done"

            [Install]
            RequiredBy=machine-config-daemon-firstboot.service
          enabled: true
          name: machine-config-daemon-pull.service
        - contents: |
            [Unit]
            Description=Applies per-node NMState network configuration
            Requires=openvswitch.service
            Wants=NetworkManager-wait-online.service
            After=NetworkManager-wait-online.service openvswitch.service network.service nodeip-configuration.service
            Before=nmstate.service kubelet-dependencies.target ovs-configuration.service node-valid-hostname.service

            [Service]
            Type=oneshot
            # Would prefer to do Restart=on-failure instead of this bash retry loop, but
            # the version of systemd we have right now doesn't support it. It should be
            # available in systemd v244 and higher.
            ExecStart=/usr/local/bin/nmstate-configuration.sh
            StandardOutput=journal+console
            StandardError=journal+console

            [Install]
            WantedBy=network-online.target
          enabled: true
          name: nmstate-configuration.service
        - contents: |
            [Unit]
            Description=Apply nmstate on-disk state
            Documentation=man:nmstate.service(8) https://www.nmstate.io
            After=NetworkManager-wait-online.service
            Before=network-online.target
            Wants=NetworkManager-wait-online.service
            Requires=NetworkManager.service

            [Service]
            Type=oneshot
            ExecStart=/usr/bin/nmstatectl service
            RemainAfterExit=yes

            [Install]
            WantedBy=NetworkManager.service
          enabled: true
          name: nmstate.service
        - contents: |
            [Unit]
            Description=Wait for a non-localhost hostname
            Before=kubelet-dependencies.target

            [Service]
            Type=oneshot
            RemainAfterExit=yes
            User=root
            ExecStart=/usr/local/bin/mco-hostname --wait

            # Wait up to 5min for the node to get a non-localhost name
            TimeoutSec=300

            [Install]
            # TODO: Change this to RequiredBy after we fix https://github.com/openshift/machine-config-operator/pull/3865#issuecomment-1746963115
            WantedBy=kubelet-dependencies.target
          enabled: true
          name: node-valid-hostname.service
        - contents: |
            [Unit]
            Description=Writes IP address configuration so that kubelet and crio services select a valid node IP
            # This only applies to VIP managing environments where the kubelet and crio IP
            # address picking logic is flawed and may end up selecting an address from a
            # different subnet or a deprecated address
            Wants=NetworkManager-wait-online.service
            After=NetworkManager-wait-online.service firstboot-osupdate.target
            Before=kubelet-dependencies.target ovs-configuration.service

            [Service]
            # Need oneshot to delay kubelet
            Type=oneshot
            # Would prefer to do Restart=on-failure instead of this bash retry loop, but
            # the version of systemd we have right now doesn't support it. It should be
            # available in systemd v244 and higher.
            ExecStart=/bin/bash -c " \
              until \
              /usr/bin/podman run --rm \
              --authfile /var/lib/kubelet/config.json \
              --net=host \
              --security-opt label=disable \
              --volume /etc/systemd/system:/etc/systemd/system \
              --volume /run/nodeip-configuration:/run/nodeip-configuration \
              quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:93e7b8c870261726d44bddc7ba0a702d3720d1838141dac837fb8c3be7c6e1a1 \
              node-ip \
              set \
              --platform BareMetal \
              --retry-on-failure \
              ${NODEIP_HINT:-} \
              10.100.0.50  \
              10.100.0.51 ; \
              do \
              sleep 5; \
              done"
            ExecStart=/bin/systemctl daemon-reload
            ExecStartPre=/bin/mkdir -p /run/nodeip-configuration
            ExecStartPost=+/usr/local/bin/configure-ip-forwarding.sh
            StandardOutput=journal+console
            StandardError=journal+console
            EnvironmentFile=-/etc/default/nodeip-configuration

            [Install]
            RequiredBy=kubelet-dependencies.target
          enabled: true
          name: nodeip-configuration.service
        - contents: |
            [Unit]
            Description=Watches for changes in /var/run/NetworkManager/resolv.conf according to on-prem IPI needs
            [Path]
            PathModified=/var/run/NetworkManager/resolv.conf
            PathModified=/run/resolv-prepender/env
            Unit=on-prem-resolv-prepender.service
            [Install]
            WantedBy=multi-user.target
          enabled: true
          name: on-prem-resolv-prepender.path
        - contents: |
            [Unit]
            Description=Populates resolv.conf according to on-prem IPI needs
            # Per https://issues.redhat.com/browse/OCPBUGS-27162 there is a problem if this is started before crio-wipe
            After=crio-wipe.service
            StartLimitIntervalSec=0
            [Service]
            Type=oneshot
            # Would prefer to do Restart=on-failure instead of this bash retry loop, but
            # the version of systemd we have right now doesn't support it. It should be
            # available in systemd v244 and higher.
            ExecStart=/bin/bash -c " \
              until \
              /usr/local/bin/resolv-prepender.sh; \
              do \
              sleep 10; \
              done"
            EnvironmentFile=-/run/resolv-prepender/env
          enabled: false
          name: on-prem-resolv-prepender.service
        - enabled: true
          name: openvswitch.service
        - contents: |
            [Unit]
            # Kdump will generate it's initramfs based on the running state when kdump.service run
            # If OVS has already run, the kdump fails to gather a working network config,
            # which prevent network log exports, sush as SSH.
            # See https://issues.redhat.com/browse/OCPBUGS-28239
            After=kdump.service
            Description=Configures OVS with proper host networking configuration
            # This service is used to move a physical NIC into OVS and reconfigure OVS to use the host IP
            Requires=openvswitch.service
            Wants=NetworkManager-wait-online.service
            After=firstboot-osupdate.target
            After=NetworkManager-wait-online.service openvswitch.service network.service nodeip-configuration.service nmstate.service
            Before=kubelet-dependencies.target node-valid-hostname.service

            [Service]
            # Need oneshot to delay kubelet
            Type=oneshot
            ExecStart=/usr/local/bin/configure-ovs.sh OVNKubernetes
            StandardOutput=journal+console
            StandardError=journal+console

            [Install]
            RequiredBy=kubelet-dependencies.target
          enabled: true
          name: ovs-configuration.service
        - dropins:
          - contents: |
              [Service]
              Restart=always
              ExecStartPre=-/bin/sh -c '/usr/bin/chown -R :$${OVS_USER_ID##*:} /var/lib/openvswitch'
              ExecStartPre=-/bin/sh -c '/usr/bin/chown -R :$${OVS_USER_ID##*:} /etc/openvswitch'
              ExecStartPre=-/bin/sh -c '/usr/bin/chown -R :$${OVS_USER_ID##*:} /run/openvswitch'
              ExecStartPost=-/usr/bin/ovs-appctl vlog/set syslog:info
              ExecReload=-/usr/bin/ovs-appctl vlog/set syslog:info
            name: 10-ovs-vswitchd-restart.conf
          name: ovs-vswitchd.service
        - dropins:
          - contents: |
              [Service]
              Restart=always
            name: 10-ovsdb-restart.conf
          enabled: true
          name: ovsdb-server.service
        - dropins:
          - contents: ""
            name: 10-mco-default-env.conf
          name: rpm-ostreed.service
        - contents: |
            [Unit]
            Description=Wait for br-ex up event from NetworkManager
            Wants=ovs-configuration.service
            After=ovs-configuration.service
            Before=node-valid-hostname.service

            [Service]
            Type=oneshot
            ExecStart=/usr/local/bin/wait-for-br-ex-up.sh

            [Install]
            RequiredBy=node-valid-hostname.service
          enabled: true
          name: wait-for-br-ex-up.service
        - contents: |
            [Unit]
            Description=Ensure IKE SA established for existing IPsec connections.
            After=ipsec.service
            Before=kubelet-dependencies.target node-valid-hostname.service

            [Service]
            Type=oneshot
            ExecStart=/usr/local/bin/ipsec-connect-wait.sh
            StandardOutput=journal+console
            StandardError=journal+console

            [Install]
            WantedBy=ipsec.service
          enabled: true
          name: wait-for-ipsec-connect.service
        - contents: |
            [Unit]
            Description=Ensure primary IP is assigned and usable
            Requires=nmstate.service
            After=nmstate.service
            Before=kubelet-dependencies.target

            [Service]
            Type=oneshot
            # Would prefer to do Restart=on-failure instead of this bash retry loop, but
            # the version of systemd we have right now doesn't support it. It should be
            # available in systemd v244 and higher.
            ExecStart=/bin/bash -c " \
              until \
              /usr/local/bin/wait-for-primary-ip.sh; \
              do \
              sleep 10; \
              done"
            StandardOutput=journal+console
            StandardError=journal+console

            [Install]
            WantedBy=network-online.target
          enabled: true
          name: wait-for-primary-ip.service
        - dropins:
          - contents: |
              [Unit]
              ConditionPathExists=/enoent
            name: mco-disabled.conf
          name: zincati.service
        - contents: |
            [Unit]
            Description=Kubernetes Kubelet After Reboot Cleanup
            Before=kubelet.service

            [Service]
            Type=oneshot
            ExecStart=/bin/rm -f /var/lib/kubelet/cpu_manager_state
            ExecStart=/bin/rm -f /var/lib/kubelet/memory_manager_state
            ExecStart=-/bin/rm -f /var/lib/kubelet/dra_manager_state

            [Install]
            WantedBy=multi-user.target
          enabled: true
          name: kubelet-cleanup.service
    extensions: []
    fips: false
    kernelArguments:
    - schedstats=enable
    - systemd.unified_cgroup_hierarchy=1
    - cgroup_no_v1="all"
    - psi=0
    - psi=1
    kernelType: default
    osImageURL: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4e309dd906392e783a404b92dfd4fa4c32d74e2804ee37d1fb8a00c9355d5978
- apiVersion: machineconfiguration.openshift.io/v1
  kind: MachineConfig
  metadata:
    annotations:
      machineconfiguration.openshift.io/generated-by-controller-version: fcf8f254943cbcba1400ba55f3978cc292b6460b
      machineconfiguration.openshift.io/release-image-version: 4.18.26
    creationTimestamp: "2025-11-04T16:09:19Z"
    generation: 1
    name: rendered-worker-b297ff960d8ec0912f02e757a76c51d1
    ownerReferences:
    - apiVersion: machineconfiguration.openshift.io/v1
      blockOwnerDeletion: true
      controller: true
      kind: MachineConfigPool
      name: worker
      uid: 7ac2da7a-3f0d-4ad8-974e-12dd34c8fded
    resourceVersion: "11165"
    uid: d4042874-7a4f-4609-87f3-241d31568691
  spec:
    baseOSExtensionsContainerImage: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:7033f46996eddcbad8c8b8aeb18e601bdeef3d04bd7f79cd194db5e6346a7fc4
    config:
      ignition:
        version: 3.4.0
      passwd:
        users:
        - name: core
          sshAuthorizedKeys:
          - ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQDaG45aoa4HpJ+V029gSYKSv5IenhVmZcJvicGrs+D0PgzzwNIGG52iK4r3YOoEYJn4nX80OHf4ob23avJ1ruDPR9inD1c+oiAk5BLRE7CNdU1mllWE0l6pYRHfpIuCOXC6iWpX1kXbVPJZk3ytVZOgff7LkaIIzbAjDjJ+N1MQSUmKvnioh8c6WtFfQNAZ2gFBCRWPLxcjHdyTYvy+oB0qR10WpQYHrGVB0LawtudQrO/8zHcfZJpI0uFwSAvYqspgiO3hPfuT0Fx8xzAb66AK/2vF/WrMOH3AbBu5S954B+xZI4apPJN/Yy5ENRVIoL7w9V5pV5FENtsSvQ+fpFat9yoVewvy5CMo8qJHrvAqlBJ9JriVX2mnigJRkshG0F+Z7BLZUjMcueSIIzasQ2igc8nbpfElSnTmoyweiMbFIXNJJwaV/tKbFkF3J7A3fz1qbfSQ7AIHAigoUf/CnCr+j+BQs1ZZMoWGQOPwFo00OBDICnP0Pc6wBr4iN6gnDFs=
            jnakamura@JNakamura-22
      storage:
        files:
        - contents:
            source: data:,%23%20This%20file%20signals%20NetworkManager-clean-initrd-state%20service%20to%20run%20on%0A%23%20boot.%20This%20service%20is%20used%20to%20clean%20up%20the%20network%20activation%20state%0A%23%20generated%20by%20dracut%20so%20that%20other%20network%20configuration%20deployed%20by%20the%0A%23%20user%20can%20be%20activated.%20This%20only%20happens%20if%20dracut%20activated%20a%20default%0A%23%20network%20configuration%20and%20there%20is%20an%20alternate%20configuration%20available%20in%0A%23%20the%20root%20filesystem.%20Otherwise%2C%20it%20is%20assumed%20that%20the%20network%0A%23%20configuration%20activated%20by%20dracut%20is%20the%20one%20that%20is%20intended%20to%20be%20used%0A%23%20throughout%20the%20life%20of%20the%20system.%0A%23%20Opt-out%20for%20baremetal%20IPI%20deplyments%2C%20opt-in%20otherwise.%0A
          mode: 493
          overwrite: true
          path: /var/lib/mco/nm-clean-initrd-state
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-ex%20-o%20pipefail%0A%0ANM_DEVICES_DIR%3D%2Frun%2FNetworkManager%2Fdevices%0ANM_RUN_CONN_DIR%3D%2Frun%2FNetworkManager%2Fsystem-connections%0ANM_ETC_CONN_DIR%3D%2Fetc%2FNetworkManager%2Fsystem-connections%0A%0Alogger%20-t%20nm-clean-initrd-state%20%22Cleaning%20network%20activation%20state%20generated%20by%20dracut...%22%0Alogger%20-t%20nm-clean-initrd-state%20%22To%20disable%2C%20remove%20%2Fvar%2Flib%2Fmco%2Fnm-clean-initrd-state%22%0A%0Aif%20%5B%20!%20-e%20%22%24NM_DEVICES_DIR%22%20%5D%20%7C%7C%20%5B%20!%20-e%20%22%24NM_RUN_CONN_DIR%22%20%5D%20%7C%7C%20%5B%20!%20-e%20%22%24NM_ETC_CONN_DIR%22%20%5D%3B%20then%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22There%20is%20no%20network%20activation%20state%20to%20clean%22%0A%20%20exit%0Afi%0A%0A%23%20Some%20deployments%20require%20an%20active%20network%20early%20in%20the%20boot%20process.%20To%0A%23%20achieve%20this%2C%20dracut%20runs%20specific%20NetworkManager%20modules.%20This%20results%20in%0A%23%20NetworkManager%20keyfiles%20being%20generated%20(either%20default%20or%20from%20ip%20kernel%0A%23%20arguments)%20and%20activated.%20This%20activation%20generates%20state%20that%20makes%20those%0A%23%20profiles%20to%20be%20re-activated%20by%20the%20NetworkManager%20service%20later%20in%20the%0A%23%20boot%20process.%20And%20this%20has%20the%20effect%20that%20other%20profiles%20deployed%20by%20the%0A%23%20user%20for%20the%20same%20set%20of%20devices%20are%20ignored.%0A%0A%23%20Most%20of%20the%20time%20this%20is%20the%20desired%20behavior.%20The%20exception%20to%20this%20rule%0A%23%20is%20when%20the%20user%20wants%20to%20run%20the%20boot%20process%20with%20a%20different%20network%0A%23%20setup%20than%20the%20real%20root%20which%20is%20usually%20related%20to%20the%20fact%20that%0A%23%20generating%20images%20with%20customized%20kernel%20arguments%20is%20a%20complication%20in%0A%23%20the%20deployment%20pipeline.%0A%0A%23%20This%20need%20has%20been%20exacerbated%20by%20past%20NetworkManager%20bugs%20that%20activated%0A%23%20the%20network%20on%20boot%20when%20it%20was%20not%20really%20needed.%20Most%20notably%20when%20ip%0A%23%20kernel%20argument%20is%20present%2C%20something%20that%20the%20baremetal%20installer%20adds%20by%0A%23%20default.%0A%0A%23%20The%20intention%20here%20is%20to%20remove%20the%20state%20that%20was%20generated%20with%20the%0A%23%20activation%20of%20those%20profiles%20during%20dracut%20execution.%20Then%20when%0A%23%20NetworkManager%20service%20runs%2C%20the%20profiles%20generated%20by%20dracut%2C%20along%20with%0A%23%20other%20profiles%20configured%20by%20the%20user%2C%20are%20evaluated%20towards%20finding%20the%0A%23%20most%20appropriate%20profile%20to%20connect%20a%20device%20with.%20As%20a%20precaution%2C%20clean%0A%23%20state%20only%20for%20devices%20that%3A%0A%23%20-%20have%20been%20activated%20with%20a%20default%20profile%20(assume%20that%20a%20non-default%0A%23%20%20%20configuration%20expresses%20intention%20by%20user%20to%20run%20with%20it%20permanently)%0A%23%20-%20have%20a%20specific%20configured%20profile%20set%20to%20auto-connect%20(if%20there%20is%20no%0A%23%20%20%20alternate%20configured%20profile%20for%20a%20device%20it%20makes%20no%20sense%20to%0A%23%20%20%20de-activate%20anything)%0A%23%0A%23%20Although%20this%20can%20theoretically%20happen%20on%20any%20deployment%20type%2C%20need%20has%0A%23%20mostly%20come%20from%20IPI%20bare%20metal%20deployments.%20For%20the%20time%20being%2C%20this%0A%23%20should%20be%20opt-in%20in%20any%20other%20deploment%20type.%0A%23%0A%23%20There%20is%20an%20RFE%20filed%20against%20NM%20that%20once%20implemented%20would%20make%20this%0A%23%20script%20unnecessary%3A%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D2089707%0A%0Afor%20device%20in%20%22%24%7BNM_DEVICES_DIR%7D%22%2F*%3B%20do%0A%20%20if%20%5B%20!%20-e%20%22%24device%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20the%20device%20file%20name%20is%20the%20ifindex%0A%20%20ifindex%3D%24(basename%20%22%24device%22)%0A%20%20%0A%20%20%23%20get%20the%20interface%20name%20by%20ifindex%0A%20%20ifname%3D%24(ip%20-j%20link%20show%20%7C%20jq%20-r%20%22.%5B%5D%20%7C%20select(.ifindex%20%3D%3D%20%24%7Bifindex%7D)%20%7C%20.ifname%20%2F%2F%20empty%22)%0A%0A%20%20%23%20no%20interface%20name%20found%2C%20ignore%0A%20%20if%20%5B%20-z%20%22%24ifname%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20get%20the%20uuid%20of%20the%20profile%20the%20device%20has%20been%20activated%20with%0A%20%20active_profile_uuid%3D%24(sed%20-nr%20'%2F%5E%5C%5Bdevice%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Econnection-uuid%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24device%22)%0A%0A%20%20%23%20the%20device%20was%20not%20activated%20with%20any%20profile%2C%20ignore%0A%20%20if%20%5B%20-z%20%22%24active_profile_uuid%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20find%20the%20generated%20profile%20by%20uuid%0A%20%20for%20profile%20in%20%22%24%7BNM_RUN_CONN_DIR%7D%22%2F*%3B%20do%0A%20%20%20%20generated_profile_uuid%3D%24(sed%20-nr%20'%2F%5E%5C%5Bconnection%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Euuid%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20%20%20if%20%5B%20%22%24active_profile_uuid%22%20%3D%20%22%24generated_profile_uuid%22%20%5D%3B%20then%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20done%0A%0A%20%20%23%20generated%20profile%20not%20found%2C%20ignore%0A%20%20if%20%5B%20%22%24active_profile_uuid%22%20!%3D%20%22%24generated_profile_uuid%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20check%20that%20it%20is%20not%20specific%20for%20the%20device%2C%20otherwise%20ignore%0A%20%20profile_ifname%3D%24(sed%20-nr%20'%2F%5E%5C%5Bconnection%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Einterface-name%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20if%20%5B%20-n%20%22%24profile_ifname%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20profile%20not%20generated%20by%20nm-initrd-generator%2C%20ignore%0A%20%20%23%20only%20check%20it%20if%20the%20key%20is%20set%20(from%20NM%201.32.4)%0A%20%20origin%3D%24(sed%20-nr%20'%2F%5E%5C%5Buser%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Eorg.freedesktop.NetworkManager.origin%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20if%20%5B%20-n%20%22%24origin%22%20%5D%20%26%26%20%5B%20%22%24origin%22%20!%3D%20%22nm-initrd-generator%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20find%20the%20configured%20profile%20by%20name%20with%20auto-connect%20set%0A%20%20for%20profile%20in%20%22%24%7BNM_ETC_CONN_DIR%7D%22%2F*%3B%20do%0A%20%20%20%20profile_ifname%3D%24(sed%20-nr%20'%2F%5E%5C%5Bconnection%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Einterface-name%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20%20%20autoconnect%3D%24(sed%20-nr%20'%2F%5E%5C%5Bconnection%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Eautoconnect%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20%20%20if%20%5B%20%22%24profile_ifname%22%20%3D%20%22%24ifname%22%20%5D%20%26%26%20%5B%20%22%24autoconnect%22%20!%3D%20%22false%22%20%5D%3B%20then%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20done%0A%0A%20%20%23%20configured%20profile%20not%20found%2C%20ignore%0A%20%20if%20%5B%20%22%24profile_ifname%22%20!%3D%20%22%24ifname%22%20%5D%20%7C%7C%20%5B%20%22%24autoconnect%22%20%3D%20%22false%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20configured_profile_uuid%3D%24(sed%20-nr%20'%2F%5E%5C%5Bconnection%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Euuid%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22%24ifname%20activated%20with%20default%20generated%20profile%20%24generated_profile_uuid%22%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22%24ifname%20has%20different%20configured%20specific%20profile%20%24configured_profile_uuid%22%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22%24ifname%3A%20removing%20state...%22%0A%20%20%0A%20%20%23%20NM%20can%20still%20generate%20internal%20profiles%20from%20the%20IP%20address%0A%20%20%23%20configuration%20of%20devices%2C%20so%20flush%20addresses%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22Flushing%20IP%20addresses%20from%20%24ifname%22%0A%20%20ip%20addr%20flush%20%22%24ifname%22%0A%20%20ip%20-6%20addr%20flush%20%22%24ifname%22%0A%0A%20%20%23%20remove%20device%20state%20file%20to%20prevent%20NM%20to%20unilaterally%20connect%20with%20the%0A%20%20%23%20latest%20activated%20profile%20without%20evaluating%20other%20profiles%20%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22Removing%20%24device%22%0A%20%20rm%20-f%20--%20%22%24device%22%0A%0Adone%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/nm-clean-initrd-state.sh
        - contents:
            source: data:,%5Bconnection%5D%0Aipv6.dhcp-duid%3Dll%0Aipv6.dhcp-iaid%3Dmac%0A
          mode: 420
          overwrite: true
          path: /etc/NetworkManager/conf.d/01-ipv6.conf
        - contents:
            source: data:,%5Bmain%5D%0Aplugins%3Dkeyfile%2Cifcfg-rh%0A%5Bkeyfile%5D%0Apath%3D%2Fetc%2FNetworkManager%2Fsystem-connections%0A
          mode: 420
          overwrite: true
          path: /etc/NetworkManager/conf.d/20-keyfiles.conf
        - contents:
            source: data:,%5Bmain%5D%0Arc-manager%3Dunmanaged%0A
          mode: 420
          overwrite: true
          path: /etc/NetworkManager/conf.d/99-kni.conf
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-eo%20pipefail%0AIFACE%3D%241%0ASTATUS%3D%242%0A%0Afunction%20resolv_prepender%20%7B%0A%20%20mkdir%20-p%20%2Frun%2Fresolv-prepender%0A%20%20echo%20%22IP4_DOMAINS%3D%24IP4_DOMAINS%22%20%3E%20%2Frun%2Fresolv-prepender%2Fenv.new%0A%20%20echo%20%22IP6_DOMAINS%3D%24IP6_DOMAINS%22%20%3E%3E%20%2Frun%2Fresolv-prepender%2Fenv.new%0A%0A%20%20if%20!%20diff%20-q%20%2Frun%2Fresolv-prepender%2Fenv%20%2Frun%2Fresolv-prepender%2Fenv.new%3B%20then%0A%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Environment%20variable(s)%20changed.%20Systemd%20path%20unit%20will%20pick%20the%20change.%22%0A%20%20%20%20mv%20-f%20%2Frun%2Fresolv-prepender%2Fenv.new%20%2Frun%2Fresolv-prepender%2Fenv%0A%20%20fi%0A%7D%0A%0Aexport%20IP4_DOMAINS%20IP6_DOMAINS%0Aexport%20-f%20resolv_prepender%0A%0A%23%20For%20RHEL8%20with%20NetworkManager%20%3E%3D%201.36%20and%20RHEL9%20with%20NetworkManager%20%3E%3D1.42%20we%20can%20use%20simplified%20logic%0A%23%20of%20observing%20only%20a%20single%20%22dns-change%22%20event.%20Older%20version%20of%20NetworkManager%20require%20however%20that%20we%0A%23%20react%20on%20a%20set%20of%20multiple%20events.%20Once%20dns-change%20event%20is%20detected%20we%20create%20a%20flag%20file%20to%20ignore%0A%23%20subsequent%20up%26co.%20events%20as%20undesired.%0A%23%0A%23%20Given%20an%20overall%20Network%20Manager%20dispatcher%20timeout%20of%2090%20seconds%2C%20we%20are%20enforcing%20a%20slightly%20shorter%0A%23%20timeout%20for%20the%20observed%20events.%20It%20is%20not%20really%20required%20because%20all%20we%20do%20in%20this%20function%20is%20to%20write%20a%20file.%0A%23%20We%20could%20get%20rid%20of%20this%20timeout%20completely%2C%20but%20it%20also%20does%20not%20cost%20much%20to%20keep%20it.%0Acase%20%22%24STATUS%22%20in%0A%20%20dns-change)%0A%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%20triggered%20by%20%24%7BIFACE%7D%20%24%7BSTATUS%7D.%22%0A%20%20%20%20if%20%5B%20!%20-f%20%22%2Frun%2Fnetworkmanager-dns-event-detected%22%20%5D%3B%20then%0A%20%20%20%20%20%20touch%20%2Frun%2Fnetworkmanager-dns-event-detected%0A%20%20%20%20fi%0A%20%20%20%20if%20!%20timeout%2060s%20bash%20-c%20resolv_prepender%3B%20then%0A%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Timeout%20occurred%22%0A%20%20%20%20%20%20exit%201%0A%20%20%20%20fi%0A%20%20%3B%3B%0A%0A%20%20up%7Cdhcp4-change%7Cdhcp6-change%7Creapply)%0A%20%20%20%20if%20%5B%20!%20-f%20%22%2Frun%2Fnetworkmanager-dns-event-detected%22%20%5D%3B%20then%0A%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%20triggered%20by%20%24%7BIFACE%7D%20%24%7BSTATUS%7D.%22%0A%20%20%20%20%20%20if%20!%20timeout%2030s%20bash%20-c%20resolv_prepender%3B%20then%0A%20%20%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Timeout%20occurred%22%0A%20%20%20%20%20%20%20%20exit%201%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20If%20%24DHCP6_FQDN_FQDN%20is%20not%20empty%20and%20is%20not%20localhost.localdomain%20and%20static%20hostname%20was%20not%20already%20set%0A%20%20%20%20if%20%5B%5B%20-n%20%22%24DHCP6_FQDN_FQDN%22%20%26%26%20%22%24DHCP6_FQDN_FQDN%22%20!%3D%20%22localhost.localdomain%22%20%26%26%20%22%24DHCP6_FQDN_FQDN%22%20%3D~%20%22.%22%20%5D%5D%20%3B%20then%0A%20%20%20%20%20%20%20STATIC_HOSTNAME%3D%22%24(test%20!%20-e%20%2Fetc%2Fhostname%20%26%26%20echo%20-n%20%7C%7C%20cat%20%2Fetc%2Fhostname%20%7C%20xargs)%22%0A%0A%20%20%20%20%20%20%20if%20%5B%5B%20-z%20%22%24STATIC_HOSTNAME%22%20%7C%7C%20%22%24STATIC_HOSTNAME%22%20%3D%3D%20%22localhost.localdomain%22%20%5D%5D%20%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%23%20run%20with%20systemd-run%20to%20avoid%20selinux%20problems%0A%20%20%20%20%20%20%20%20%20%20systemd-run%20--property%3DType%3Doneshot%20--unit%20resolve-prepender-hostnamectl%20-Pq%20%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20hostnamectl%20set-hostname%20--static%20--transient%20%24DHCP6_FQDN_FQDN%0A%20%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20if%20%5B%5B%20%22%24STATUS%22%20%3D%3D%20%22up%22%20%5D%5D%20%26%26%20%5B%5B%20%24IFACE%20%3D%3D%20%22br-ex%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20%2Fbin%2Fmkdir%20-p%20%2Frun%2Fnodeip-configuration%0A%20%20%20%20%20%20%20%20touch%20%2Frun%2Fnodeip-configuration%2Fbr-ex-up%0A%20%20%20%20fi%0A%20%20%3B%3B%0A%20%20*)%0A%20%20%3B%3B%0Aesac%0A
          mode: 493
          overwrite: true
          path: /etc/NetworkManager/dispatcher.d/30-resolv-prepender
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-ex%20-o%20pipefail%0A%0Aif%20%5B%5B%20%22OVNKubernetes%22%20%3D%3D%20%22OVNKubernetes%22%20%26%26%20%22%24CONNECTION_ID%22%20%3D%3D%20%22Wired%20Connection%22%20%5D%5D%0Athen%0A%20%20%20%20%3E%262%20echo%20%22Refusing%20to%20modify%20default%20connection.%22%0A%20%20%20%20exit%200%0Afi%0A%0Aif%20%5B%20-z%20%24%7BDHCP4_IP_ADDRESS%3A-%7D%20%5D%0Athen%0A%20%20%20%20%3E%262%20echo%20%22Not%20a%20DHCP4%20address.%20Ignoring.%22%0A%20%20%20%20exit%200%0Afi%0A%0Aif%20%5B%20%24%7BDHCP4_DHCP_LEASE_TIME%3A-0%7D%20-lt%204294967295%20%5D%0Athen%0A%20%20%20%20%3E%262%20echo%20%22Not%20an%20infinite%20DHCP4%20lease.%20Ignoring.%22%0A%20%20%20%20exit%200%0Afi%0A%0AIPS%3D(%24IP4_ADDRESS_0)%0ACIDR%3D%24%7BIPS%5B0%5D%7D%0AGATEWAY%3D%24%7BIPS%5B1%5D%7D%0A%0ATYPE%3D%24(nmcli%20--get-values%20connection.type%20connection%20show%20%22%24CONNECTION_ID%22)%0A%0A%23%20Modifying%20the%20default%20connection%20id%20directly%20doesn't%20do%20what%20we%20want.%0A%23%20If%20we%20see%20that%2C%20then%20we%20need%20to%20create%20a%20new%20connection.%0Aif%20%5B%20%22%24CONNECTION_ID%22%20%3D%3D%20%22Wired%20Connection%22%20%5D%0Athen%0A%20%20%20%20if%20!%20nmcli%20con%20show%20inf-lease-to-static%0A%20%20%20%20then%0A%20%20%20%20%20%20%20%20nmcli%20con%20add%20type%20%22%24TYPE%22%20con-name%20inf-lease-to-static%0A%20%20%20%20fi%0A%20%20%20%20STATIC_INT_NAME%3Dinf-lease-to-static%0Aelse%0A%20%20%20%20STATIC_INT_NAME%3D%22%24CONNECTION_ID%22%0Afi%0Anmcli%20con%20mod%20%22%24STATIC_INT_NAME%22%20%5C%0A%20%20conn.interface%20%22%241%22%20%5C%0A%20%20connection.autoconnect%20yes%20%5C%0A%20%20ipv4.addresses%20%22%24CIDR%22%20%5C%0A%20%20ipv4.method%20manual%20%5C%0A%20%20ipv4.gateway%20%22%24GATEWAY%22%20%5C%0A%20%20ipv4.dns%20%22%24IP4_NAMESERVERS%22%0A%0Aif%20%5B%20-n%20%22%24IP4_DOMAINS%22%20%5D%3B%20then%0A%20%20%20%20nmcli%20con%20mod%20%22%24STATIC_INT_NAME%22%20ipv4.dns-search%20%22%24IP4_DOMAINS%22%0Afi%0Aplus%3D''%0Afor%20i%20in%20%24(seq%200%20%24((%24IP4_NUM_ROUTES-1))%20)%0Ado%0A%20%20%20%20varname%3D%22IP4_ROUTE_%24i%22%0A%20%20%20%20nmcli%20con%20mod%20%22%24STATIC_INT_NAME%22%20%24%7Bplus%7Dipv4.routes%20%22%24%7B!varname%7D%22%0A%20%20%20%20plus%3D'%2B'%0Adone%0A%0Anmcli%20con%20up%20%22%24STATIC_INT_NAME%22%0A%0Aif%20%5B%20-n%20%22%24%7BDHCP4_HOST_NAME%3A-%7D%22%20%5D%0Athen%0A%20%20%20%20systemd-run%20--property%3DType%3Doneshot%20--unit%20static-dhcp-hostnamectl%20-Pq%20%5C%0A%20%20%20%20%20%20hostnamectl%20set-hostname%20--static%20--transient%20%22%24DHCP4_HOST_NAME%22%0Afi%0A
          mode: 493
          overwrite: true
          path: /etc/NetworkManager/dispatcher.d/30-static-dhcp
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-ex%20-o%20pipefail%0A%0Aif%20%5B%20-z%20%22%24DHCP6_IP6_ADDRESS%22%20%5D%0Athen%0A%20%20%20%20%3E%262%20echo%20%22Not%20a%20DHCP6%20address.%20Ignoring.%22%0A%20%20%20%20exit%200%0Afi%0A%0ALEASE_TIME%3D%24(ip%20-j%20-6%20a%20show%20%22%24DEVICE_IFACE%22%20%7C%20jq%20-r%20%22.%5B%5D.addr_info%5B%5D%20%7C%20select(.scope%3D%3D%5C%22global%5C%22)%20%7C%20select(.deprecated!%3Dtrue)%20%7C%20select(.local%3D%3D%5C%22%24DHCP6_IP6_ADDRESS%5C%22)%20%7C%20.preferred_life_time%22)%0APREFIX_LEN%3D%24(ip%20-j%20-6%20a%20show%20%22%24DEVICE_IFACE%22%20%7C%20jq%20-r%20%22.%5B%5D.addr_info%5B%5D%20%7C%20select(.scope%3D%3D%5C%22global%5C%22)%20%7C%20select(.deprecated!%3Dtrue)%20%7C%20select(.local%3D%3D%5C%22%24DHCP6_IP6_ADDRESS%5C%22)%20%7C%20.prefixlen%22)%0A%0Aif%20%5B%20%24%7BLEASE_TIME%3A-0%7D%20-lt%204294967295%20%5D%0Athen%0A%20%20%20%20%3E%262%20echo%20%22Not%20an%20infinite%20DHCP6%20lease.%20Ignoring.%22%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20We%20don't%20want%20this%20to%20run%20before%20OVNKubernetes%20creates%20its%20bridge.%20If%20we%0A%23%20see%20the%20default%20CONNECTION_ID%20we%20know%20to%20wait.%0Aif%20%5B%20%22%24CONNECTION_ID%22%20%3D%3D%20%22Wired%20Connection%22%20%5D%0Athen%0A%20%20%20%20%3E%262%20echo%20%22Refusing%20to%20modify%20default%20connection.%22%0A%20%20%20%20exit%200%0Afi%0A%0ACIDR%3D%22%24DHCP6_IP6_ADDRESS%2F%24PREFIX_LEN%22%0Anmcli%20con%20mod%20%22%24CONNECTION_ID%22%20ipv6.addresses%20%22%24CIDR%22%0Anmcli%20con%20mod%20%22%24CONNECTION_ID%22%20connection.autoconnect%20%22yes%22%0Anmcli%20con%20mod%20%22%24CONNECTION_ID%22%20ipv6.method%20%22manual%22%0Anmcli%20con%20mod%20%22%24CONNECTION_ID%22%20ipv6.gateway%20%22%24IP6_GATEWAY%22%0Anmcli%20con%20mod%20%22%24CONNECTION_ID%22%20ipv6.dns%20%22%24IP6_NAMESERVERS%22%0ASEARCH_DOMAIN%3D%22%24%7BDHCP6_FQDN_FQDN%23*.%7D%22%0Aif%20%5B%20-n%20%22%24SEARCH_DOMAIN%22%20%5D%3B%20then%0A%20%20%20%20nmcli%20con%20mod%20%22%24CONNECTION_ID%22%20ipv6.dns-search%20%22%24SEARCH_DOMAIN%22%0Afi%0Aplus%3D''%0Afor%20i%20in%20%24(seq%200%20%24((%24IP6_NUM_ROUTES-1))%20)%0Ado%0A%20%20%20%20varname%3D%22IP6_ROUTE_%24i%22%0A%20%20%20%20nmcli%20con%20mod%20%22%24CONNECTION_ID%22%20%24%7Bplus%7Dipv6.routes%20%22%24%7B!varname%7D%22%0A%20%20%20%20plus%3D'%2B'%0Adone%0A%0A%23%20Copy%20it%20from%20the%20OverlayFS%20mount%20to%20the%20persistent%20lowerdir%0Acp%20%22%24CONNECTION_FILENAME%22%20%2Fetc%2FNetworkManager%2Fsystem-connections%0A
          mode: 493
          overwrite: true
          path: /etc/NetworkManager/dispatcher.d/30-static-dhcpv6
        - contents:
            source: data:,
          mode: 384
          overwrite: true
          path: /etc/pki/ca-trust/source/anchors/openshift-config-user-ca-bundle.crt
        - contents:
            source: data:,KUBERNETES_SERVICE_HOST%3D'api-int.comp-poc-rh01.rhpoc.int'%0AKUBERNETES_SERVICE_PORT%3D'6443'%0A
          mode: 420
          overwrite: true
          path: /etc/kubernetes/apiserver-url.env
        - contents:
            source: data:,%23%20This%20file%20is%20managed%20by%20machine-config-operator.%0A%23%20Suppress%20audit%20rules%20which%20always%20trigger%20for%20container%0A%23%20workloads%2C%20as%20they%20spam%20the%20audit%20log.%20%20Workloads%20are%20expected%0A%23%20to%20be%20dynamic%2C%20and%20the%20networking%20stack%20uses%20iptables.%0A-a%20exclude%2Calways%20-F%20msgtype%3DNETFILTER_CFG%0A%23%20The%20default%20bridged%20networking%20enables%20promiscuous%20on%20the%20veth%0A%23%20device.%20%20Ideally%2C%20we'd%20teach%20audit%20to%20ignore%20only%20veth%20devices%2C%0A%23%20since%20one%20might%20legitimately%20care%20about%20promiscuous%20on%20real%20physical%0A%23%20devices.%20%20But%20we%20can't%20currently%20differentiate.%0A-a%20exclude%2Calways%20-F%20msgtype%3DANOM_PROMISCUOUS%0A
          mode: 420
          overwrite: true
          path: /etc/audit/rules.d/mco-audit-quiet-containers.rules
        - contents:
            source: data:,mode%3A%20unicast%0A
          mode: 420
          overwrite: true
          path: /etc/keepalived/monitor.conf
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%0A%23%20ESP%20offload%2C%20either%20in%20actual%20hardware%20or%20as%20part%20as%20GRO%20(generic%0A%23%20recieve%20offload)%20does%20not%20work%20for%20interfaces%20attached%20to%20an%20OVS%20bridge%0A%23%20so%20turn%20it%20off%20for%20the%20time%20being.%0A%23%20https%3A%2F%2Fissues.redhat.com%2Fbrowse%2FRHEL-58811%0A%0A%23%20Depends%20on%20ipsec%20service%20drop-in%20to%20start%20it%20after%20configure-ovs%20to%20make%0A%23%20sure%20offloads%20are%20disabled%20before%20ipsec%20starts.%0A%0Aif%20%5B%5B%20%22%242%22%20!%3D%20%22up%22%20%5D%5D%3B%20then%0A%20%20exit%0Afi%0A%0Adevice%3D%24DEVICE_IFACE%0Akind_slave%3D%24(ip%20-j%20-d%20link%20show%20%22%24device%22%20%7C%20jq%20-r%20'.%5B0%5D%20%7C%20.linkinfo.info_slave_kind%20%2F%2F%20empty')%0A%0Aif%20%5B%20%22%24kind_slave%22%20%3D%20%22openvswitch%22%20%5D%3B%20then%0A%20%20for%20feature%20in%20tx-esp-segmentation%20esp-hw-offload%20esp-tx-csum-hw-offload%3B%20do%0A%20%20%20%20if%20ethtool%20-k%20%22%24device%22%20%7C%20grep%20-qE%20%22%5E%24%7Bfeature%7D%3A%20off%22%3B%20then%0A%20%20%20%20%20%20%23%20already%20disabled%2C%20nothing%20to%20do%0A%20%20%20%20%20%20continue%0A%20%20%20%20fi%0A%20%20%20%20%0A%20%20%20%20logger%20-t%2099-esp-offload%20-s%20%22Setting%20%24feature%20off%20for%20%24device%3A%20unsupported%20when%20attached%20to%20Open%20vSwitch%20bridge%22%0A%20%20%20%20ethtool%20-K%20%22%24device%22%20%22%24feature%22%20off%0A%20%20done%0Afi%0A
          mode: 484
          overwrite: true
          path: /etc/NetworkManager/dispatcher.d/99-esp-offload
        - contents:
            source: data:,r%20%2Fetc%2Fkubernetes%2Fcni%2Fnet.d%2F80-openshift-network.conf%0Ar%20%2Fetc%2Fkubernetes%2Fcni%2Fnet.d%2F10-ovn-kubernetes.conf%0Ad%20%2Frun%2Fmultus%2Fcni%2Fnet.d%2F%200755%20root%20root%20-%20-%0AD%20%2Fvar%2Flib%2Fcni%2Fnetworks%2Fopenshift-sdn%2F%200755%20root%20root%20-%20-%0A
          mode: 420
          overwrite: true
          path: /etc/tmpfiles.d/cleanup-cni.conf
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-ex%0A%0A%23%20Used%20for%20on-prem%20deployments%20to%20enable%20ip%20forwarding%20as%20part%20of%20nodeip-configuration%20service.%0A%23%20IP%20forwarding%20is%20required%20on%20the%20node%20IP%20(k8s%20API)%20interface%20in%20order%20for%20keepalived%20to%20function.%0A%0Aecho%20%22Configuring%20IP%20Forwarding...%22%0Aovnk_config_dir%3D'%2Fetc%2Fovnk'%0Aip_hint_file%3D%22%2Frun%2Fnodeip-configuration%2Fprimary-ip%22%0A%0Aget_ip_from_ip_hint_file()%20%7B%0A%20%20local%20ip_hint_file%3D%22%241%22%0A%20%20if%20%5B%5B%20!%20-f%20%22%24%7Bip_hint_file%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22error%3A%20unable%20to%20enable%20IP%20forwarding.%20IP%20hint%20file%3A%20%24%7Bip_hint_file%7D%20does%20not%20exist!%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%20%20ip_hint%3D%24(cat%20%22%24%7Bip_hint_file%7D%22)%0A%20%20echo%20%22%24%7Bip_hint%7D%22%0A%7D%0A%0Aget_nodeip_hint_interface()%20%7B%0A%20%20local%20ip_hint%3D%22%22%0A%20%20local%20ip_hint_file%3D%22%241%22%0A%20%20local%20iface%3D%22%22%0A%0A%20%20ip_hint%3D%24(get_ip_from_ip_hint_file%20%22%24%7Bip_hint_file%7D%22)%0A%20%20if%20%5B%5B%20-z%20%22%24%7Bip_hint%7D%22%20%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22error%3A%20unable%20to%20enable%20IP%20forwarding.%20IP%20hint%20file%3A%20%24%7Bip_hint_file%7D%20is%20empty!%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%0A%20%20iface%3D%24(ip%20-j%20addr%20%7C%20jq%20-r%20%22first(.%5B%5D%20%7C%20select(any(.addr_info%5B%5D%3B%20.local%3D%3D%5C%22%24%7Bip_hint%7D%5C%22)))%20%7C%20.ifname%22)%0A%20%20if%20%5B%5B%20-z%20%22%24%7Biface%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22error%3A%20unable%20to%20enable%20IP%20forwarding.%20Cannot%20detect%20valid%20interface%20within%20file%3A%20%24%7Bip_hint_file%7D%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%20%20echo%20%22%24%7Biface%7D%22%0A%7D%0A%0Aiface%3D%24(get_nodeip_hint_interface%20%22%24%7Bip_hint_file%7D%22)%0A%0Aecho%20%22Node%20IP%20interface%20determined%20as%3A%20%24%7Biface%7D.%20Enabling%20IP%20forwarding...%22%0Afile_paths%3D(%22%2Fproc%2Fsys%2Fnet%2Fipv4%2Fconf%2F%24%7Biface%7D%2Fforwarding%22%20%22%2Fproc%2Fsys%2Fnet%2Fipv6%2Fconf%2F%24%7Biface%7D%2Fforwarding%22)%0Afor%20file_path%20in%20%22%24%7Bfile_paths%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20if%20%5B%20-f%20%22%24%7Bfile_path%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%221%22%20%3E%20%22%24%7Bfile_path%7D%22%0A%20%20%20%20fi%0Adone%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/configure-ip-forwarding.sh
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-x%0A%0Aif%20%5B%20-e%20%2Fetc%2Fnmstate%2Fopenshift%2Fapplied%20%5D%3B%20then%0A%20%20echo%20%22Skipping%20configure-ovs%20due%20to%20manual%20network%20configuration%22%0A%20%20exit%200%0Afi%0A%0A%23%20This%20file%20is%20not%20needed%20anymore%20in%204.7%2B%2C%20but%20when%20rolling%20back%20to%204.6%0A%23%20the%20ovs%20pod%20needs%20it%20to%20know%20ovs%20is%20running%20on%20the%20host.%0Atouch%20%2Fvar%2Frun%2Fovs-config-executed%0A%0A%23%20These%20are%20well%20knwon%20NM%20default%20paths%0ANM_CONN_ETC_PATH%3D%22%2Fetc%2FNetworkManager%2Fsystem-connections%22%0ANM_CONN_RUN_PATH%3D%22%2Frun%2FNetworkManager%2Fsystem-connections%22%0A%0A%23%20This%20is%20the%20path%20where%20NM%20is%20known%20to%20be%20configured%20to%20store%20user%20keyfiles%20%0ANM_CONN_CONF_PATH%3D%22%24NM_CONN_ETC_PATH%22%0A%0A%23%20This%20is%20where%20we%20want%20our%20keyfiles%20to%20finally%20reside.%20configure-ovs%0A%23%20operates%20with%20temporary%20keyfiles%20in%20NM_CONN_RUN_PATH%20and%20then%20as%20a%20last%0A%23%20step%20moves%20those%20keyfiles%20to%20NM_CONN_SET_PATH%20if%20it%20is%20a%20different%20path%0A%23%20(not%20by%20default).%20This%20mitigates%20hard%20interruptions%20(SIGKILL%2C%20hard%20reboot)%0A%23%20of%20configure-ovs%20leaving%20the%20machine%20with%20a%20half-baked%20set%20of%20keyfiles%0A%23%20that%20might%20prevent%20machine%20networking%20from%20working%20correctly.%0ANM_CONN_SET_PATH%3D%22%24%7BNM_CONN_SET_PATH%3A-%24NM_CONN_RUN_PATH%7D%22%0A%0AMANAGED_NM_CONN_SUFFIX%3D%22-slave-ovs-clone%22%0A%23%20Workaround%20to%20ensure%20OVS%20is%20installed%20due%20to%20bug%20in%20systemd%20Requires%3A%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1888017%0Acopy_nm_conn_files()%20%7B%0A%20%20local%20dst_path%3D%22%241%22%0A%20%20for%20src%20in%20%22%24%7BMANAGED_NM_CONN_FILES%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20src_path%3D%24(dirname%20%22%24src%22)%0A%20%20%20%20file%3D%24(basename%20%22%24src%22)%0A%20%20%20%20if%20%5B%20-f%20%22%24src_path%2F%24file%22%20%5D%3B%20then%0A%20%20%20%20%20%20if%20%5B%20!%20-f%20%22%24dst_path%2F%24file%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22Copying%20configuration%20%24file%22%0A%20%20%20%20%20%20%20%20cp%20%22%24src_path%2F%24file%22%20%22%24dst_path%2F%24file%22%0A%20%20%20%20%20%20elif%20!%20cmp%20--silent%20%22%24src_path%2F%24file%22%20%22%24dst_path%2F%24file%22%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22Copying%20updated%20configuration%20%24file%22%0A%20%20%20%20%20%20%20%20cp%20-f%20%22%24src_path%2F%24file%22%20%22%24dst_path%2F%24file%22%0A%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20echo%20%22Skipping%20%24file%20since%20it's%20equal%20at%20destination%22%0A%20%20%20%20%20%20fi%0A%20%20%20%20else%0A%20%20%20%20%20%20echo%20%22Skipping%20%24file%20since%20it%20does%20not%20exist%20at%20source%22%0A%20%20%20%20fi%0A%20%20done%0A%7D%0A%0Aupdate_nm_conn_files_base()%20%7B%0A%20%20base_path%3D%24%7B1%7D%0A%20%20bridge_name%3D%24%7B2%7D%0A%20%20port_name%3D%24%7B3%7D%0A%20%20ovs_port%3D%22ovs-port-%24%7Bbridge_name%7D%22%0A%20%20ovs_interface%3D%22ovs-if-%24%7Bbridge_name%7D%22%0A%20%20default_port_name%3D%22ovs-port-%24%7Bport_name%7D%22%20%23%20ovs-port-phys0%0A%20%20bridge_interface_name%3D%22ovs-if-%24%7Bport_name%7D%22%20%23%20ovs-if-phys0%0A%20%20%23%20In%20RHEL7%20files%20in%20%2F%7Betc%2Crun%7D%2FNetworkManager%2Fsystem-connections%20end%20without%20the%20suffix%20'.nmconnection'%2C%20whereas%20in%20RHCOS%20they%20end%20with%20the%20suffix.%0A%20%20MANAGED_NM_CONN_FILES%3D(%24(echo%20%22%24%7Bbase_path%7D%22%2F%7B%22%24bridge_name%22%2C%22%24ovs_interface%22%2C%22%24ovs_port%22%2C%22%24bridge_interface_name%22%2C%22%24default_port_name%22%7D%7B%2C.nmconnection%7D))%0A%20%20shopt%20-s%20nullglob%0A%20%20MANAGED_NM_CONN_FILES%2B%3D(%24%7Bbase_path%7D%2F*%24%7BMANAGED_NM_CONN_SUFFIX%7D.nmconnection%20%24%7Bbase_path%7D%2F*%24%7BMANAGED_NM_CONN_SUFFIX%7D)%0A%20%20shopt%20-u%20nullglob%0A%7D%0A%0Aupdate_nm_conn_run_files()%20%7B%0A%20%20update_nm_conn_files_base%20%22%24%7BNM_CONN_RUN_PATH%7D%22%20%22%24%7B1%7D%22%20%22%24%7B2%7D%22%0A%7D%0A%0Aupdate_nm_conn_set_files()%20%7B%0A%20%20update_nm_conn_files_base%20%22%24%7BNM_CONN_SET_PATH%7D%22%20%22%24%7B1%7D%22%20%22%24%7B2%7D%22%0A%7D%0A%0Aupdate_nm_conn_etc_files()%20%7B%0A%20%20update_nm_conn_files_base%20%22%24%7BNM_CONN_ETC_PATH%7D%22%20%22%24%7B1%7D%22%20%22%24%7B2%7D%22%0A%7D%0A%0A%23%20Move%20and%20reload%20keyfiles%20at%20their%20final%20destination%0Aset_nm_conn_files()%20%7B%0A%20%20if%20%5B%20%22%24NM_CONN_RUN_PATH%22%20!%3D%20%22%24NM_CONN_SET_PATH%22%20%5D%3B%20then%0A%20%20%20%20update_nm_conn_run_files%20br-ex%20phys0%0A%20%20%20%20copy_nm_conn_files%20%22%24NM_CONN_SET_PATH%22%0A%20%20%20%20rm_nm_conn_files%0A%20%20%20%20update_nm_conn_run_files%20br-ex1%20phys1%0A%20%20%20%20copy_nm_conn_files%20%22%24NM_CONN_SET_PATH%22%0A%20%20%20%20rm_nm_conn_files%0A%0A%20%20%20%20%23%20reload%20keyfiles%0A%20%20%20%20nmcli%20connection%20reload%0A%20%20fi%0A%7D%0A%0A%23%20Used%20to%20remove%20files%20managed%20by%20configure-ovs%20and%20temporary%20leftover%20files%20from%20network%20manager%0Arm_nm_conn_files()%20%7B%0A%20%20for%20file%20in%20%22%24%7BMANAGED_NM_CONN_FILES%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20if%20%5B%20-f%20%22%24file%22%20%5D%3B%20then%0A%20%20%20%20%20%20rm%20-f%20%22%24file%22%0A%20%20%20%20%20%20echo%20%22Removed%20nmconnection%20file%20%24file%22%0A%20%20%20%20%20%20nm_config_changed%3D1%0A%20%20%20%20fi%0A%20%20done%0A%20%20for%20file%20in%20%22%24%7BMANAGED_NM_CONN_FILES%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20for%20temp%20in%20%24(compgen%20-G%20%22%24%7Bfile%7D.*%22)%3B%20do%0A%20%20%20%20%20%20rm%20-f%20%22%24temp%22%0A%20%20%20%20%20%20echo%20%22Removed%20nmconnection%20temporary%20file%20%24temp%22%0A%20%20%20%20%20%20nm_config_changed%3D1%0A%20%20%20%20done%0A%20%20done%0A%7D%0A%0A%23%20Used%20to%20clone%20a%20slave%20connection%20by%20uuid%2C%20returns%20new%20name%0Aclone_slave_connection()%20%7B%0A%20%20local%20uuid%3D%22%241%22%0A%20%20local%20old_name%0A%20%20old_name%3D%22%24(nmcli%20-g%20connection.id%20connection%20show%20uuid%20%22%24uuid%22)%22%0A%20%20local%20new_name%3D%22%24%7Bold_name%7D%24%7BMANAGED_NM_CONN_SUFFIX%7D%22%0A%20%20if%20nmcli%20connection%20show%20id%20%22%24%7Bnew_name%7D%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20echo%20%22WARNING%3A%20existing%20ovs%20slave%20%24%7Bnew_name%7D%20connection%20profile%20file%20found%2C%20overwriting...%22%20%3E%262%0A%20%20%20%20nmcli%20connection%20delete%20id%20%22%24%7Bnew_name%7D%22%20%26%3E%20%2Fdev%2Fnull%0A%20%20fi%0A%20%20clone_nm_conn%20%24uuid%20%22%24%7Bnew_name%7D%22%0A%20%20echo%20%22%24%7Bnew_name%7D%22%0A%7D%0A%0A%23%20Used%20to%20replace%20an%20old%20master%20connection%20uuid%20with%20a%20new%20one%20on%20all%20connections%0Areplace_connection_master()%20%7B%0A%20%20local%20old%3D%22%241%22%0A%20%20local%20new%3D%22%242%22%0A%20%20for%20conn_uuid%20in%20%24(nmcli%20-g%20UUID%20connection%20show)%20%3B%20do%0A%20%20%20%20if%20%5B%20%22%24(nmcli%20-g%20connection.master%20connection%20show%20uuid%20%22%24conn_uuid%22)%22%20!%3D%20%22%24old%22%20%5D%3B%20then%0A%20%20%20%20%20%20continue%0A%20%20%20%20fi%0A%0A%20%20%20%20local%20active_state%3D%24(nmcli%20-g%20GENERAL.STATE%20connection%20show%20%22%24conn_uuid%22)%0A%20%20%20%20local%20autoconnect%3D%24(nmcli%20-g%20connection.autoconnect%20connection%20show%20%22%24conn_uuid%22)%0A%20%20%20%20if%20%5B%20%22%24active_state%22%20!%3D%20%22activated%22%20%5D%20%26%26%20%5B%20%22%24autoconnect%22%20!%3D%20%22yes%22%20%5D%3B%20then%0A%20%20%20%20%20%20%23%20Assume%20that%20slave%20profiles%20intended%20to%20be%20used%20are%20those%20that%20are%3A%0A%20%20%20%20%20%20%23%20-%20active%0A%20%20%20%20%20%20%23%20-%20or%20inactive%20(which%20might%20be%20due%20to%20link%20being%20down)%20but%20to%20be%20autoconnected.%0A%20%20%20%20%20%20%23%20Otherwise%2C%20ignore%20them.%0A%20%20%20%20%20%20continue%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20make%20changes%20for%20slave%20profiles%20in%20a%20new%20clone%0A%20%20%20%20local%20new_name%0A%20%20%20%20new_name%3D%24(clone_slave_connection%20%24conn_uuid)%0A%0A%20%20%20%20mod_nm_conn%20%22%24new_name%22%20connection.master%20%22%24new%22%20connection.autoconnect-priority%20100%20connection.autoconnect%20no%20%0A%20%20%20%20echo%20%22Replaced%20master%20%24old%20with%20%24new%20for%20slave%20profile%20%24new_name%22%0A%20%20done%0A%7D%0A%0A%23%20when%20creating%20the%20bridge%2C%20we%20use%20a%20value%20lower%20than%20NM's%20ethernet%20device%20default%20route%20metric%0A%23%20(we%20pick%2048%20and%2049%20to%20be%20lower%20than%20anything%20that%20NM%20chooses%20by%20default)%0ABRIDGE_METRIC%3D%2248%22%0ABRIDGE1_METRIC%3D%2249%22%0A%23%20Given%20an%20interface%2C%20generates%20NM%20configuration%20to%20add%20to%20an%20OVS%20bridge%0Aconvert_to_bridge()%20%7B%0A%20%20local%20iface%3D%24%7B1%7D%0A%20%20local%20bridge_name%3D%24%7B2%7D%0A%20%20local%20port_name%3D%24%7B3%7D%0A%20%20local%20bridge_metric%3D%24%7B4%7D%0A%20%20local%20ovs_port%3D%22ovs-port-%24%7Bbridge_name%7D%22%0A%20%20local%20ovs_interface%3D%22ovs-if-%24%7Bbridge_name%7D%22%0A%20%20local%20default_port_name%3D%22ovs-port-%24%7Bport_name%7D%22%20%23%20ovs-port-phys0%0A%20%20local%20bridge_interface_name%3D%22ovs-if-%24%7Bport_name%7D%22%20%23%20ovs-if-phys0%0A%0A%20%20if%20%5B%20%22%24iface%22%20%3D%20%22%24bridge_name%22%20%5D%3B%20then%0A%20%20%20%20%23%20handle%20vlans%20and%20bonds%20etc%20if%20they%20have%20already%20been%0A%20%20%20%20%23%20configured%20via%20nm%20key%20files%20and%20br-ex%20is%20already%20up%0A%20%20%20%20ifaces%3D%24(ovs-vsctl%20list-ifaces%20%24%7Biface%7D)%0A%20%20%20%20for%20intf%20in%20%24ifaces%3B%20do%20configure_driver_options%20%24intf%3B%20done%0A%20%20%20%20echo%20%22Networking%20already%20configured%20and%20up%20for%20%24%7Bbridge-name%7D!%22%0A%20%20%20%20return%0A%20%20fi%0A%0A%20%20%23%20flag%20to%20reload%20NM%20to%20account%20for%20all%20the%20configuration%20changes%0A%20%20%23%20going%20forward%0A%20%20nm_config_changed%3D1%0A%0A%20%20if%20%5B%20-z%20%22%24iface%22%20%5D%3B%20then%0A%20%20%20%20echo%20%22ERROR%3A%20Unable%20to%20find%20default%20gateway%20interface%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%20%20%23%20find%20the%20MAC%20from%20OVS%20config%20or%20the%20default%20interface%20to%20use%20for%20OVS%20internal%20port%0A%20%20%23%20this%20prevents%20us%20from%20getting%20a%20different%20DHCP%20lease%20and%20dropping%20connection%0A%20%20if%20!%20iface_mac%3D%24(%3C%22%2Fsys%2Fclass%2Fnet%2F%24%7Biface%7D%2Faddress%22)%3B%20then%0A%20%20%20%20echo%20%22Unable%20to%20determine%20default%20interface%20MAC%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%0A%20%20echo%20%22MAC%20address%20found%20for%20iface%3A%20%24%7Biface%7D%3A%20%24%7Biface_mac%7D%22%0A%0A%20%20%23%20find%20MTU%20from%20original%20iface%0A%20%20iface_mtu%3D%24(ip%20link%20show%20%22%24iface%22%20%7C%20awk%20'%7Bprint%20%245%3B%20exit%7D')%0A%20%20if%20%5B%5B%20-z%20%22%24iface_mtu%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22Unable%20to%20determine%20default%20interface%20MTU%2C%20defaulting%20to%201500%22%0A%20%20%20%20iface_mtu%3D1500%0A%20%20else%0A%20%20%20%20echo%20%22MTU%20found%20for%20iface%3A%20%24%7Biface%7D%3A%20%24%7Biface_mtu%7D%22%0A%20%20fi%0A%0A%20%20%23%20store%20old%20conn%20for%20later%0A%20%20old_conn%3D%24(nmcli%20--fields%20UUID%2CDEVICE%20conn%20show%20--active%20%7C%20awk%20%22%2F%5Cs%24%7Biface%7D%5Cs*%5C%24%2F%20%7Bprint%20%5C%241%7D%22)%0A%0A%20%20if%20%5B%5B%20-z%20%22%24old_conn%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22ERROR%3A%20cannot%20find%20connection%20for%20interface%3A%20%24%7Biface%7D%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%0A%20%20%23%20create%20bridge%0A%20%20if%20!%20nmcli%20connection%20show%20%22%24bridge_name%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-br%20%22%24bridge_name%22%0A%20%20%20%20add_nm_conn%20%22%24bridge_name%22%20type%20ovs-bridge%20conn.interface%20%22%24bridge_name%22%20802-3-ethernet.mtu%20%24%7Biface_mtu%7D%20%5C%0A%20%20%20%20connection.autoconnect-slaves%201%0A%20%20fi%0A%0A%20%20%23%20find%20default%20port%20to%20add%20to%20bridge%0A%20%20if%20!%20nmcli%20connection%20show%20%22%24default_port_name%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-port%20%22%24bridge_name%22%20%24%7Biface%7D%0A%20%20%20%20add_nm_conn%20%22%24default_port_name%22%20type%20ovs-port%20conn.interface%20%24%7Biface%7D%20slave-type%20ovs-bridge%20master%20%22%24bridge_name%22%20%5C%0A%20%20%20%20connection.autoconnect-slaves%201%0A%20%20fi%0A%0A%20%20if%20!%20nmcli%20connection%20show%20%22%24ovs_port%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-port%20%22%24bridge_name%22%20%22%24bridge_name%22%0A%20%20%20%20add_nm_conn%20%22%24ovs_port%22%20type%20ovs-port%20conn.interface%20%22%24bridge_name%22%20slave-type%20ovs-bridge%20master%20%22%24bridge_name%22%0A%20%20fi%0A%0A%20%20extra_phys_args%3D()%0A%20%20%23%20check%20if%20this%20interface%20is%20a%20vlan%2C%20bond%2C%20team%2C%20or%20ethernet%20type%0A%20%20if%20%5B%20%22%24(nmcli%20--get-values%20connection.type%20conn%20show%20%24%7Bold_conn%7D)%22%20%3D%3D%20%22vlan%22%20%5D%3B%20then%0A%20%20%20%20iface_type%3Dvlan%0A%20%20%20%20vlan_id%3D%24(nmcli%20--get-values%20vlan.id%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20if%20%5B%20-z%20%22%24vlan_id%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22ERROR%3A%20unable%20to%20determine%20vlan_id%20for%20vlan%20connection%3A%20%24%7Bold_conn%7D%22%0A%20%20%20%20%20%20exit%201%0A%20%20%20%20fi%0A%20%20%20%20vlan_parent%3D%24(nmcli%20--get-values%20vlan.parent%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20if%20%5B%20-z%20%22%24vlan_parent%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22ERROR%3A%20unable%20to%20determine%20vlan_parent%20for%20vlan%20connection%3A%20%24%7Bold_conn%7D%22%0A%20%20%20%20%20%20exit%201%0A%20%20%20%20fi%0A%0A%20%20%20%20if%20nmcli%20connection%20show%20uuid%20%22%24vlan_parent%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20%20%20%23%20if%20the%20VLAN%20connection%20is%20configured%20with%20a%20connection%20UUID%20as%20parent%2C%20we%20need%20to%20find%20the%20underlying%20device%0A%20%20%20%20%20%20%23%20and%20create%20the%20bridge%20against%20it%2C%20as%20the%20parent%20connection%20can%20be%20replaced%20by%20another%20bridge.%0A%20%20%20%20%20%20vlan_parent%3D%24(nmcli%20--get-values%20GENERAL.DEVICES%20conn%20show%20uuid%20%24%7Bvlan_parent%7D)%0A%20%20%20%20fi%0A%0A%20%20%20%20extra_phys_args%3D(%20dev%20%22%24%7Bvlan_parent%7D%22%20id%20%22%24%7Bvlan_id%7D%22%20)%0A%20%20elif%20%5B%20%22%24(nmcli%20--get-values%20connection.type%20conn%20show%20%24%7Bold_conn%7D)%22%20%3D%3D%20%22bond%22%20%5D%3B%20then%0A%20%20%20%20iface_type%3Dbond%0A%20%20%20%20%23%20check%20bond%20options%0A%20%20%20%20bond_opts%3D%24(nmcli%20--get-values%20bond.options%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20if%20%5B%20-n%20%22%24bond_opts%22%20%5D%3B%20then%0A%20%20%20%20%20%20extra_phys_args%2B%3D(%20bond.options%20%22%24%7Bbond_opts%7D%22%20)%0A%20%20%20%20%20%20MODE_REGEX%3D%22(%5E%7C%2C)mode%3Dactive-backup(%2C%7C%24)%22%0A%20%20%20%20%20%20MAC_REGEX%3D%22(%5E%7C%2C)fail_over_mac%3D(1%7Cactive%7C2%7Cfollow)(%2C%7C%24)%22%0A%20%20%20%20%20%20if%20%5B%5B%20%24bond_opts%20%3D~%20%24MODE_REGEX%20%5D%5D%20%26%26%20%5B%5B%20%24bond_opts%20%3D~%20%24MAC_REGEX%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20clone_mac%3D0%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%20%20elif%20%5B%20%22%24(nmcli%20--get-values%20connection.type%20conn%20show%20%24%7Bold_conn%7D)%22%20%3D%3D%20%22team%22%20%5D%3B%20then%0A%20%20%20%20iface_type%3Dteam%0A%20%20%20%20%23%20check%20team%20config%20options%0A%20%20%20%20team_config_opts%3D%24(nmcli%20--get-values%20team.config%20-e%20no%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20if%20%5B%20-n%20%22%24team_config_opts%22%20%5D%3B%20then%0A%20%20%20%20%20%20%23%20team.config%20is%20json%2C%20remove%20spaces%20to%20avoid%20problems%20later%20on%0A%20%20%20%20%20%20extra_phys_args%2B%3D(%20team.config%20%22%24%7Bteam_config_opts%2F%2F%5B%5B%3Aspace%3A%5D%5D%2F%7D%22%20)%0A%20%20%20%20%20%20team_mode%3D%24(echo%20%22%24%7Bteam_config_opts%7D%22%20%7C%20jq%20-r%20%22.runner.name%20%2F%2F%20empty%22)%0A%20%20%20%20%20%20team_mac_policy%3D%24(echo%20%22%24%7Bteam_config_opts%7D%22%20%7C%20jq%20-r%20%22.runner.hwaddr_policy%20%2F%2F%20empty%22)%0A%20%20%20%20%20%20MAC_REGEX%3D%22(by_active%7Conly_active)%22%0A%20%20%20%20%20%20if%20%5B%20%22%24team_mode%22%20%3D%20%22activebackup%22%20%5D%20%26%26%20%5B%5B%20%22%24team_mac_policy%22%20%3D~%20%24MAC_REGEX%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20clone_mac%3D0%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%20%20elif%20%5B%20%22%24(nmcli%20--get-values%20connection.type%20conn%20show%20%24%7Bold_conn%7D)%22%20%3D%3D%20%22tun%22%20%5D%3B%20then%0A%20%20%20%20iface_type%3Dtun%0A%20%20%20%20tun_mode%3D%24(nmcli%20--get-values%20tun.mode%20-e%20no%20connection%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20extra_phys_args%2B%3D(%20tun.mode%20%22%24%7Btun_mode%7D%22%20)%0A%20%20elif%20%5B%20%22%24(nmcli%20--get-values%20connection.type%20conn%20show%20%24%7Bold_conn%7D)%22%20%3D%3D%20%22bridge%22%20%5D%3B%20then%0A%20%20%20%20iface_type%3Dbridge%0A%20%20else%0A%20%20%20%20iface_type%3D802-3-ethernet%0A%20%20fi%0A%0A%20%20if%20%5B%20!%20%22%24%7Bclone_mac%3A-%7D%22%20%3D%20%220%22%20%5D%3B%20then%0A%20%20%20%20%23%20In%20active-backup%20link%20aggregation%2C%20with%20fail_over_mac%20mode%20enabled%2C%0A%20%20%20%20%23%20cloning%20the%20mac%20address%20is%20not%20supported.%20It%20is%20possible%20then%20that%0A%20%20%20%20%23%20br-ex%20has%20a%20different%20mac%20address%20than%20the%20bond%20which%20might%20be%0A%20%20%20%20%23%20troublesome%20on%20some%20platforms%20where%20the%20nic%20won't%20accept%20packets%20with%0A%20%20%20%20%23%20a%20different%20destination%20mac.%20But%20nobody%20has%20complained%20so%20far%20so%20go%20on%0A%20%20%20%20%23%20with%20what%20we%20got.%20%0A%20%20%20%20%0A%20%20%20%20%23%20Do%20set%20it%20though%20for%20other%20link%20aggregation%20configurations%20where%20the%0A%20%20%20%20%23%20mac%20address%20would%20otherwise%20depend%20on%20enslave%20order%20for%20which%20we%20have%0A%20%20%20%20%23%20no%20control%20going%20forward.%0A%20%20%20%20extra_phys_args%2B%3D(%20802-3-ethernet.cloned-mac-address%20%22%24%7Biface_mac%7D%22%20)%0A%20%20fi%0A%0A%20%20%23%20use%20%24%7Bextra_phys_args%5B%40%5D%2B%22%24%7Bextra_phys_args%5B%40%5D%7D%22%7D%20instead%20of%20%24%7Bextra_phys_args%5B%40%5D%7D%20to%20be%20compatible%20with%20bash%204.2%20in%20RHEL7.9%0A%20%20if%20!%20nmcli%20connection%20show%20%22%24bridge_interface_name%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20destroy%20interface%20%24%7Biface%7D%0A%20%20%20%20ovs_default_port_conn%3D%24(nmcli%20-g%20connection.uuid%20conn%20show%20%22%24default_port_name%22)%0A%20%20%20%20add_nm_conn%20%22%24bridge_interface_name%22%20type%20%24%7Biface_type%7D%20conn.interface%20%24%7Biface%7D%20master%20%22%24ovs_default_port_conn%22%20%5C%0A%20%20%20%20%20%20slave-type%20ovs-port%20connection.autoconnect-priority%20100%20connection.autoconnect-slaves%201%20802-3-ethernet.mtu%20%24%7Biface_mtu%7D%20%5C%0A%20%20%20%20%20%20%24%7Bextra_phys_args%5B%40%5D%2B%22%24%7Bextra_phys_args%5B%40%5D%7D%22%7D%0A%20%20fi%0A%0A%20%20%23%20Get%20the%20new%20connection%20uuids%0A%20%20new_conn%3D%24(nmcli%20-g%20connection.uuid%20conn%20show%20%22%24bridge_interface_name%22)%0A%20%20ovs_port_conn%3D%24(nmcli%20-g%20connection.uuid%20conn%20show%20%22%24ovs_port%22)%0A%0A%20%20%23%20Update%20connections%20with%20master%20property%20set%20to%20use%20the%20new%20connection%0A%20%20replace_connection_master%20%24old_conn%20%24new_conn%0A%20%20replace_connection_master%20%24iface%20%24new_conn%0A%0A%20%20ipv4_method%3D%24(nmcli%20-g%20ipv4.method%20conn%20show%20%22%24old_conn%22)%0A%20%20ipv6_method%3D%24(nmcli%20-g%20ipv6.method%20conn%20show%20%22%24old_conn%22)%0A%0A%20%20ipv4_addresses%3D%24(nmcli%20-g%20ipv4.addresses%20conn%20show%20%22%24old_conn%22)%0A%20%20ipv6_addresses%3D%24(nmcli%20-g%20ipv6.addresses%20conn%20show%20%22%24old_conn%22)%0A%0A%20%20%23%20Warn%20about%20an%20invalid%20MTU%20that%20will%20most%20likely%20fail%20in%20one%20way%20or%0A%20%20%23%20another%0A%20%20if%20%5B%20%24%7Biface_mtu%7D%20-lt%201280%20%5D%20%26%26%20%5B%20%22%24%7Bipv6_method%7D%22%20!%3D%20%22disabled%22%20%5D%3B%20then%0A%20%20%20%20echo%20%22WARNING%3A%20MTU%20%24%7Biface_mtu%7D%20is%20lower%20than%20the%20minimum%20required%20of%201280%20for%20IPv6%22%0A%20%20fi%0A%0A%20%20if%20!%20nmcli%20connection%20show%20%22%24ovs_interface%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20destroy%20interface%20%22%24bridge_name%22%0A%20%20%20%20%23%20Clone%20the%20connection%20in%20case%20the%20method%20is%20manual%20or%20in%20case%20the%20an%20address%20is%20set%20(DHCP%20%2B%20static%20IP)%0A%20%20%20%20if%20%5B%20%22%24%7Bipv4_method%7D%22%20%3D%20%22manual%22%20%5D%20%7C%7C%20%5B%20%22%24%7Bipv4_addresses%7D%22%20!%3D%20%22%22%20%5D%20%7C%7C%20%5B%20%22%24%7Bipv6_method%7D%22%20%3D%20%22manual%22%20%5D%20%7C%7C%20%5B%20%22%24%7Bipv6_addresses%7D%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22Static%20IP%20addressing%20detected%20on%20default%20gateway%20connection%3A%20%24%7Bold_conn%7D%22%0A%20%20%20%20%20%20%23%20clone%20the%20old%20connection%20to%20get%20the%20address%20settings%0A%20%20%20%20%20%20%23%20prefer%20cloning%20vs%20copying%20the%20connection%20file%20to%20avoid%20problems%20with%20selinux%0A%20%20%20%20%20%20clone_nm_conn%20%22%24%7Bold_conn%7D%22%20%22%24%7Bovs_interface%7D%22%0A%20%20%20%20%20%20shopt%20-s%20nullglob%0A%20%20%20%20%20%20new_conn_files%3D(%24%7BNM_CONN_RUN_PATH%7D%2F%22%24%7Bovs_interface%7D%22*)%0A%20%20%20%20%20%20shopt%20-u%20nullglob%0A%20%20%20%20%20%20if%20%5B%20%24%7B%23new_conn_files%5B%40%5D%7D%20-ne%201%20%5D%20%7C%7C%20%5B%20!%20-f%20%22%24%7Bnew_conn_files%5B0%5D%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22ERROR%3A%20could%20not%20find%20%24%7Bovs_interface%7D%20conn%20file%20after%20cloning%20from%20%24%7Bold_conn%7D%22%0A%20%20%20%20%20%20%20%20exit%201%0A%20%20%20%20%20%20fi%0A%20%20%20%20%20%20new_conn_file%3D%22%24%7Bnew_conn_files%5B0%5D%7D%22%0A%0A%20%20%20%20%20%20%23%20modify%20the%20connection%20type%20directly%20because%20it%20can't%20be%20modified%0A%20%20%20%20%20%20%23%20through%20nmcli%0A%20%20%20%20%20%20sed%20-i%20'%2F%5E%5C%5Bconnection%5C%5D%24%2F%2C%2F%5E%5C%5B%2F%20s%2F%5Etype%3D.*%24%2Ftype%3Dovs-interface%2F'%20%24%7Bnew_conn_file%7D%0A%0A%20%20%20%20%20%20%23%20modify%20some%20more%20settings%20through%20nmcli%0A%20%20%20%20%20%20mod_nm_conn%20%22%24%7Bovs_interface%7D%22%20conn.interface%20%22%24bridge_name%22%20%5C%0A%20%20%20%20%20%20%20%20connection.multi-connect%20%22%22%20connection.autoconnect%20no%20%5C%0A%20%20%20%20%20%20%20%20connection.master%20%22%24ovs_port_conn%22%20connection.slave-type%20ovs-port%20%5C%0A%20%20%20%20%20%20%20%20ovs-interface.type%20internal%20%5C%0A%20%20%20%20%20%20%20%20802-3-ethernet.mtu%20%24%7Biface_mtu%7D%20802-3-ethernet.cloned-mac-address%20%24%7Biface_mac%7D%20%5C%0A%20%20%20%20%20%20%20%20ipv4.route-metric%20%22%24%7Bbridge_metric%7D%22%20ipv6.route-metric%20%22%24%7Bbridge_metric%7D%22%0A%0A%20%20%20%20%20%20echo%20%22Loaded%20new%20%24ovs_interface%20connection%20file%3A%20%24%7Bnew_conn_file%7D%22%0A%20%20%20%20else%0A%20%20%20%20%20%20extra_if_brex_args%3D%22%22%0A%20%20%20%20%20%20%23%20check%20if%20interface%20had%20ipv4%2Fipv6%20addresses%20assigned%0A%20%20%20%20%20%20num_ipv4_addrs%3D%24(ip%20-j%20a%20show%20dev%20%24%7Biface%7D%20%7C%20jq%20%22.%5B0%5D.addr_info%20%7C%20map(.%20%7C%20select(.family%20%3D%3D%20%5C%22inet%5C%22))%20%7C%20length%22)%0A%20%20%20%20%20%20if%20%5B%20%22%24num_ipv4_addrs%22%20-gt%200%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20extra_if_brex_args%2B%3D%22ipv4.may-fail%20no%20%22%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20%23%20IPV6%20should%20have%20at%20least%20a%20link%20local%20address.%20Check%20for%20more%20than%201%20to%20see%20if%20there%20is%20an%0A%20%20%20%20%20%20%23%20assigned%20address.%0A%20%20%20%20%20%20num_ip6_addrs%3D%24(ip%20-j%20a%20show%20dev%20%24%7Biface%7D%20%7C%20jq%20%22.%5B0%5D.addr_info%20%7C%20map(.%20%7C%20select(.family%20%3D%3D%20%5C%22inet6%5C%22%20and%20.scope%20!%3D%20%5C%22link%5C%22))%20%7C%20length%22)%0A%20%20%20%20%20%20if%20%5B%20%22%24num_ip6_addrs%22%20-gt%200%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20extra_if_brex_args%2B%3D%22ipv6.may-fail%20no%20%22%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20%23%20check%20for%20dhcp%20client%20ids%0A%20%20%20%20%20%20dhcp_client_id%3D%24(nmcli%20--get-values%20ipv4.dhcp-client-id%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20%20%20if%20%5B%20-n%20%22%24dhcp_client_id%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20extra_if_brex_args%2B%3D%22ipv4.dhcp-client-id%20%24%7Bdhcp_client_id%7D%20%22%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20dhcp6_client_id%3D%24(nmcli%20--get-values%20ipv6.dhcp-duid%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20%20%20if%20%5B%20-n%20%22%24dhcp6_client_id%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20extra_if_brex_args%2B%3D%22ipv6.dhcp-duid%20%24%7Bdhcp6_client_id%7D%20%22%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20ipv6_addr_gen_mode%3D%24(nmcli%20--get-values%20ipv6.addr-gen-mode%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20%20%20if%20%5B%20-n%20%22%24ipv6_addr_gen_mode%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20extra_if_brex_args%2B%3D%22ipv6.addr-gen-mode%20%24%7Bipv6_addr_gen_mode%7D%20%22%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20add_nm_conn%20%22%24ovs_interface%22%20type%20ovs-interface%20slave-type%20ovs-port%20conn.interface%20%22%24bridge_name%22%20master%20%22%24ovs_port_conn%22%20%5C%0A%20%20%20%20%20%20%20%20802-3-ethernet.mtu%20%24%7Biface_mtu%7D%20802-3-ethernet.cloned-mac-address%20%24%7Biface_mac%7D%20%5C%0A%20%20%20%20%20%20%20%20ipv4.method%20%22%24%7Bipv4_method%7D%22%20ipv4.route-metric%20%22%24%7Bbridge_metric%7D%22%20%5C%0A%20%20%20%20%20%20%20%20ipv6.method%20%22%24%7Bipv6_method%7D%22%20ipv6.route-metric%20%22%24%7Bbridge_metric%7D%22%20%5C%0A%20%20%20%20%20%20%20%20%24%7Bextra_if_brex_args%7D%0A%20%20%20%20fi%0A%20%20fi%0A%0A%20%20configure_driver_options%20%22%24%7Biface%7D%22%0A%7D%0A%0A%23%20Used%20to%20remove%20a%20bridge%0Aremove_ovn_bridges()%20%7B%0A%20%20bridge_name%3D%24%7B1%7D%0A%20%20port_name%3D%24%7B2%7D%0A%0A%20%20%23%20Remove%20the%20keyfiles%20from%20known%20configuration%20paths%0A%20%20update_nm_conn_run_files%20%24%7Bbridge_name%7D%20%24%7Bport_name%7D%0A%20%20rm_nm_conn_files%0A%20%20update_nm_conn_set_files%20%24%7Bbridge_name%7D%20%24%7Bport_name%7D%0A%20%20rm_nm_conn_files%0A%20%20%23%20Shouldn't%20be%20necessary%2C%20workaround%20for%20https%3A%2F%2Fissues.redhat.com%2Fbrowse%2FOCPBUGS-41489%0A%20%20update_nm_conn_etc_files%20%24%7Bbridge_name%7D%20%24%7Bport_name%7D%0A%20%20rm_nm_conn_files%0A%0A%20%20%23%20NetworkManager%20will%20not%20remove%20%24%7Bbridge_name%7D%20if%20it%20has%20the%20patch%20port%20created%20by%20ovn-kubernetes%0A%20%20%23%20so%20remove%20explicitly%0A%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-br%20%24%7Bbridge_name%7D%0A%7D%0A%0A%23%20Removes%20any%20previous%20ovs%20configuration%0Aremove_all_ovn_bridges()%20%7B%0A%20%20echo%20%22Reverting%20any%20previous%20OVS%20configuration%22%0A%20%20%0A%20%20remove_ovn_bridges%20br-ex%20phys0%0A%20%20remove_ovn_bridges%20br-ex1%20phys1%0A%20%20%0A%20%20echo%20%22OVS%20configuration%20successfully%20reverted%22%0A%7D%0A%0A%23%20Reloads%20NM%20NetworkManager%20profiles%20if%20any%20configuration%20change%20was%20done.%0A%23%20Accepts%20a%20list%20of%20devices%20that%20should%20be%20re-connect%20after%20reload.%0Areload_profiles_nm()%20%7B%0A%20%20if%20%5B%20%24%7Bnm_config_changed%3A-0%7D%20-eq%200%20%5D%3B%20then%0A%20%20%20%20%23%20no%20config%20was%20changed%2C%20no%20need%20to%20reload%0A%20%20%20%20return%0A%20%20fi%0A%0A%20%20%23%20reload%20profiles%0A%20%20nmcli%20connection%20reload%0A%0A%20%20%23%20precautionary%20sleep%20of%2010s%20(default%20timeout%20of%20NM%20to%20bring%20down%20devices)%0A%20%20sleep%2010%0A%0A%20%20%23%20After%20reload%2C%20devices%20that%20were%20already%20connected%20should%20connect%20again%0A%20%20%23%20if%20any%20profile%20is%20available.%20If%20no%20profile%20is%20available%2C%20a%20device%20can%0A%20%20%23%20remain%20disconnected%20and%20we%20have%20to%20explicitly%20connect%20it%20so%20that%20a%0A%20%20%23%20profile%20is%20generated.%20This%20can%20happen%20for%20physical%20devices%20but%20should%0A%20%20%23%20not%20happen%20for%20software%20devices%20as%20those%20always%20require%20a%20profile.%0A%20%20for%20dev%20in%20%24%40%3B%20do%0A%20%20%20%20%23%20Only%20attempt%20to%20connect%20a%20disconnected%20device%0A%20%20%20%20local%20connected_state%3D%24(nmcli%20-g%20GENERAL.STATE%20device%20show%20%22%24dev%22%20%7C%7C%20echo%20%22%22)%0A%20%20%20%20if%20%5B%5B%20%22%24connected_state%22%20%3D~%20%22disconnected%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%23%20keep%20track%20if%20a%20profile%20by%20the%20same%20name%20as%20the%20device%20existed%20%0A%20%20%20%20%20%20%23%20before%20we%20attempt%20activation%0A%20%20%20%20%20%20local%20named_profile_existed%3D%24(%5B%20-f%20%22%24%7BNM_CONN_CONF_PATH%7D%2F%24%7Bdev%7D%22%20%5D%20%7C%7C%20%5B%20-f%20%22%24%7BNM_CONN_CONF_PATH%7D%2F%24%7Bdev%7D.nmconnection%22%20%5D%20%26%26%20echo%20%22yes%22)%0A%20%20%20%20%20%20%0A%20%20%20%20%20%20for%20i%20in%20%7B1..10%7D%3B%20do%0A%20%20%20%20%20%20%20%20%20%20echo%20%22Attempt%20%24i%20to%20connect%20device%20%24dev%22%0A%20%20%20%20%20%20%20%20%20%20nmcli%20device%20connect%20%22%24dev%22%20%26%26%20break%0A%20%20%20%20%20%20%20%20%20%20sleep%205%0A%20%20%20%20%20%20done%0A%0A%20%20%20%20%20%20%23%20if%20a%20profile%20did%20not%20exist%20before%20but%20does%20now%2C%20it%20was%20generated%0A%20%20%20%20%20%20%23%20but%20we%20want%20it%20to%20be%20ephemeral%2C%20so%20move%20it%20back%20to%20%2Frun%0A%20%20%20%20%20%20if%20%5B%20!%20%22%24named_profile_existed%22%20%3D%20%22yes%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20MANAGED_NM_CONN_FILES%3D(%22%24%7BNM_CONN_CONF_PATH%7D%2F%24%7Bdev%7D%22%20%22%24%7BNM_CONN_CONF_PATH%7D%2F%24%7Bdev%7D.nmconnection%22)%0A%20%20%20%20%20%20%20%20copy_nm_conn_files%20%22%24%7BNM_CONN_RUN_PATH%7D%22%0A%20%20%20%20%20%20%20%20rm_nm_conn_files%0A%20%20%20%20%20%20%20%20%23%20reload%20profiles%20so%20that%20NM%20notices%20that%20some%20might%20have%20been%20moved%0A%20%20%20%20%20%20%20%20nmcli%20connection%20reload%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20echo%20%22Waiting%20for%20interface%20%24dev%20to%20activate...%22%0A%20%20%20%20if%20!%20timeout%2060%20bash%20-c%20%22while%20!%20nmcli%20-g%20DEVICE%2CSTATE%20c%20%7C%20grep%20%22'%22'%22%24dev%22%3Aactivated'%22'%22%3B%20do%20sleep%205%3B%20done%22%3B%20then%0A%20%20%20%20%20%20echo%20%22WARNING%3A%20%24dev%20did%20not%20activate%22%0A%20%20%20%20fi%0A%20%20done%0A%0A%20%20nm_config_changed%3D0%0A%7D%0A%0A%23%20Removes%20all%20configuration%20and%20reloads%20NM%20if%20necessary%0Arollback_nm()%20%7B%0A%20%20phys0%3D%24(get_bridge_physical_interface%20ovs-if-phys0)%0A%20%20phys1%3D%24(get_bridge_physical_interface%20ovs-if-phys1)%0A%20%20%0A%20%20%23%20Revert%20changes%20made%20by%20%2Fusr%2Flocal%2Fbin%2Fconfigure-ovs.sh%20during%20SDN%20migration.%0A%20%20remove_all_ovn_bridges%0A%20%20%0A%20%20%23%20reload%20profiles%20so%20that%20NM%20notices%20that%20some%20were%20removed%0A%20%20reload_profiles_nm%20%22%24phys0%22%20%22%24phys1%22%0A%7D%0A%0A%23%20Add%20a%20temporary%20deactivated%20connection%20profile%20%0A%23%20First%20argument%20is%20the%20connection%20name%20folowed%20by%20arguments%20passed%20to%0A%23%20%60nmcli%20connection%20add%60%0Aadd_nm_conn()%20%7B%0A%20%20%23%20Use%20%60save%20no%60%20to%20add%20a%20temporary%20profile%0A%20%20nmcli%20c%20add%20save%20no%20con-name%20%22%24%40%22%20connection.autoconnect%20no%0A%7D%0A%0A%23%20Modify%20a%20temporary%20connection%20profile%20%0A%23%20First%20argument%20is%20the%20connection%20name%20followed%20by%20arguments%20passed%20to%0A%23%20%60nmcli%20connection%20modify%60%0Amod_nm_conn()%20%7B%0A%20%20%23%20the%20easiest%20thing%20to%20do%20here%20would%20be%20to%20use%20%60nmcli%20c%20mod%20--temporary%60%0A%20%20%23%20but%20there%20is%20a%20bug%20in%20selinux%20profiles%20that%20denies%20NM%20from%20performing%0A%20%20%23%20the%20operation%0A%20%20local%20dst_path%3D%24%7BNM_CONN_RUN_PATH%7D%2F%241.nmconnection%0A%20%20local%20src_path%0A%20%20src_path%3D%24(mktemp)%0A%20%20shift%0A%20%20cat%20%22%24dst_path%22%20%3E%20%22%24src_path%22%0A%20%20rm%20-f%20%22%24dst_path%22%0A%20%20nmcli%20--offline%20c%20mod%20%22%24%40%22%20%3C%20%22%24src_path%22%20%3E%20%22%24dst_path%22%0A%20%20rm%20-f%20%22%24src_path%22%0A%20%20chmod%20600%20%22%24dst_path%22%0A%20%20nmcli%20c%20load%20%22%24dst_path%22%0A%7D%0A%0A%23%20Clone%20to%20a%20temporary%20connection%20profile%20%0A%23%20First%20argument%20is%20the%20connection%20to%20clone%2C%20second%20argument%20is%20the%20clone%20name%0Aclone_nm_conn()%20%7B%0A%20%20%23%20clone%20as%20temporary%20so%20that%20it%20is%20generated%20in%20NM_CONN_RUN_PATH%0A%20%20nmcli%20connection%20clone%20--temporary%20%22%241%22%20%22%242%22%20%26%3E%20%2Fdev%2Fnull%0A%7D%0A%0A%23%20Activates%20an%20ordered%20set%20of%20NM%20connection%20profiles%0Aactivate_nm_connections()%20%7B%0A%20%20local%20connections%3D(%22%24%40%22)%0A%0A%20%20%23%20We%20want%20autoconnect%20set%20for%20our%20cloned%20slave%20profiles%20so%20that%20they%20are%0A%20%20%23%20used%20over%20the%20original%20profiles%20if%20implicitly%20re-activated%20with%20other%0A%20%20%23%20dependant%20profiles.%20Otherwise%20if%20a%20slave%20activates%20with%20an%20old%20profile%2C%0A%20%20%23%20the%20old%20master%20profile%20might%20activate%20as%20well%2C%20interfering%20and%20causing%0A%20%20%23%20further%20activations%20to%20fail.%0A%20%20%23%20Slave%20interfaces%20should%20already%20be%20active%20so%20setting%20autoconnect%20here%0A%20%20%23%20won't%20implicitly%20activate%20them%20but%20there%20is%20an%20edge%20case%20where%20a%20slave%0A%20%20%23%20might%20be%20inactive%20(link%20down%20for%20example)%20and%20in%20that%20case%20setting%0A%20%20%23%20autoconnect%20will%20cause%20an%20implicit%20activation.%20This%20is%20not%20necessarily%20a%0A%20%20%23%20problem%20and%20hopefully%20we%20can%20make%20sure%20everything%20is%20activated%20as%20we%0A%20%20%23%20want%20next.%0A%20%20for%20conn%20in%20%22%24%7Bconnections%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20local%20slave_type%3D%24(nmcli%20-g%20connection.slave-type%20connection%20show%20%22%24conn%22)%0A%20%20%20%20if%20%5B%20%22%24slave_type%22%20%3D%20%22team%22%20%5D%20%7C%7C%20%5B%20%22%24slave_type%22%20%3D%20%22bond%22%20%5D%3B%20then%0A%20%20%20%20%20%20mod_nm_conn%20%22%24conn%22%20connection.autoconnect%20yes%0A%20%20%20%20fi%0A%20%20done%0A%0A%20%20%23%20Activate%20all%20connections%20and%20fail%20if%20activation%20fails%0A%20%20%23%20For%20slave%20connections%20-%20for%20as%20long%20as%20at%20least%20one%20slave%20that%20belongs%20to%20a%20bond%2Fteam%0A%20%20%23%20comes%20up%2C%20we%20should%20not%20fail%0A%20%20declare%20-A%20master_interfaces%0A%20%20for%20conn%20in%20%22%24%7Bconnections%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20%23%20Get%20the%20slave%20type%0A%20%20%20%20local%20slave_type%3D%24(nmcli%20-g%20connection.slave-type%20connection%20show%20%22%24conn%22)%0A%20%20%20%20local%20is_slave%3Dfalse%0A%20%20%20%20if%20%5B%20%22%24slave_type%22%20%3D%20%22team%22%20%5D%20%7C%7C%20%5B%20%22%24slave_type%22%20%3D%20%22bond%22%20%5D%3B%20then%0A%20%20%20%20%20%20is_slave%3Dtrue%0A%20%20%20%20fi%20%0A%0A%20%20%20%20%23%20For%20slave%20interfaces%2C%20initialize%20the%20master%20interface%20to%20false%20if%20the%20key%20is%20not%20yet%20in%20the%20array%0A%20%20%20%20local%20master_interface%0A%20%20%20%20if%20%24is_slave%3B%20then%0A%20%20%20%20%20%20master_interface%3D%24(nmcli%20-g%20connection.master%20connection%20show%20%22%24conn%22)%0A%20%20%20%20%20%20if%20!%20%5B%5B%20-v%20%22master_interfaces%5B%24master_interface%5D%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20master_interfaces%5B%22%24master_interface%22%5D%3Dfalse%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20slaves%20should%20implicitly%20activate%2C%20give%20them%20a%20chance%20to%20do%20so%0A%20%20%20%20if%20%24is_slave%3B%20then%0A%20%20%20%20%20%20if%20!%20timeout%205%20bash%20-c%20%22while%20!%20nmcli%20-g%20GENERAL.STATE%20conn%20show%20%22%24conn%22%20%7C%20grep%20activated%3B%20do%20sleep%201%3B%20done%22%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22WARNING%3A%20slave%20%24conn%20did%20not%20implicitly%20activate%20in%205s%2C%20activating%20explicitly.%22%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Do%20not%20activate%20interfaces%20that%20are%20already%20active%0A%20%20%20%20%23%20But%20set%20the%20entry%20in%20master_interfaces%20to%20true%20if%20this%20is%20a%20slave%0A%20%20%20%20%23%20Also%20set%20autoconnect%20to%20yes%0A%20%20%20%20local%20active_state%3D%24(nmcli%20-g%20GENERAL.STATE%20conn%20show%20%22%24conn%22)%0A%20%20%20%20if%20%5B%20%22%24active_state%22%20%3D%3D%20%22activated%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22Connection%20%24conn%20already%20activated%22%0A%20%20%20%20%20%20if%20%24is_slave%3B%20then%0A%20%20%20%20%20%20%20%20master_interfaces%5B%24master_interface%5D%3Dtrue%0A%20%20%20%20%20%20fi%0A%20%20%20%20%20%20mod_nm_conn%20%22%24conn%22%20connection.autoconnect%20yes%0A%20%20%20%20%20%20continue%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Activate%20all%20interfaces%20that%20are%20not%20yet%20active%0A%20%20%20%20for%20i%20in%20%7B1..10%7D%3B%20do%0A%20%20%20%20%20%20echo%20%22Attempt%20%24i%20to%20bring%20up%20connection%20%24conn%22%0A%20%20%20%20%20%20nmcli%20conn%20up%20%22%24conn%22%20%26%26%20s%3D0%20%26%26%20break%20%7C%7C%20s%3D%24%3F%0A%20%20%20%20%20%20sleep%205%0A%20%20%20%20done%0A%20%20%20%20if%20%5B%20%24s%20-eq%200%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22Brought%20up%20connection%20%24conn%20successfully%22%0A%20%20%20%20%20%20if%20%24is_slave%3B%20then%0A%20%20%20%20%20%20%20%20master_interfaces%5B%22%24master_interface%22%5D%3Dtrue%0A%20%20%20%20%20%20fi%0A%20%20%20%20elif%20!%20%24is_slave%3B%20then%0A%20%20%20%20%20%20echo%20%22ERROR%3A%20Cannot%20bring%20up%20connection%20%24conn%20after%20%24i%20attempts%22%0A%20%20%20%20%20%20return%20%24s%0A%20%20%20%20fi%0A%20%20%20%20mod_nm_conn%20%22%24conn%22%20connection.autoconnect%20yes%0A%20%20done%0A%20%20%23%20Check%20that%20all%20master%20interfaces%20report%20at%20least%20a%20single%20active%20slave%0A%20%20%23%20Note%3A%20associative%20arrays%20require%20an%20exclamation%20mark%20when%20looping%0A%20%20for%20i%20in%20%22%24%7B!master_interfaces%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20if%20!%20%24%7Bmaster_interfaces%5B%22%24i%22%5D%7D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22ERROR%3A%20Cannot%20bring%20up%20any%20slave%20interface%20for%20master%20interface%3A%20%24i%22%0A%20%20%20%20%20%20%20%20return%201%0A%20%20%20%20fi%0A%20%20done%0A%7D%0A%0A%23%20Accepts%20parameters%20%24iface_default_hint_file%2C%20%24iface%0A%23%20Writes%20content%20of%20%24iface%20into%20%24iface_default_hint_file%0Awrite_iface_default_hint()%20%7B%0A%20%20local%20iface_default_hint_file%3D%22%241%22%0A%20%20local%20iface%3D%22%242%22%0A%0A%20%20echo%20%22%24%7Biface%7D%22%20%3E%7C%20%22%24%7Biface_default_hint_file%7D%22%0A%7D%0A%0A%23%20Accepts%20parameters%20%24iface_default_hint_file%0A%23%20Returns%20the%20stored%20interface%20default%20hint%20if%20the%20hint%20is%20non-empty%2C%0A%23%20not%20br-ex%2C%20not%20br-ex1%20and%20if%20the%20interface%20can%20be%20found%20in%20%2Fsys%2Fclass%2Fnet%0Aget_iface_default_hint()%20%7B%0A%20%20local%20iface_default_hint_file%3D%241%0A%20%20if%20%5B%20-f%20%22%24%7Biface_default_hint_file%7D%22%20%5D%3B%20then%0A%20%20%20%20local%20iface_default_hint%3D%24(cat%20%22%24%7Biface_default_hint_file%7D%22)%0A%20%20%20%20if%20%5B%20%22%24%7Biface_default_hint%7D%22%20!%3D%20%22%22%20%5D%20%26%26%0A%20%20%20%20%20%20%20%20%5B%20%22%24%7Biface_default_hint%7D%22%20!%3D%20%22br-ex%22%20%5D%20%26%26%0A%20%20%20%20%20%20%20%20%5B%20%22%24%7Biface_default_hint%7D%22%20!%3D%20%22br-ex1%22%20%5D%20%26%26%0A%20%20%20%20%20%20%20%20%5B%20-d%20%22%2Fsys%2Fclass%2Fnet%2F%24%7Biface_default_hint%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22%24%7Biface_default_hint%7D%22%0A%20%20%20%20%20%20%20%20return%0A%20%20%20%20fi%0A%20%20fi%0A%20%20echo%20%22%22%0A%7D%0A%0Aget_ip_from_ip_hint_file()%20%7B%0A%20%20local%20ip_hint_file%3D%22%241%22%0A%20%20if%20%5B%5B%20!%20-f%20%22%24%7Bip_hint_file%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20return%0A%20%20fi%0A%20%20ip_hint%3D%24(cat%20%22%24%7Bip_hint_file%7D%22)%0A%20%20echo%20%22%24%7Bip_hint%7D%22%0A%7D%0A%0A%23%20This%20function%20waits%20for%20ip%20address%20of%20br-ex%20to%20be%20bindable%20only%20in%20case%20of%20ipv6%0A%23%20This%20is%20workaround%20for%20OCPBUGS-673%20as%20it%20will%20not%20allow%20starting%20crio%0A%23%20before%20address%20is%20bindable%0Atry_to_bind_ipv6_address()%20%7B%0A%20%20%23%20Retry%20for%201%20minute%0A%20%20retries%3D60%0A%20%20until%20%5B%5B%20%24%7Bretries%7D%20-eq%200%20%5D%5D%3B%20do%0A%20%20%20%20ip%3D%24(ip%20-6%20-j%20addr%20%7C%20jq%20-r%20%22first(.%5B%5D%20%7C%20select(.ifname%3D%3D%5C%22br-ex%5C%22)%20%7C%20.addr_info%5B%5D%20%7C%20select(.scope%3D%3D%5C%22global%5C%22)%20%7C%20.local)%22)%0A%20%20%20%20if%20%5B%5B%20%22%24%7Bip%7D%22%20%3D%3D%20%22%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22No%20ipv6%20ip%20to%20bind%20was%20found%22%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20%20%20random_port%3D%24(shuf%20-i%2050000-60000%20-n%201)%0A%20%20%20%20echo%20%22Trying%20to%20bind%20%24%7Bip%7D%20on%20port%20%24%7Brandom_port%7D%22%0A%20%20%20%20exit_code%3D%24(timeout%202s%20nc%20-l%20%22%24%7Bip%7D%22%20%24%7Brandom_port%7D%3B%20echo%20%24%3F)%0A%20%20%20%20if%20%5B%5B%20exit_code%20-eq%20124%20%5D%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22Address%20bound%20successfully%22%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20%20%20sleep%201%0A%20%20%20%20((%20retries--%20))%0A%20%20done%0A%20%20if%20%5B%5B%20%24%7Bretries%7D%20-eq%200%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22Failed%20to%20bind%20ip%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%7D%0A%0A%23%20Get%20interface%20that%20matches%20ip%20from%20node%20ip%20hint%20file%0A%23%20in%20case%20file%20not%20exists%20return%20nothing%20and%0A%23%20fallback%20to%20default%20interface%20search%20flow%0Aget_nodeip_hint_interface()%20%7B%0A%20%20local%20ip_hint%3D%22%22%0A%20%20local%20ip_hint_file%3D%22%241%22%0A%20%20local%20extra_bridge%3D%22%242%22%0A%20%20local%20iface%3D%22%22%0A%0A%20%20ip_hint%3D%24(get_ip_from_ip_hint_file%20%22%24%7Bip_hint_file%7D%22)%0A%20%20if%20%5B%5B%20-z%20%22%24%7Bip_hint%7D%22%20%20%5D%5D%3B%20then%0A%20%20%20%20return%0A%20%20fi%0A%0A%20%20iface%3D%24(ip%20-j%20addr%20%7C%20jq%20-r%20%22first(.%5B%5D%20%7C%20select(any(.addr_info%5B%5D%3B%20.local%3D%3D%5C%22%24%7Bip_hint%7D%5C%22)%20and%20.ifname!%3D%5C%22br-ex1%5C%22%20and%20.ifname!%3D%5C%22%24%7Bextra_bridge%7D%5C%22))%20%7C%20.ifname%22)%0A%20%20if%20%5B%5B%20-n%20%22%24%7Biface%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22%24%7Biface%7D%22%0A%20%20fi%0A%7D%0A%0A%23%20Accepts%20parameters%20%24bridge_interface%20(e.g.%20ovs-port-phys0)%0A%23%20Returns%20the%20physical%20interface%20name%20if%20%24bridge_interface%20exists%2C%20%22%22%20otherwise%0Aget_bridge_physical_interface()%20%7B%0A%20%20local%20bridge_interface%3D%22%241%22%0A%20%20local%20physical_interface%3D%22%22%0A%20%20physical_interface%3D%24(nmcli%20-g%20connection.interface-name%20conn%20show%20%22%24%7Bbridge_interface%7D%22%202%3E%2Fdev%2Fnull%20%7C%7C%20echo%20%22%22)%0A%20%20echo%20%22%24%7Bphysical_interface%7D%22%0A%7D%0A%0A%23%20Accepts%20parameters%20%24iface_default_hint_file%2C%20%24extra_bridge_file%2C%20%24ip_hint_file%2C%20%24default_bridge_file%0A%23%20Determines%20the%20interface%20to%20be%20used%20for%20br-ex.%20Order%20of%20priority%20is%3A%0A%23%201.%20Use%20the%20user%20specified%20interface%20if%20provided%20in%20the%20default%20bridge%20file%0A%23%202.%20Use%20the%20node%20IP%20hint%20interface%0A%23%203.%20Use%20the%20previously%20selected%20interface%0A%23%204.%20Use%20the%20interface%20detected%20as%20default%20gateway%0A%23%0A%23%20Read%20%24default_bridge_file%20and%20return%20the%20contained%20interface.%20Otherwise%2C%0A%23%20read%20%24ip_hint_file%20and%20return%20the%20interface%20that%20matches%20this%20ip.%20Otherwise%2C%0A%23%20if%20the%20default%20interface%20is%20br-ex%2C%20use%20that%20and%20return.%0A%23%20If%20the%20default%20interface%20is%20not%20br-ex%3A%0A%23%20Check%20if%20there%20is%20a%20valid%20hint%20inside%20%24iface_default_hint_file.%20If%20so%2C%20use%20that%20hint.%0A%23%20If%20there%20is%20no%20valid%20hint%2C%20use%20the%20default%20interface%20that%20we%20found%20during%20the%20step%0A%23%20earlier.%0A%23%20Never%20use%20the%20interface%20that%20is%20provided%20inside%20%24extra_bridge_file%20for%20br-ex1.%0A%23%20Never%20use%20br-ex1.%0A%23%20Write%20the%20default%20interface%20to%20%24iface_default_hint_file%0Aget_default_bridge_interface()%20%7B%0A%20%20local%20iface%3D%22%22%0A%20%20local%20counter%3D0%0A%20%20local%20iface_default_hint_file%3D%22%241%22%0A%20%20local%20extra_bridge_file%3D%22%242%22%0A%20%20local%20ip_hint_file%3D%22%243%22%0A%20%20local%20default_bridge_file%3D%22%244%22%0A%20%20local%20extra_bridge%3D%22%22%0A%0A%20%20if%20%5B%20-f%20%22%24%7Bextra_bridge_file%7D%22%20%5D%3B%20then%0A%20%20%20%20extra_bridge%3D%24(cat%20%24%7Bextra_bridge_file%7D)%0A%20%20fi%0A%0A%20%20%23%20try%20to%20use%20user%20specified%20file%20first%0A%20%20if%20%5B%20-f%20%22%24default_bridge_file%22%20%5D%3B%20then%0A%20%20%20%20iface%3D%24(cat%20%22%24%7Bdefault_bridge_file%7D%22)%0A%20%20%20%20if%20%5B%20-z%20%22%24iface%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22ERROR%3A%20User%20specified%20bridge%20file%20detected%20without%20any%20data%22%0A%20%20%20%20%20%20exit%201%0A%20%20%20%20fi%0A%20%20%20%20echo%20%22%24%7Biface%7D%22%0A%20%20%20%20return%0A%20%20fi%0A%0A%20%20%23%20if%20node%20ip%20was%20set%2C%20we%20should%20search%20for%20interface%20that%20matches%20it%0A%20%20iface%3D%24(get_nodeip_hint_interface%20%22%24%7Bip_hint_file%7D%22%20%22%24%7Bextra_bridge%7D%22)%0A%20%20if%20%5B%5B%20-n%20%22%24%7Biface%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22%24%7Biface%7D%22%0A%20%20%20%20return%0A%20%20fi%0A%0A%20%20%23%20find%20default%20interface%0A%20%20%23%20the%20default%20interface%20might%20be%20br-ex%2C%20so%20check%20this%20before%20looking%20at%20the%20hint%0A%20%20while%20%5B%20%24%7Bcounter%7D%20-lt%2012%20%5D%3B%20do%0A%20%20%20%20%23%20check%20ipv4%0A%20%20%20%20%23%20never%20use%20the%20interface%20that's%20specified%20in%20extra_bridge_file%0A%20%20%20%20%23%20never%20use%20br-ex1%0A%20%20%20%20if%20%5B%20%22%24%7Bextra_bridge%7D%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20iface%3D%24(ip%20route%20show%20default%20%7C%20grep%20-v%20%22br-ex1%22%20%7C%20grep%20-v%20%22%24%7Bextra_bridge%7D%22%20%7C%20awk%20'%7B%20if%20(%244%20%3D%3D%20%22dev%22)%20%7B%20print%20%245%3B%20exit%20%7D%20%7D')%0A%20%20%20%20else%0A%20%20%20%20%20%20iface%3D%24(ip%20route%20show%20default%20%7C%20grep%20-v%20%22br-ex1%22%20%7C%20awk%20'%7B%20if%20(%244%20%3D%3D%20%22dev%22)%20%7B%20print%20%245%3B%20exit%20%7D%20%7D')%0A%20%20%20%20fi%0A%20%20%20%20if%20%5B%5B%20-n%20%22%24%7Biface%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20%20%20%23%20check%20ipv6%0A%20%20%20%20%23%20never%20use%20the%20interface%20that's%20specified%20in%20extra_bridge_file%0A%20%20%20%20%23%20never%20use%20br-ex1%0A%20%20%20%20if%20%5B%20%22%24%7Bextra_bridge%7D%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20iface%3D%24(ip%20-6%20route%20show%20default%20%7C%20grep%20-v%20%22br-ex1%22%20%7C%20grep%20-v%20%22%24%7Bextra_bridge%7D%22%20%7C%20awk%20'%7B%20if%20(%244%20%3D%3D%20%22dev%22)%20%7B%20print%20%245%3B%20exit%20%7D%20%7D')%0A%20%20%20%20else%0A%20%20%20%20%20%20iface%3D%24(ip%20-6%20route%20show%20default%20%7C%20grep%20-v%20%22br-ex1%22%20%7C%20awk%20'%7B%20if%20(%244%20%3D%3D%20%22dev%22)%20%7B%20print%20%245%3B%20exit%20%7D%20%7D')%0A%20%20%20%20fi%0A%20%20%20%20if%20%5B%5B%20-n%20%22%24%7Biface%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20%20%20counter%3D%24((counter%2B1))%0A%20%20%20%20sleep%205%0A%20%20done%0A%0A%20%20%23%20if%20the%20default%20interface%20does%20not%20point%20out%20of%20br-ex%20or%20br-ex1%0A%20%20if%20%5B%20%22%24%7Biface%7D%22%20!%3D%20%22br-ex%22%20%5D%20%26%26%20%5B%20%22%24%7Biface%7D%22%20!%3D%20%22br-ex1%22%20%5D%3B%20then%0A%20%20%20%20%23%20determine%20if%20an%20interface%20default%20hint%20exists%20from%20a%20previous%20run%0A%20%20%20%20%23%20and%20if%20the%20interface%20has%20a%20valid%20default%20route%0A%20%20%20%20iface_default_hint%3D%24(get_iface_default_hint%20%22%24%7Biface_default_hint_file%7D%22)%0A%20%20%20%20if%20%5B%20%22%24%7Biface_default_hint%7D%22%20!%3D%20%22%22%20%5D%20%26%26%0A%20%20%20%20%20%20%20%20%5B%20%22%24%7Biface_default_hint%7D%22%20!%3D%20%22%24%7Biface%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%23%20start%20wherever%20count%20left%20off%20in%20the%20previous%20loop%0A%20%20%20%20%20%20%23%20allow%20this%20for%20one%20more%20iteration%20than%20the%20previous%20loop%0A%20%20%20%20%20%20while%20%5B%20%24%7Bcounter%7D%20-le%2012%20%5D%3B%20do%0A%20%20%20%20%20%20%20%20%23%20check%20ipv4%0A%20%20%20%20%20%20%20%20if%20%5B%20%22%24(ip%20route%20show%20default%20dev%20%22%24%7Biface_default_hint%7D%22)%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20iface%3D%22%24%7Biface_default_hint%7D%22%0A%20%20%20%20%20%20%20%20%20%20break%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20%23%20check%20ipv6%0A%20%20%20%20%20%20%20%20if%20%5B%20%22%24(ip%20-6%20route%20show%20default%20dev%20%22%24%7Biface_default_hint%7D%22)%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20iface%3D%22%24%7Biface_default_hint%7D%22%0A%20%20%20%20%20%20%20%20%20%20break%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20counter%3D%24((counter%2B1))%0A%20%20%20%20%20%20%20%20sleep%205%0A%20%20%20%20%20%20done%0A%20%20%20%20fi%0A%20%20%20%20%23%20store%20what%20was%20determined%20was%20the%20(new)%20default%20interface%20inside%0A%20%20%20%20%23%20the%20default%20hint%20file%20for%20future%20reference%0A%20%20%20%20if%20%5B%20%22%24%7Biface%7D%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20write_iface_default_hint%20%22%24%7Biface_default_hint_file%7D%22%20%22%24%7Biface%7D%22%0A%20%20%20%20fi%0A%20%20fi%0A%20%20echo%20%22%24%7Biface%7D%22%0A%7D%0A%0A%23%20Used%20to%20print%20network%20state%0Aprint_state()%20%7B%0A%20%20echo%20%22Current%20device%2C%20connection%2C%20interface%20and%20routing%20state%3A%22%0A%20%20nmcli%20-g%20all%20device%20%7C%20grep%20-v%20unmanaged%0A%20%20nmcli%20-g%20all%20connection%0A%20%20ip%20-d%20address%20show%0A%20%20ip%20route%20show%0A%20%20ip%20-6%20route%20show%0A%7D%0A%0A%23%20Setup%20an%20exit%20trap%20to%20rollback%20on%20error%0Ahandle_exit()%20%7B%0A%20%20e%3D%24%3F%0A%20%20tdir%3D%24(mktemp%20-u%20-d%20-t%20%22configure-ovs-%24(date%20%2B%25Y-%25m-%25d-%25H-%25M-%25S)-XXXXXXXXXX%22)%0A%20%20%0A%20%20if%20%5B%20%24e%20-eq%200%20%5D%3B%20then%0A%20%20%20%20print_state%0A%20%20%20%20%23%20remove%20previous%20troubleshooting%20information%0A%20%20%20%20rm%20-rf%20%22%24(dirname%20%22%24tdir%22)%2Fconfigure-ovs-*%22%0A%20%20%20%20exit%200%0A%20%20fi%0A%0A%20%20echo%20%22ERROR%3A%20configure-ovs%20exited%20with%20error%3A%20%24e%22%0A%20%20print_state%0A%0A%20%20%23%20remove%20previous%20troubleshooting%20information%20except%20the%20oldest%20one%0A%20%20mapfile%20-t%20tdirs%20%3C%20%3C(compgen%20-G%20%22%24(dirname%20%22%24tdir%22)%2Fconfigure-ovs-*%22)%0A%20%20unset%20-v%20%22tdirs%5B0%5D%22%0A%20%20for%20dir%20in%20%22%24%7Btdirs%5B%40%5D%7D%22%3B%20do%20rm%20-rf%20%22%24dir%22%3B%20done%0A%0A%20%20%23%20copy%20configuration%20to%20tmp%20for%20troubleshooting%0A%20%20mkdir%20-p%20%22%24tdir%22%0A%20%20update_nm_conn_run_files%20br-ex%20phys0%0A%20%20copy_nm_conn_files%20%22%24tdir%22%0A%20%20update_nm_conn_run_files%20br-ex1%20phys1%0A%20%20copy_nm_conn_files%20%22%24tdir%22%0A%20%20echo%20%22Copied%20OVS%20configuration%20to%20%24tdir%20for%20troubleshooting%22%0A%0A%20%20%23%20attempt%20to%20restore%20the%20previous%20network%20state%0A%20%20echo%20%22Attempting%20to%20restore%20previous%20configuration...%22%0A%20%20rollback_nm%0A%20%20print_state%0A%0A%20%20exit%20%24e%0A%7D%0A%0A%23%20Setup%20a%20signal%20trap%20to%20rollback%0Ahandle_termination()%20%7B%0A%20%20echo%20%22WARNING%3A%20configure-ovs%20has%20been%20requested%20to%20terminate%2C%20quitting...%22%0A%20%20%0A%20%20%23%20by%20exiting%20with%20an%20error%20we%20will%20cleanup%20after%20ourselves%20in%20a%0A%20%20%23%20subsequent%20call%20to%20handle_exit%0A%20%20exit%201%0A%7D%0A%0A%23%20main%20function%0Aconfigure_ovs()%20%7B%0A%20%20set%20-eu%0A%0A%20%20%23%20setup%20traps%20to%20handle%20signals%20and%20other%20abnormal%20exits%0A%20%20trap%20'handle_termination'%20TERM%20INT%0A%20%20trap%20'handle_exit'%20EXIT%0A%0A%20%20%23%20this%20flag%20tracks%20if%20any%20config%20change%20was%20made%0A%20%20nm_config_changed%3D0%0A%0A%20%20%23%20Check%20that%20we%20are%20provided%20a%20valid%20NM%20connection%20path%0A%20%20if%20%5B%20%22%24NM_CONN_SET_PATH%22%20!%3D%20%22%24NM_CONN_CONF_PATH%22%20%5D%20%26%26%20%5B%20%22%24NM_CONN_SET_PATH%22%20!%3D%20%22%24NM_CONN_RUN_PATH%22%20%5D%3B%20then%0A%20%20%20%20echo%20%22Error%3A%20Incorrect%20NM%20connection%20path%3A%20%24NM_CONN_SET_PATH%20is%20not%20%24NM_CONN_CONF_PATH%20nor%20%24NM_CONN_RUN_PATH%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%0A%20%20%23%20Clean%20up%20old%20config%20on%20behalf%20of%20mtu-migration%0A%20%20if%20!%20systemctl%20-q%20is-enabled%20mtu-migration%3B%20then%0A%20%20%20%20echo%20%22Cleaning%20up%20left%20over%20mtu%20migration%20configuration%22%0A%20%20%20%20rm%20-rf%20%2Fetc%2Fcno%2Fmtu-migration%0A%20%20fi%0A%0A%20%20if%20!%20rpm%20-qa%20%7C%20grep%20-q%20openvswitch%3B%20then%0A%20%20%20%20echo%20%22WARNING%3A%20Openvswitch%20package%20is%20not%20installed!%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%0A%20%20%23%20print%20initial%20state%0A%20%20print_state%0A%0A%20%20if%20%5B%20%22%241%22%20%3D%3D%20%22OVNKubernetes%22%20%5D%3B%20then%0A%20%20%20%20%23%20Configures%20NICs%20onto%20OVS%20bridge%20%22br-ex%22%0A%20%20%20%20%23%20Configuration%20is%20either%20auto-detected%20or%20provided%20through%20a%20config%20file%20written%20already%20in%20Network%20Manager%0A%20%20%20%20%23%20key%20files%20under%20%2Fetc%2FNetworkManager%2Fsystem-connections%2F%0A%20%20%20%20%23%20Managing%20key%20files%20is%20outside%20of%20the%20scope%20of%20this%20script%0A%0A%20%20%20%20%23%20if%20the%20interface%20is%20of%20type%20vmxnet3%20add%20multicast%20capability%20for%20that%20driver%0A%20%20%20%20%23%20History%3A%20BZ%3A1854355%0A%20%20%20%20function%20configure_driver_options%20%7B%0A%20%20%20%20%20%20intf%3D%241%0A%20%20%20%20%20%20if%20%5B%20!%20-f%20%22%2Fsys%2Fclass%2Fnet%2F%24%7Bintf%7D%2Fdevice%2Fuevent%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22Device%20file%20doesn't%20exist%2C%20skipping%20setting%20multicast%20mode%22%0A%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20driver%3D%24(cat%20%22%2Fsys%2Fclass%2Fnet%2F%24%7Bintf%7D%2Fdevice%2Fuevent%22%20%7C%20grep%20DRIVER%20%7C%20awk%20-F%20%22%3D%22%20'%7Bprint%20%242%7D')%0A%20%20%20%20%20%20%20%20echo%20%22Driver%20name%20is%22%20%24driver%0A%20%20%20%20%20%20%20%20if%20%5B%20%22%24driver%22%20%3D%20%22vmxnet3%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20ip%20link%20set%20dev%20%22%24%7Bintf%7D%22%20allmulticast%20on%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20fi%0A%20%20%20%20%7D%0A%0A%20%20%20%20ovnk_config_dir%3D'%2Fetc%2Fovnk'%0A%20%20%20%20ovnk_var_dir%3D'%2Fvar%2Flib%2Fovnk'%0A%20%20%20%20extra_bridge_file%3D%22%24%7Bovnk_config_dir%7D%2Fextra_bridge%22%0A%20%20%20%20iface_default_hint_file%3D%22%24%7Bovnk_var_dir%7D%2Fiface_default_hint%22%0A%20%20%20%20ip_hint_file%3D%22%2Frun%2Fnodeip-configuration%2Fprimary-ip%22%0A%20%20%20%20%23%20explicitly%20specify%20which%20interface%20should%20be%20used%20with%20the%20default%20bridge%0A%20%20%20%20default_bridge_file%3D%22%24%7Bovnk_config_dir%7D%2Fdefault_bridge%22%0A%0A%20%20%20%20%23%20make%20sure%20to%20create%20ovnk_config_dir%20if%20it%20does%20not%20exist%2C%20yet%0A%20%20%20%20mkdir%20-p%20%22%24%7Bovnk_config_dir%7D%22%0A%20%20%20%20%23%20make%20sure%20to%20create%20ovnk_var_dir%20if%20it%20does%20not%20exist%2C%20yet%0A%20%20%20%20mkdir%20-p%20%22%24%7Bovnk_var_dir%7D%22%0A%0A%20%20%20%20%23%20For%20upgrade%20scenarios%2C%20make%20sure%20that%20we%20stabilize%20what%20we%20already%20configured%0A%20%20%20%20%23%20before.%20If%20we%20do%20not%20have%20a%20valid%20interface%20hint%2C%20find%20the%20physical%20interface%0A%20%20%20%20%23%20that's%20attached%20to%20ovs-if-phys0.%0A%20%20%20%20%23%20If%20we%20find%20such%20an%20interface%2C%20write%20it%20to%20the%20hint%20file.%0A%20%20%20%20iface_default_hint%3D%24(get_iface_default_hint%20%22%24%7Biface_default_hint_file%7D%22)%0A%20%20%20%20if%20%5B%20%22%24%7Biface_default_hint%7D%22%20%3D%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20current_interface%3D%24(get_bridge_physical_interface%20ovs-if-phys0)%0A%20%20%20%20%20%20if%20%5B%20%22%24%7Bcurrent_interface%7D%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20write_iface_default_hint%20%22%24%7Biface_default_hint_file%7D%22%20%22%24%7Bcurrent_interface%7D%22%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20delete%20iface_default_hint_file%20if%20it%20has%20the%20same%20content%20as%20extra_bridge_file%0A%20%20%20%20%23%20in%20that%20case%2C%20we%20must%20also%20force%20a%20reconfiguration%20of%20our%20network%20interfaces%0A%20%20%20%20%23%20to%20make%20sure%20that%20we%20reconcile%20this%20conflict%0A%20%20%20%20if%20%5B%20-f%20%22%24%7Biface_default_hint_file%7D%22%20%5D%20%26%26%0A%20%20%20%20%20%20%5B%20-f%20%22%24%7Bextra_bridge_file%7D%22%20%5D%20%26%26%0A%20%20%20%20%20%20%5B%20%22%24(cat%20%22%24%7Biface_default_hint_file%7D%22)%22%20%3D%3D%20%22%24(cat%20%22%24%7Bextra_bridge_file%7D%22)%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22%24%7Biface_default_hint_file%7D%20and%20%24%7Bextra_bridge_file%7D%20share%20the%20same%20content%22%0A%20%20%20%20%20%20echo%20%22Deleting%20file%20%24%7Biface_default_hint_file%7D%20to%20choose%20a%20different%20interface%22%0A%20%20%20%20%20%20rm%20-f%20%22%24%7Biface_default_hint_file%7D%22%0A%20%20%20%20%20%20rm%20-f%20%2Frun%2Fconfigure-ovs-boot-done%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20on%20every%20boot%20we%20rollback%20and%20generate%20the%20configuration%20again%2C%20to%20take%0A%20%20%20%20%23%20in%20any%20changes%20that%20have%20possibly%20been%20applied%20in%20the%20standard%0A%20%20%20%20%23%20configuration%20sources%0A%20%20%20%20if%20%5B%20!%20-f%20%2Frun%2Fconfigure-ovs-boot-done%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22Running%20on%20boot%2C%20restoring%20previous%20configuration%20before%20proceeding...%22%0A%20%20%20%20%20%20rollback_nm%0A%20%20%20%20%20%20print_state%0A%20%20%20%20fi%0A%20%20%20%20touch%20%2Frun%2Fconfigure-ovs-boot-done%0A%0A%20%20%20%20iface%3D%24(get_default_bridge_interface%20%22%24%7Biface_default_hint_file%7D%22%20%22%24%7Bextra_bridge_file%7D%22%20%22%24%7Bip_hint_file%7D%22%20%22%24%7Bdefault_bridge_file%7D%22)%0A%0A%20%20%20%20if%20%5B%20%22%24iface%22%20!%3D%20%22br-ex%22%20%5D%3B%20then%0A%20%20%20%20%20%20%23%20Specified%20interface%20is%20not%20br-ex.%0A%20%20%20%20%20%20%23%20Some%20deployments%20use%20a%20temporary%20solution%20where%20br-ex%20is%20moved%20out%20from%20the%20default%20gateway%20interface%0A%20%20%20%20%20%20%23%20and%20bound%20to%20a%20different%20nic%20(https%3A%2F%2Fgithub.com%2Ftrozet%2Fopenshift-ovn-migration).%0A%20%20%20%20%20%20%23%20This%20is%20now%20supported%20through%20an%20extra%20bridge%20if%20requested.%20If%20that%20is%20the%20case%2C%20we%20rollback.%0A%20%20%20%20%20%20%23%20We%20also%20rollback%20if%20it%20looks%20like%20we%20need%20to%20configure%20things%2C%20just%20in%20case%20there%20are%20any%20leftovers%0A%20%20%20%20%20%20%23%20from%20previous%20attempts.%0A%20%20%20%20%20%20if%20%5B%20-f%20%22%24extra_bridge_file%22%20%5D%20%7C%7C%20%5B%20-z%20%22%24(nmcli%20connection%20show%20--active%20br-ex%202%3E%20%2Fdev%2Fnull)%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22Bridge%20br-ex%20is%20not%20active%2C%20restoring%20previous%20configuration%20before%20proceeding...%22%0A%20%20%20%20%20%20%20%20rollback_nm%0A%20%20%20%20%20%20%20%20print_state%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20convert_to_bridge%20%22%24iface%22%20%22br-ex%22%20%22phys0%22%20%22%24%7BBRIDGE_METRIC%7D%22%0A%0A%20%20%20%20%23%20Check%20if%20we%20need%20to%20configure%20the%20second%20bridge%0A%20%20%20%20if%20%5B%20-f%20%22%24extra_bridge_file%22%20%5D%20%26%26%20(!%20nmcli%20connection%20show%20br-ex1%20%26%3E%20%2Fdev%2Fnull%20%7C%7C%20!%20nmcli%20connection%20show%20ovs-if-phys1%20%26%3E%20%2Fdev%2Fnull)%3B%20then%0A%20%20%20%20%20%20interface%3D%24(head%20-n%201%20%24extra_bridge_file)%0A%20%20%20%20%20%20convert_to_bridge%20%22%24interface%22%20%22br-ex1%22%20%22phys1%22%20%22%24%7BBRIDGE1_METRIC%7D%22%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Check%20if%20we%20need%20to%20remove%20the%20second%20bridge%0A%20%20%20%20if%20%5B%20!%20-f%20%22%24extra_bridge_file%22%20%5D%20%26%26%20(nmcli%20connection%20show%20br-ex1%20%26%3E%20%2Fdev%2Fnull%20%7C%7C%20nmcli%20connection%20show%20ovs-if-phys1%20%26%3E%20%2Fdev%2Fnull)%3B%20then%0A%20%20%20%20%20%20remove_ovn_bridges%20br-ex1%20phys1%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Remove%20bridges%20created%20by%20openshift-sdn%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-br%20br0%0A%0A%20%20%20%20%23%20Make%20sure%20everything%20is%20activated.%20Do%20it%20in%20a%20specific%20order%3A%0A%20%20%20%20%23%20-%20activate%20br-ex%20first%2C%20due%20to%20autoconnect-slaves%20this%20will%20also%0A%20%20%20%20%23%20%20%20activate%20ovs-port-br-ex%2C%20ovs-port-phys0%20and%20ovs-if-phys0.%20It%20is%0A%20%20%20%20%23%20%20%20important%20that%20ovs-if-phys0%20activates%20with%20br-ex%20to%20avoid%20the%0A%20%20%20%20%23%20%20%20ovs-if-phys0%20profile%20being%20overridden%20with%20a%20profile%20generated%20from%0A%20%20%20%20%23%20%20%20kargs.%20The%20activation%20of%20ovs-if-phys0%2C%20if%20a%20bond%2C%20might%20cause%20the%0A%20%20%20%20%23%20%20%20slaves%20to%20re-activate%2C%20but%20it%20should%20be%20with%20our%20profiles%20since%20they%0A%20%20%20%20%23%20%20%20have%20higher%20priority%0A%20%20%20%20%23%20-%20make%20sure%20that%20ovs-if-phys0%20and%20its%20slaves%2C%20if%20any%2C%20are%20activated.%0A%20%20%20%20%23%20-%20finally%20activate%20ovs-if-br-ex%20which%20holds%20the%20IP%20configuration.%0A%20%20%20%20connections%3D(br-ex%20ovs-if-phys0)%0A%20%20%20%20if%20%5B%20-f%20%22%24extra_bridge_file%22%20%5D%3B%20then%0A%20%20%20%20%20%20connections%2B%3D(br-ex1%20ovs-if-phys1)%0A%20%20%20%20fi%0A%20%20%20%20while%20IFS%3D%20read%20-r%20connection%3B%20do%0A%20%20%20%20%20%20if%20%5B%5B%20%24connection%20%3D%3D%20*%22%24MANAGED_NM_CONN_SUFFIX%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20connections%2B%3D(%22%24connection%22)%0A%20%20%20%20%20%20fi%0A%20%20%20%20done%20%3C%20%3C(nmcli%20-g%20NAME%20c)%0A%20%20%20%20connections%2B%3D(ovs-if-br-ex)%0A%20%20%20%20if%20%5B%20-f%20%22%24extra_bridge_file%22%20%5D%3B%20then%0A%20%20%20%20%20%20connections%2B%3D(ovs-if-br-ex1)%0A%20%20%20%20fi%0A%20%20%20%20activate_nm_connections%20%22%24%7Bconnections%5B%40%5D%7D%22%0A%20%20%20%20try_to_bind_ipv6_address%0A%20%20%20%20set_nm_conn_files%0A%20%20elif%20%5B%20%22%241%22%20%3D%3D%20%22OpenShiftSDN%22%20%5D%3B%20then%0A%20%20%20%20%23%20Revert%20changes%20made%20by%20%2Fusr%2Flocal%2Fbin%2Fconfigure-ovs.sh%20during%20SDN%20migration.%0A%20%20%20%20rollback_nm%0A%20%20%20%20%0A%20%20%20%20%23%20Remove%20bridges%20created%20by%20ovn-kubernetes%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-br%20br-int%20--%20--if-exists%20del-br%20br-local%0A%20%20fi%0A%7D%0A%0A%23%20Retry%20configure_ovs%20until%20it%20succeeds.%0A%23%20By%20default%2C%20retry%20every%2015%20minutes%20to%20give%20enough%20time%20to%20gather%0A%23%20troubleshooting%20information%20in%20between.%20Note%20that%20configure_ovs%20has%20other%0A%23%20internal%20retry%20mechanisms.%20This%20retry%20is%20intended%20to%20give%20some%0A%23%20self-healing%20capabilities%20to%20temporary%20but%20not%20necessarily%20short-lived%0A%23%20infrastructure%20problems.%0ARETRY%3D%22%24%7BRETRY-15m%7D%22%0Awhile%20true%3B%20do%0A%0A%20%20%23%20Disable%20retries%20if%20termination%20signal%20is%20received.%20Note%20that%20systemd%0A%20%20%23%20sends%20the%20signals%20to%20all%20processes%20in%20the%20group%20by%20default%20so%20we%20expect%0A%20%20%23%20configure_ovs%20to%20get%20its%20own%20signals.%0A%20%20trap%20'echo%20%22WARNING%3A%20termination%20requested%2C%20disabling%20retries%22%3B%20RETRY%3D%22%22'%20INT%20TERM%0A%20%20%0A%20%20%23%20Run%20configure_ovs%20in%20a%20sub-shell.%20%0A%20%20(%20configure_ovs%20%22%24%40%22%20)%0A%20%20e%3D%24%3F%0A%0A%20%20%23%20Handle%20signals%20while%20we%20sleep%0A%20%20trap%20'handle_termination'%20INT%20TERM%0A%20%20%0A%20%20%23%20Exit%20if%20succesful%20and%20not%20configured%20to%20retry%0A%20%20%5B%20%22%24e%22%20-eq%200%20%5D%20%7C%7C%20%5B%20-z%20%22%24RETRY%22%20%5D%20%26%26%20exit%20%22%24e%22%0A%20%20%0A%20%20echo%20%22configure-ovs%20failed%2C%20will%20retry%20after%20%24RETRY%22%0A%20%20%23%20flag%20that%20a%20retry%20has%20happened%0A%20%20touch%20%2Ftmp%2Fconfigure-ovs-retry%0A%20%20sleep%20%22%24RETRY%22%0A%0Adone%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/configure-ovs.sh
        - contents:
            source: data:,%23%20This%20file%20is%20generated%20by%20the%20Machine%20Config%20Operator's%20containerruntimeconfig%20controller.%0A%23%0A%23%20storage.conf%20is%20the%20configuration%20file%20for%20all%20tools%0A%23%20that%20share%20the%20containers%2Fstorage%20libraries%0A%23%20See%20man%205%20containers-storage.conf%20for%20more%20information%0A%23%20The%20%22container%20storage%22%20table%20contains%20all%20of%20the%20server%20options.%0A%5Bstorage%5D%0A%0A%23%20Default%20storage%20driver%2C%20must%20be%20set%20for%20proper%20operation.%0Adriver%20%3D%20%22overlay%22%0A%0A%23%20Temporary%20storage%20location%0Arunroot%20%3D%20%22%2Frun%2Fcontainers%2Fstorage%22%0A%0A%23%20Primary%20Read%2FWrite%20location%20of%20container%20storage%0Agraphroot%20%3D%20%22%2Fvar%2Flib%2Fcontainers%2Fstorage%22%0A%0A%5Bstorage.options%5D%0A%23%20Storage%20options%20to%20be%20passed%20to%20underlying%20storage%20drivers%0A%0A%23%20AdditionalImageStores%20is%20used%20to%20pass%20paths%20to%20additional%20Read%2FOnly%20image%20stores%0A%23%20Must%20be%20comma%20separated%20list.%0Aadditionalimagestores%20%3D%20%5B%0A%5D%0A%0A%23%20Remap-UIDs%2FGIDs%20is%20the%20mapping%20from%20UIDs%2FGIDs%20as%20they%20should%20appear%20inside%20of%0A%23%20a%20container%2C%20to%20UIDs%2FGIDs%20as%20they%20should%20appear%20outside%20of%20the%20container%2C%20and%0A%23%20the%20length%20of%20the%20range%20of%20UIDs%2FGIDs.%20%20Additional%20mapped%20sets%20can%20be%20listed%0A%23%20and%20will%20be%20heeded%20by%20libraries%2C%20but%20there%20are%20limits%20to%20the%20number%20of%0A%23%20mappings%20which%20the%20kernel%20will%20allow%20when%20you%20later%20attempt%20to%20run%20a%0A%23%20container.%0A%23%0A%23%20remap-uids%20%3D%200%3A1668442479%3A65536%0A%23%20remap-gids%20%3D%200%3A1668442479%3A65536%0A%0A%23%20Remap-User%2FGroup%20is%20a%20name%20which%20can%20be%20used%20to%20look%20up%20one%20or%20more%20UID%2FGID%0A%23%20ranges%20in%20the%20%2Fetc%2Fsubuid%20or%20%2Fetc%2Fsubgid%20file.%20%20Mappings%20are%20set%20up%20starting%0A%23%20with%20an%20in-container%20ID%20of%200%20and%20the%20a%20host-level%20ID%20taken%20from%20the%20lowest%0A%23%20range%20that%20matches%20the%20specified%20name%2C%20and%20using%20the%20length%20of%20that%20range.%0A%23%20Additional%20ranges%20are%20then%20assigned%2C%20using%20the%20ranges%20which%20specify%20the%0A%23%20lowest%20host-level%20IDs%20first%2C%20to%20the%20lowest%20not-yet-mapped%20container-level%20ID%2C%0A%23%20until%20all%20of%20the%20entries%20have%20been%20used%20for%20maps.%20This%20setting%20overrides%20the%0A%23%20Remap-UIDs%2FGIDs%20setting.%0A%23%0A%23%20remap-user%20%3D%20%22storage%22%0A%23%20remap-group%20%3D%20%22storage%22%0A%0A%5Bstorage.options.pull_options%5D%0A%23%20Options%20controlling%20how%20storage%20is%20populated%20when%20pulling%20images.%0A%0A%23%20Enable%20the%20%22zstd%3Achunked%22%20feature%2C%20which%20allows%20partial%20pulls%2C%20reusing%0A%23%20content%20that%20already%20exists%20on%20the%20system.%20This%20is%20disabled%20by%20default%2C%0A%23%20and%20must%20be%20explicitly%20enabled%20to%20be%20used.%20For%20more%20on%20zstd%3Achunked%2C%20see%0A%23%20https%3A%2F%2Fgithub.com%2Fcontainers%2Fstorage%2Fblob%2Fmain%2Fdocs%2Fcontainers-storage-zstd-chunked.md%0Aenable_partial_images%20%3D%20%22false%22%0A%0A%23%20Tells%20containers%2Fstorage%20to%20use%20hard%20links%20rather%20then%20create%20new%20files%20in%0A%23%20the%20image%2C%20if%20an%20identical%20file%20already%20existed%20in%20storage.%0Ause_hard_links%20%3D%20%22false%22%0A%0A%23%20Path%20to%20an%20ostree%20repository%20that%20might%20have%0A%23%20previously%20pulled%20content%20which%20can%20be%20used%20when%20attempting%20to%20avoid%0A%23%20pulling%20content%20from%20the%20container%20registry.%0Aostree_repos%20%3D%20%22%22%0A%0A%5Bstorage.options.overlay%5D%0A%23%20Storage%20Options%20for%20overlay%0A%0A%23%20Do%20not%20create%20a%20PRIVATE%20bind%20mount%20on%20the%20home%20directory.%0Askip_mount_home%20%3D%20%22true%22%0A%0A%23%20Size%20is%20used%20to%20set%20a%20maximum%20size%20of%20the%20container%20image.%20%20Only%20supported%20by%0A%23%20certain%20container%20storage%20drivers.%0Asize%20%3D%20%22%22%0A
          mode: 420
          overwrite: true
          path: /etc/containers/storage.conf
        - contents:
            source: data:,.%20%7B%0A%20%20%20%20errors%0A%20%20%20%20bufsize%20512%0A%20%20%20%20health%20%3A18080%0A%20%20%20%20forward%20.%20%7B%7B-%20range%20%24upstream%20%3A%3D%20.DNSUpstreams%7D%7D%20%7B%7B%24upstream%7D%7D%7B%7B-%20end%7D%7D%20%7B%0A%20%20%20%20%20%20%20%20policy%20sequential%0A%20%20%20%20%7D%0A%20%20%20%20cache%2030%0A%20%20%20%20reload%0A%20%20%20%20template%20IN%20%7B%7B%20.Cluster.IngressVIPRecordType%20%7D%7D%20comp-poc-rh01.rhpoc.int%20%7B%0A%20%20%20%20%20%20%20%20match%20.*%5B.%5Dapps.comp-poc-rh01.rhpoc.int%0A%20%20%20%20%20%20%20%20answer%20%22%7B%7B%22%7B%7B%20.Name%20%7D%7D%22%7D%7D%2060%20in%20%7B%7B%22%7B%7B%20.Type%20%7D%7D%22%7D%7D%2010.100.0.51%22%0A%20%20%20%20%20%20%20%20fallthrough%0A%20%20%20%20%7D%0A%20%20%20%20template%20IN%20%7B%7B%20.Cluster.IngressVIPEmptyType%20%7D%7D%20comp-poc-rh01.rhpoc.int%20%7B%0A%20%20%20%20%20%20%20%20match%20.*%5B.%5Dapps.comp-poc-rh01.rhpoc.int%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20fallthrough%0A%20%20%20%20%7D%0A%20%20%20%20template%20IN%20%7B%7B%20.Cluster.APIVIPRecordType%20%7D%7D%20comp-poc-rh01.rhpoc.int%20%7B%0A%20%20%20%20%20%20%20%20match%20%5Eapi.comp-poc-rh01.rhpoc.int%0A%20%20%20%20%20%20%20%20answer%20%22%7B%7B%22%7B%7B%20.Name%20%7D%7D%22%7D%7D%2060%20in%20%7B%7B%22%7B%7B%20.Type%20%7D%7D%22%7D%7D%2010.100.0.50%22%0A%20%20%20%20%20%20%20%20fallthrough%0A%20%20%20%20%7D%0A%20%20%20%20template%20IN%20%7B%7B%20.Cluster.APIVIPEmptyType%20%7D%7D%20comp-poc-rh01.rhpoc.int%20%7B%0A%20%20%20%20%20%20%20%20match%20%5Eapi.comp-poc-rh01.rhpoc.int%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20fallthrough%0A%20%20%20%20%7D%0A%20%20%20%20template%20IN%20%7B%7B%20.Cluster.APIVIPRecordType%20%7D%7D%20comp-poc-rh01.rhpoc.int%20%7B%0A%20%20%20%20%20%20%20%20match%20%5Eapi-int.comp-poc-rh01.rhpoc.int%0A%20%20%20%20%20%20%20%20answer%20%22%7B%7B%22%7B%7B%20.Name%20%7D%7D%22%7D%7D%2060%20in%20%7B%7B%22%7B%7B%20.Type%20%7D%7D%22%7D%7D%2010.100.0.50%22%0A%20%20%20%20%20%20%20%20fallthrough%0A%20%20%20%20%7D%0A%20%20%20%20template%20IN%20%7B%7B%20.Cluster.APIVIPEmptyType%20%7D%7D%20comp-poc-rh01.rhpoc.int%20%7B%0A%20%20%20%20%20%20%20%20match%20%5Eapi-int.comp-poc-rh01.rhpoc.int%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20fallthrough%0A%20%20%20%20%7D%0A%20%20%20%20hosts%20%7B%0A%20%20%20%20%20%20%20%20%7B%7B-%20range%20.Cluster.NodeAddresses%20%7D%7D%0A%20%20%20%20%20%20%20%20%7B%7B%20.Address%20%7D%7D%20%7B%7B%20.Name%20%7D%7D%20%7B%7B%20.Name%20%7D%7D.%7B%7B%20%24.Cluster.Name%20%7D%7D.%7B%7B%20%24.Cluster.Domain%20%7D%7D%0A%20%20%20%20%20%20%20%20%7B%7B-%20end%20%7D%7D%0A%20%20%20%20%20%20%20%20fallthrough%0A%20%20%20%20%7D%0A%7D%0A
          mode: 420
          overwrite: true
          path: /etc/kubernetes/static-pod-resources/coredns/Corefile.tmpl
        - contents:
            source: data:,kind%3A%20Pod%0AapiVersion%3A%20v1%0Ametadata%3A%0A%20%20name%3A%20coredns%0A%20%20namespace%3A%20openshift-kni-infra%0A%20%20creationTimestamp%3A%0A%20%20deletionGracePeriodSeconds%3A%2065%0A%20%20labels%3A%0A%20%20%20%20app%3A%20kni-infra-coredns%0A%20%20annotations%3A%0A%20%20%20%20target.workload.openshift.io%2Fmanagement%3A%20'%7B%22effect%22%3A%20%22PreferredDuringScheduling%22%7D'%0A%20%20%20%20openshift.io%2Frequired-scc%3A%20privileged%0Aspec%3A%0A%20%20volumes%3A%0A%20%20-%20name%3A%20resource-dir%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fetc%2Fkubernetes%2Fstatic-pod-resources%2Fcoredns%22%0A%20%20-%20name%3A%20kubeconfig%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20-%20name%3A%20conf-dir%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fetc%2Fcoredns%22%0A%20%20-%20name%3A%20nm-resolv%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fvar%2Frun%2FNetworkManager%22%0A%20%20-%20name%3A%20nodeip-configuration%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Frun%2Fnodeip-configuration%22%0A%20%20initContainers%3A%0A%20%20-%20name%3A%20render-config-coredns%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A93e7b8c870261726d44bddc7ba0a702d3720d1838141dac837fb8c3be7c6e1a1%0A%20%20%20%20command%3A%0A%20%20%20%20-%20runtimecfg%0A%20%20%20%20-%20render%0A%20%20%20%20-%20%22%2Fvar%2Flib%2Fkubelet%2Fkubeconfig%22%0A%20%20%20%20-%20%22--api-vips%22%0A%20%20%20%20-%20%2210.100.0.50%22%0A%20%20%20%20-%20%22--ingress-vips%22%0A%20%20%20%20-%20%2210.100.0.51%22%0A%20%20%20%20-%20%22%2Fconfig%22%0A%20%20%20%20-%20%22--out-dir%22%0A%20%20%20%20-%20%22%2Fetc%2Fcoredns%22%0A%20%20%20%20-%20%22--resolvconf-path%22%0A%20%20%20%20-%20%22%2Fvar%2Frun%2FNetworkManager%2Fresolv.conf%22%0A%20%20%20%20resources%3A%20%7B%7D%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20kubeconfig%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20resource-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fconfig%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20conf-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fcoredns%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20nm-resolv%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Frun%2FNetworkManager%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20nodeip-configuration%0A%20%20%20%20%20%20mountPath%3A%20%22%2Frun%2Fnodeip-configuration%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20imagePullPolicy%3A%20IfNotPresent%0A%20%20containers%3A%0A%20%20-%20name%3A%20coredns%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A4f6294ed30ab476019aaaa77874157facc77413988f82ffc46f94d3a98d2e4f1%0A%20%20%20%20args%3A%0A%20%20%20%20-%20%22--conf%22%0A%20%20%20%20-%20%22%2Fetc%2Fcoredns%2FCorefile%22%0A%20%20%20%20resources%3A%0A%20%20%20%20%20%20requests%3A%0A%20%20%20%20%20%20%20%20cpu%3A%20100m%0A%20%20%20%20%20%20%20%20memory%3A%20200Mi%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20conf-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fcoredns%22%0A%20%20%20%20-%20name%3A%20nodeip-configuration%0A%20%20%20%20%20%20mountPath%3A%20%22%2Frun%2Fnodeip-configuration%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20livenessProbe%3A%0A%20%20%20%20%20%20httpGet%3A%0A%20%20%20%20%20%20%20%20path%3A%20%2Fhealth%0A%20%20%20%20%20%20%20%20port%3A%2018080%0A%20%20%20%20%20%20%20%20scheme%3A%20HTTP%0A%20%20%20%20%20%20initialDelaySeconds%3A%2060%0A%20%20%20%20%20%20timeoutSeconds%3A%205%0A%20%20%20%20%20%20successThreshold%3A%201%0A%20%20%20%20%20%20failureThreshold%3A%205%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20imagePullPolicy%3A%20IfNotPresent%0A%20%20-%20name%3A%20coredns-monitor%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A93e7b8c870261726d44bddc7ba0a702d3720d1838141dac837fb8c3be7c6e1a1%0A%20%20%20%20command%3A%0A%20%20%20%20-%20corednsmonitor%0A%20%20%20%20-%20%22%2Fvar%2Flib%2Fkubelet%2Fkubeconfig%22%0A%20%20%20%20-%20%22%2Fconfig%2FCorefile.tmpl%22%0A%20%20%20%20-%20%22%2Fetc%2Fcoredns%2FCorefile%22%0A%20%20%20%20-%20%22--api-vips%22%0A%20%20%20%20-%20%2210.100.0.50%22%0A%20%20%20%20-%20%22--ingress-vips%22%0A%20%20%20%20-%20%2210.100.0.51%22%0A%20%20%20%20resources%3A%0A%20%20%20%20%20%20requests%3A%0A%20%20%20%20%20%20%20%20cpu%3A%20100m%0A%20%20%20%20%20%20%20%20memory%3A%20200Mi%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20kubeconfig%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20resource-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fconfig%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20conf-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fcoredns%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20nm-resolv%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Frun%2FNetworkManager%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20nodeip-configuration%0A%20%20%20%20%20%20mountPath%3A%20%22%2Frun%2Fnodeip-configuration%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20imagePullPolicy%3A%20IfNotPresent%0A%20%20hostNetwork%3A%20true%0A%20%20tolerations%3A%0A%20%20-%20operator%3A%20Exists%0A%20%20priorityClassName%3A%20system-node-critical%0Astatus%3A%20%7B%7D%0A
          mode: 420
          overwrite: true
          path: /etc/kubernetes/manifests/coredns.yaml
        - contents:
            source: data:,Initial%20Creation%0A
          mode: 384
          overwrite: true
          path: /etc/docker/certs.d/.create
        - contents:
            source: data:,%23%20Proxy%20environment%20variables%20will%20be%20populated%20in%20this%20file.%20Properly%0A%23%20url%20encoded%20passwords%20with%20special%20characters%20will%20use%20'%25%3CHEX%3E%3CHEX%3E'.%0A%23%20Systemd%20requires%20that%20any%20%25%20used%20in%20a%20password%20be%20represented%20as%0A%23%20%25%25%20in%20a%20unit%20file%20since%20%25%20is%20a%20prefix%20for%20macros%3B%20this%20restriction%20does%20not%0A%23%20apply%20for%20environment%20files.%20Templates%20that%20need%20the%20proxy%20set%20should%20use%0A%23%20'EnvironmentFile%3D%2Fetc%2Fmco%2Fproxy.env'.%0A
          mode: 420
          overwrite: true
          path: /etc/mco/proxy.env
        - contents:
            source: data:,%5BManager%5D%0ADefaultEnvironment%3DGODEBUG%3Dx509ignoreCN%3D0%0A
          mode: 420
          overwrite: true
          path: /etc/systemd/system.conf.d/10-default-env-godebug.conf
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%23%20Workaround%3A%0A%23%20https%3A%2F%2Fissues.redhat.com%2Fbrowse%2FOCPBUGS-38779%0A%0Adriver%3D%24(nmcli%20-t%20-m%20tabular%20-f%20general.driver%20dev%20show%20%22%24%7BDEVICE_IFACE%7D%22)%0A%0Aif%20%5B%5B%20%22%242%22%20%3D%3D%20%22up%22%20%26%26%20%22%24%7Bdriver%7D%22%20%3D%3D%20%22idpf%22%20%5D%5D%3B%20then%0A%20%20ethtool%20-K%20%24%7BDEVICE_IFACE%7D%20tx-checksumming%20off%0Afi
          mode: 484
          overwrite: true
          path: /etc/NetworkManager/dispatcher.d/99-gcp-disable-idpf-tx-checksum-off
        - contents:
            source: data:,%23%20Force-load%20legacy%20iptables%20so%20it%20is%20usable%20from%20pod%20network%20namespaces%0Aip_tables%0A
          mode: 420
          overwrite: true
          path: /etc/modules-load.d/iptables.conf
        - contents:
            source: data:,global_defs%20%7B%0A%20%20%20%20enable_script_security%0A%20%20%20%20script_user%20root%0A%20%20%20%20max_auto_priority%20-1%0A%20%20%20%20vrrp_garp_master_refresh%2060%0A%7D%0A%0A%23%20TODO%3A%20Improve%20this%20check.%20The%20port%20is%20assumed%20to%20be%20alive.%0A%23%20Need%20to%20assess%20what%20is%20the%20ramification%20if%20the%20port%20is%20not%20there.%0Avrrp_script%20chk_ingress_ready%20%7B%0A%20%20%20%20script%20%22%2Fusr%2Fbin%2Ftimeout%200.9%20%2Fusr%2Fbin%2Fcurl%20-o%20%2Fdev%2Fnull%20-Lfs%20http%3A%2F%2Flocalhost%3A1936%2Fhealthz%2Fready%22%0A%20%20%20%20interval%201%0A%20%20%20%20weight%2010%0A%20%20%20%20rise%203%0A%20%20%20%20fall%202%0A%7D%0A%0Avrrp_script%20chk_ingress%20%7B%0A%20%20%20%20script%20%22%2Fusr%2Fbin%2Ftimeout%200.9%20%2Fusr%2Fbin%2Fcurl%20-o%20%2Fdev%2Fnull%20-Lfs%20http%3A%2F%2Flocalhost%3A1936%2Fhealthz%22%0A%20%20%20%20interval%201%0A%20%20%20%20rise%203%0A%20%20%20%20fall%202%0A%7D%0A%0Avrrp_script%20chk_default_ingress%20%7B%0A%20%20%20%20script%20%22%2Fusr%2Fbin%2Ftimeout%204.9%20%2Fetc%2Fkeepalived%2Fchk_default_ingress.sh%22%0A%20%20%20%20interval%205%0A%20%20%20%20weight%2050%0A%20%20%20%20rise%203%0A%20%20%20%20fall%202%0A%7D%0A%0A%7B%7B%20range%20%24i%2C%20%24config%20%3A%3D%20.Configs%20%7D%7D%0A%7B%7B%24nonVirtualIP%20%3A%3D%20.NonVirtualIP%7D%7D%0A%0A%7B%7B%24participateInIngressVRPP%20%3A%3D%20not%20.EnableUnicast%7D%7D%0A%7B%7B-%20if%20.EnableUnicast%7D%7D%0A%7B%7B-%20range%20.IngressConfig.Peers%7D%7D%0A%7B%7B-%20if%20eq%20%24nonVirtualIP%20.%7D%7D%0A%7B%7B%24participateInIngressVRPP%20%3D%20true%7D%7D%0A%7B%7B-%20end%7D%7D%0A%7B%7B-%20end%7D%7D%0A%7B%7B-%20end%7D%7D%0A%0A%7B%7Bif%20%24participateInIngressVRPP%7D%7D%0Avrrp_instance%20%7B%7B%20.Cluster.Name%20%7D%7D_INGRESS_%7B%7B%24i%7D%7D%20%7B%0A%20%20%20%20state%20BACKUP%0A%20%20%20%20interface%20%7B%7B%20.VRRPInterface%20%7D%7D%0A%20%20%20%20virtual_router_id%20%7B%7B%20.Cluster.IngressVirtualRouterID%20%7D%7D%0A%20%20%20%20priority%2020%0A%20%20%20%20advert_int%201%0A%20%20%20%20%7B%7Bif%20.EnableUnicast%7D%7D%0A%20%20%20%20unicast_src_ip%20%7B%7B.NonVirtualIP%7D%7D%0A%20%20%20%20unicast_peer%20%7B%0A%20%20%20%20%20%20%20%20%7B%7B-%20range%20.IngressConfig.Peers%7D%7D%0A%20%20%20%20%20%20%20%20%7B%7B-%20if%20ne%20%24nonVirtualIP%20.%7D%7D%0A%20%20%20%20%20%20%20%20%7B%7B.%7D%7D%0A%20%20%20%20%20%20%20%20%7B%7B-%20end%7D%7D%0A%20%20%20%20%20%20%20%20%7B%7B-%20end%7D%7D%0A%20%20%20%20%7D%0A%20%20%20%20%7B%7Bend%7D%7D%0A%20%20%20%20authentication%20%7B%0A%20%20%20%20%20%20%20%20auth_type%20PASS%0A%20%20%20%20%20%20%20%20auth_pass%20%7B%7B%20.Cluster.Name%20%7D%7D_ingress_vip%0A%20%20%20%20%7D%0A%20%20%20%20virtual_ipaddress%20%7B%0A%20%20%20%20%20%20%20%20%7B%7B%20.Cluster.IngressVIP%20%7D%7D%2F%7B%7B%20.Cluster.VIPNetmask%20%7D%7D%20label%20vip%0A%20%20%20%20%7D%0A%20%20%20%20track_script%20%7B%0A%20%20%20%20%20%20%20%20chk_ingress%0A%20%20%20%20%20%20%20%20chk_ingress_ready%0A%20%20%20%20%20%20%20%20chk_default_ingress%0A%20%20%20%20%7D%0A%7D%0A%7B%7B%20end%20%7D%7D%0A%7B%7B%20end%20%7D%7D%0A
          mode: 420
          overwrite: true
          path: /etc/kubernetes/static-pod-resources/keepalived/keepalived.conf.tmpl
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Achroot%20%2Fhost%20%2Fbin%2Fcrictl%20pods%20--namespace%20openshift-ingress%20--state%20Ready%20%7C%20grep%20-qE%20'router-default-%5B%5B%3Aalnum%3A%5D%5D%7B5%2C%7D-%5B%5B%3Aalnum%3A%5D%5D%7B5%2C%7D'%0A
          mode: 493
          overwrite: true
          path: /etc/kubernetes/static-pod-resources/keepalived/scripts/chk_default_ingress.sh.tmpl
        - contents:
            source: data:,kind%3A%20Pod%0AapiVersion%3A%20v1%0Ametadata%3A%0A%20%20name%3A%20keepalived%0A%20%20namespace%3A%20openshift-kni-infra%0A%20%20creationTimestamp%3A%0A%20%20deletionGracePeriodSeconds%3A%2065%0A%20%20labels%3A%0A%20%20%20%20app%3A%20kni-infra-vrrp%0A%20%20annotations%3A%0A%20%20%20%20target.workload.openshift.io%2Fmanagement%3A%20'%7B%22effect%22%3A%20%22PreferredDuringScheduling%22%7D'%0A%20%20%20%20openshift.io%2Frequired-scc%3A%20privileged%0Aspec%3A%0A%20%20volumes%3A%0A%20%20-%20name%3A%20resource-dir%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fetc%2Fkubernetes%2Fstatic-pod-resources%2Fkeepalived%22%0A%20%20-%20name%3A%20script-dir%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fetc%2Fkubernetes%2Fstatic-pod-resources%2Fkeepalived%2Fscripts%22%0A%20%20-%20name%3A%20kubeconfig%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fetc%2Fkubernetes%22%0A%20%20-%20name%3A%20kubeconfigvarlib%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20-%20name%3A%20conf-dir%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fetc%2Fkeepalived%22%0A%20%20-%20name%3A%20run-dir%0A%20%20%20%20empty-dir%3A%20%7B%7D%0A%20%20-%20name%3A%20chroot-host%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2F%22%0A%20%20-%20name%3A%20nodeip-configuration%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Frun%2Fnodeip-configuration%22%0A%20%20initContainers%3A%0A%20%20-%20name%3A%20render-config-keepalived%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A93e7b8c870261726d44bddc7ba0a702d3720d1838141dac837fb8c3be7c6e1a1%0A%20%20%20%20command%3A%0A%20%20%20%20-%20runtimecfg%0A%20%20%20%20-%20render%0A%20%20%20%20-%20%22%2Fetc%2Fkubernetes%2Fkubeconfig%22%0A%20%20%20%20-%20%22--api-vips%22%0A%20%20%20%20-%20%2210.100.0.50%22%0A%20%20%20%20-%20%22--ingress-vips%22%0A%20%20%20%20-%20%2210.100.0.51%22%0A%20%20%20%20-%20%22%2Fconfig%22%0A%20%20%20%20-%20%22--out-dir%22%0A%20%20%20%20-%20%22%2Fetc%2Fkeepalived%22%0A%20%20%20%20resources%3A%20%7B%7D%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20kubeconfig%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fkubernetes%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20script-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fconfig%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20conf-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fkeepalived%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20nodeip-configuration%0A%20%20%20%20%20%20mountPath%3A%20%22%2Frun%2Fnodeip-configuration%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20imagePullPolicy%3A%20IfNotPresent%0A%20%20containers%3A%0A%20%20-%20name%3A%20keepalived%0A%20%20%20%20securityContext%3A%0A%20%20%20%20%20%20capabilities%3A%0A%20%20%20%20%20%20%20%20add%3A%20%5B%22NET_ADMIN%22%2C%20%22NET_RAW%22%2C%20%22SYS_CHROOT%22%5D%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A3b0561a80561d95854d5f364f8cd6c3458d27cfb798bf93e09ffcfab97609216%0A%20%20%20%20env%3A%0A%20%20%20%20%20%20-%20name%3A%20NSS_SDB_USE_CACHE%0A%20%20%20%20%20%20%20%20value%3A%20%22no%22%0A%20%20%20%20command%3A%0A%20%20%20%20-%20%2Fbin%2Fbash%0A%20%20%20%20-%20-c%0A%20%20%20%20-%20%7C%0A%20%20%20%20%20%20%23%2Fbin%2Fbash%0A%20%20%20%20%20%20sigterm_handler()%0A%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20if%20pid%3D%24(pgrep%20-o%20keepalived)%3B%20then%0A%20%20%20%20%20%20%20%20%20%20kill%20-s%20SIGTERM%20%22%24pid%22%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%7D%0A%0A%20%20%20%20%20%20reload_keepalived()%0A%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20if%20pid%3D%24(pgrep%20-o%20keepalived)%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20kill%20-s%20SIGHUP%20%22%24pid%22%0A%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20%2Fusr%2Fsbin%2Fkeepalived%20-f%20%2Fetc%2Fkeepalived%2Fkeepalived.conf%20--dont-fork%20--vrrp%20--log-detail%20--log-console%20%26%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%7D%0A%0A%20%20%20%20%20%20msg_handler()%0A%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20while%20read%20-r%20line%3B%20do%0A%20%20%20%20%20%20%20%20%20%20echo%20%22The%20client%20sent%3A%20%24line%22%20%3E%262%0A%20%20%20%20%20%20%20%20%20%20%23%20currently%20only%20'reload'%20msg%20is%20supported%0A%20%20%20%20%20%20%20%20%20%20if%20%5B%20%22%24line%22%20%3D%20reload%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20reload_keepalived%0A%20%20%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20done%0A%20%20%20%20%20%20%7D%0A%0A%20%20%20%20%20%20remove_vip()%0A%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20address%3D%241%0A%20%20%20%20%20%20%20%20interface%3D%24(ip%20-o%20a%20%7C%20awk%20%22%2F%5Cs%24%7Baddress%7D%5C%2F%2F%20%7Bprint%20%5C%242%7D%22)%0A%20%20%20%20%20%20%20%20cidr%3D%24(ip%20-o%20a%20%7C%20awk%20%22%2F%5Cs%24%7Baddress%7D%5C%2F%2F%20%7Bprint%20%5C%244%7D%22)%0A%20%20%20%20%20%20%20%20if%20%5B%20-n%20%22%24interface%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20ip%20a%20del%20%24cidr%20dev%20%24interface%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%7D%0A%0A%20%20%20%20%20%20set%20-ex%0A%20%20%20%20%20%20%23%20Ensure%20that%20we%20don't%20have%20stale%20VIPs%20configured%0A%20%20%20%20%20%20%23%20See%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1931505%0A%20%20%20%20%20%20remove_vip%20%2210.100.0.50%22%0A%20%20%20%20%20%20remove_vip%20%2210.100.0.51%22%0A%20%20%20%20%20%20declare%20-r%20keepalived_sock%3D%22%2Fvar%2Frun%2Fkeepalived%2Fkeepalived.sock%22%0A%20%20%20%20%20%20export%20-f%20msg_handler%0A%20%20%20%20%20%20export%20-f%20reload_keepalived%0A%20%20%20%20%20%20export%20-f%20sigterm_handler%0A%0A%20%20%20%20%20%20%23%20in%20remote%20worker%20case%20sleep%20forever%0A%20%20%20%20%20%20if%20%5B%20-f%20%22%2Frun%2Fnodeip-configuration%2Fremote-worker%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20sleep%20infinity%0A%20%20%20%20%20%20%20%20%20exit%200%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20trap%20sigterm_handler%20SIGTERM%0A%20%20%20%20%20%20if%20%5B%20-s%20%22%2Fetc%2Fkeepalived%2Fkeepalived.conf%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%2Fusr%2Fsbin%2Fkeepalived%20-f%20%2Fetc%2Fkeepalived%2Fkeepalived.conf%20--dont-fork%20--vrrp%20--log-detail%20--log-console%20%26%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20rm%20-f%20%22%24keepalived_sock%22%0A%20%20%20%20%20%20socat%20UNIX-LISTEN%3A%24%7Bkeepalived_sock%7D%2Cfork%20system%3A'bash%20-c%20msg_handler'%0A%20%20%20%20resources%3A%0A%20%20%20%20%20%20requests%3A%0A%20%20%20%20%20%20%20%20cpu%3A%20100m%0A%20%20%20%20%20%20%20%20memory%3A%20200Mi%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20conf-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fkeepalived%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20run-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Frun%2Fkeepalived%22%0A%20%20%20%20-%20name%3A%20chroot-host%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fhost%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20kubeconfigvarlib%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20nodeip-configuration%0A%20%20%20%20%20%20mountPath%3A%20%22%2Frun%2Fnodeip-configuration%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20livenessProbe%3A%0A%20%20%20%20%20%20exec%3A%0A%20%20%20%20%20%20%20%20command%3A%0A%20%20%20%20%20%20%20%20-%20%2Fbin%2Fbash%0A%20%20%20%20%20%20%20%20-%20-c%0A%20%20%20%20%20%20%20%20-%20%7C%0A%20%20%20%20%20%20%20%20%20%20%5B%20!%20-s%20%22%2Fetc%2Fkeepalived%2Fkeepalived.conf%22%20%5D%20%7C%7C%20(echo%20%22%22%20%3E%20%2Ftmp%2Fkeepalived.data%20%26%26%20kill%20-s%20SIGUSR1%20%22%24(pgrep%20-o%20keepalived)%22%20%26%26%20for%20i%20in%20%24(seq%205)%3B%20do%20grep%20-q%20%22VRRP%20Instance%22%20%2Ftmp%2Fkeepalived.data%20%26%26%20exit%200%20%7C%7C%20sleep%201%3B%20done%20%26%26%20exit%201)%0A%20%20%20%20%20%20initialDelaySeconds%3A%2020%0A%20%20%20%20%20%20timeoutSeconds%3A%205%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20imagePullPolicy%3A%20IfNotPresent%0A%20%20-%20name%3A%20keepalived-monitor%0A%20%20%20%20securityContext%3A%0A%20%20%20%20%20%20capabilities%3A%0A%20%20%20%20%20%20%20%20add%3A%20%5B%22NET_ADMIN%22%2C%20%22SYS_CHROOT%22%5D%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A93e7b8c870261726d44bddc7ba0a702d3720d1838141dac837fb8c3be7c6e1a1%0A%20%20%20%20env%3A%0A%20%20%20%20%20%20-%20name%3A%20ENABLE_UNICAST%0A%20%20%20%20%20%20%20%20value%3A%20%22yes%22%0A%20%20%20%20%20%20-%20name%3A%20IS_BOOTSTRAP%0A%20%20%20%20%20%20%20%20value%3A%20%22no%22%0A%20%20%20%20%20%20-%20name%3A%20POD_NAMESPACE%0A%20%20%20%20%20%20%20%20valueFrom%3A%0A%20%20%20%20%20%20%20%20%20%20fieldRef%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20fieldPath%3A%20metadata.namespace%0A%20%20%20%20command%3A%0A%20%20%20%20-%20%2Fbin%2Fbash%0A%20%20%20%20-%20-c%0A%20%20%20%20-%20%7C%0A%20%20%20%20%20%20%23%2Fbin%2Fbash%0A%20%20%20%20%20%20%23%20in%20remote%20worker%20case%20sleep%20forever%0A%20%20%20%20%20%20if%20%5B%20-f%20%22%2Frun%2Fnodeip-configuration%2Fremote-worker%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20sleep%20infinity%0A%20%20%20%20%20%20%20%20%20%20exit%200%0A%20%20%20%20%20%20fi%0A%20%20%20%20%20%20api_vips%3D10.100.0.50%0A%20%20%20%20%20%20ingress_vips%3D10.100.0.51%0A%20%20%20%20%20%20dynkeepalived%20%2Fvar%2Flib%2Fkubelet%2Fkubeconfig%20%2Fconfig%2Fkeepalived.conf.tmpl%20%2Fetc%2Fkeepalived%2Fkeepalived.conf%20--api-vips%20%22%24%7Bapi_vips%7D%22%20--ingress-vips%20%22%24%7Bingress_vips%7D%22%0A%20%20%20%20resources%3A%0A%20%20%20%20%20%20requests%3A%0A%20%20%20%20%20%20%20%20cpu%3A%20100m%0A%20%20%20%20%20%20%20%20memory%3A%20200Mi%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20resource-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fconfig%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20kubeconfigvarlib%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20conf-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fkeepalived%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20run-dir%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Frun%2Fkeepalived%22%0A%20%20%20%20-%20name%3A%20chroot-host%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fhost%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20nodeip-configuration%0A%20%20%20%20%20%20mountPath%3A%20%22%2Frun%2Fnodeip-configuration%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20imagePullPolicy%3A%20IfNotPresent%0A%20%20hostNetwork%3A%20true%0A%20%20tolerations%3A%0A%20%20-%20operator%3A%20Exists%0A%20%20priorityClassName%3A%20system-node-critical%0Astatus%3A%20%7B%7D%0A
          mode: 420
          overwrite: true
          path: /etc/kubernetes/manifests/keepalived.yaml
        - contents:
            source: data:,NODE_SIZING_ENABLED%3Dfalse%0ASYSTEM_RESERVED_MEMORY%3D1Gi%0ASYSTEM_RESERVED_CPU%3D500m%0ASYSTEM_RESERVED_ES%3D1Gi
          mode: 420
          overwrite: true
          path: /etc/node-sizing-enabled.env
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-e%0ANODE_SIZES_ENV%3D%24%7BNODE_SIZES_ENV%3A-%2Fetc%2Fnode-sizing.env%7D%0AVERSION_1%3D1%0AVERSION_2%3D2%0ANODE_AUTO_SIZING_VERSION%3D%24%7BNODE_AUTO_SIZING_VERSION%3A-%24VERSION_2%7D%0ANODE_AUTO_SIZING_VERSION_FILE%3D%24%7BNODE_AUTO_SIZING_VERSION_FILE%3A-%2Fetc%2Fnode-sizing-version.json%7D%0Afunction%20dynamic_memory_sizing%20%7B%0A%20%20%20%20total_memory%3D%24(free%20-g%7Cawk%20'%2F%5EMem%3A%2F%7Bprint%20%242%7D')%0A%20%20%20%20%23%20total_memory%3D8%20test%20the%20recommended%20values%20by%20modifying%20this%20value%0A%20%20%20%20recommended_systemreserved_memory%3D0%0A%20%20%20%20if%20((%24total_memory%20%3C%3D%204))%3B%20then%20%23%2025%25%20of%20the%20first%204GB%20of%20memory%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24total_memory%200.25%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D0%0A%20%20%20%20else%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D1%0A%20%20%20%20%20%20%20%20total_memory%3D%24((total_memory-4))%0A%20%20%20%20fi%0A%20%20%20%20if%20((%24total_memory%20%3C%3D%204))%3B%20then%20%23%2020%25%20of%20the%20next%204GB%20of%20memory%20(up%20to%208GB)%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%20%24(echo%20%24total_memory%200.20%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D0%0A%20%20%20%20else%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%200.80%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D%24((total_memory-4))%0A%20%20%20%20fi%0A%20%20%20%20if%20((%24total_memory%20%3C%3D%208))%3B%20then%20%23%2010%25%20of%20the%20next%208GB%20of%20memory%20(up%20to%2016GB)%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%20%24(echo%20%24total_memory%200.10%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D0%0A%20%20%20%20else%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%200.80%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D%24((total_memory-8))%0A%20%20%20%20fi%0A%20%20%20%20if%20((%24total_memory%20%3C%3D%20112))%3B%20then%20%23%206%25%20of%20the%20next%20112GB%20of%20memory%20(up%20to%20128GB)%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%20%24(echo%20%24total_memory%200.06%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D0%0A%20%20%20%20else%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%206.72%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D%24((total_memory-112))%0A%20%20%20%20fi%0A%20%20%20%20if%20((%24total_memory%20%3E%3D%200))%3B%20then%20%23%202%25%20of%20any%20memory%20above%20128GB%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%20%24(echo%20%24total_memory%200.02%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20fi%0A%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%20%7C%20awk%20'%7Bprintf(%22%25d%5Cn%22%2C%241%20%2B%200.5)%7D')%20%23%20Round%20off%20so%20we%20avoid%20float%20conversions%0A%20%20%20%20echo%20%22SYSTEM_RESERVED_MEMORY%3D%24%7Brecommended_systemreserved_memory%7DGi%22%3E%3E%20%24%7BNODE_SIZES_ENV%7D%0A%7D%0Afunction%20dynamic_cpu_sizing%20%7B%0A%20%20%20%20total_cpu%3D%24(getconf%20_NPROCESSORS_ONLN)%0A%20%20%20%20if%20%5B%20%22%241%22%20-eq%20%22%24VERSION_1%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D0%0A%20%20%20%20%20%20%20%20if%20((%24total_cpu%20%3C%3D%201))%3B%20then%20%23%206%25%20of%20the%20first%20core%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24total_cpu%200.06%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D0%0A%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D0.06%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D%24((total_cpu-1))%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20if%20((%24total_cpu%20%3C%3D%201))%3B%20then%20%23%201%25%20of%20the%20next%20core%20(up%20to%202%20cores)%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24recommended_systemreserved_cpu%20%24(echo%20%24total_cpu%200.01%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D0%0A%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24recommended_systemreserved_cpu%200.01%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D%24((total_cpu-1))%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20if%20((%24total_cpu%20%3C%3D%202))%3B%20then%20%23%200.5%25%20of%20the%20next%202%20cores%20(up%20to%204%20cores)%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24recommended_systemreserved_cpu%20%24(echo%20%24total_cpu%200.005%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D0%0A%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24recommended_systemreserved_cpu%200.01%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D%24((total_cpu-2))%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20if%20((%24total_cpu%20%3E%3D%200))%3B%20then%20%23%200.25%25%20of%20any%20cores%20above%204%20cores%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24recommended_systemreserved_cpu%20%24(echo%20%24total_cpu%200.0025%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20else%0A%20%20%20%20%20%20%20%20%23%20Base%20allocation%20for%201%20CPU%20in%20fractions%20of%20a%20core%20(60%20millicores%20%3D%200.06%20CPU%20core)%0A%20%20%20%20%20%20%20%20base_allocation_fraction%3D0.06%0A%20%20%20%20%20%20%20%20%23%20Increment%20per%20additional%20CPU%20in%20fractions%20of%20a%20core%20(12%20millicores%20%3D%200.012%20CPU%20core)%0A%20%20%20%20%20%20%20%20increment_per_cpu_fraction%3D0.012%0A%20%20%20%20%20%20%20%20if%20((total_cpu%20%3E%201))%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Calculate%20the%20total%20system-reserved%20CPU%20in%20fractions%2C%20starting%20with%20the%20base%20allocation%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20and%20adding%20the%20incremental%20fraction%20for%20each%20additional%20CPU%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(awk%20-v%20base%3D%22%24base_allocation_fraction%22%20-v%20increment%3D%22%24increment_per_cpu_fraction%22%20-v%20cpus%3D%22%24total_cpu%22%20'BEGIN%20%7Bprintf%20%22%25.2f%5Cn%22%2C%20base%20%2B%20increment%20*%20(cpus%20-%201)%7D')%0A%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20For%20a%20single%20CPU%2C%20use%20the%20base%20allocation%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24base_allocation_fraction%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Enforce%20minimum%20threshold%20of%200.5%20CPU%0A%20%20%20%20recommended_systemreserved_cpu%3D%24(awk%20-v%20val%3D%22%24recommended_systemreserved_cpu%22%20'BEGIN%20%7Bif%20(val%20%3C%200.5)%20print%200.5%3B%20else%20print%20val%7D')%0A%0A%20%20%20%20echo%20%22SYSTEM_RESERVED_CPU%3D%24%7Brecommended_systemreserved_cpu%7D%22%3E%3E%20%24%7BNODE_SIZES_ENV%7D%0A%7D%0Afunction%20dynamic_ephemeral_sizing%20%7B%0A%20%20%20%20echo%20%22Not%20implemented%20yet%22%0A%7D%0Afunction%20dynamic_pid_sizing%20%7B%0A%20%20%20%20echo%20%22Not%20implemented%20yet%22%0A%7D%0Afunction%20set_memory%20%7B%0A%20%20%20%20SYSTEM_RESERVED_MEMORY%3D%241%0A%20%20%20%20if%20%5B%20-z%20%22%24%7BSYSTEM_RESERVED_MEMORY%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20SYSTEM_RESERVED_MEMORY%3D%221Gi%22%0A%20%20%20%20fi%0A%20%20%20%20echo%20%22SYSTEM_RESERVED_MEMORY%3D%24%7BSYSTEM_RESERVED_MEMORY%7D%22%20%3E%3E%20%24%7BNODE_SIZES_ENV%7D%0A%7D%0Afunction%20set_cpu%20%7B%0A%20%20%20%20SYSTEM_RESERVED_CPU%3D%241%0A%20%20%20%20if%20%5B%20-z%20%22%24%7BSYSTEM_RESERVED_CPU%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20SYSTEM_RESERVED_CPU%3D%22500m%22%0A%20%20%20%20fi%0A%20%20%20%20echo%20%22SYSTEM_RESERVED_CPU%3D%24%7BSYSTEM_RESERVED_CPU%7D%22%20%3E%3E%20%24%7BNODE_SIZES_ENV%7D%0A%7D%0Afunction%20set_es%20%7B%0A%20%20%20%20SYSTEM_RESERVED_ES%3D%241%0A%20%20%20%20if%20%5B%20-z%20%22%24%7BSYSTEM_RESERVED_ES%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20SYSTEM_RESERVED_ES%3D%221Gi%22%0A%20%20%20%20fi%0A%20%20%20%20echo%20%22SYSTEM_RESERVED_ES%3D%24%7BSYSTEM_RESERVED_ES%7D%22%20%3E%3E%20%24%7BNODE_SIZES_ENV%7D%0A%7D%0Afunction%20dynamic_node_sizing%20%7B%0A%20%20%20%20rm%20-f%20%24%7BNODE_SIZES_ENV%7D%0A%20%20%20%20dynamic_memory_sizing%0A%20%20%20%20dynamic_cpu_sizing%20%241%0A%20%20%20%20set_es%20%242%0A%20%20%20%20%23dynamic_ephemeral_sizing%0A%20%20%20%20%23dynamic_pid_sizing%0A%7D%0Afunction%20static_node_sizing%20%7B%0A%20%20%20%20rm%20-f%20%24%7BNODE_SIZES_ENV%7D%0A%20%20%20%20set_memory%20%241%0A%20%20%20%20set_cpu%20%242%0A%20%20%20%20set_es%20%243%0A%7D%0Afunction%20create_version_file%20%7B%0A%20%20%20%20echo%20%22%7B%5C%22version%5C%22%3A%20%241%7D%22%20%3E%20%242%0A%7D%0Aif%20!%20%5B%20-f%20%24NODE_AUTO_SIZING_VERSION_FILE%20%5D%3B%20then%0A%20%20%20%20create_version_file%20%24NODE_AUTO_SIZING_VERSION%20%24NODE_AUTO_SIZING_VERSION_FILE%0Afi%0Anew_version%3D%24(jq%20.version%20%24NODE_AUTO_SIZING_VERSION_FILE)%0Aif%20%5B%20%241%20%3D%3D%20%22true%22%20%5D%3B%20then%0A%20%20%20%20dynamic_node_sizing%20%24new_version%20%244%0Aelif%20%5B%20%241%20%3D%3D%20%22false%22%20%5D%3B%20then%0A%20%20%20%20static_node_sizing%20%242%20%243%20%244%0Aelse%0A%20%20%20%20echo%20%22Unrecognized%20command%20line%20option.%20Valid%20options%20are%20%5C%22true%5C%22%20or%20%5C%22false%5C%22%22%0Afi%0A
          mode: 493
          overwrite: true
          path: /usr/local/sbin/dynamic-system-reserved-calc.sh
        - contents:
            source: data:,%23%20Turning%20on%20Accounting%20helps%20track%20down%20performance%20issues.%0A%5BManager%5D%0ADefaultCPUAccounting%3Dyes%0ADefaultMemoryAccounting%3Dyes%0ADefaultBlockIOAccounting%3Dyes%0A
          mode: 420
          overwrite: true
          path: /etc/systemd/system.conf.d/kubelet-cgroups.conf
        - contents:
            source: data:,%5BService%5D%0AEnvironment%3D%22KUBELET_LOG_LEVEL%3D2%22%0A
          mode: 420
          overwrite: true
          path: /etc/systemd/system/kubelet.service.d/20-logging.conf
        - contents:
            source: data:,%23%20ignore%20known%20SDN-managed%20devices%0A%5Bdevice%5D%0Amatch-device%3Dinterface-name%3Abr-int%3Binterface-name%3Abr-local%3Binterface-name%3Abr-nexthop%3Binterface-name%3Aovn-k8s-*%3Binterface-name%3Ak8s-*%3Binterface-name%3Atun0%3Binterface-name%3Abr0%3Binterface-name%3Apatch-br-*%3Binterface-name%3Abr-ext%3Binterface-name%3Aext-vxlan%3Binterface-name%3Aext%3Binterface-name%3Aint%3Binterface-name%3Avxlan_sys_*%3Binterface-name%3Agenev_sys_*%3Bdriver%3Aveth%0Amanaged%3D0%0A
          mode: 420
          overwrite: true
          path: /etc/NetworkManager/conf.d/sdn.conf
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-eux%0A%0A%23%20Clean%20up%20old%20config%20on%20behalf%20of%20mtu-migration%0Aif%20!%20systemctl%20-q%20is-enabled%20mtu-migration%3B%20then%0A%20%20echo%20%22Cleaning%20up%20left%20over%20mtu%20migration%20configuration%22%0A%20%20rm%20-rf%20%2Fetc%2Fcno%2Fmtu-migration%0Afi%0A%0Aif%20%5B%20-e%20%2Fetc%2Fnmstate%2Fopenshift%2Fapplied%20%5D%3B%20then%0A%20%20echo%20%22Configuration%20already%20applied%2C%20exiting%22%0A%20%20exit%200%0Afi%0A%0Asrc_path%3D%22%2Fetc%2Fnmstate%2Fopenshift%22%0Adst_path%3D%22%2Fetc%2Fnmstate%22%0Ahostname%3D%24(hostname%20-s)%0Ahost_file%3D%22%24%7Bhostname%7D.yml%22%0Acluster_file%3D%22cluster.yml%22%0Aconfig_file%3D%22%22%0Aif%20%5B%20-s%20%22%24src_path%2F%24host_file%22%20%5D%3B%20then%0A%20%20config_file%3D%24host_file%0Aelif%20%5B%20-s%20%22%24src_path%2F%24cluster_file%22%20%5D%3B%20then%0A%20%20config_file%3D%24cluster_file%0Aelse%0A%20%20echo%20%22No%20configuration%20found%20at%20%24src_path%2F%24host_file%20or%20%24src_path%2F%24cluster_file%22%0A%20%20exit%200%0Afi%0A%0Aif%20%5B%20-e%20%22%24dst_path%2F%24config_file%22%20%5D%3B%20then%0A%20%20echo%20%22ERROR%3A%20File%20%24dst_path%2F%24config_file%20exists.%20Refusing%20to%20overwrite.%22%0A%20%20exit%201%0Afi%0A%0A%23%20Handle%20the%20case%20where%20we're%20migrating%20from%20configure-ovs%0Aovs-vsctl%20--timeout%3D30%20--if-exists%20del-br%20br-ex%0A%0A%23%20Handle%20the%20case%20where%20we're%20migrating%20from%20OpenShift%20SDN%0Aovs-vsctl%20--timeout%3D30%20--if-exists%20del-br%20br0%0A%0Acp%20%22%24src_path%2F%24config_file%22%20%2Fetc%2Fnmstate%0Atouch%20%2Fetc%2Fnmstate%2Fopenshift%2Fapplied%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/nmstate-configuration.sh
        - contents:
            source: data:,%5Bservice%5D%0Akeep_state_file_after_apply%20%3D%20true%0A
          mode: 420
          overwrite: true
          path: /etc/nmstate/nmstate.conf
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%23%20Set%20interface%20ofport_request%20to%20guarantee%20stable%20ofport%20numbers.%20This%20is%20important%20for%20flow%20matches.%0A%23%20Otherwise%2C%20another%20ofport%20number%20is%20assigned%20to%20the%20interface%20on%20every%20restart%20of%20NetworkManager.%0A%23%20This%20script%20will%20build%20an%20associative%20array%20INTERFACE_NAME-%3Eofport_request%20and%20will%20save%20it%20to%20file%20CONFIGURATION_FILE.%0A%23%20When%20an%20interface%20is%20brought%20up%2C%20this%20will%20reuse%20the%20value%20from%20the%20associative%20array%20if%20such%20a%20value%20exists.%0A%23%20Otherwise%2C%20this%20will%20try%20to%20use%20the%20current%20ofport%20value.%20If%20the%20ofport%20value%20is%20already%20reserved%2C%20then%0A%23%20this%20uses%20the%20lowest%20available%20numerical%20value%2C%20instead.%0Aset%20-eux%20-o%20pipefail%0Aif%20%5B%5B%20%22OVNKubernetes%22%20!%3D%20%22OVNKubernetes%22%20%5D%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0AINTERFACE_NAME%3D%241%0AOPERATION%3D%242%0A%0A%23%20Only%20execute%20this%20on%20pre-up%0Aif%20%5B%20%22%24%7BOPERATION%7D%22%20!%3D%20%22pre-up%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20interface's%20NM%20uuid%0AINTERFACE_CONNECTION_UUID%3D%24(nmcli%20-t%20-f%20device%2Ctype%2Cuuid%20conn%20%7C%20awk%20-F%20'%3A'%20'%7Bif(%241%3D%3D%22'%24%7BINTERFACE_NAME%7D'%22%20%26%26%20%242!~%2F%5Eovs*%2F)%20print%20%24NF%7D')%0Aif%20%5B%20%22%24%7BINTERFACE_CONNECTION_UUID%7D%22%20%3D%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20interface's%20slave-type.%20If%20this%20is%20not%20an%20ovs-port%2C%20then%20exit%0AINTERFACE_OVS_SLAVE_TYPE%3D%24(nmcli%20-t%20-f%20connection.slave-type%20conn%20show%20%22%24%7BINTERFACE_CONNECTION_UUID%7D%22%20%7C%20awk%20-F%20'%3A'%20'%7Bprint%20%24NF%7D')%0Aif%20%5B%20%22%24%7BINTERFACE_OVS_SLAVE_TYPE%7D%22%20!%3D%20%22ovs-port%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20This%20is%20not%20necessarily%20a%20UUID%20(can%20be%20a%20name%20in%20case%20of%20bonds)%20but%20this%20should%20be%20unique%0APORT%3D%24(nmcli%20-t%20-f%20connection.master%20conn%20show%20%22%24%7BINTERFACE_CONNECTION_UUID%7D%22%20%7C%20awk%20-F%20'%3A'%20'%7Bprint%20%24NF%7D')%0Aif%20%5B%20%22%24%7BPORT%7D%22%20%3D%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20interface's%20NM%20uuid%0APORT_CONNECTION_UUID%3D%24(nmcli%20-t%20-f%20device%2Ctype%2Cuuid%20conn%20%7C%20awk%20-F%20'%3A'%20'%7Bif(%20(%241%3D%3D%22'%24%7BPORT%7D'%22%20%7C%7C%20%243%3D%3D%22'%24%7BPORT%7D'%22)%20%26%26%20%242~%2F%5Eovs*%2F)%20print%20%24NF%7D')%0Aif%20%5B%20%22%24%7BPORT_CONNECTION_UUID%7D%22%20%3D%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20port's%20slave-type.%20If%20this%20is%20not%20an%20ovs-bridge%2C%20then%20exit%0APORT_OVS_SLAVE_TYPE%3D%24(nmcli%20-t%20-f%20connection.slave-type%20conn%20show%20%22%24%7BPORT_CONNECTION_UUID%7D%22%20%7C%20awk%20-F%20'%3A'%20'%7Bprint%20%24NF%7D')%0Aif%20%5B%20%22%24%7BPORT_OVS_SLAVE_TYPE%7D%22%20!%3D%20%22ovs-bridge%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20port's%20master.%20If%20it%20doesn't%20have%20any%2C%20assume%20it's%20not%20our%20bridge%0ABRIDGE_ID%3D%24(nmcli%20-t%20-f%20connection.master%20conn%20show%20%22%24%7BPORT_CONNECTION_UUID%7D%22%20%7C%20awk%20-F%20'%3A'%20'%7Bprint%20%24NF%7D')%0Aif%20%5B%20%22%24%7BBRIDGE_ID%7D%22%20%3D%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20bridge%20name%0ABRIDGE_NAME%3D%24(nmcli%20-t%20-f%20connection.interface-name%20conn%20show%20%22%24%7BBRIDGE_ID%7D%22%20%7C%20awk%20-F%20'%3A'%20'%7Bprint%20%24NF%7D')%0A%23%20Limit%20this%20to%20br-ex%20and%20br-ex1%20only.%20If%20one%20wanted%20to%20enable%20this%20for%20all%20OVS%20bridges%2C%0A%23%20the%20condition%20would%20be%3A%20if%20%5B%20%22%24BRIDGE_NAME%22%20%3D%3D%20%22%22%20%5D%3B%20then%0Aif%20%5B%20%22%24%7BBRIDGE_NAME%7D%22%20!%3D%20%22br-ex%22%20%5D%20%26%26%20%5B%20%22%24%7BBRIDGE_NAME%7D%22%20!%3D%20%22br-ex1%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Make%20sure%20that%20the%20interface%20is%20plugged%20into%20OVS%0A%23%20This%20should%20always%20be%20the%20case%20given%20that%20we%20are%20in%20pre-up%2C%20but%20exit%20gracefully%20in%20the%20odd%20case%20that%20it's%20not%0Aif%20!%20ovs-vsctl%20list%20interface%20%22%24%7BINTERFACE_NAME%7D%22%20%3E%2Fdev%2Fnull%202%3E%261%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0ACONFIGURATION_FILE%3D%22%2Frun%2Fofport_requests.%24%7BBRIDGE_NAME%7D%22%0A%0A%23%20Declare%20a%20new%20associative%20array.%20If%20CONFIGURATION_FILE%20exists%2C%20source%20entries%20from%20there%0Adeclare%20-A%20INTERFACES%0Aif%20%5B%20-f%20%22%24%7BCONFIGURATION_FILE%7D%22%20%5D%3B%20then%0A%20%20%20%20echo%20%22Sourcing%20configuration%20file%20'%24%7BCONFIGURATION_FILE%7D'%20with%20contents%3A%22%0A%20%20%20%20cat%20%22%24%7BCONFIGURATION_FILE%7D%22%0A%20%20%20%20source%20%22%24%7BCONFIGURATION_FILE%7D%22%0Afi%0A%0A%23%20get_interface_ofport_request%20will%20return%0A%23%20*%20either%3A%20the%20current%20ofport%20assignment%20for%20the%20port%20if%20no%20interface%20has%20claimed%20this%20ofport%20number%2C%20yet%0A%23%20*%20or%3A%20%20%20%20%20the%20lowest%20available%20free%20ofport%20number%0Afunction%20get_interface_ofport_request()%20%7B%0A%20%20%20%20%23%20Build%20an%20array%20that%20only%20contains%20the%20currently%20reserved%20ofport_requests%0A%20%20%20%20declare%20-A%20ofport_requests%0A%20%20%20%20for%20interface_name%20in%20%22%24%7B!INTERFACES%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20%20%20%20%20ofport_requests%5B%24%7BINTERFACES%5B%24interface_name%5D%7D%5D%3D%24%7BINTERFACES%5B%24interface_name%5D%7D%0A%20%20%20%20done%0A%0A%20%20%20%20%23%20Get%20the%20current%20ofport%20number%20assignment%0A%20%20%20%20local%20current_ofport%3D%24(ovs-vsctl%20get%20Interface%20%22%24%7BINTERFACE_NAME%7D%22%20ofport)%0A%0A%20%20%20%20%23%20If%20the%20current%20ofport%20number%20is%20still%20free%2C%20use%20it%0A%20%20%20%20if%20!%20%5B%20%22%24%7Bofport_requests%5B%24current_ofport%5D%2Ba%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%24current_ofport%0A%20%20%20%20%20%20%20%20return%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20If%20the%20current%20ofport%20number%20is%20not%20free%2C%20return%20the%20lowest%20free%20entry%0A%20%20%20%20i%3D0%0A%20%20%20%20for%20i%20in%20%7B1..65000%7D%3B%20do%0A%20%20%20%20%20%20%20%20if%20!%20%5B%20%22%24%7Bofport_requests%5B%24i%5D%2Ba%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20echo%20%24i%0A%20%20%20%20%20%20%20%20%20%20%20%20return%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20done%0A%0A%20%20%20%20%23%20if%20we%20still%20cannot%20find%20an%20ID%2C%20exit%20with%20an%20error%0A%20%20%20%20echo%20%22Impossible%20to%20find%20an%20ofport%20ID%20for%20interface%20%24%7BINTERFACE_NAME%7D%22%20%3E%262%0A%20%20%20%20exit%201%0A%7D%0A%0A%23%20If%20INTERFACES%5BINTERFACE_NAME%5D%20exists%2C%20use%20that%20value%0A%23%20If%20INTERFACES%5BINTERFACE_NAME%5D%20does%20not%20exists%2C%20use%20the%20value%20from%20get_interface_ofport_request%0Aif%20!%20%5B%20%22%24%7BINTERFACES%5B%24INTERFACE_NAME%5D%2Ba%7D%22%20%5D%3B%20then%0A%20%20%20%20INTERFACES%5B%24INTERFACE_NAME%5D%3D%24(get_interface_ofport_request)%0Afi%0A%23%20Set%20ofport_request%20according%20to%20INTERFACES%5BINTERFACE_NAME%5D%0Aovs-vsctl%20set%20Interface%20%22%24%7BINTERFACE_NAME%7D%22%20ofport_request%3D%24%7BINTERFACES%5B%24INTERFACE_NAME%5D%7D%0A%0A%23%20Save%20current%20state%20of%20INTERFACES%20to%20CONFIGURATION_FILE%0Adeclare%20-p%20INTERFACES%20%3E%7C%20%22%24%7BCONFIGURATION_FILE%7D%22%0A
          mode: 493
          overwrite: true
          path: /etc/NetworkManager/dispatcher.d/pre-up.d/10-ofport-request.sh
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%0A%23%20Extract%20Podman%20version%20and%20determine%20the%20signature%20policy%0A%2Fusr%2Fbin%2Fpodman%20-v%20%7C%20%2Fbin%2Fawk%20'%7B%0A%20%20%20%20split(%243%2C%20version%2C%20%22-%22)%3B%0A%20%20%20%20clean_version%20%3D%20version%5B1%5D%3B%0A%0A%20%20%20%20split(clean_version%2C%20current%2C%20%2F%5C.%2F)%3B%0A%20%20%20%20split(%224.4.1%22%2C%20target%2C%20%2F%5C.%2F)%3B%0A%0A%20%20%20%20for%20(i%20%3D%201%3B%20i%20%3C%3D%203%3B%20i%2B%2B)%20%7B%0A%20%20%20%20%20%20%20%20if%20((current%5Bi%5D%20%2B%200)%20%3C%20(target%5Bi%5D%20%2B%200))%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20print%20%22--signature-policy%20%2Fetc%2Fmachine-config-daemon%2Fpolicy-for-old-podman.json%22%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20exit%3B%0A%20%20%20%20%20%20%20%20%7D%20else%20if%20((current%5Bi%5D%20%2B%200)%20%3E%20(target%5Bi%5D%20%2B%200))%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20exit%3B%0A%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%7D%0A%7D'%20%3E%20%2Ftmp%2Fpodman_policy_args%0A
          mode: 493
          overwrite: true
          path: /etc/machine-config-daemon/generate_podman_policy_args.sh
        - contents:
            source: data:,%7B%22auths%22%3A%7B%22cloud.openshift.com%22%3A%7B%22auth%22%3A%22b3BlbnNoaWZ0LXJlbGVhc2UtZGV2K29jbV9hY2Nlc3NfOTRmZDViZTMwOTM3NGU5NDlkM2Q5NzhmOTQzZGFlYTI6TDc0UlozWjNEUUM1U0RFMjBUUUU3UDRZR1RNSDRIRUdMUkMySzk3MjJMSE1PMlBPVUNaUDJFVVo0UDc1N1RLQw%3D%3D%22%2C%22email%22%3A%22jgoldberg%40allcovered.com%22%7D%2C%22quay.io%22%3A%7B%22auth%22%3A%22b3BlbnNoaWZ0LXJlbGVhc2UtZGV2K29jbV9hY2Nlc3NfOTRmZDViZTMwOTM3NGU5NDlkM2Q5NzhmOTQzZGFlYTI6TDc0UlozWjNEUUM1U0RFMjBUUUU3UDRZR1RNSDRIRUdMUkMySzk3MjJMSE1PMlBPVUNaUDJFVVo0UDc1N1RLQw%3D%3D%22%2C%22email%22%3A%22jgoldberg%40allcovered.com%22%7D%2C%22registry.connect.redhat.com%22%3A%7B%22auth%22%3A%22fHVoYy1wb29sLTljZTJiZWU4LTUwYWQtNDVlNC04NDExLTNkNjQ1NWNkODI1NjpleUpoYkdjaU9pSlNVelV4TWlKOS5leUp6ZFdJaU9pSTNaakppTldOallXWXhZVEEwWXpZMVlUSTFaRGN6TjJSa05UVXlNbVJqWWlKOS5NZHFkUUgzenYyMHFzQ0dfR2hGYy1WSzFRNGRsOW05TFhqcmhQNjNjUDh0dDVGX25Wc1U5NGxlcmVVSEQ4R1FXRUxDZlIzeE5HQ2dOSXFPNWUyNC02U3NGOFNTQV9RSnZIODVzLTBBWXlWMHY2QnJxV21CRHNLSWdnSzE2SFhWUzd4cTlSZ05hN200RFRMdUF2RUdtVkRSQ05VUVNFN1FMTWMxaUVhSVI4RVdrT0pPUklQd3hQM3YyUDlsTHpSRWtKYl82WVRjUWRjQUR3T0d1OWkzUHIwMWRHX1d4QU90NkFxcFZBX0JSaHRhNFRjWTFwSHk1bXBlWWVIVnE3Q3hzZWFRV3FzR01Oc0lObkFFNGdjV0MyekVXVl9NZHpIQXVad203WWsxMjg5VVhfYnhVMWhDUkVzdG5zdGdCSERheFRpSTFjalZSZkJ4X05hb0RMU01GVXBzNmlDVXhTTUxzVmc3Mi04LVJHal9nVmMxRDZPNjJkODJoakdaaW5HekJsendzMkZLYlFnNDRjb1VWcWpDdUMwdktCdVJRbDhkX0taVGZTWFVSTS0wOE91YjBNdDRIMjVjZmx6bjNERWdDcUtlSVlUYVdMS3ZranRKVy1MaGdLRjlDUHFqWmozUjhwN2xja2ZkR0lPbHRvY0hZY0xXVlM3QURjdmRNaWVLa3p5STRHb2RPamp2NU5OVF9UWDdjRHBRRVdWUnlENkxkOElXODA4SHVoSmtfa2R0MWVDSkxSTTVUdFBSRHVxZ3UwODlqcWM4WXRVWFhfcm9KcFhoSE5iMUlnekZTdFJqZktTSVJ6YTdlV2g4VWxvRmNwNXJZOV9VeDFTaFVnZ3JlQXFmQ1Y4NXF5Wjlya2RibVNZUE5PRVdzTmtUeGJoY0Q4YWpkYlJrWkFCRQ%3D%3D%22%2C%22email%22%3A%22jgoldberg%40allcovered.com%22%7D%2C%22registry.redhat.io%22%3A%7B%22auth%22%3A%22fHVoYy1wb29sLTljZTJiZWU4LTUwYWQtNDVlNC04NDExLTNkNjQ1NWNkODI1NjpleUpoYkdjaU9pSlNVelV4TWlKOS5leUp6ZFdJaU9pSTNaakppTldOallXWXhZVEEwWXpZMVlUSTFaRGN6TjJSa05UVXlNbVJqWWlKOS5NZHFkUUgzenYyMHFzQ0dfR2hGYy1WSzFRNGRsOW05TFhqcmhQNjNjUDh0dDVGX25Wc1U5NGxlcmVVSEQ4R1FXRUxDZlIzeE5HQ2dOSXFPNWUyNC02U3NGOFNTQV9RSnZIODVzLTBBWXlWMHY2QnJxV21CRHNLSWdnSzE2SFhWUzd4cTlSZ05hN200RFRMdUF2RUdtVkRSQ05VUVNFN1FMTWMxaUVhSVI4RVdrT0pPUklQd3hQM3YyUDlsTHpSRWtKYl82WVRjUWRjQUR3T0d1OWkzUHIwMWRHX1d4QU90NkFxcFZBX0JSaHRhNFRjWTFwSHk1bXBlWWVIVnE3Q3hzZWFRV3FzR01Oc0lObkFFNGdjV0MyekVXVl9NZHpIQXVad203WWsxMjg5VVhfYnhVMWhDUkVzdG5zdGdCSERheFRpSTFjalZSZkJ4X05hb0RMU01GVXBzNmlDVXhTTUxzVmc3Mi04LVJHal9nVmMxRDZPNjJkODJoakdaaW5HekJsendzMkZLYlFnNDRjb1VWcWpDdUMwdktCdVJRbDhkX0taVGZTWFVSTS0wOE91YjBNdDRIMjVjZmx6bjNERWdDcUtlSVlUYVdMS3ZranRKVy1MaGdLRjlDUHFqWmozUjhwN2xja2ZkR0lPbHRvY0hZY0xXVlM3QURjdmRNaWVLa3p5STRHb2RPamp2NU5OVF9UWDdjRHBRRVdWUnlENkxkOElXODA4SHVoSmtfa2R0MWVDSkxSTTVUdFBSRHVxZ3UwODlqcWM4WXRVWFhfcm9KcFhoSE5iMUlnekZTdFJqZktTSVJ6YTdlV2g4VWxvRmNwNXJZOV9VeDFTaFVnZ3JlQXFmQ1Y4NXF5Wjlya2RibVNZUE5PRVdzTmtUeGJoY0Q4YWpkYlJrWkFCRQ%3D%3D%22%2C%22email%22%3A%22jgoldberg%40allcovered.com%22%7D%7D%7D%0A
          mode: 384
          overwrite: true
          path: /var/lib/kubelet/config.json
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-eo%20pipefail%0A%0Afunction%20pull_baremetal_runtime_cfg_image%20%7B%0A%20%20%20%20%23%20By%20default%20podman%20retries%20to%20pull%20an%20image%203%20times%20with%201%20second%20back-off.%20It%20is%20not%20configurable.%20For%20this%0A%20%20%20%20%23%20reason%20we%20are%20implementing%20our%20own%20logic%20of%20pulling%20image%20and%20retrying%20indefinitely.%0A%20%20%20%20%23%20Ref.%3A%20https%3A%2F%2Fgithub.com%2Fcontainers%2Fcommon%2Fblob%2Fe028741ef77fdfa3ae261b9d23cdd50253d586c4%2Flibimage%2Fcopier.go%23L27-L30%0A%0A%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Checking%20if%20baremetal%20runtime%20cfg%20image%20already%20exists%22%0A%20%20%20%20if%20!%20%2Fusr%2Fbin%2Fpodman%20image%20exists%20%22quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A93e7b8c870261726d44bddc7ba0a702d3720d1838141dac837fb8c3be7c6e1a1%22%3B%20then%0A%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Starting%20download%20of%20baremetal%20runtime%20cfg%20image%22%0A%20%20%20%20%20%20while%20!%20%2Fusr%2Fbin%2Fpodman%20pull%20--authfile%20%2Fvar%2Flib%2Fkubelet%2Fconfig.json%20%22quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A93e7b8c870261726d44bddc7ba0a702d3720d1838141dac837fb8c3be7c6e1a1%22%3B%20do%20sleep%201%3B%20done%0A%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Download%20of%20baremetal%20runtime%20cfg%20image%20completed%22%0A%20%20%20%20else%0A%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Image%20exists%2C%20no%20need%20to%20download%22%0A%20%20%20%20fi%0A%7D%0A%0Afunction%20resolv_prepender%20%7B%0A%20%20%20%20%20%20%20%20%23%20In%20DHCP%20connections%2C%20the%20resolv.conf%20content%20may%20be%20late%2C%20thus%20we%20wait%20for%20nameservers%0A%20%20%20%20%20%20%20%20while%20!%20grep%20nameserver%20%2Fvar%2Frun%2FNetworkManager%2Fresolv.conf%3B%20do%0A%20%20%20%20%20%20%20%20%20%20%20%20%3E%262%20echo%20%20%22NM%20resolv-prepender%3A%20NM%20resolv.conf%20still%20empty%20of%20nameserver%22%0A%20%20%20%20%20%20%20%20%20%20%20%20sleep%200.5%0A%20%20%20%20%20%20%20%20done%0A%0A%20%20%20%20%20%20%20%20%23%20Ensure%20resolv.conf%20exists%20and%20contains%20nameservers%20before%20we%20try%20to%20pull%20image%20or%20run%20podman%0A%20%20%20%20%20%20%20%20if%20%5B%5B%20!%20-e%20%2Fetc%2Fresolv.conf%20%5D%5D%20%7C%7C%20!%20grep%20-q%20nameserver%20%2Fetc%2Fresolv.conf%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20cp%20%2Fvar%2Frun%2FNetworkManager%2Fresolv.conf%20%2Fetc%2Fresolv.conf%0A%20%20%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20%20%20%23%20Ensure%20baremetalRuntimeCfgImage%20is%20pulled%20in%20a%20reliable%20way%20before%20trying%20to%20use%20it%0A%20%20%20%20%20%20%20%20%23%20in%20the%20subsequent%20code%0A%20%20%20%20%20%20%20%20pull_baremetal_runtime_cfg_image%0A%0A%20%20%20%20%20%20%20%20NAMESERVER_IP%3D%22%24(%2Fusr%2Fbin%2Fpodman%20run%20--rm%20%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20--authfile%20%2Fvar%2Flib%2Fkubelet%2Fconfig.json%20%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20--net%3Dhost%20%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A93e7b8c870261726d44bddc7ba0a702d3720d1838141dac837fb8c3be7c6e1a1%20%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20node-ip%20%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20show%20%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%2210.100.0.50%22%20%20%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%2210.100.0.51%22%20)%22%0A%20%20%20%20%20%20%20%20DOMAINS%3D%22%24%7BIP4_DOMAINS%3A-%7D%20%24%7BIP6_DOMAINS%3A-%7D%20comp-poc-rh01.rhpoc.int%22%0A%20%20%20%20%20%20%20%20if%20%5B%5B%20-n%20%22%24NAMESERVER_IP%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20KNICONFDONEPATH%3D%22%2Frun%2Fresolv-prepender-kni-conf-done%22%0A%20%20%20%20%20%20%20%20%20%20%20%20if%20systemctl%20-q%20is-enabled%20systemd-resolved%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Configure%20for%20OKD%20domain%20and%20local%20IP%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20mkdir%20-p%20%2Fetc%2Fsystemd%2Fresolved.conf.d%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20KNICONFTMPPATH%3D%22%24(mktemp)%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20KNICONFPATH%3D%22%2Fetc%2Fsystemd%2Fresolved.conf.d%2F60-kni.conf%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20echo%20%22%5BResolve%5D%22%20%3E%20%22%24%7BKNICONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20echo%20%22DNS%3D%24NAMESERVER_IP%22%20%3E%3E%20%22%24%7BKNICONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20echo%20%22Domains%3D%24%7BDOMAINS%7D%22%20%3E%3E%20%22%24%7BKNICONFTMPPATH%7D%22%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20If%20KNI%20conf%20is%20not%20created%20or%20doesn't%20match%20what%20is%20generated%20or%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20if%20we%20haven't%20completed%20a%20full%20update%20-%20create%20or%20update%20it%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20%5B%5B%20!%20-f%20%22%24%7BKNICONFPATH%7D%22%20%5D%5D%20%7C%7C%20%5B%5B%20!%20-f%20%22%24%7BKNICONFDONEPATH%7D%22%20%5D%5D%20%7C%7C%20!%20cmp%20--silent%20%22%24%7BKNICONFPATH%7D%22%20%22%24%7BKNICONFTMPPATH%7D%22%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Creating%2Fupdating%20%2Fetc%2Fsystemd%2Fresolved.conf.d%2F60-kni.conf%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Remove%20the%20done%20file%20flag%20before%20writing%20the%20config%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20This%20would%20guard%20against%20interruptions%20and%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20prevent%20double%20restart%20of%20systemd-resolved%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20rm%20-f%20%22%24%7BKNICONFDONEPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Copy%20tmp%20file%20contents%20to%20preserve%20permissions%20and%20SELinux%20label%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20cat%20%22%24%7BKNICONFTMPPATH%7D%22%20%3E%20%22%24%7BKNICONFPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20%5B%5B%20!%20-f%20%22%24%7BKNICONFDONEPATH%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20systemctl%20-q%20is-active%20systemd-resolved%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Restarting%20systemd-resolved%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20systemctl%20restart%20systemd-resolved%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20touch%20%22%24%7BKNICONFDONEPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20rm%20-rf%20%22%24%7BKNICONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%3E%262%20echo%20%22NM%20resolv-prepender%3A%20Prepending%20'nameserver%20%24NAMESERVER_IP'%20to%20%2Fetc%2Fresolv.conf%20(other%20nameservers%20from%20%2Fvar%2Frun%2FNetworkManager%2Fresolv.conf)%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20RESOLVCONFTMPPATH%3D%22%24(mktemp)%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20sed%20-e%20%22%2FGenerated%20by%2Fc%23%20Generated%20by%20KNI%20resolv%20prepender%20NM%20dispatcher%20script%22%20%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%2Fvar%2Frun%2FNetworkManager%2Fresolv.conf%20%3E%20%22%24%7BRESOLVCONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20sed%20-i%20%220%2C%2F%5Enameserver.*%2Fs%2F%2Fnameserver%20%24NAMESERVER_IP%5Cn%5C0%2F%22%20%22%24%7BRESOLVCONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20!%20grep%20-q%20search%20%22%24%7BRESOLVCONFTMPPATH%7D%22%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Make%20sure%20we%20have%20a%20search%20entry%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20echo%20%22search%20comp-poc-rh01.rhpoc.int%22%20%3E%3E%20%22%24%7BRESOLVCONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Make%20sure%20cluster%20domain%20is%20first%20in%20the%20search%20list%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20sed%20-i%20%22s%2F%5Esearch%20%5C(.*%5C)%2Fsearch%20comp-poc-rh01.rhpoc.int%20%5C1%2F%22%20%22%24%7BRESOLVCONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Remove%20duplicate%20cluster%20domain%20entries%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20sed%20-i%20%22s%2F%5C(search%20comp-poc-rh01.rhpoc.int.*%5C)%20comp-poc-rh01.rhpoc.int%5C(%20.*%5C%7C%24%5C)%2F%5C1%5C2%2F%22%20%22%24%7BRESOLVCONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Only%20leave%20the%20first%203%20nameservers%20in%20%2Fetc%2Fresolv.conf%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20sed%20-i%20'%3Aa%20%24!%7BN%3B%20ba%7D%3B%20s%2F%5C(%5E%5C%7C%5Cn%5C)nameserver%2F%5Cn%23%20nameserver%2F4g'%20%22%24%7BRESOLVCONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Only%20touch%20existing%20resolv.conf%20if%20files%20actually%20differ%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20!%20cmp%20-s%20%22%24%7BRESOLVCONFTMPPATH%7D%22%20%2Fetc%2Fresolv.conf%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20chmod%20644%20%22%24%7BRESOLVCONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20mv%20-Zf%20%22%24%7BRESOLVCONFTMPPATH%7D%22%20%2Fetc%2Fresolv.conf%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Workaround%20for%20bz%201929160.%20Reload%20NetworkManager%20to%20force%20it%20to%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20re-run%20the%20lookup%20of%20the%20hostname%20now%20that%20we%20know%20we%20have%20DNS%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20servers%20configured%20correctly%20in%20resolv.conf.%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20nmcli%20general%20reload%20dns-rc%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20touch%20%22%24%7BKNICONFDONEPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20rm%20-rf%20%22%24%7BRESOLVCONFTMPPATH%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20fi%0A%7D%0A%0Aresolv_prepender%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/resolv-prepender.sh
        - contents:
            source: data:,%23%20Needed%20by%20the%20OpenShift%20SDN.%20See%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1758552%0Anet.ipv4.conf.all.arp_announce%20%3D%202%0A
          mode: 420
          overwrite: true
          path: /etc/sysctl.d/arp.conf
        - contents:
            source: data:,%23%20See%3A%20rhbz%231384746%2C%20OCPBUGS-24012%0Anet.ipv4.neigh.default.gc_thresh1%3D8192%0Anet.ipv4.neigh.default.gc_thresh2%3D32768%0Anet.ipv4.neigh.default.gc_thresh3%3D65536%0Anet.ipv6.neigh.default.gc_thresh1%3D8192%0Anet.ipv6.neigh.default.gc_thresh2%3D32768%0Anet.ipv6.neigh.default.gc_thresh3%3D65536%0A
          mode: 420
          overwrite: true
          path: /etc/sysctl.d/gc-thresh.conf
        - contents:
            source: data:,%0Afs.inotify.max_user_watches%20%3D%2065536%0Afs.inotify.max_user_instances%20%3D%208192%0A
          mode: 420
          overwrite: true
          path: /etc/sysctl.d/inotify.conf
        - contents:
            source: data:,vm.unprivileged_userfaultfd%20%3D%201
          mode: 420
          overwrite: true
          path: /etc/sysctl.d/enable-userfaultfd.conf
        - contents:
            source: data:,%23%20Needed%20for%20OpenShift%20Logging%20(ElasticSearch).%20See%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1793714%0Avm.max_map_count%20%3D%20262144%0A
          mode: 420
          overwrite: true
          path: /etc/sysctl.d/vm-max-map.conf
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-euo%20pipefail%0A%0A%23%20First%2C%20we%20need%20to%20wait%20until%20DHCP%20finishes%20and%20the%20node%20has%20a%20non-%60localhost%60%0A%23%20hostname%20before%20%60kubelet.service%60%20starts.%0A%23%20That's%20the%20%60--wait%60%20argument%20as%20used%20by%20%60node-valid-hostname.service%60.%0A%23%0A%23%20Second%2C%20on%20GCP%20specifically%20we%20truncate%20the%20hostname%20if%20it's%20%3E63%20characters.%0A%23%20That's%20%60gcp-hostname.service%60.%0A%0A%23%20Block%20indefinitely%20until%20the%20host%20gets%20a%20non-localhost%20name.%0A%23%20Note%20node-valid-hostname.service%20uses%20systemd%20to%20abort%20if%20this%20takes%20too%20long.%0Await_localhost()%20%7B%0A%20%20%20%20echo%20%22waiting%20for%20non-localhost%20hostname%20to%20be%20assigned%22%0A%20%20%20%20while%20%5B%5B%20%22%24(%3C%20%2Fproc%2Fsys%2Fkernel%2Fhostname)%22%20%3D~%20(localhost%7Clocalhost.localdomain)%20%5D%5D%3B%0A%20%20%20%20do%0A%20%20%20%20%20%20%20%20sleep%201%0A%20%20%20%20done%0A%20%20%20%20echo%20%22node%20identified%20as%20%24(%3C%2Fproc%2Fsys%2Fkernel%2Fhostname)%22%0A%20%20%20%20echo%20%22saving%20hostname%20to%20prevent%20NetworkManager%20from%20ever%20unsetting%20it%22%0A%20%20%20%20hostnamectl%20set-hostname%20--static%20--transient%20%24(%3C%2Fproc%2Fsys%2Fkernel%2Fhostname)%0A%20%20%20%20exit%200%0A%7D%0A%0Aset_gcp_hostname()%20%7B%0A%20%20%20%20%2Fusr%2Fbin%2Fafterburn%20--provider%20gcp%20--hostname%3D%2Frun%2Fafterburn.hostname%0A%0A%20%20%20%20local%20host_name%3D%24(cat%20%2Frun%2Fafterburn.hostname)%0A%20%20%20%20local%20type_arg%3D%22transient%22%0A%0A%20%20%20%20%23%20%2Fetc%2Fhostname%20is%20used%20for%20static%20hostnames%20and%20is%20authoritative.%0A%20%20%20%20%23%20This%20will%20check%20to%20make%20sure%20that%20the%20static%20hostname%20is%20the%0A%20%20%20%20%23%20less%20than%20or%20equal%20to%2063%20characters%20in%20length.%0A%20%20%20%20if%20%5B%20-f%20%2Fetc%2Fhostname%20%5D%20%26%26%20%5B%20%22%24(cat%20%2Fetc%2Fhostname%20%7C%20wc%20-m)%22%20-gt%200%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20etc_name%3D%22%24(%3C%20%2Fetc%2Fhostname)%22%0A%20%20%20%20%20%20%20%20type_arg%3D%22static%22%0A%20%20%20%20%20%20%20%20if%20%5B%20%22%24%7Betc_name%7D%22%20!%3D%20%22%24%7Bhost_name%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20echo%20%22%2Fetc%2Fhostname%20is%20set%20to%20%24%7Betc_name%7D%20but%20does%20not%20match%20%24%7Bhost_name%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20echo%20%22using%20%2Fetc%2Fhostname%20as%20the%20authoritative%20name%22%0A%20%20%20%20%20%20%20%20%20%20%20%20host_name%3D%22%24%7Betc_name%7D%22%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Only%20mutate%20the%20hostname%20if%20the%20length%20is%20longer%20than%2063%20characters.%20The%0A%20%20%20%20%23%20hostname%20will%20be%20the%20lesser%20of%2063%20characters%20after%20the%20first%20dot%20in%20the%0A%20%20%20%20%23%20FQDN.%20%20This%20algorithm%20is%20only%20known%20to%20work%20in%20GCP%2C%20and%20hence%20is%20only%0A%20%20%20%20%23%20executed%20in%20GCP.%0A%20%20%20%20if%20%5B%20%22%24%7B%23host_name%7D%22%20-gt%2063%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20alt_name%3D%24(printf%20%22%24%7Bhost_name%7D%22%20%7C%20cut%20-f1%20-d'.'%20%7C%20cut%20-c%20-63)%0A%20%20%20%20%20%20%20%20echo%20%22%24%7Bhost_name%7D%20is%20longer%20than%2063%20characters%2C%20using%20truncated%20hostname%22%0A%20%20%20%20%20%20%20%20host_name%3D%22%24%7Balt_name%7D%22%0A%20%20%20%20fi%0A%20%20%20%20echo%20%22setting%20%24%7Btype_arg%7D%20hostname%20to%20%24%7Bhost_name%7D%22%0A%20%20%20%20%2Fbin%2Fhostnamectl%20%22--%24%7Btype_arg%7D%22%20set-hostname%20%22%24%7Bhost_name%7D%22%0A%20%20%20%20exit%200%0A%7D%0A%0Aset_openstack_hostname()%20%7B%0A%20%20%20%20%23%20Read%20metadata%20written%20by%20afterburn%20service%0A%20%20%20%20.%20%2Frun%2Fmetadata%2Fafterburn%0A%0A%20%20%20%20%23%20node-valid-hostname%20sets%20persistent%20hostname%20from%20%2Fproc%2Fsys%2Fkernel%2Fhostname%0A%20%20%20%20echo%20%22%24AFTERBURN_OPENSTACK_HOSTNAME%22%20%3E%20%2Fproc%2Fsys%2Fkernel%2Fhostname%0A%7D%0A%0Aset_powervs_hostname()%20%7B%0A%20%20%20%20%23%20Read%20metadata%20written%20by%20afterburn%20service%0A%20%20%20%20.%20%2Frun%2Fmetadata%2Fafterburn%0A%0A%20%20%20%20%23%20node-valid-hostname%20sets%20persistent%20hostname%20from%20%2Fproc%2Fsys%2Fkernel%2Fhostname%0A%20%20%20%20echo%20%22%24AFTERBURN_POWERVS_LOCAL_HOSTNAME%22%20%3E%20%2Fproc%2Fsys%2Fkernel%2Fhostname%0A%7D%0A%0Aarg%3D%24%7B1%7D%3B%20shift%3B%0Acase%20%22%24%7Barg%7D%22%20in%0A%20%20%20%20--wait)%20wait_localhost%3B%3B%0A%20%20%20%20--gcp)%20set_gcp_hostname%3B%3B%0A%20%20%20%20--openstack)%20set_openstack_hostname%3B%3B%0A%20%20%20%20--powervs)%20set_powervs_hostname%3B%3B%0A%20%20%20%20*)%20echo%20%22Unhandled%20arg%20%24arg%22%3B%20exit%201%0Aesac%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/mco-hostname
        - contents:
            source: data:,
          mode: 493
          overwrite: true
          path: /etc/kubernetes/kubelet-plugins/volume/exec/.dummy
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%23%20Workaround%3A%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1941714%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1935539%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1987108%0A%0Adriver%3D%24(nmcli%20-t%20-m%20tabular%20-f%20general.driver%20dev%20show%20%22%24%7BDEVICE_IFACE%7D%22)%0A%0Aif%20%5B%5B%20%22%242%22%20%3D%3D%20%22up%22%20%26%26%20%22%24%7Bdriver%7D%22%20%3D%3D%20%22vmxnet3%22%20%5D%5D%3B%20then%0A%20%20logger%20-s%20%2299-vsphere-disable-tx-udp-tnl%20triggered%20by%20%24%7B2%7D%20on%20device%20%24%7BDEVICE_IFACE%7D.%22%0A%20%20ethtool%20-K%20%24%7BDEVICE_IFACE%7D%20tx-udp_tnl-segmentation%20off%0A%20%20ethtool%20-K%20%24%7BDEVICE_IFACE%7D%20tx-udp_tnl-csum-segmentation%20off%0A%20%20ethtool%20-K%20%24%7BDEVICE_IFACE%7D%20tx-checksum-ip-generic%20off%0Afi%0A
          mode: 484
          overwrite: true
          path: /etc/NetworkManager/dispatcher.d/99-vsphere-disable-tx-udp-tnl
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%0Auntil%20%5B%20-e%20%2Frun%2Fnodeip-configuration%2Fbr-ex-up%20%5D%0Ado%0A%20%20sleep%201%0Adone%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/wait-for-br-ex-up.sh
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-x%0A%0Aif%20%5B%20!%20-e%20%22%2Fetc%2Fipsec.d%2Fopenshift.conf%22%20%5D%3B%20then%0A%20%20exit%200%0Afi%0A%0A%23%20Modify%20existing%20IPsec%20connection%20entries%20with%20%22auto%3Dstart%22%0A%23%20option%20and%20restart%20ipsec%20systemd%20service.%20This%20helps%20to%0A%23%20establish%20IKE%20SAs%20for%20the%20existing%20IPsec%20connections%20with%0A%23%20peer%20nodes.%20This%20option%20will%20be%20deleted%20from%20connections%0A%23%20once%20ovs-monitor-ipsec%20process%20spinned%20up%20on%20the%20node%20by%0A%23%20ovn-ipsec-host%20pod%2C%20but%20still%20it%20won't%20reestablish%20IKE%20SAs%0A%23%20again%20with%20peer%20nodes%2C%20so%20it%20shouldn't%20be%20a%20problem.%0Aif%20!%20grep%20-q%20%22auto%3Dstart%22%20%2Fetc%2Fipsec.d%2Fopenshift.conf%3B%20then%0A%20%20sed%20-i%20'%2F%5E.*conn%20ovn.*%24%2Fa%5C%20%20%20%20auto%3Dstart'%20%2Fetc%2Fipsec.d%2Fopenshift.conf%0Afi%0Achroot%20%2Fproc%2F1%2Froot%20ipsec%20restart%0A%0A%23%20Wait%20for%20upto%2060s%20to%20get%20IPsec%20SAs%20to%20establish%20with%20peer%20nodes.%0Atimeout%3D60%0Aelapsed%3D0%0Adesiredconn%3D%22%22%0Aestablishedsa%3D%22%22%0Awhile%20%5B%5B%20%24elapsed%20-lt%20%24timeout%20%5D%5D%3B%20do%0A%20%20desiredconn%3D%24(grep%20-E%20'%5E%5Cs*conn%5Cs%2B'%20%2Fetc%2Fipsec.d%2Fopenshift.conf%20%7C%20grep%20-v%20'%25default'%20%7C%20awk%20'%7Bprint%20%242%7D'%20%7C%20tr%20'%20'%20'%5Cn'%20%7C%20sort%20%7C%20tr%20'%5Cn'%20'%20')%0A%20%20establishedsa%3D%24(ipsec%20showstates%20%7C%20grep%20STATE_V2_ESTABLISHED_CHILD_SA%20%7C%20grep%20-o%20'%22%5B%5E%22%5D*%22'%20%7C%20sed%20's%2F%22%2F%2Fg'%20%7C%20tr%20'%20'%20'%5Cn'%20%7C%20sort%20%7C%20uniq%20%7C%20tr%20'%5Cn'%20'%20')%0A%20%20if%20%5B%20%22%24desiredconn%22%20%3D%3D%20%22%24establishedsa%22%20%5D%3B%20then%0A%20%20%20%20echo%20%22IPsec%20SAs%20are%20established%20for%20desired%20connections%20after%20%24%7Belapsed%7Ds%22%0A%20%20%20%20break%0A%20%20else%0A%20%20%20%20echo%20%22IPsec%20SAs%20are%20not%20established%20yet%2C%20total%20waited%20time%20%24%7Belapsed%7Ds%22%0A%20%20%20%20sleep%202s%0A%20%20fi%0A%20%20elapsed%3D%24((elapsed%20%2B%202))%0Adone%0A%0Aif%20%5B%5B%20%24elapsed%20-ge%20%24timeout%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22Timed%20out%20waiting%2C%20some%20connections%20are%20not%20established%2C%20desired%20conns%20%24desiredconn%2C%20established%20conns%20%24establishedsa%22%0Afi%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/ipsec-connect-wait.sh
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-eux%0A%0Aif%20%5B%20!%20-e%20%2Fetc%2Fnmstate%2Fopenshift%2Fapplied%20%5D%3B%20then%0A%20%20%23%20No%20need%20to%20do%20this%20if%20no%20NMState%20configuration%20was%20applied%0A%20%20exit%200%0Afi%0A%0A%23%20This%20logic%20is%20borrowed%20from%20configure-ovs.sh%0A%23%20TODO%3A%20Find%20a%20platform-agnostic%20way%20to%20do%20this.%20It%20won't%20work%20on%20platforms%20where%0A%23%20nodeip-configuration%20is%20not%20used.%0Aip%3D%24(cat%20%2Frun%2Fnodeip-configuration%2Fprimary-ip)%0Aif%20%5B%5B%20%22%24%7Bip%7D%22%20%3D%3D%20%22%22%20%5D%5D%3B%20then%0A%20%20echo%20%22No%20ip%20to%20bind%20was%20found%22%0A%20%20exit%201%0Afi%0Awhile%20%3A%0Ado%0A%20%20random_port%3D%24(shuf%20-i%2050000-60000%20-n%201)%0A%20%20echo%20%22Trying%20to%20bind%20%24%7Bip%7D%20on%20port%20%24%7Brandom_port%7D%22%0A%20%20exit_code%3D%24(timeout%202s%20nc%20-l%20%22%24%7Bip%7D%22%20%24%7Brandom_port%7D%3B%20echo%20%24%3F)%0A%20%20if%20%5B%5B%20exit_code%20-eq%20124%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22Address%20bound%20successfully%22%0A%20%20%20%20exit%200%0A%20%20fi%0A%20%20sleep%2010%0Adone%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/wait-for-primary-ip.sh
        - contents:
            source: data:,unqualified-search-registries%20%3D%20%5B'registry.access.redhat.com'%2C%20'docker.io'%5D%0A
          mode: 420
          overwrite: true
          path: /etc/containers/registries.conf
        - contents:
            source: data:,%5Bcrio%5D%0Ainternal_wipe%20%3D%20true%0Ainternal_repair%20%3D%20true%0A%0A%5Bcrio.api%5D%0Astream_address%20%3D%20%22127.0.0.1%22%0Astream_port%20%3D%20%220%22%0A%0A%5Bcrio.runtime%5D%0Aselinux%20%3D%20true%0Aconmon%20%3D%20%22%22%0Aconmon_cgroup%20%3D%20%22pod%22%0Adefault_env%20%3D%20%5B%0A%20%20%20%20%22NSS_SDB_USE_CACHE%3Dno%22%2C%0A%5D%0Alog_level%20%3D%20%22info%22%0Acgroup_manager%20%3D%20%22systemd%22%0Adefault_sysctls%20%3D%20%5B%0A%20%20%20%20%22net.ipv4.ping_group_range%3D0%202147483647%22%2C%0A%5D%0Adefault_runtime%20%3D%20%22crun%22%0Ahooks_dir%20%3D%20%5B%0A%20%20%20%20%22%2Fetc%2Fcontainers%2Foci%2Fhooks.d%22%2C%0A%20%20%20%20%22%2Frun%2Fcontainers%2Foci%2Fhooks.d%22%2C%0A%20%20%20%20%22%2Fusr%2Fshare%2Fcontainers%2Foci%2Fhooks.d%22%2C%0A%5D%0Amanage_ns_lifecycle%20%3D%20true%0Aabsent_mount_sources_to_reject%20%3D%20%5B%0A%20%20%20%20%22%2Fetc%2Fhostname%22%2C%0A%5D%0Adrop_infra_ctr%20%3D%20true%0A%0A%5Bcrio.runtime.runtimes.runc%5D%0Aruntime_root%20%3D%20%22%2Frun%2Frunc%22%0Aallowed_annotations%20%3D%20%5B%0A%20%20%20%20%22io.containers.trace-syscall%22%2C%0A%20%20%20%20%22io.kubernetes.cri-o.Devices%22%2C%0A%20%20%20%20%22io.kubernetes.cri-o.LinkLogs%22%2C%0A%5D%0A%0A%5Bcrio.runtime.runtimes.crun%5D%0Aruntime_root%20%3D%20%22%2Frun%2Fcrun%22%0Aallowed_annotations%20%3D%20%5B%0A%20%20%20%20%22io.containers.trace-syscall%22%2C%0A%20%20%20%20%22io.kubernetes.cri-o.Devices%22%2C%0A%20%20%20%20%22io.kubernetes.cri-o.LinkLogs%22%2C%0A%5D%0A%23%20Based%20on%20https%3A%2F%2Fgithub.com%2Fcontainers%2Fcrun%2Fblob%2F27d7dd3a0%2FREADME.md%3Fplain%3D1%23L48%0Acontainer_min_memory%20%3D%20%22512KiB%22%0Adefault_annotations%20%3D%20%7B%22run.oci.systemd.subgroup%22%20%3D%20%22%22%7D%0A%0A%5Bcrio.runtime.workloads.openshift-builder%5D%0Aactivation_annotation%20%3D%20%22io.openshift.builder%22%0Aallowed_annotations%20%3D%20%5B%0A%20%20%22io.kubernetes.cri-o.userns-mode%22%2C%0A%20%20%22io.kubernetes.cri-o.Devices%22%0A%5D%0A%5Bcrio.runtime.workloads.openshift-builder.resources%5D%0A%0A%5Bcrio.image%5D%0Aglobal_auth_file%20%3D%20%22%2Fvar%2Flib%2Fkubelet%2Fconfig.json%22%0Apause_image%20%3D%20%22quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A2f61599219ee63c77391e05d2e02a8a5baae1c463d0ef965c49a5c470546db90%22%0Apause_image_auth_file%20%3D%20%22%2Fvar%2Flib%2Fkubelet%2Fconfig.json%22%0Apause_command%20%3D%20%22%2Fusr%2Fbin%2Fpod%22%0A%0A%5Bcrio.network%5D%0Anetwork_dir%20%3D%20%22%2Fetc%2Fkubernetes%2Fcni%2Fnet.d%2F%22%0Aplugin_dirs%20%3D%20%5B%0A%20%20%20%20%22%2Fvar%2Flib%2Fcni%2Fbin%22%2C%0A%20%20%20%20%22%2Fusr%2Flibexec%2Fcni%22%2C%0A%5D%0A%0A%5Bcrio.metrics%5D%0Aenable_metrics%20%3D%20true%0Ametrics_host%20%3D%20%22127.0.0.1%22%0Ametrics_port%20%3D%209537%0Ametrics_collectors%20%3D%20%5B%0A%20%20%22operations%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22operations_total%22%0A%20%20%22operations_latency_microseconds_total%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22operations_latency_seconds_total%22%0A%20%20%22operations_latency_microseconds%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22operations_latency_seconds%22%0A%20%20%22operations_errors%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22operations_errors_total%22%0A%20%20%22image_pulls_layer_size%22%2C%0A%20%20%22containers_oom_total%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22containers_oom_count_total%22%0A%20%20%22containers_oom%22%2C%0A%20%20%23%20Drop%20metrics%20with%20excessive%20label%20cardinality.%0A%20%20%23%20%22image_pulls_by_digest%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_pulls_bytes_total%22%0A%20%20%23%20%22image_pulls_by_name%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_pulls_bytes_total%22%0A%20%20%23%20%22image_pulls_by_name_skipped%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_pulls_skipped_bytes_total%22%0A%20%20%23%20%22image_pulls_failures%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_pulls_failure_total%22%0A%20%20%23%20%22image_pulls_successes%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_pulls_success_total%22%0A%20%20%23%20%22image_layer_reuse%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_layer_reuse_total%22%0A%20%20%22operations_total%22%2C%0A%20%20%22operations_latency_seconds_total%22%2C%0A%20%20%22operations_latency_seconds%22%2C%0A%20%20%22operations_errors_total%22%2C%0A%20%20%22image_pulls_bytes_total%22%2C%0A%20%20%22image_pulls_skipped_bytes_total%22%2C%0A%20%20%22image_pulls_success_total%22%2C%0A%20%20%22image_pulls_failure_total%22%2C%0A%20%20%22image_layer_reuse_total%22%2C%0A%20%20%22containers_oom_count_total%22%2C%0A%20%20%22processes_defunct%22%0A%5D%0A
          mode: 420
          overwrite: true
          path: /etc/crio/crio.conf.d/00-default
        - contents:
            source: data:,%7B%0A%20%20%20%20%22default%22%3A%20%5B%0A%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%22type%22%3A%20%22insecureAcceptAnything%22%0A%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%5D%2C%0A%20%20%20%20%22transports%22%3A%0A%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%22docker-daemon%22%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22%22%3A%20%5B%7B%22type%22%3A%22insecureAcceptAnything%22%7D%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20%20%20%7D%0A%7D%0A
          mode: 420
          overwrite: true
          path: /etc/machine-config-daemon/policy-for-old-podman.json
        - contents:
            source: data:,%7B%0A%20%20%20%20%22default%22%3A%20%5B%0A%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%22type%22%3A%20%22insecureAcceptAnything%22%0A%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%5D%2C%0A%20%20%20%20%22transports%22%3A%0A%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%22docker-daemon%22%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22%22%3A%20%5B%7B%22type%22%3A%22insecureAcceptAnything%22%7D%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20%20%20%7D%0A%7D
          mode: 420
          overwrite: true
          path: /etc/containers/policy.json
        - contents:
            source: data:,
          mode: 420
          overwrite: true
          path: /etc/kubernetes/cloud.conf
        - contents:
            source: data:,authorization%3A%0A%20%20static%3A%0A%20%20%20%20-%20resourceRequest%3A%20false%0A%20%20%20%20%20%20path%3A%20%2Fmetrics%0A%20%20%20%20%20%20verb%3A%20get%0A%20%20%20%20%20%20user%3A%0A%20%20%20%20%20%20%20%20name%3A%20system%3Aserviceaccount%3Aopenshift-monitoring%3Aprometheus-k8s
          mode: 420
          overwrite: true
          path: /etc/kubernetes/crio-metrics-proxy.cfg
        - contents:
            source: data:,apiVersion%3A%20v1%0Akind%3A%20Pod%0Ametadata%3A%0A%20%20name%3A%20kube-rbac-proxy-crio%0A%20%20namespace%3A%20openshift-machine-config-operator%0A%20%20annotations%3A%0A%20%20%20%20target.workload.openshift.io%2Fmanagement%3A%20'%7B%22effect%22%3A%20%22PreferredDuringScheduling%22%7D'%0A%20%20%20%20openshift.io%2Frequired-scc%3A%20privileged%0Aspec%3A%0A%20%20volumes%3A%0A%20%20-%20name%3A%20etc-kube%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fetc%2Fkubernetes%22%0A%20%20-%20name%3A%20var-lib-kubelet%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20hostNetwork%3A%20true%0A%20%20priorityClassName%3A%20system-cluster-critical%0A%20%20initContainers%3A%0A%20%20-%20name%3A%20setup%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3Ab6413e64e7d5885315b3cabc65c2af82135ee649b1664976b3d300884d302414%0A%20%20%20%20imagePullPolicy%3A%20IfNotPresent%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20var-lib-kubelet%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20command%3A%20%5B'%2Fbin%2Fbash'%2C%20'-ec'%5D%0A%20%20%20%20args%3A%0A%20%20%20%20-%20%7C%0A%20%20%20%20%20%20echo%20-n%20%22Waiting%20for%20kubelet%20key%20and%20certificate%20to%20be%20available%22%0A%20%20%20%20%20%20while%20%5B%20-n%20%22%24(test%20-e%20%2Fvar%2Flib%2Fkubelet%2Fpki%2Fkubelet-server-current.pem)%22%20%5D%20%3B%20do%0A%20%20%20%20%20%20%20%20echo%20-n%20%22.%22%0A%20%20%20%20%20%20%20%20sleep%201%0A%20%20%20%20%20%20%20%20((%20tries%20%2B%3D%201%20))%0A%20%20%20%20%20%20%20%20if%20%5B%5B%20%22%24%7Btries%7D%22%20-gt%2010%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20echo%20%22Timed%20out%20waiting%20for%20kubelet%20key%20and%20cert.%22%0A%20%20%20%20%20%20%20%20%20%20exit%201%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20done%0A%20%20%20%20securityContext%3A%0A%20%20%20%20%20%20privileged%3A%20true%0A%20%20%20%20resources%3A%0A%20%20%20%20%20%20requests%3A%0A%20%20%20%20%20%20%20%20memory%3A%2050Mi%0A%20%20%20%20%20%20%20%20cpu%3A%205m%0A%20%20containers%3A%0A%20%20-%20name%3A%20kube-rbac-proxy-crio%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3Ab6413e64e7d5885315b3cabc65c2af82135ee649b1664976b3d300884d302414%0A%20%20%20%20securityContext%3A%0A%20%20%20%20%20%20privileged%3A%20true%0A%20%20%20%20ports%3A%0A%20%20%20%20-%20containerPort%3A%209637%0A%20%20%20%20args%3A%0A%20%20%20%20-%20--secure-listen-address%3D%3A9637%0A%20%20%20%20-%20--config-file%3D%2Fetc%2Fkubernetes%2Fcrio-metrics-proxy.cfg%0A%20%20%20%20-%20--client-ca-file%3D%2Fetc%2Fkubernetes%2Fkubelet-ca.crt%0A%20%20%20%20-%20--logtostderr%3Dtrue%0A%20%20%20%20-%20--kubeconfig%3D%2Fvar%2Flib%2Fkubelet%2Fkubeconfig%0A%20%20%20%20-%20--tls-cipher-suites%3DTLS_AES_128_GCM_SHA256%2CTLS_AES_256_GCM_SHA384%2CTLS_CHACHA20_POLY1305_SHA256%2CTLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256%2CTLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256%2CTLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384%2CTLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384%2CTLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256%2CTLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256%20%0A%20%20%20%20-%20--tls-min-version%3DVersionTLS12%0A%20%20%20%20-%20--upstream%3Dhttp%3A%2F%2F127.0.0.1%3A9537%0A%20%20%20%20-%20--tls-cert-file%3D%2Fvar%2Flib%2Fkubelet%2Fpki%2Fkubelet-server-current.pem%0A%20%20%20%20-%20--tls-private-key-file%3D%2Fvar%2Flib%2Fkubelet%2Fpki%2Fkubelet-server-current.pem%0A%20%20%20%20resources%3A%0A%20%20%20%20%20%20requests%3A%0A%20%20%20%20%20%20%20%20cpu%3A%2020m%0A%20%20%20%20%20%20%20%20memory%3A%2050Mi%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20etc-kube%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fkubernetes%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20%20%20readOnly%3A%20true%0A%20%20%20%20-%20name%3A%20var-lib-kubelet%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20%20%20readOnly%3A%20true
          mode: 420
          overwrite: true
          path: /etc/kubernetes/manifests/criometricsproxy.yaml
        - contents:
            compression: ""
            source: data:text/plain;charset=utf-8;base64,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
          mode: 420
          overwrite: true
          path: /etc/kubernetes/kubelet.conf
        - contents:
            source: data:,%23!%2Fbin%2Fsh%0Aif%20%5B%20-x%20%2Fusr%2Fbin%2Fkubensenter%20%5D%3B%20then%0A%20%20exec%20%2Fusr%2Fbin%2Fkubensenter%20%22%24%40%22%0Aelse%0A%20%20exec%20%22%24%40%22%0Afi%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/kubenswrapper
        - contents:
            source: data:text/plain;charset=utf-8;base64,CnBvb2wgMC5yaGVsLnBvb2wubnRwLm9yZyBpYnVyc3QKZHJpZnRmaWxlIC92YXIvbGliL2Nocm9ueS9kcmlmdAptYWtlc3RlcCAxLjAgMwpydGNzeW5jCmxvZ2RpciAvdmFyL2xvZy9jaHJvbnkKc2VydmVyIDc0LjIwOC4yNS40NiBpYnVyc3QKc2VydmVyIHRpbWUubG10bGFicy5jb20gaWJ1cnN0CnNlcnZlciBsaXRoaXVtLmNvbnN0YW50LmNvbSBpYnVyc3QKc2VydmVyIDY5LjE3Ni44NC4zOCBpYnVyc3QKc2VydmVyIGFybTEubWF4aG9zdC5pbyBpYnVyc3QKc2VydmVyIG50cDEubGF4LnVzLmhvam1hcmsubmV0IGlidXJzdApzZXJ2ZXIgbnRwMTEua2VybmZ1c2lvbi5hdCBpYnVyc3QKc2VydmVyIHRyaWFuZ2xlLmthbnNhcy5uZXQgaWJ1cnN0
          mode: 420
          overwrite: true
          path: /etc/chrony.conf
      systemd:
        units:
        - contents: |
            [Unit]
            Description=Cleans NetworkManager state generated by dracut
            # Removal of this file signals firstboot completion
            ConditionPathExists=!/etc/ignition-machine-config-encapsulated.json
            # This is opt-in for some deployment types, and opt-out for others.
            ConditionPathExists=/var/lib/mco/nm-clean-initrd-state
            Wants=network-pre.target
            Before=network-pre.target

            [Service]
            Type=oneshot
            # Remove any existing state possibly generated NM run by dracut. We want NM to
            # consider all profiles autoconnect priority when it starts instead of
            # remembering which profile was a device activated with when NM is run by
            # dracut.
            ExecStart=/usr/local/bin/nm-clean-initrd-state.sh
            StandardOutput=journal+console
            StandardError=journal+console

            [Install]
            WantedBy=network-online.target
          enabled: true
          name: NetworkManager-clean-initrd-state.service
        - dropins:
          - contents: |
              # vim:set ft=systemd :
              #
              # This drop-in will enable any service built with this
              # github.com/containers/kubemntns library to properly join the mount namespace
              # managed by kubens.service
              #

              [Unit]
              After=kubens.service

              [Service]
              EnvironmentFile=-/run/kubens/env
            name: 01-kubens.conf
          - contents: ""
            name: 10-mco-default-env.conf
          - contents: |
              [Service]
              Environment="ENABLE_PROFILE_UNIX_SOCKET=true"
            name: 10-mco-profile-unix-socket.conf
          - contents: |
              [Unit]
              After=kubelet-dependencies.target
              Requires=kubelet-dependencies.target
            name: 05-mco-ordering.conf
          - contents: |
              [Service]
              Environment="GODEBUG=x509ignoreCN=0,madvdontneed=1"
            name: 10-mco-default-madv.conf
          name: crio.service
        - dropins:
          - contents: |
              [Unit]
              ConditionPathExists=/enoent
            name: mco-disabled.conf
          name: docker.socket
        - contents: |
            [Unit]
            Description=The firstboot OS update has completed
            Documentation=https://github.com/openshift/machine-config-operator/
            Requires=basic.target

            [Install]
            WantedBy=default.target
          enabled: true
          name: firstboot-osupdate.target
        - dropins:
          - contents: |
              [Unit]
              After=ovs-configuration.service
              Before=crio.service
            name: 01-after-configure-ovs.conf
          name: ipsec.service
        - contents: |
            [Unit]
            Description=Dynamically sets the system reserved for the kubelet
            Wants=network-online.target
            After=network-online.target firstboot-osupdate.target
            Before=kubelet-dependencies.target

            [Service]
            # Need oneshot to delay kubelet
            Type=oneshot
            RemainAfterExit=yes
            EnvironmentFile=/etc/node-sizing-enabled.env
            ExecStart=/bin/bash /usr/local/sbin/dynamic-system-reserved-calc.sh ${NODE_SIZING_ENABLED} ${SYSTEM_RESERVED_MEMORY} ${SYSTEM_RESERVED_CPU} ${SYSTEM_RESERVED_ES}
            [Install]
            RequiredBy=kubelet-dependencies.target
          enabled: true
          name: kubelet-auto-node-size.service
        - contents: |
            [Unit]
            Description=Dependencies necessary to run kubelet
            Documentation=https://github.com/openshift/machine-config-operator/
            Requires=basic.target network-online.target
            Wants=NetworkManager-wait-online.service crio-wipe.service
            Wants=rpc-statd.service chrony-wait.service
          name: kubelet-dependencies.target
        - contents: |
            [Unit]
            Description=Kubernetes Kubelet
            Requires=crio.service kubelet-dependencies.target
            After=kubelet-dependencies.target
            After=ostree-finalize-staged.service

            [Service]
            Type=notify
            ExecStartPre=/bin/mkdir --parents /etc/kubernetes/manifests
            ExecStartPre=-/usr/sbin/restorecon -ri /var/lib/kubelet/pod-resources /usr/local/bin/kubenswrapper /usr/bin/kubensenter
            Environment="KUBELET_NODE_IP=0.0.0.0"
            EnvironmentFile=/etc/os-release
            EnvironmentFile=-/etc/kubernetes/kubelet-workaround
            EnvironmentFile=-/etc/kubernetes/kubelet-env
            EnvironmentFile=/etc/node-sizing.env

            ExecStart=/usr/local/bin/kubenswrapper \
                /usr/bin/kubelet \
                  --config=/etc/kubernetes/kubelet.conf \
                  --bootstrap-kubeconfig=/etc/kubernetes/kubeconfig \
                  --kubeconfig=/var/lib/kubelet/kubeconfig \
                  --container-runtime-endpoint=/var/run/crio/crio.sock \
                  --runtime-cgroups=/system.slice/crio.service \
                  --node-labels=node-role.kubernetes.io/worker,node.openshift.io/os_id=${ID},${CUSTOM_KUBELET_LABELS} \
                  --node-ip=${KUBELET_NODE_IP} \
                  --address=${KUBELET_NODE_IP} \
                  --minimum-container-ttl-duration=6m0s \
                  --volume-plugin-dir=/etc/kubernetes/kubelet-plugins/volume/exec \
                  --cloud-provider= \
                  --hostname-override=${KUBELET_NODE_NAME} \
                  --pod-infra-container-image=quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:2f61599219ee63c77391e05d2e02a8a5baae1c463d0ef965c49a5c470546db90 \
                  --system-reserved=cpu=${SYSTEM_RESERVED_CPU},memory=${SYSTEM_RESERVED_MEMORY},ephemeral-storage=${SYSTEM_RESERVED_ES} \
                  --v=${KUBELET_LOG_LEVEL}

            Restart=always
            RestartSec=10

            [Install]
            WantedBy=multi-user.target
          dropins:
          - contents: |
              # vim:set ft=systemd :
              #
              # This drop-in will enable any service built with this
              # github.com/containers/kubemntns library to properly join the mount namespace
              # managed by kubens.service
              #

              [Unit]
              After=kubens.service

              [Service]
              EnvironmentFile=-/run/kubens/env
            name: 01-kubens.conf
          - contents: ""
            name: 10-mco-default-env.conf
          - contents: |
              [Service]
              # Wait for resolv-prepender to configure nameservers, exit 255 otherwise
              # to mark the unit as failed and retry later
              ExecCondition=/bin/bash -c '[ -f /run/resolv-prepender-kni-conf-done ] || { echo "NM resolv-prepender failed"; exit 255; }'
            name: 10-mco-on-prem-wait-resolv.conf
          - contents: |
              [Service]
              Environment="GODEBUG=x509ignoreCN=0,madvdontneed=1"
            name: 10-mco-default-madv.conf
          enabled: true
          name: kubelet.service
        - contents: |
            [Unit]
            Description=Manages a mount namespace for kubernetes-specific mounts

            [Service]
            Type=oneshot
            RemainAfterExit=yes
            RuntimeDirectory=kubens
            Environment=RUNTIME_DIRECTORY=%t/kubens
            Environment=BIND_POINT=%t/kubens/mnt
            Environment=ENVFILE=%t/kubens/env

            # Set up the runtime directory as an unbindable mountpoint
            ExecStartPre=bash -c "findmnt ${RUNTIME_DIRECTORY} || mount --make-unbindable --bind ${RUNTIME_DIRECTORY} ${RUNTIME_DIRECTORY}"
            # Ensure the bind point exists
            ExecStartPre=touch ${BIND_POINT}
            # Use 'unshare' to create the new mountpoint, then 'mount --make-rshared' so it cascades internally
            ExecStart=unshare --mount=${BIND_POINT} --propagation slave mount --make-rshared /
            # Finally, set an env pointer for ease-of-use
            ExecStartPost=bash -c 'echo "KUBENSMNT=${BIND_POINT}" > "${ENVFILE}"'

            # On stop, a recursive unmount cleans up the namespace and bind-mounted unbindable parent directory
            ExecStop=umount -R ${RUNTIME_DIRECTORY}

            [Install]
            WantedBy=multi-user.target
          enabled: false
          name: kubens.service
        - contents: |
            [Unit]
            Description=Machine Config Daemon Firstboot
            # Make sure it runs only on OSTree booted system
            ConditionPathExists=/run/ostree-booted
            # Removal of this file signals firstboot completion
            ConditionPathExists=/etc/ignition-machine-config-encapsulated.json
            After=machine-config-daemon-pull.service
            Before=kubelet-dependencies.target

            [Service]
            Type=oneshot
            RemainAfterExit=yes
            # Disable existing repos (if any) so that OS extensions would use embedded RPMs only
            ExecStartPre=-/usr/bin/sh -c "sed -i 's/enabled=1/enabled=0/' /etc/yum.repos.d/*.repo"
            # Run this via podman because we want to use the nmstatectl binary in our container
            ExecStart=/usr/bin/podman run --rm --privileged --net=host -v /:/rootfs  --entrypoint machine-config-daemon 'quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:94bac6c3782cf6579032c7c9dabca74146753d9a44591125acd30d606d7d340c' firstboot-complete-machineconfig --persist-nics
            ExecStart=/usr/bin/podman run --rm --privileged --pid=host --net=host -v /:/rootfs  --entrypoint machine-config-daemon 'quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:94bac6c3782cf6579032c7c9dabca74146753d9a44591125acd30d606d7d340c' firstboot-complete-machineconfig
            [Install]
            RequiredBy=firstboot-osupdate.target
          enabled: true
          name: machine-config-daemon-firstboot.service
        - contents: |
            [Unit]
            Description=Machine Config Daemon Pull
            # Make sure it runs only on OSTree booted system
            ConditionPathExists=/run/ostree-booted
            # This "stamp file" is unlinked when we complete
            # machine-config-daemon-firstboot.service
            ConditionPathExists=/etc/ignition-machine-config-encapsulated.json
            # Run after crio-wipe so the pulled MCD image is protected against a corrupted storage from a forced shutdown
            Wants=crio-wipe.service NetworkManager-wait-online.service
            After=crio-wipe.service NetworkManager-wait-online.service network.service

            [Service]
            Type=oneshot
            RemainAfterExit=yes
            ExecStartPre=/etc/machine-config-daemon/generate_podman_policy_args.sh
            ExecStart=/bin/sh -c "while ! /usr/bin/podman pull $(cat /tmp/podman_policy_args) --authfile=/var/lib/kubelet/config.json 'quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:94bac6c3782cf6579032c7c9dabca74146753d9a44591125acd30d606d7d340c'; do sleep 1; done"

            [Install]
            RequiredBy=machine-config-daemon-firstboot.service
          enabled: true
          name: machine-config-daemon-pull.service
        - contents: |
            [Unit]
            Description=Applies per-node NMState network configuration
            Requires=openvswitch.service
            Wants=NetworkManager-wait-online.service
            After=NetworkManager-wait-online.service openvswitch.service network.service nodeip-configuration.service
            Before=nmstate.service kubelet-dependencies.target ovs-configuration.service node-valid-hostname.service

            [Service]
            Type=oneshot
            # Would prefer to do Restart=on-failure instead of this bash retry loop, but
            # the version of systemd we have right now doesn't support it. It should be
            # available in systemd v244 and higher.
            ExecStart=/usr/local/bin/nmstate-configuration.sh
            StandardOutput=journal+console
            StandardError=journal+console

            [Install]
            WantedBy=network-online.target
          enabled: true
          name: nmstate-configuration.service
        - contents: |
            [Unit]
            Description=Apply nmstate on-disk state
            Documentation=man:nmstate.service(8) https://www.nmstate.io
            After=NetworkManager-wait-online.service
            Before=network-online.target
            Wants=NetworkManager-wait-online.service
            Requires=NetworkManager.service

            [Service]
            Type=oneshot
            ExecStart=/usr/bin/nmstatectl service
            RemainAfterExit=yes

            [Install]
            WantedBy=NetworkManager.service
          enabled: true
          name: nmstate.service
        - contents: |
            [Unit]
            Description=Wait for a non-localhost hostname
            Before=kubelet-dependencies.target

            [Service]
            Type=oneshot
            RemainAfterExit=yes
            User=root
            ExecStart=/usr/local/bin/mco-hostname --wait

            # Wait up to 5min for the node to get a non-localhost name
            TimeoutSec=300

            [Install]
            # TODO: Change this to RequiredBy after we fix https://github.com/openshift/machine-config-operator/pull/3865#issuecomment-1746963115
            WantedBy=kubelet-dependencies.target
          enabled: true
          name: node-valid-hostname.service
        - contents: |
            [Unit]
            Description=Writes IP address configuration so that kubelet and crio services select a valid node IP
            # This only applies to VIP managing environments where the kubelet and crio IP
            # address picking logic is flawed and may end up selecting an address from a
            # different subnet or a deprecated address
            Wants=NetworkManager-wait-online.service
            After=NetworkManager-wait-online.service firstboot-osupdate.target
            Before=kubelet-dependencies.target ovs-configuration.service

            [Service]
            # Need oneshot to delay kubelet
            Type=oneshot
            # Would prefer to do Restart=on-failure instead of this bash retry loop, but
            # the version of systemd we have right now doesn't support it. It should be
            # available in systemd v244 and higher.
            ExecStart=/bin/bash -c " \
              until \
              /usr/bin/podman run --rm \
              --authfile /var/lib/kubelet/config.json \
              --net=host \
              --security-opt label=disable \
              --volume /etc/systemd/system:/etc/systemd/system \
              --volume /run/nodeip-configuration:/run/nodeip-configuration \
              quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:93e7b8c870261726d44bddc7ba0a702d3720d1838141dac837fb8c3be7c6e1a1 \
              node-ip \
              set \
              --platform BareMetal \
              --retry-on-failure \
              ${NODEIP_HINT:-} \
              10.100.0.50  \
              10.100.0.51 ; \
              do \
              sleep 5; \
              done"
            ExecStart=/bin/systemctl daemon-reload
            ExecStartPre=/bin/mkdir -p /run/nodeip-configuration
            ExecStartPost=+/usr/local/bin/configure-ip-forwarding.sh
            StandardOutput=journal+console
            StandardError=journal+console
            EnvironmentFile=-/etc/default/nodeip-configuration

            [Install]
            RequiredBy=kubelet-dependencies.target
          enabled: true
          name: nodeip-configuration.service
        - contents: |
            [Unit]
            Description=Watches for changes in /var/run/NetworkManager/resolv.conf according to on-prem IPI needs
            [Path]
            PathModified=/var/run/NetworkManager/resolv.conf
            PathModified=/run/resolv-prepender/env
            Unit=on-prem-resolv-prepender.service
            [Install]
            WantedBy=multi-user.target
          enabled: true
          name: on-prem-resolv-prepender.path
        - contents: |
            [Unit]
            Description=Populates resolv.conf according to on-prem IPI needs
            # Per https://issues.redhat.com/browse/OCPBUGS-27162 there is a problem if this is started before crio-wipe
            After=crio-wipe.service
            StartLimitIntervalSec=0
            [Service]
            Type=oneshot
            # Would prefer to do Restart=on-failure instead of this bash retry loop, but
            # the version of systemd we have right now doesn't support it. It should be
            # available in systemd v244 and higher.
            ExecStart=/bin/bash -c " \
              until \
              /usr/local/bin/resolv-prepender.sh; \
              do \
              sleep 10; \
              done"
            EnvironmentFile=-/run/resolv-prepender/env
          enabled: false
          name: on-prem-resolv-prepender.service
        - enabled: true
          name: openvswitch.service
        - contents: |
            [Unit]
            # Kdump will generate it's initramfs based on the running state when kdump.service run
            # If OVS has already run, the kdump fails to gather a working network config,
            # which prevent network log exports, sush as SSH.
            # See https://issues.redhat.com/browse/OCPBUGS-28239
            After=kdump.service
            Description=Configures OVS with proper host networking configuration
            # This service is used to move a physical NIC into OVS and reconfigure OVS to use the host IP
            Requires=openvswitch.service
            Wants=NetworkManager-wait-online.service
            After=firstboot-osupdate.target
            After=NetworkManager-wait-online.service openvswitch.service network.service nodeip-configuration.service nmstate.service
            Before=kubelet-dependencies.target node-valid-hostname.service

            [Service]
            # Need oneshot to delay kubelet
            Type=oneshot
            ExecStart=/usr/local/bin/configure-ovs.sh OVNKubernetes
            StandardOutput=journal+console
            StandardError=journal+console

            [Install]
            RequiredBy=kubelet-dependencies.target
          enabled: true
          name: ovs-configuration.service
        - dropins:
          - contents: |
              [Service]
              Restart=always
              ExecStartPre=-/bin/sh -c '/usr/bin/chown -R :$${OVS_USER_ID##*:} /var/lib/openvswitch'
              ExecStartPre=-/bin/sh -c '/usr/bin/chown -R :$${OVS_USER_ID##*:} /etc/openvswitch'
              ExecStartPre=-/bin/sh -c '/usr/bin/chown -R :$${OVS_USER_ID##*:} /run/openvswitch'
              ExecStartPost=-/usr/bin/ovs-appctl vlog/set syslog:info
              ExecReload=-/usr/bin/ovs-appctl vlog/set syslog:info
            name: 10-ovs-vswitchd-restart.conf
          name: ovs-vswitchd.service
        - dropins:
          - contents: |
              [Service]
              Restart=always
            name: 10-ovsdb-restart.conf
          enabled: true
          name: ovsdb-server.service
        - dropins:
          - contents: ""
            name: 10-mco-default-env.conf
          name: rpm-ostreed.service
        - contents: |
            [Unit]
            Description=Wait for br-ex up event from NetworkManager
            Wants=ovs-configuration.service
            After=ovs-configuration.service
            Before=node-valid-hostname.service

            [Service]
            Type=oneshot
            ExecStart=/usr/local/bin/wait-for-br-ex-up.sh

            [Install]
            RequiredBy=node-valid-hostname.service
          enabled: true
          name: wait-for-br-ex-up.service
        - contents: |
            [Unit]
            Description=Ensure IKE SA established for existing IPsec connections.
            After=ipsec.service
            Before=kubelet-dependencies.target node-valid-hostname.service

            [Service]
            Type=oneshot
            ExecStart=/usr/local/bin/ipsec-connect-wait.sh
            StandardOutput=journal+console
            StandardError=journal+console

            [Install]
            WantedBy=ipsec.service
          enabled: true
          name: wait-for-ipsec-connect.service
        - contents: |
            [Unit]
            Description=Ensure primary IP is assigned and usable
            Requires=nmstate.service
            After=nmstate.service
            Before=kubelet-dependencies.target

            [Service]
            Type=oneshot
            # Would prefer to do Restart=on-failure instead of this bash retry loop, but
            # the version of systemd we have right now doesn't support it. It should be
            # available in systemd v244 and higher.
            ExecStart=/bin/bash -c " \
              until \
              /usr/local/bin/wait-for-primary-ip.sh; \
              do \
              sleep 10; \
              done"
            StandardOutput=journal+console
            StandardError=journal+console

            [Install]
            WantedBy=network-online.target
          enabled: true
          name: wait-for-primary-ip.service
        - dropins:
          - contents: |
              [Unit]
              ConditionPathExists=/enoent
            name: mco-disabled.conf
          name: zincati.service
        - contents: |
            [Unit]
            Description=Kubernetes Kubelet After Reboot Cleanup
            Before=kubelet.service

            [Service]
            Type=oneshot
            ExecStart=/bin/rm -f /var/lib/kubelet/cpu_manager_state
            ExecStart=/bin/rm -f /var/lib/kubelet/memory_manager_state
            ExecStart=-/bin/rm -f /var/lib/kubelet/dra_manager_state

            [Install]
            WantedBy=multi-user.target
          enabled: true
          name: kubelet-cleanup.service
    extensions: []
    fips: false
    kernelArguments:
    - schedstats=enable
    - systemd.unified_cgroup_hierarchy=1
    - cgroup_no_v1="all"
    - psi=0
    kernelType: default
    osImageURL: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4e309dd906392e783a404b92dfd4fa4c32d74e2804ee37d1fb8a00c9355d5978
- apiVersion: machineconfiguration.openshift.io/v1
  kind: MachineConfigPool
  metadata:
    creationTimestamp: "2025-11-04T16:09:01Z"
    generation: 4
    labels:
      machineconfiguration.openshift.io/mco-built-in: ""
      operator.machineconfiguration.openshift.io/required-for-upgrade: ""
      pools.operator.machineconfiguration.openshift.io/master: ""
    name: master
    resourceVersion: "301718699"
    uid: 94ee58c6-d020-4644-985a-6daad3eb3116
  spec:
    configuration:
      name: rendered-master-75b612782c9b85e89669001a76df78c0
      source:
      - apiVersion: machineconfiguration.openshift.io/v1
        kind: MachineConfig
        name: 00-master
      - apiVersion: machineconfiguration.openshift.io/v1
        kind: MachineConfig
        name: 01-master-container-runtime
      - apiVersion: machineconfiguration.openshift.io/v1
        kind: MachineConfig
        name: 01-master-kubelet
      - apiVersion: machineconfiguration.openshift.io/v1
        kind: MachineConfig
        name: 50-masters-chrony-configuration
      - apiVersion: machineconfiguration.openshift.io/v1
        kind: MachineConfig
        name: 50-masters-enable-schedstats
      - apiVersion: machineconfiguration.openshift.io/v1
        kind: MachineConfig
        name: 97-master-generated-kubelet
      - apiVersion: machineconfiguration.openshift.io/v1
        kind: MachineConfig
        name: 98-master-generated-kubelet
      - apiVersion: machineconfiguration.openshift.io/v1
        kind: MachineConfig
        name: 99-assisted-installer-master-ssh
      - apiVersion: machineconfiguration.openshift.io/v1
        kind: MachineConfig
        name: 99-master-generated-registries
      - apiVersion: machineconfiguration.openshift.io/v1
        kind: MachineConfig
        name: 99-master-idmapd-conf
      - apiVersion: machineconfiguration.openshift.io/v1
        kind: MachineConfig
        name: 99-master-ssh
      - apiVersion: machineconfiguration.openshift.io/v1
        kind: MachineConfig
        name: 99-openshift-machineconfig-master-psi-karg
    machineConfigSelector:
      matchLabels:
        machineconfiguration.openshift.io/role: master
    nodeSelector:
      matchLabels:
        node-role.kubernetes.io/master: ""
    paused: false
  status:
    certExpirys:
    - bundle: KubeAPIServerServingCAData
      expiry: "2035-11-02T15:42:17Z"
      subject: CN=admin-kubeconfig-signer,OU=openshift
    - bundle: KubeAPIServerServingCAData
      expiry: "2026-03-05T10:55:38Z"
      subject: CN=openshift-kube-controller-manager-operator_csr-signer-signer@1767524138
    - bundle: KubeAPIServerServingCAData
      expiry: "2026-02-19T22:55:55Z"
      subject: CN=kube-csr-signer_@1768949754
    - bundle: KubeAPIServerServingCAData
      expiry: "2026-03-08T06:04:06Z"
      subject: CN=kube-csr-signer_@1770357846
    - bundle: KubeAPIServerServingCAData
      expiry: "2026-04-05T18:04:06Z"
      subject: CN=openshift-kube-controller-manager-operator_csr-signer-signer@1770228246
    - bundle: KubeAPIServerServingCAData
      expiry: "2026-11-04T15:42:21Z"
      subject: CN=kube-apiserver-to-kubelet-signer,OU=openshift
    - bundle: KubeAPIServerServingCAData
      expiry: "2026-11-04T15:42:21Z"
      subject: CN=kube-control-plane-signer,OU=openshift
    - bundle: KubeAPIServerServingCAData
      expiry: "2026-04-05T18:02:19Z"
      subject: CN=openshift-kube-apiserver-operator_kube-control-plane-signer@1770228139
    - bundle: KubeAPIServerServingCAData
      expiry: "2026-03-04T15:42:46Z"
      subject: CN=openshift-kube-apiserver-operator_kube-control-plane-signer@1767454966
    - bundle: KubeAPIServerServingCAData
      expiry: "2035-11-02T15:42:18Z"
      subject: CN=kubelet-bootstrap-kubeconfig-signer,OU=openshift
    - bundle: KubeAPIServerServingCAData
      expiry: "2026-11-04T16:08:18Z"
      subject: CN=openshift-kube-apiserver-operator_node-system-admin-signer@1762272498
    conditions:
    - lastTransitionTime: "2025-11-04T16:09:20Z"
      message: ""
      reason: ""
      status: "False"
      type: RenderDegraded
    - lastTransitionTime: "2026-02-07T02:50:27Z"
      message: All nodes are updated with MachineConfig rendered-master-75b612782c9b85e89669001a76df78c0
      reason: ""
      status: "True"
      type: Updated
    - lastTransitionTime: "2026-02-07T02:50:27Z"
      message: ""
      reason: ""
      status: "False"
      type: Updating
    - lastTransitionTime: "2026-02-07T02:50:27Z"
      message: ""
      reason: ""
      status: "False"
      type: NodeDegraded
    - lastTransitionTime: "2026-02-07T02:50:27Z"
      message: ""
      reason: ""
      status: "False"
      type: Degraded
    configuration:
      name: rendered-master-75b612782c9b85e89669001a76df78c0
      source:
      - apiVersion: machineconfiguration.openshift.io/v1
        kind: MachineConfig
        name: 00-master
      - apiVersion: machineconfiguration.openshift.io/v1
        kind: MachineConfig
        name: 01-master-container-runtime
      - apiVersion: machineconfiguration.openshift.io/v1
        kind: MachineConfig
        name: 01-master-kubelet
      - apiVersion: machineconfiguration.openshift.io/v1
        kind: MachineConfig
        name: 50-masters-chrony-configuration
      - apiVersion: machineconfiguration.openshift.io/v1
        kind: MachineConfig
        name: 50-masters-enable-schedstats
      - apiVersion: machineconfiguration.openshift.io/v1
        kind: MachineConfig
        name: 97-master-generated-kubelet
      - apiVersion: machineconfiguration.openshift.io/v1
        kind: MachineConfig
        name: 98-master-generated-kubelet
      - apiVersion: machineconfiguration.openshift.io/v1
        kind: MachineConfig
        name: 99-assisted-installer-master-ssh
      - apiVersion: machineconfiguration.openshift.io/v1
        kind: MachineConfig
        name: 99-master-generated-registries
      - apiVersion: machineconfiguration.openshift.io/v1
        kind: MachineConfig
        name: 99-master-idmapd-conf
      - apiVersion: machineconfiguration.openshift.io/v1
        kind: MachineConfig
        name: 99-master-ssh
      - apiVersion: machineconfiguration.openshift.io/v1
        kind: MachineConfig
        name: 99-openshift-machineconfig-master-psi-karg
    degradedMachineCount: 0
    machineCount: 3
    observedGeneration: 4
    readyMachineCount: 3
    unavailableMachineCount: 0
    updatedMachineCount: 3
- apiVersion: machineconfiguration.openshift.io/v1
  kind: MachineConfigPool
  metadata:
    creationTimestamp: "2025-11-04T16:09:01Z"
    generation: 8
    labels:
      machineconfiguration.openshift.io/mco-built-in: ""
      pools.operator.machineconfiguration.openshift.io/worker: ""
    name: worker
    resourceVersion: "301714610"
    uid: 7ac2da7a-3f0d-4ad8-974e-12dd34c8fded
  spec:
    configuration:
      name: rendered-worker-ab2040a4a9286b39411b0e4c2a09785d
      source:
      - apiVersion: machineconfiguration.openshift.io/v1
        kind: MachineConfig
        name: 00-worker
      - apiVersion: machineconfiguration.openshift.io/v1
        kind: MachineConfig
        name: 01-worker-container-runtime
      - apiVersion: machineconfiguration.openshift.io/v1
        kind: MachineConfig
        name: 01-worker-kubelet
      - apiVersion: machineconfiguration.openshift.io/v1
        kind: MachineConfig
        name: 50-workers-chrony-configuration
      - apiVersion: machineconfiguration.openshift.io/v1
        kind: MachineConfig
        name: 50-workers-enable-schedstats
      - apiVersion: machineconfiguration.openshift.io/v1
        kind: MachineConfig
        name: 97-worker-generated-kubelet
      - apiVersion: machineconfiguration.openshift.io/v1
        kind: MachineConfig
        name: 98-worker-generated-kubelet
      - apiVersion: machineconfiguration.openshift.io/v1
        kind: MachineConfig
        name: 99-openshift-machineconfig-worker-psi-karg
      - apiVersion: machineconfiguration.openshift.io/v1
        kind: MachineConfig
        name: 99-worker-generated-registries
      - apiVersion: machineconfiguration.openshift.io/v1
        kind: MachineConfig
        name: 99-worker-idmapd-conf
      - apiVersion: machineconfiguration.openshift.io/v1
        kind: MachineConfig
        name: 99-worker-ssh
    machineConfigSelector:
      matchLabels:
        machineconfiguration.openshift.io/role: worker
    nodeSelector:
      matchLabels:
        node-role.kubernetes.io/worker: ""
    paused: false
  status:
    certExpirys:
    - bundle: KubeAPIServerServingCAData
      expiry: "2035-11-02T15:42:17Z"
      subject: CN=admin-kubeconfig-signer,OU=openshift
    - bundle: KubeAPIServerServingCAData
      expiry: "2026-03-05T10:55:38Z"
      subject: CN=openshift-kube-controller-manager-operator_csr-signer-signer@1767524138
    - bundle: KubeAPIServerServingCAData
      expiry: "2026-02-19T22:55:55Z"
      subject: CN=kube-csr-signer_@1768949754
    - bundle: KubeAPIServerServingCAData
      expiry: "2026-03-08T06:04:06Z"
      subject: CN=kube-csr-signer_@1770357846
    - bundle: KubeAPIServerServingCAData
      expiry: "2026-04-05T18:04:06Z"
      subject: CN=openshift-kube-controller-manager-operator_csr-signer-signer@1770228246
    - bundle: KubeAPIServerServingCAData
      expiry: "2026-11-04T15:42:21Z"
      subject: CN=kube-apiserver-to-kubelet-signer,OU=openshift
    - bundle: KubeAPIServerServingCAData
      expiry: "2026-11-04T15:42:21Z"
      subject: CN=kube-control-plane-signer,OU=openshift
    - bundle: KubeAPIServerServingCAData
      expiry: "2026-04-05T18:02:19Z"
      subject: CN=openshift-kube-apiserver-operator_kube-control-plane-signer@1770228139
    - bundle: KubeAPIServerServingCAData
      expiry: "2026-03-04T15:42:46Z"
      subject: CN=openshift-kube-apiserver-operator_kube-control-plane-signer@1767454966
    - bundle: KubeAPIServerServingCAData
      expiry: "2035-11-02T15:42:18Z"
      subject: CN=kubelet-bootstrap-kubeconfig-signer,OU=openshift
    - bundle: KubeAPIServerServingCAData
      expiry: "2026-11-04T16:08:18Z"
      subject: CN=openshift-kube-apiserver-operator_node-system-admin-signer@1762272498
    conditions:
    - lastTransitionTime: "2025-11-04T16:09:20Z"
      message: ""
      reason: ""
      status: "False"
      type: RenderDegraded
    - lastTransitionTime: "2026-02-07T02:48:16Z"
      message: All nodes are updated with MachineConfig rendered-worker-ab2040a4a9286b39411b0e4c2a09785d
      reason: ""
      status: "True"
      type: Updated
    - lastTransitionTime: "2026-02-07T02:48:16Z"
      message: ""
      reason: ""
      status: "False"
      type: Updating
    - lastTransitionTime: "2026-02-07T02:48:16Z"
      message: ""
      reason: ""
      status: "False"
      type: NodeDegraded
    - lastTransitionTime: "2026-02-07T02:48:16Z"
      message: ""
      reason: ""
      status: "False"
      type: Degraded
    configuration:
      name: rendered-worker-ab2040a4a9286b39411b0e4c2a09785d
      source:
      - apiVersion: machineconfiguration.openshift.io/v1
        kind: MachineConfig
        name: 00-worker
      - apiVersion: machineconfiguration.openshift.io/v1
        kind: MachineConfig
        name: 01-worker-container-runtime
      - apiVersion: machineconfiguration.openshift.io/v1
        kind: MachineConfig
        name: 01-worker-kubelet
      - apiVersion: machineconfiguration.openshift.io/v1
        kind: MachineConfig
        name: 50-workers-chrony-configuration
      - apiVersion: machineconfiguration.openshift.io/v1
        kind: MachineConfig
        name: 50-workers-enable-schedstats
      - apiVersion: machineconfiguration.openshift.io/v1
        kind: MachineConfig
        name: 97-worker-generated-kubelet
      - apiVersion: machineconfiguration.openshift.io/v1
        kind: MachineConfig
        name: 98-worker-generated-kubelet
      - apiVersion: machineconfiguration.openshift.io/v1
        kind: MachineConfig
        name: 99-openshift-machineconfig-worker-psi-karg
      - apiVersion: machineconfiguration.openshift.io/v1
        kind: MachineConfig
        name: 99-worker-generated-registries
      - apiVersion: machineconfiguration.openshift.io/v1
        kind: MachineConfig
        name: 99-worker-idmapd-conf
      - apiVersion: machineconfiguration.openshift.io/v1
        kind: MachineConfig
        name: 99-worker-ssh
    degradedMachineCount: 0
    machineCount: 3
    observedGeneration: 8
    readyMachineCount: 3
    unavailableMachineCount: 0
    updatedMachineCount: 3
kind: List
metadata:
  resourceVersion: ""
